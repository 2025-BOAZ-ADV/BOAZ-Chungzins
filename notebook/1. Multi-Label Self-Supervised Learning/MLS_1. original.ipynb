{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef6b52e2",
      "metadata": {
        "id": "ef6b52e2"
      },
      "source": [
        "#### 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ugSgMLQYIDpX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugSgMLQYIDpX",
        "outputId": "bfc4b929-7171-4429-fb7e-d65fbb32e3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc03a42",
      "metadata": {
        "id": "9dc03a42"
      },
      "source": [
        "##### 1. Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04d7d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04d7d6f",
        "outputId": "74b32ba8-525f-4d7f-fc2a-5982ec084f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanillahub12\u001b[0m (\u001b[33mboaz_woony-boaz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "\n",
        "# wandb 로그인\n",
        "wandb.login(key=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992382bf",
      "metadata": {
        "id": "992382bf"
      },
      "source": [
        "##### 2. 라이브러리 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5MISAwpScmYt",
      "metadata": {
        "id": "5MISAwpScmYt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ebed6c5",
      "metadata": {
        "id": "8ebed6c5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch import Tensor\n",
        "from torchsummary import summary\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d453e5f",
      "metadata": {
        "id": "2d453e5f"
      },
      "source": [
        "##### 3. 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mSXgKx8GoItj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSXgKx8GoItj",
        "outputId": "63d180e3-66a3-49f8-ab7c-d0a594e25b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/ADV 프로젝트/data/ICBHI/ICBHI_final_database\"\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/ADV 프로젝트/checkpoints\"\n",
        "PICKLE_PATH = \"/content/drive/MyDrive/ADV 프로젝트/pickle\"\n",
        "text = \"/content/drive/MyDrive/ADV 프로젝트/data/ICBHI/ICBHI_challenge_train_test.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecaaf5a1",
      "metadata": {
        "id": "ecaaf5a1"
      },
      "source": [
        "##### 4. Seed 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f4e372",
      "metadata": {
        "id": "c9f4e372"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nydfgBckyPt3",
      "metadata": {
        "id": "nydfgBckyPt3"
      },
      "source": [
        "## 1. Data Load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3fdcf1",
      "metadata": {
        "id": "ce3fdcf1"
      },
      "source": [
        "#### 1.1 Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OhJa9jivcg1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJa9jivcg1k",
        "outputId": "52b76545-a374-4542-e9e8-596a7d1b5f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train :539, Test: 381, Total: 920\n"
          ]
        }
      ],
      "source": [
        "# WAV 파일이 있는 디렉토리 경로\n",
        "data_dir = ROOT\n",
        "txt_dir = ROOT\n",
        "\n",
        "df = pd.read_csv(text, sep='\\t', header=None)\n",
        "\n",
        "# 컬럼 이름 변경\n",
        "df.columns = ['filename', 'set']\n",
        "\n",
        "# train, test split\n",
        "train_df = df[df['set'] == 'train']\n",
        "test_df = df[df['set'] == 'test']\n",
        "\n",
        "# filename list\n",
        "train_list = sorted(train_df['filename'].tolist())\n",
        "test_list = sorted(test_df['filename'].tolist())\n",
        "\n",
        "print(f'Train :{len(train_list)}, Test: {len(test_list)}, Total: {len(train_list) + len(test_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04291977",
      "metadata": {
        "id": "04291977"
      },
      "source": [
        "#### 1.2 Pretext-Finetune Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ESBIVnKej0G9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBIVnKej0G9",
        "outputId": "91f4f11f-f4c6-4145-f8ff-b69818300797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pretrain] 환자 수: 74, 샘플 수: 431\n",
            "[Finetune] 환자 수: 43, 샘플 수: 108\n"
          ]
        }
      ],
      "source": [
        "# shuffle train data\n",
        "df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# split ratio\n",
        "train_size = int(0.8 * len(df_shuffled))\n",
        "\n",
        "# pretrain, finetune split\n",
        "pretrain_df = df_shuffled[:train_size]\n",
        "finetune_df = df_shuffled[train_size:]\n",
        "\n",
        "# filename list (pretext_list -> pretrain list)\n",
        "pretrain_list = sorted(pretrain_df['filename'].tolist())\n",
        "finetune_list = sorted(finetune_df['filename'].tolist())\n",
        "\n",
        "# patient id list\n",
        "pretrain_patient_list = []\n",
        "for filename in pretrain_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    pretrain_patient_list.append(number)\n",
        "\n",
        "finetune_patient_list = []\n",
        "for filename in finetune_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    finetune_patient_list.append(number)\n",
        "\n",
        "pretrain_patient_counts = pd.Series(pretrain_patient_list).value_counts()\n",
        "finetune_patient_counts = pd.Series(finetune_patient_list).value_counts()\n",
        "\n",
        "print(f\"[Pretrain] 환자 수: {len(pretrain_patient_counts.index)}, 샘플 수: {pretrain_patient_counts.sum()}\")\n",
        "print(f\"[Finetune] 환자 수: {len(finetune_patient_counts.index)}, 샘플 수: {finetune_patient_counts.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oVi6lzuPpSbk",
      "metadata": {
        "id": "oVi6lzuPpSbk"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8c7719",
      "metadata": {
        "id": "5e8c7719"
      },
      "source": [
        "#### 2.1 Args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634b232e",
      "metadata": {
        "id": "634b232e"
      },
      "source": [
        "        K: queue size; number of negative keys (default: 65536)\n",
        "        m: moco momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add5c69b",
      "metadata": {
        "id": "add5c69b"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    # Audio & Spectrogram\n",
        "    target_sr = 4000\n",
        "    frame_size = 1024\n",
        "    hop_length = 512    # frame_size 절반\n",
        "    n_mels = 128\n",
        "    target_sec = 8\n",
        "\n",
        "    # Augmentation\n",
        "    time_mask_param = 0.5\n",
        "    freq_mask_param = 0.5\n",
        "\n",
        "    # Train\n",
        "    lr = 0.03\n",
        "    warm = True                     # warm-up 사용 여부\n",
        "    warm_epochs = 10                # warm-up 적용할 초기 epoch 수\n",
        "    warmup_from = lr * 0.1          # warm-up 시작 learning rate (보통 lr의 10%)\n",
        "    warmup_to = lr\n",
        "\n",
        "    batch_size = 128\n",
        "    workers = 4\n",
        "    epochs = 300\n",
        "    weight_decay = 1e-3\n",
        "\n",
        "    resume = None\n",
        "    schedule=[120, 160] # schedule\n",
        "\n",
        "    # MLS\n",
        "    K = 1024\n",
        "    momentum = 0.999\n",
        "    T = 0.07\n",
        "    dim_prj = 128\n",
        "    top_k = 15\n",
        "    lambda_bce = 0.5\n",
        "    out_dim = 512\n",
        "\n",
        "    # Linear Evaluation\n",
        "    ft_epochs = 100\n",
        "\n",
        "    # etc\n",
        "    gpu = 0\n",
        "    data = \"./data_path\"\n",
        "    seed=42\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e1f949",
      "metadata": {
        "id": "58e1f949"
      },
      "source": [
        "#### 2.2 Utils (func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2d1329",
      "metadata": {
        "id": "8d2d1329"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# cycle의 클래스를 추출\n",
        "def get_class(cr, wh):\n",
        "    if cr == 1 and wh == 1:\n",
        "        return 3\n",
        "    elif cr == 0 and wh == 1:\n",
        "        return 2\n",
        "    elif cr == 1 and wh == 0:\n",
        "        return 1\n",
        "    elif cr == 0 and wh == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Mel Spectrogram 생성 ( sr=4KHz, frame_size=1024, hop_length=512, n_mels=128 )\n",
        "def generate_mel_spectrogram(waveform, sample_rate, frame_size, hop_length, n_mels):\n",
        "    if hop_length is None:\n",
        "        hop_length = frame_size // 2\n",
        "    mel_spec_transform = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=frame_size,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "    mel_spectrogram = mel_spec_transform(waveform)\n",
        "    mel_db = T.AmplitudeToDB()(mel_spectrogram)\n",
        "\n",
        "    # scaling\n",
        "    mean = mel_db.mean()\n",
        "    std = mel_db.std() + 1e-6\n",
        "\n",
        "    return (mel_db - mean) / std\n",
        "\n",
        "# Cycle Repeat 또는 Crop\n",
        "def repeat_or_truncate_segment(mel_segment, target_frames):\n",
        "    current_frames = mel_segment.shape[-1]\n",
        "    if current_frames >= target_frames:\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "    else:\n",
        "        repeat_ratio = math.ceil(target_frames / current_frames)\n",
        "        mel_segment = mel_segment.repeat(1, 1, repeat_ratio)\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "\n",
        "def preprocess_waveform_segment(waveform, unit_length):\n",
        "\n",
        "    \"\"\"unit_length 기준으로 waveform을 repeat + padding 또는 crop하여 길이 정규화\"\"\"\n",
        "    waveform = waveform.squeeze(0)  # (1, L) → (L,) 로 바꿔도 무방\n",
        "    length_adj = unit_length - len(waveform)\n",
        "\n",
        "    if length_adj > 0:\n",
        "        # waveform이 너무 짧은 경우 → repeat + zero-padding\n",
        "        half_unit = unit_length // 2\n",
        "\n",
        "        if length_adj < half_unit:\n",
        "            # 길이 차이가 작으면 단순 padding\n",
        "            half_adj = length_adj // 2\n",
        "            waveform = F.pad(waveform, (half_adj, length_adj - half_adj))\n",
        "        else:\n",
        "            # 반복 후 부족한 부분 padding\n",
        "            repeat_factor = unit_length // len(waveform)\n",
        "            waveform = waveform.repeat(repeat_factor)[:unit_length]\n",
        "            remaining = unit_length - len(waveform)\n",
        "            half_pad = remaining // 2\n",
        "            waveform = F.pad(waveform, (half_pad, remaining - half_pad))\n",
        "    else:\n",
        "        # waveform이 너무 길면 앞쪽 1/4 내에서 랜덤 crop\n",
        "        length_adj = len(waveform) - unit_length\n",
        "        start = random.randint(0, length_adj // 4)\n",
        "        waveform = waveform[start:start + unit_length]\n",
        "\n",
        "    return waveform.unsqueeze(0)  # 다시 (1, L)로\n",
        "\n",
        "# 데이터 Spec Augmentation ( 0~80% Random Masking )\n",
        "def apply_spec_augment(mel_segment):\n",
        "\n",
        "    M = mel_segment.shape[-1]\n",
        "    F = mel_segment.shape[-2]\n",
        "\n",
        "    # torchaudio의 마스킹은 0부터 mask_param까지 균등분포에서 랜덤하게 길이를 선택\n",
        "    time_masking = T.TimeMasking(time_mask_param=int(M * 0.8))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=int(F * 0.8) )\n",
        "\n",
        "    aug1 = freq_masking(mel_segment.clone())\n",
        "    aug2 = time_masking(mel_segment.clone())\n",
        "    aug3 = freq_masking(time_masking(mel_segment.clone()))\n",
        "\n",
        "    return aug1, aug2, aug3\n",
        "\n",
        "# Waveform resample\n",
        "def resample_waveform(waveform, orig_sr, target_sr=args.target_sr):\n",
        "    if orig_sr != target_sr:\n",
        "        resampler = torchaudio.transforms.Resample(\n",
        "            orig_freq=orig_sr,\n",
        "            new_freq=target_sr\n",
        "        )\n",
        "        return resampler(waveform), target_sr\n",
        "    return waveform, orig_sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70af5e6b",
      "metadata": {
        "id": "70af5e6b"
      },
      "outputs": [],
      "source": [
        "##############################################\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# -------------------- Augmentation functions (ICBHI 멜스펙트로그램에 최적화) --------------------\n",
        "\n",
        "def spec_augment(mel, time_mask_ratio=0.15, freq_mask_ratio=0.15):\n",
        "    \"\"\"\n",
        "    SpecAugment: 시간/주파수 영역 마스킹\n",
        "    - 시간축 마스킹: 63 * 0.15 ≈ 9 프레임\n",
        "    - 주파수 마스킹: 128 * 0.1 ≈ 12 채널\n",
        "    \"\"\"\n",
        "    M = mel.shape[-1]  # 시간 축\n",
        "    F = mel.shape[-2]  # 주파수 축\n",
        "\n",
        "    time_masking = T.TimeMasking(time_mask_param=max(1, int(M * time_mask_ratio)))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=max(1, int(F * freq_mask_ratio)))\n",
        "\n",
        "    mel = freq_masking(mel.clone())\n",
        "    mel = time_masking(mel)\n",
        "    return mel\n",
        "\n",
        "def add_noise(mel, noise_level=0.001):\n",
        "    \"\"\"\n",
        "    노이즈 추가: 적당한 수준의 표준 정규분포 노이즈 (너무 높으면 손실 커짐)\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(mel) * noise_level\n",
        "    return mel + noise\n",
        "\n",
        "def pitch_shift(mel, n_steps=2):\n",
        "    \"\"\"\n",
        "    주파수 축 순환 이동 (mel axis). shape은 그대로 유지됨.\n",
        "    n_steps=2면 ±2 멜 채널만 이동.\n",
        "    \"\"\"\n",
        "    shift = random.randint(-n_steps, n_steps)\n",
        "    if shift == 0:\n",
        "        return mel\n",
        "    if shift > 0:\n",
        "        mel = torch.cat([mel[:, :, shift:, :], mel[:, :, :shift, :]], dim=2)\n",
        "    else:\n",
        "        shift = abs(shift)\n",
        "        mel = torch.cat([mel[:, :, -shift:, :], mel[:, :, :-shift, :]], dim=2)\n",
        "    return mel\n",
        "\n",
        "def time_stretch(mel, min_rate=0.95, max_rate=1.05):\n",
        "    \"\"\"\n",
        "    시간 축 길이 조절. 너무 심하지 않게 ±5% 범위로만 조정.\n",
        "    - shape 유지 위해 interpolation 후 crop/pad\n",
        "    \"\"\"\n",
        "    rate = random.uniform(min_rate, max_rate)\n",
        "    if rate == 1.0:\n",
        "        return mel\n",
        "\n",
        "    orig_size = mel.shape[-1]\n",
        "    target_size = int(orig_size * rate)\n",
        "\n",
        "    mel_stretched = F.interpolate(\n",
        "        mel, size=(mel.shape[-2], target_size),  # (mel_bins, time)\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    if target_size > orig_size:\n",
        "        return mel_stretched[..., :orig_size]\n",
        "    else:\n",
        "        pad = orig_size - target_size\n",
        "        return F.pad(mel_stretched, (0, pad))\n",
        "\n",
        "# -------------------- Dispatcher --------------------\n",
        "\n",
        "AUGMENTATION_FUNCTIONS_TORCH = {\n",
        "    \"spec_augment\": spec_augment,\n",
        "    \"add_noise\": add_noise,\n",
        "    \"pitch_shift\": pitch_shift,\n",
        "    \"time_stretch\": time_stretch\n",
        "}\n",
        "\n",
        "def apply_augmentations_torch(x, methods=[], **kwargs):\n",
        "    for method in methods:\n",
        "        func = AUGMENTATION_FUNCTIONS_TORCH.get(method)\n",
        "        if func is None:\n",
        "            raise ValueError(f\"Unknown augmentation: {method}\")\n",
        "        x = func(x, **kwargs.get(method, {}))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a62aa74",
      "metadata": {
        "id": "4a62aa74"
      },
      "outputs": [],
      "source": [
        "def aug(repeat_mel):\n",
        "    # 먼저 복사본 준비\n",
        "    mel1 = repeat_mel.clone()\n",
        "    mel2 = repeat_mel.clone()\n",
        "\n",
        "    # 각각 다른 증강 A, B 적용\n",
        "    aug1 = apply_augmentations_torch(mel1, methods=[\"add_noise\"], add_noise={\"noise_level\": 0.005})\n",
        "    aug2 = apply_augmentations_torch(mel2, methods=[\"time_stretch\"], time_stretch={\"min_rate\": 0.8, \"max_rate\": 1.2})\n",
        "    # aug3 = apply_augmentations_torch(mel3, methods=[\"pitch_shift\"], pitch_shift={\"n_steps\": 2})\n",
        "\n",
        "    # # 각 결과에 spec_augment 추가 적용\n",
        "    aug1_spec = spec_augment(aug1, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "    aug2_spec = spec_augment(aug2, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "    # aug3_spec = spec_augment(aug3, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "\n",
        "    return aug1_spec, aug2_spec, None\n",
        "\n",
        "\n",
        "def get_timestamp():\n",
        "    \"\"\"Outputs current time in KST like 2404070830\"\"\"\n",
        "    kst_time = datetime.now(ZoneInfo(\"Asia/Seoul\"))\n",
        "    return kst_time.strftime('%y%m%d%H%M')\n",
        "\n",
        "# Origin\n",
        "# def aug(repeat_mel):\n",
        "#     aug1, aug2, aug3 = apply_spec_augment(repeat_mel)\n",
        "#     return aug1, aug2, aug3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e684cb",
      "metadata": {
        "id": "39e684cb"
      },
      "source": [
        "#### 2.3 CycleDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1642a79a",
      "metadata": {
        "id": "1642a79a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CycleDataset(Dataset):\n",
        "    def __init__(self, filename_list, wav_dir, txt_dir, target_sec=args.target_sec, target_sr=args.target_sr, frame_size=args.frame_size, hop_length=args.hop_length, n_mels=args.n_mels):\n",
        "        self.filename_list = filename_list\n",
        "        self.wav_dir = wav_dir\n",
        "        self.txt_dir = txt_dir\n",
        "        self.target_sec = target_sec\n",
        "        self.target_sr = target_sr\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "\n",
        "        self.cycle_list = []\n",
        "\n",
        "        print(\"[INFO] Preprocessing cycles...\")\n",
        "        for filename in tqdm(self.filename_list):\n",
        "            txt_path = os.path.join(self.txt_dir, filename + '.txt')\n",
        "            wav_path = os.path.join(self.wav_dir, filename + '.wav')\n",
        "\n",
        "            if not os.path.exists(txt_path):\n",
        "                print(f\"[WARNING] Missing file: {txt_path}\")\n",
        "            if not os.path.exists(wav_path):\n",
        "                print(f\"[WARNING] Missing file: {wav_path}\")\n",
        "\n",
        "            # Load annotation\n",
        "            cycle_data = np.loadtxt(txt_path, usecols=(0, 1))\n",
        "            lung_label = np.loadtxt(txt_path, usecols=(2, 3))\n",
        "\n",
        "            # Load waveform\n",
        "            waveform, orig_sr = torchaudio.load(wav_path)\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)  # Stereo to mono\n",
        "\n",
        "            # Resample to target sample rate (4kHz)\n",
        "            waveform, sample_rate = resample_waveform(waveform, orig_sr, self.target_sr)\n",
        "\n",
        "            for idx in range(len(cycle_data)):\n",
        "                # 호흡 주기 start, end\n",
        "                start_sample = int(cycle_data[idx, 0] * sample_rate)\n",
        "                end_sample = int(cycle_data[idx, 1] * sample_rate)\n",
        "                lung_duration = cycle_data[idx, 1] - cycle_data[idx, 0]\n",
        "\n",
        "                if end_sample <= start_sample:\n",
        "                    continue  # 잘못된 구간 스킵\n",
        "\n",
        "                # Waveform repeat + padding 후 Mel_db\n",
        "                cycle_wave = waveform[:, start_sample:end_sample]\n",
        "                normed_wave = preprocess_waveform_segment(cycle_wave, unit_length=int(self.target_sec * self.target_sr))\n",
        "                mel = generate_mel_spectrogram(normed_wave, sample_rate, frame_size=self.frame_size, hop_length=self.hop_length, n_mels=self.n_mels)\n",
        "\n",
        "                # crackle, wheeze -> class\n",
        "                cr = int(lung_label[idx, 0])\n",
        "                wh = int(lung_label[idx, 1])\n",
        "                label = get_class(cr, wh)\n",
        "\n",
        "                multi_label = torch.tensor([\n",
        "                    float(label in [1, 3]),\n",
        "                    float(label in [2, 3])\n",
        "                ])  # 변환된 multi-label 반환\n",
        "\n",
        "                # meta_data\n",
        "                meta_data = (filename, lung_duration)\n",
        "\n",
        "                self.cycle_list.append((mel, multi_label, meta_data))\n",
        "\n",
        "        print(f\"[INFO] Total cycles collected: {len(self.cycle_list)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cycle_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel, label, meta_data = self.cycle_list[idx]\n",
        "        return mel, label, meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d5a070",
      "metadata": {
        "id": "55d5a070"
      },
      "source": [
        "##### Pickle.dump"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752088df",
      "metadata": {
        "id": "752088df"
      },
      "source": [
        "CycleDataset 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d386e82",
      "metadata": {
        "id": "9d386e82"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import matplotlib.pyplot as plt\n",
        "# import librosa.display\n",
        "\n",
        "# wav_dir = ROOT\n",
        "# txt_dir = ROOT\n",
        "\n",
        "# # 1. Dataset 로드\n",
        "# train_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# test_dataset = CycleDataset(test_list, wav_dir, txt_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BQgVyGnrDbN",
      "metadata": {
        "id": "4BQgVyGnrDbN"
      },
      "source": [
        "pickle로 train_dataset, test_dataset 외부 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a273735",
      "metadata": {
        "id": "7a273735"
      },
      "outputs": [],
      "source": [
        "pickle_name = f'MLS_{args.target_sr//1000}kHz_{args.frame_size}win_{args.hop_length}hop_{args.n_mels}mel_{args.target_sec}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd34caa0",
      "metadata": {
        "id": "cd34caa0"
      },
      "outputs": [],
      "source": [
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset\n",
        "# }\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, pickle_name + '.pkl')\n",
        "# with open(save_path, 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zRqSwthYTtxq",
      "metadata": {
        "id": "zRqSwthYTtxq"
      },
      "outputs": [],
      "source": [
        "# # 2. 간단 통계\n",
        "# print(f\"Total cycles: {len(train_dataset)}\")\n",
        "\n",
        "# label_counter = [0] * 4  # normal, crackle, wheeze, both\n",
        "# for _, multi_label,_ in train_dataset:\n",
        "#     if torch.equal(multi_label, torch.tensor([0., 0.])):\n",
        "#         label_counter[0] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 0.])):\n",
        "#         label_counter[1] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([0., 1.])):\n",
        "#         label_counter[2] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 1.])):\n",
        "#         label_counter[3] += 1\n",
        "\n",
        "# for idx, count in enumerate(label_counter):\n",
        "#     print(f\"Class {idx}: {count} cycles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yJPtbC3BrqAE",
      "metadata": {
        "id": "yJPtbC3BrqAE"
      },
      "source": [
        "##### Pickle.load\n",
        "저장된 train_dataset, test_dataset을 로드  \n",
        "(> Aug 는 Moco 모델에서 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EWrjdCFSrmER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWrjdCFSrmER",
        "outputId": "6b437dce-f371-4bbc-c198-643ab1dc1c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Train] Cycles: 4142\n",
            "[Test] Cycles: 2756\n"
          ]
        }
      ],
      "source": [
        "save_path = os.path.join(PICKLE_PATH, pickle_name + '.pkl')\n",
        "with open(save_path, 'rb') as f:\n",
        "    pickle_dict = pickle.load(f)\n",
        "\n",
        "train_dataset = pickle_dict['train_dataset']\n",
        "test_dataset = pickle_dict['test_dataset']\n",
        "\n",
        "print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "print(f\"[Test] Cycles: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcca3481",
      "metadata": {
        "id": "bcca3481"
      },
      "source": [
        "#### 2.4 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f19b4a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f19b4a7",
        "outputId": "933e3a6c-0f75-4610-b9dc-385eaf937da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrain set size: 3257, Finetune set size: 885\n"
          ]
        }
      ],
      "source": [
        "# ---------------- 학습 데이터 구성(seed) ----------------\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# train_dataset 내에서 각 파일의 인덱스를 추출\n",
        "pretrain_idx = []\n",
        "finetune_idx = []\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "    filename = train_dataset[i][2][0]\n",
        "\n",
        "    if filename in pretrain_list:\n",
        "        pretrain_idx.append(i)\n",
        "    elif filename in finetune_list:\n",
        "        finetune_idx.append(i)\n",
        "\n",
        "# 인덱스 순서 셔플\n",
        "random.shuffle(pretrain_idx)\n",
        "random.shuffle(finetune_idx)\n",
        "\n",
        "print(f\"Pretrain set size: {len(pretrain_idx)}, Finetune set size: {len(finetune_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce2c3c8",
      "metadata": {
        "id": "cce2c3c8"
      },
      "source": [
        "코드 실행 환경에 따라 num_workers를 적절한 값으로 지정해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432ae0cd",
      "metadata": {
        "id": "432ae0cd"
      },
      "outputs": [],
      "source": [
        "# Dataset 생성 (Subset)\n",
        "pretrain_dataset = Subset(train_dataset, pretrain_idx)\n",
        "finetune_dataset = Subset(train_dataset, finetune_idx)\n",
        "\n",
        "# DataLoader 생성\n",
        "pretrain_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "finetune_loader = DataLoader(\n",
        "    finetune_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8iNQDqY0Su9h",
      "metadata": {
        "id": "8iNQDqY0Su9h"
      },
      "outputs": [],
      "source": [
        "seed_everything(42)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=4,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b492ad67",
      "metadata": {
        "id": "b492ad67"
      },
      "source": [
        "label 분포 확인 (단순 참고용, 실제 환경에서는 pretrain set의 label 분포가 어떤지 알 수 없음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea9d290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea9d290",
        "outputId": "7c7940fe-2d7c-4085-9cb9-3a43d1ec925e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrain sample: 3257\n",
            "Pretrain label distribution: Counter({0: 1607, 1: 953, 2: 417, 3: 280})\n",
            "\n",
            "Finetune sample: 885\n",
            "Finetune label distribution: Counter({0: 456, 1: 262, 2: 84, 3: 83})\n",
            "Test sample: 2756\n",
            "Test label distribution: Counter({0: 1579, 1: 649, 2: 385, 3: 143})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# label\n",
        "labels = torch.stack([multi_label for _, multi_label, _ in train_dataset])\n",
        "\n",
        "# pretext와 finetune 데이터셋의 라벨 분포 출력\n",
        "pretrain_labels = labels[pretrain_idx]\n",
        "pretrain_labels_class = (\n",
        "    pretrain_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    pretrain_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "finetune_labels = labels[finetune_idx]\n",
        "finetune_labels_class = (\n",
        "    finetune_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    finetune_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "# test 데이터셋의 라벨 분포 출력\n",
        "test_labels = torch.stack([multi_label for _, multi_label, _ in test_dataset])\n",
        "test_labels_class = (\n",
        "    test_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    test_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "print(f\"Pretrain sample: {len(pretrain_labels_class)}\")\n",
        "print(\"Pretrain label distribution:\", Counter(pretrain_labels_class.tolist()))\n",
        "print(f\"\\nFinetune sample: {len(finetune_labels_class)}\")\n",
        "print(\"Finetune label distribution:\", Counter(finetune_labels_class.tolist()))\n",
        "print(f\"\\nTest sample: {len(test_labels_class)}\")\n",
        "print(\"Test label distribution:\", Counter(test_labels_class.tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed559ff1",
      "metadata": {
        "id": "ed559ff1"
      },
      "source": [
        "## 3. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca710799",
      "metadata": {
        "id": "ca710799"
      },
      "source": [
        "#### 3.1 Pre-trained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2caf4a6c",
      "metadata": {
        "id": "2caf4a6c"
      },
      "outputs": [],
      "source": [
        "def backbone_resnet():\n",
        "    # 1. 기본 ResNet50 생성 (pretrained=False로 시작)\n",
        "    resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "    # 2. 첫 번째 conv 레이어를 1채널용으로 수정\n",
        "    resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # 먼저 fc 제거\n",
        "    resnet.fc = nn.Identity()\n",
        "\n",
        "    # 3. ImageNet 가중치 로드 (conv1 제외)\n",
        "    state_dict = load_state_dict_from_url(\n",
        "        'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "        progress=True\n",
        "    )\n",
        "    if 'conv1.weight' in state_dict:\n",
        "        del state_dict['conv1.weight']\n",
        "    resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    return resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SbHFZiQNQaBB",
      "metadata": {
        "id": "SbHFZiQNQaBB"
      },
      "source": [
        "ResNet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i9H1NPXgQVKV",
      "metadata": {
        "id": "i9H1NPXgQVKV"
      },
      "outputs": [],
      "source": [
        "# from torchvision import models\n",
        "# from torch.hub import load_state_dict_from_url\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def backbone_resnet():\n",
        "#     # 1. 기본 ResNet34 생성\n",
        "#     resnet = models.resnet34(pretrained=False)\n",
        "\n",
        "#     # 2. 첫 번째 conv 레이어를 1채널용으로 수정\n",
        "#     resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "#     # fc 제거\n",
        "#     resnet.fc = nn.Identity()\n",
        "\n",
        "#     # 3. ImageNet 가중치 로드 (conv1 제외)\n",
        "#     state_dict = load_state_dict_from_url(\n",
        "#         'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "#         progress=True\n",
        "#     )\n",
        "#     if 'conv1.weight' in state_dict:\n",
        "#         del state_dict['conv1.weight']\n",
        "#     resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "#     return resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7EFbqsBSk9E",
      "metadata": {
        "id": "K7EFbqsBSk9E"
      },
      "source": [
        "ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KQtvFgzaSjTO",
      "metadata": {
        "id": "KQtvFgzaSjTO"
      },
      "outputs": [],
      "source": [
        "# from torchvision import models\n",
        "# from torch.hub import load_state_dict_from_url\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def backbone_resnet():\n",
        "#     # 1. 기본 ResNet18 생성\n",
        "#     resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "#     # 2. 첫 번째 conv 레이어를 1채널용으로 수정\n",
        "#     resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "#     # fc 제거\n",
        "#     resnet.fc = nn.Identity()\n",
        "\n",
        "#     # 3. ImageNet 가중치 로드 (conv1 제외)\n",
        "#     state_dict = load_state_dict_from_url(\n",
        "#         'https://download.pytorch.org/models/resnet18-f37072fd.pth',\n",
        "#         progress=True\n",
        "#     )\n",
        "#     if 'conv1.weight' in state_dict:\n",
        "#         del state_dict['conv1.weight']\n",
        "#     resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "#     return resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f21daa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f21daa",
        "outputId": "08fc745f-c109-4d85-cbe4-4e55638aca18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 112, 32]           3,136\n",
            "       BatchNorm2d-2          [-1, 64, 112, 32]             128\n",
            "              ReLU-3          [-1, 64, 112, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 16]               0\n",
            "            Conv2d-5           [-1, 64, 56, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 16]             128\n",
            "              ReLU-7           [-1, 64, 56, 16]               0\n",
            "            Conv2d-8           [-1, 64, 56, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 16]             128\n",
            "             ReLU-10           [-1, 64, 56, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 16]               0\n",
            "           Conv2d-12           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 16]             128\n",
            "             ReLU-14           [-1, 64, 56, 16]               0\n",
            "           Conv2d-15           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 16]             128\n",
            "             ReLU-17           [-1, 64, 56, 16]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 16]               0\n",
            "           Conv2d-19           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-20           [-1, 64, 56, 16]             128\n",
            "             ReLU-21           [-1, 64, 56, 16]               0\n",
            "           Conv2d-22           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-23           [-1, 64, 56, 16]             128\n",
            "             ReLU-24           [-1, 64, 56, 16]               0\n",
            "       BasicBlock-25           [-1, 64, 56, 16]               0\n",
            "           Conv2d-26           [-1, 128, 28, 8]          73,728\n",
            "      BatchNorm2d-27           [-1, 128, 28, 8]             256\n",
            "             ReLU-28           [-1, 128, 28, 8]               0\n",
            "           Conv2d-29           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-30           [-1, 128, 28, 8]             256\n",
            "           Conv2d-31           [-1, 128, 28, 8]           8,192\n",
            "      BatchNorm2d-32           [-1, 128, 28, 8]             256\n",
            "             ReLU-33           [-1, 128, 28, 8]               0\n",
            "       BasicBlock-34           [-1, 128, 28, 8]               0\n",
            "           Conv2d-35           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-36           [-1, 128, 28, 8]             256\n",
            "             ReLU-37           [-1, 128, 28, 8]               0\n",
            "           Conv2d-38           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-39           [-1, 128, 28, 8]             256\n",
            "             ReLU-40           [-1, 128, 28, 8]               0\n",
            "       BasicBlock-41           [-1, 128, 28, 8]               0\n",
            "           Conv2d-42           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-43           [-1, 128, 28, 8]             256\n",
            "             ReLU-44           [-1, 128, 28, 8]               0\n",
            "           Conv2d-45           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-46           [-1, 128, 28, 8]             256\n",
            "             ReLU-47           [-1, 128, 28, 8]               0\n",
            "       BasicBlock-48           [-1, 128, 28, 8]               0\n",
            "           Conv2d-49           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-50           [-1, 128, 28, 8]             256\n",
            "             ReLU-51           [-1, 128, 28, 8]               0\n",
            "           Conv2d-52           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-53           [-1, 128, 28, 8]             256\n",
            "             ReLU-54           [-1, 128, 28, 8]               0\n",
            "       BasicBlock-55           [-1, 128, 28, 8]               0\n",
            "           Conv2d-56           [-1, 256, 14, 4]         294,912\n",
            "      BatchNorm2d-57           [-1, 256, 14, 4]             512\n",
            "             ReLU-58           [-1, 256, 14, 4]               0\n",
            "           Conv2d-59           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-60           [-1, 256, 14, 4]             512\n",
            "           Conv2d-61           [-1, 256, 14, 4]          32,768\n",
            "      BatchNorm2d-62           [-1, 256, 14, 4]             512\n",
            "             ReLU-63           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-64           [-1, 256, 14, 4]               0\n",
            "           Conv2d-65           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-66           [-1, 256, 14, 4]             512\n",
            "             ReLU-67           [-1, 256, 14, 4]               0\n",
            "           Conv2d-68           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-69           [-1, 256, 14, 4]             512\n",
            "             ReLU-70           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-71           [-1, 256, 14, 4]               0\n",
            "           Conv2d-72           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-73           [-1, 256, 14, 4]             512\n",
            "             ReLU-74           [-1, 256, 14, 4]               0\n",
            "           Conv2d-75           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-76           [-1, 256, 14, 4]             512\n",
            "             ReLU-77           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-78           [-1, 256, 14, 4]               0\n",
            "           Conv2d-79           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-80           [-1, 256, 14, 4]             512\n",
            "             ReLU-81           [-1, 256, 14, 4]               0\n",
            "           Conv2d-82           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-83           [-1, 256, 14, 4]             512\n",
            "             ReLU-84           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-85           [-1, 256, 14, 4]               0\n",
            "           Conv2d-86           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-87           [-1, 256, 14, 4]             512\n",
            "             ReLU-88           [-1, 256, 14, 4]               0\n",
            "           Conv2d-89           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-90           [-1, 256, 14, 4]             512\n",
            "             ReLU-91           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-92           [-1, 256, 14, 4]               0\n",
            "           Conv2d-93           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-94           [-1, 256, 14, 4]             512\n",
            "             ReLU-95           [-1, 256, 14, 4]               0\n",
            "           Conv2d-96           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-97           [-1, 256, 14, 4]             512\n",
            "             ReLU-98           [-1, 256, 14, 4]               0\n",
            "       BasicBlock-99           [-1, 256, 14, 4]               0\n",
            "          Conv2d-100            [-1, 512, 7, 2]       1,179,648\n",
            "     BatchNorm2d-101            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-102            [-1, 512, 7, 2]               0\n",
            "          Conv2d-103            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-104            [-1, 512, 7, 2]           1,024\n",
            "          Conv2d-105            [-1, 512, 7, 2]         131,072\n",
            "     BatchNorm2d-106            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-107            [-1, 512, 7, 2]               0\n",
            "      BasicBlock-108            [-1, 512, 7, 2]               0\n",
            "          Conv2d-109            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-110            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-111            [-1, 512, 7, 2]               0\n",
            "          Conv2d-112            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-114            [-1, 512, 7, 2]               0\n",
            "      BasicBlock-115            [-1, 512, 7, 2]               0\n",
            "          Conv2d-116            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-117            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-118            [-1, 512, 7, 2]               0\n",
            "          Conv2d-119            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-121            [-1, 512, 7, 2]               0\n",
            "      BasicBlock-122            [-1, 512, 7, 2]               0\n",
            "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "        Identity-124                  [-1, 512]               0\n",
            "================================================================\n",
            "Total params: 21,278,400\n",
            "Trainable params: 21,278,400\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 27.52\n",
            "Params size (MB): 81.17\n",
            "Estimated Total Size (MB): 108.74\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# summary 함수 사용: (채널, 높이, 너비) 크기를 지정\n",
        "summary(backbone_resnet().to(device), input_size=(1, 224, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "drRVCaSiYo8i",
      "metadata": {
        "id": "drRVCaSiYo8i"
      },
      "source": [
        "#### 3.1 Other Bacbones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZXV5zCCSfnBg",
      "metadata": {
        "id": "ZXV5zCCSfnBg"
      },
      "source": [
        "DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o0Scakd0Ysge",
      "metadata": {
        "id": "o0Scakd0Ysge"
      },
      "outputs": [],
      "source": [
        "def backbone_densenet121():\n",
        "    # 1. DenseNet121 구조만 (pretrained=False)\n",
        "    densenet = models.densenet121(pretrained=False)\n",
        "\n",
        "    # 2. 첫번째 conv 레이어를 1채널로 교체\n",
        "    old_conv = densenet.features.conv0\n",
        "    new_conv = nn.Conv2d(\n",
        "        1, old_conv.out_channels,\n",
        "        kernel_size=old_conv.kernel_size,\n",
        "        stride=old_conv.stride,\n",
        "        padding=old_conv.padding,\n",
        "        bias=(old_conv.bias is not None)\n",
        "    )\n",
        "    densenet.features.conv0 = new_conv\n",
        "\n",
        "    # 3. ImageNet 가중치 불러오기 (conv0 제외)\n",
        "    state_dict = load_state_dict_from_url(\n",
        "        'https://download.pytorch.org/models/densenet121-a639ec97.pth', progress=True\n",
        "    )\n",
        "    # conv0 (features.conv0.weight) 삭제\n",
        "    if 'features.conv0.weight' in state_dict:\n",
        "        del state_dict['features.conv0.weight']\n",
        "    densenet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    densenet.classifier = nn.Identity()\n",
        "\n",
        "    return densenet\n",
        "\n",
        "def backbone_densenet161():\n",
        "    # 1. DenseNet161 구조만 (pretrained=False)\n",
        "    densenet = models.densenet161(pretrained=False)\n",
        "\n",
        "    # 2. 첫번째 conv 레이어를 1채널로 교체\n",
        "    old_conv = densenet.features.conv0\n",
        "    new_conv = nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=old_conv.out_channels,\n",
        "        kernel_size=old_conv.kernel_size,\n",
        "        stride=old_conv.stride,\n",
        "        padding=old_conv.padding,\n",
        "        bias=(old_conv.bias is not None)\n",
        "    )\n",
        "    densenet.features.conv0 = new_conv\n",
        "\n",
        "    # 3. ImageNet 가중치 불러오기 (conv0 제외)\n",
        "    state_dict = load_state_dict_from_url(\n",
        "        'https://download.pytorch.org/models/densenet161-8d451a50.pth', progress=True\n",
        "    )\n",
        "    if 'features.conv0.weight' in state_dict:\n",
        "        del state_dict['features.conv0.weight']\n",
        "    densenet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    # 4. classifier 제거\n",
        "    densenet.classifier = nn.Identity()\n",
        "\n",
        "    return densenet\n",
        "\n",
        "def backbone_densenet201():\n",
        "    # 1. DenseNet201 구조만 (pretrained=False)\n",
        "    densenet = models.densenet201(pretrained=False)\n",
        "\n",
        "    # 2. 첫번째 conv 레이어를 1채널로 교체\n",
        "    old_conv = densenet.features.conv0\n",
        "    new_conv = nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=old_conv.out_channels,\n",
        "        kernel_size=old_conv.kernel_size,\n",
        "        stride=old_conv.stride,\n",
        "        padding=old_conv.padding,\n",
        "        bias=(old_conv.bias is not None)\n",
        "    )\n",
        "    densenet.features.conv0 = new_conv\n",
        "\n",
        "    # 3. ImageNet 가중치 불러오기 (conv0 제외)\n",
        "    state_dict = load_state_dict_from_url(\n",
        "        'https://download.pytorch.org/models/densenet201-c1103571.pth', progress=True\n",
        "    )\n",
        "    if 'features.conv0.weight' in state_dict:\n",
        "        del state_dict['features.conv0.weight']\n",
        "    densenet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    # 4. classifier 제거\n",
        "    densenet.classifier = nn.Identity()\n",
        "\n",
        "    return densenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X9NtN9RnaYpt",
      "metadata": {
        "id": "X9NtN9RnaYpt"
      },
      "outputs": [],
      "source": [
        "# !pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-tJVzKM2ZLJy",
      "metadata": {
        "id": "-tJVzKM2ZLJy"
      },
      "outputs": [],
      "source": [
        "# from torchinfo import summary\n",
        "\n",
        "# model = backbone_densenet121().to(device)\n",
        "# summary(model, input_size=(1, 1, 224, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0305c74",
      "metadata": {
        "id": "e0305c74"
      },
      "source": [
        "#### 3.2 MoCo (MLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ska5GunlcKzI",
      "metadata": {
        "id": "ska5GunlcKzI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# K: queue_g의 크기\n",
        "# dim_enc: projector 통과 전, g1,g2 벡터의 차원\n",
        "# dim_prj: projector 통과 후, z1,z2 벡터의 차원\n",
        "class MoCo(nn.Module):\n",
        "    def __init__(self, base_encoder, dim_enc=args.out_dim, dim_prj=128, K=512, m=0.999, T=0.07, top_k=10, lambda_bce=0.5):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "        self.top_k = top_k\n",
        "        self.lambda_bce = lambda_bce\n",
        "\n",
        "        self.encoder_q = base_encoder()\n",
        "        self.encoder_k = base_encoder()\n",
        "\n",
        "        dim_enc = dim_enc\n",
        "        self.proj_head_q = nn.Sequential(\n",
        "            nn.Linear(dim_enc, dim_enc),\n",
        "            nn.BatchNorm1d(dim_enc),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_enc, dim_prj)\n",
        "        )\n",
        "        self.proj_head_k = nn.Sequential(\n",
        "            nn.Linear(dim_enc, dim_enc),\n",
        "            nn.BatchNorm1d(dim_enc),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_enc, dim_prj)\n",
        "        )\n",
        "\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False\n",
        "\n",
        "        self.register_buffer(\"queue_g\", F.normalize(torch.randn(dim_enc, K), dim=0))      # g2를 정규화한 후 열 단위로 Qg에 저장\n",
        "        self.register_buffer(\"queue_z\", F.normalize(torch.randn(dim_prj, K), dim=0))      # z2를 정규화한 후 열 단위로 Qz에 저장\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))               # 현재 queue에 새로 쓸 위치(인덱스)를 추적하는 포인터 역할\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, g2, z2):\n",
        "        batch_size = g2.shape[0]\n",
        "        ptr = int(self.queue_ptr)\n",
        "        assert self.K % batch_size == 0\n",
        "        self.queue_g[:, ptr:ptr+batch_size] = g2.T.detach()\n",
        "        self.queue_z[:, ptr:ptr+batch_size] = z2.T.detach()\n",
        "        self.queue_ptr[0] = (ptr + batch_size) % self.K\n",
        "\n",
        "    def forward(self, im_q, im_k, epoch=None, warmup_epochs=10):\n",
        "        # encoder_q → g1 (feature)\n",
        "        g1 = F.normalize(self.encoder_q(im_q), dim=1)  # shape: [B, 2048]\n",
        "\n",
        "        # projection head → z1\n",
        "        z1 = F.normalize(self.proj_head_q(g1), dim=1)  # shape: [B, 128]\n",
        "\n",
        "        # encoder k\n",
        "        with torch.no_grad():\n",
        "            self._momentum_update_key_encoder()\n",
        "            g2 = F.normalize(self.encoder_k(im_k), dim=1)\n",
        "            z2 = F.normalize(self.proj_head_k(g2), dim=1)\n",
        "\n",
        "        # top-k mining\n",
        "        sim_g = torch.matmul(g1, self.queue_g.clone().detach())  # [N, K]\n",
        "        # Ablation(1-1) Hard top-k\n",
        "        topk_idx = torch.topk(sim_g, self.top_k, dim=1).indices\n",
        "        y = torch.zeros_like(sim_g)\n",
        "        y.scatter_(1, topk_idx, 1.0)\n",
        "        # # Ablation(1-2) Soft top-k\n",
        "        # topk_sim, topk_idx = torch.topk(sim_g, self.top_k, dim=1)\n",
        "        # y = torch.zeros_like(sim_g)\n",
        "        # y.scatter_(1, topk_idx, F.softmax(topk_sim / self.T, dim=1))\n",
        "\n",
        "        ##################################################################\n",
        "        # logits from z1 · Qz\n",
        "        sim_z = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        # Ablation(2-1) BCE Loss\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y) # 개선-> sigmoid(sim_z), 1/D\n",
        "\n",
        "        # # Ablation(2-2) Weighted BCE Loss\n",
        "        # pos_weight = torch.ones_like(sim_z) * (self.K / self.top_k)\n",
        "        # bce_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y, pos_weight=pos_weight)\n",
        "        # # Ablation(2-3) another Weighted BCE Loss (비추, top-k만 보는 느낌)\n",
        "        # raw_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y, reduction='none')  # shape: [B, K]\n",
        "        # bce_loss = raw_loss.sum() / (y.sum() + 1e-6)\n",
        "\n",
        "        ###################################################################\n",
        "        # InfoNCE loss\n",
        "        l_pos = torch.sum(z1 * z2, dim=1, keepdim=True)\n",
        "        l_neg = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1) / self.T\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(logits.device)\n",
        "        info_nce_loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "\n",
        "        # # Triplet loss\n",
        "        # margin = 1.0  # 하이퍼파라미터, 필요에 따라 조정\n",
        "\n",
        "        # B, D = z1.shape               # batch size, embedding dim\n",
        "        # K = self.queue_z.shape[1]     # queue size\n",
        "        # top_k = topk_idx.shape[1]     # positive 개수\n",
        "\n",
        "        # # (1) queue_z를 [K, D]로 transpose\n",
        "        # queue_z_t = self.queue_z.clone().detach().T                     # [K, D]\n",
        "\n",
        "        # # (2) positive embeddings: [B, top_k, D]\n",
        "        # pos_z = queue_z_t[topk_idx]                                     # advanced indexing\n",
        "\n",
        "        # # (3) negative indices mask 생성 후 negative embeddings: [B, K-top_k, D]\n",
        "        # all_idx = torch.arange(K, device=z1.device).unsqueeze(0).repeat(B, 1)  # [B, K]\n",
        "        # neg_mask = torch.ones((B, K), dtype=torch.bool, device=z1.device)\n",
        "        # neg_mask.scatter_(1, topk_idx, False)                            # positive 위치만 False\n",
        "        # neg_idx = all_idx[neg_mask].view(B, K - top_k)                  # [B, K-top_k]\n",
        "        # neg_z = queue_z_t[neg_idx]                                      # [B, K-top_k, D]\n",
        "\n",
        "        # # (4) 유클리드 거리 계산\n",
        "        # #     d_pos: [B, top_k], d_neg: [B, K-top_k]\n",
        "        # d_pos = torch.cdist(z1.unsqueeze(1), pos_z, p=2).squeeze(1)\n",
        "        # d_neg = torch.cdist(z1.unsqueeze(1), neg_z, p=2).squeeze(1)\n",
        "\n",
        "        # # (5) hardest positive (가장 먼) / hardest negative (가장 가까운)\n",
        "        # hardest_pos, _ = d_pos.max(dim=1)   # [B]\n",
        "        # hardest_neg, _ = d_neg.min(dim=1)   # [B]\n",
        "\n",
        "        # # (6) triplet loss\n",
        "        # triplet_loss = F.relu(hardest_pos - hardest_neg + margin).mean()\n",
        "\n",
        "\n",
        "        # Total loss (with optional warmup) # MLS 논문에서는 warmup 아예 안쓴다고 함\n",
        "        if epoch is not None and epoch < warmup_epochs:\n",
        "            loss = info_nce_loss\n",
        "        # else:\n",
        "        loss = info_nce_loss + self.lambda_bce * bce_loss\n",
        "        # print(f\"INFO_NCE: {info_nce_loss}\")\n",
        "        # print(f\"TRIPLET: {triplet_loss}\")\n",
        "        # print(f\"BCE: {bce_loss}\")\n",
        "\n",
        "        self._dequeue_and_enqueue(g2, z2)\n",
        "\n",
        "        return loss, logits, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc1bf21",
      "metadata": {
        "id": "1cc1bf21"
      },
      "source": [
        "## 4. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-BkAfkqhyHrY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkAfkqhyHrY",
        "outputId": "e44fb42a-b0d8-4542-a7c3-5d458437010b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 63])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(pretrain_loader))[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iWjL-9oSm76P",
      "metadata": {
        "id": "iWjL-9oSm76P"
      },
      "outputs": [],
      "source": [
        "pretrain_project_name = f'SHS_aug(T.N)_PT_{args.batch_size}bs_top{args.top_k}_{args.lambda_bce}ld_{get_timestamp()}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e745fdd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "e745fdd5",
        "outputId": "d23d5744-7e9a-4e82-dcb1-222e8e9e89b8"
      },
      "outputs": [],
      "source": [
        "# 모델 지정하기 전 seed 고정 필요\n",
        "seed_everything(args.seed) # Seed 고정\n",
        "\n",
        "wandb.init(\n",
        "    project=\"ICBHI_MSL_Ablation_all\",           # 프로젝트 이름\n",
        "    name=f\"{pretrain_project_name}\", # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.ft_epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay,\n",
        "    }\n",
        ")\n",
        "\n",
        "# 1. MoCo 모델 생성\n",
        "model = MoCo(\n",
        "    base_encoder = backbone_resnet,\n",
        "    dim_enc = args.out_dim,\n",
        "    dim_prj = args.dim_prj,\n",
        "    K = args.K,\n",
        "    m = args.momentum,\n",
        "    T = args.T,\n",
        "    top_k = args.top_k,\n",
        "    lambda_bce = args.lambda_bce\n",
        ").cuda()\n",
        "\n",
        "# 2. Optimizer\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=args.lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=args.weight_decay,\n",
        "    nesterov=True\n",
        ")\n",
        "\n",
        "# 3. Cosine Scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)\n",
        "\n",
        "# 4. Train\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    # ===============================\n",
        "    # Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    ######################### train_loader로 변경하였음 #########################\n",
        "    ######################### train_loader로 변경하였음 #########################\n",
        "    ######################### train_loader로 변경하였음 #########################\n",
        "    for i, (repeat_mel, label, _) in enumerate(train_loader): # label 여기선 사용 X\n",
        "        im_q, im_k, _ = aug(repeat_mel)\n",
        "\n",
        "        # scaling augs\n",
        "        im_q = (im_q - im_q.mean() ) / (im_q.std() + 1e-6)\n",
        "        im_k = (im_k - im_k.mean() ) / (im_k.std() + 1e-6)\n",
        "\n",
        "        im_q = im_q.cuda(device=args.gpu, non_blocking=True)\n",
        "        im_k = im_k.cuda(device=args.gpu, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, output, target = model(im_q=im_q, im_k=im_k)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} | Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"[Epoch {epoch} | Step {i}] im_q: {im_q.shape}, im_k: {im_k.shape}\")\n",
        "\n",
        "    # =====================================\n",
        "    # Scheduler\n",
        "    # =====================================\n",
        "    scheduler.step()\n",
        "\n",
        "    # # =====================================\n",
        "    # Logging with wandb\n",
        "    # =====================================\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    wandb.log({\n",
        "        # \"epoch\": epoch,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        # \"lr\": current_lr\n",
        "    })\n",
        "\n",
        "    # =====================================\n",
        "    # Checkpoint (Every 100 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"💾 Saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "    # ===============================\n",
        "    # Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if avg_train_loss < best_loss:\n",
        "        best_loss = avg_train_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZSwN7t7l2n5",
      "metadata": {
        "id": "sZSwN7t7l2n5"
      },
      "source": [
        "## 5. Linear Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646538df",
      "metadata": {
        "id": "646538df"
      },
      "source": [
        "#### validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33da3ad9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33da3ad9",
        "outputId": "006848a5-df01-46c1-a32b-d056cfba130b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2756"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66818a3",
      "metadata": {
        "id": "e66818a3"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).int()  # threshold = 0.5\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()   # [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy() # [N, 2]\n",
        "\n",
        "    avg_loss = running_loss / len(val_loader)\n",
        "\n",
        "    # # 개별 label별 sensitivity/specificity 계산\n",
        "    # crackle_sens = crackle_spec = wheeze_sens = wheeze_spec = 0\n",
        "\n",
        "    # for i in range(2):\n",
        "    #     y_true = all_labels[:, i]\n",
        "    #     y_pred = all_preds[:, i]\n",
        "\n",
        "    #     cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    #     if cm.shape == (2, 2):\n",
        "    #         TN, FP, FN, TP = cm.ravel()\n",
        "    #     else:\n",
        "    #         TN = FP = FN = TP = 0  # 안전처리\n",
        "\n",
        "    #     sens = TP / (TP + FN + 1e-6)\n",
        "    #     spec = TN / (TN + FP + 1e-6)\n",
        "\n",
        "    #     if i == 0:\n",
        "    #         crackle_sens, crackle_spec = sens, spec\n",
        "    #     else:\n",
        "    #         wheeze_sens, wheeze_spec = sens, spec\n",
        "\n",
        "    # avg_sens = (crackle_sens + wheeze_sens) / 2\n",
        "    # avg_spec = (crackle_spec + wheeze_spec) / 2\n",
        "    # icbhi_score = (avg_sens + avg_spec) / 2\n",
        "\n",
        "    return avg_loss, all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b5fa31",
      "metadata": {
        "id": "d3b5fa31"
      },
      "source": [
        "### Weighted loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4475c581",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4475c581",
        "outputId": "85beccdf-e6f9-4b87-fbd9-5e6f76cfbd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 - Positives (1): 792 / 2756 samples\n",
            "Class 1 - Positives (1): 528 / 2756 samples\n",
            "Class Weights: tensor([1.7399, 2.6098], device='cuda:0')\n",
            "alpha_norm: tensor([0.4000, 0.6000], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 💡 다중 라벨 예시: targets는 [B, C] binary matrix (e.g., [1, 0, 1, 0])\n",
        "label_list = []\n",
        "\n",
        "# 👇 train_dataset이 (x, multi_label_tensor, _) 형태라고 가정\n",
        "for _, label, _ in test_dataset:\n",
        "    label_list.append(label)  # label: Tensor([0, 1, 0, 1])처럼\n",
        "\n",
        "# 전체 label을 합치기\n",
        "all_labels = torch.stack(label_list, dim=0)  # shape: [N, C]\n",
        "num_classes = all_labels.size(1)\n",
        "total_samples = all_labels.size(0)\n",
        "\n",
        "# 클래스별 1의 개수 세기\n",
        "class_counts = all_labels.sum(dim=0)  # shape: [C]\n",
        "class_weights = total_samples / (num_classes * class_counts + 1e-6)  # smoothed\n",
        "\n",
        "# tensor로 변환\n",
        "class_weights_tensor = class_weights.float().to(device)\n",
        "\n",
        "# 🔹 출력\n",
        "for i, count in enumerate(class_counts.tolist()):\n",
        "    print(f\"Class {i} - Positives (1): {int(count)} / {total_samples} samples\")\n",
        "print(f\"Class Weights: {class_weights_tensor}\")\n",
        "\n",
        "alpha_norm = class_weights_tensor / class_weights_tensor.sum()\n",
        "print(f\"alpha_norm: {alpha_norm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N6RiJJnHjnRg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6RiJJnHjnRg",
        "outputId": "fcd859eb-70ac-45dd-a04d-72738db6aafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw Class Weights: tensor([1.2826, 2.6497])\n",
            "Normalized Alpha (sum=1): tensor([0.3262, 0.6738])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ⚙️ 각 클래스의 positive 개수 (from label distribution)\n",
        "crackle_pos = 262 + 83  # label 1 or 3\n",
        "wheeze_pos  = 84 + 83   # label 2 or 3\n",
        "\n",
        "total_samples = 885\n",
        "num_classes = 2\n",
        "\n",
        "# ⚖️ 기본 class weight 계산: inverse frequency\n",
        "class_counts = torch.tensor([crackle_pos, wheeze_pos], dtype=torch.float)\n",
        "class_weights = total_samples / (num_classes * class_counts + 1e-6)\n",
        "\n",
        "# ✅ 정규화: sum = 1\n",
        "alpha_norm = class_weights / class_weights.sum()\n",
        "\n",
        "# 출력\n",
        "print(\"Raw Class Weights:\", class_weights)\n",
        "print(\"Normalized Alpha (sum=1):\", alpha_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e58ee2",
      "metadata": {
        "id": "86e58ee2"
      },
      "source": [
        "### Multi-label Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d6150e",
      "metadata": {
        "id": "72d6150e"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiLabelFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Tensor of shape [C], or scalar\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        logits: [B, C] - raw scores\n",
        "        targets: [B, C] - binary or soft labels\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)  # [B, C]\n",
        "        ce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')  # [B, C]\n",
        "\n",
        "        pt = probs * targets + (1 - probs) * (1 - targets)  # p_t\n",
        "        focal_weight = (1 - pt) ** self.gamma               # (1 - pt)^γ\n",
        "\n",
        "        loss = focal_weight * ce_loss                       # focal weight 적용\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)  # [B, C]\n",
        "            loss = alpha_factor * loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "class StableMultiLabelFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # tensor of shape [C] or None\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        probs = torch.clamp(probs, min=self.eps, max=1.0 - self.eps)\n",
        "\n",
        "        # Focal weight\n",
        "        pt = probs * targets + (1 - probs) * (1 - targets)\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        # BCE loss\n",
        "        ce_loss = - (targets * torch.log(probs) + (1 - targets) * torch.log(1 - probs))\n",
        "\n",
        "        loss = focal_weight * ce_loss\n",
        "\n",
        "        # Safe alpha (class weights) application\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.dim() == 1:\n",
        "                alpha = self.alpha.view(1, -1)  # reshape for broadcasting\n",
        "            else:\n",
        "                alpha = self.alpha\n",
        "            loss = alpha * loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zTgAvNcjFdzA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTgAvNcjFdzA",
        "outputId": "8a94398b-51c9-4f61-aaf7-eb1154a612e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.5652, 4.2994], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "label_dist = Counter({0:456, 1:262, 2:84, 3:83})  # Finetune 분포\n",
        "\n",
        "# Crackle: (1 + Both), Wheeze: (2 + Both)\n",
        "n_crackle = label_dist[1] + label_dist[3]  # 262 + 83\n",
        "n_wheeze  = label_dist[2] + label_dist[3]  # 84 + 83\n",
        "n_total   = sum(label_dist.values())       # 885\n",
        "\n",
        "pos_weight = torch.tensor([\n",
        "    (n_total - n_crackle) / (n_crackle + 1e-6),\n",
        "    (n_total - n_wheeze) / (n_wheeze + 1e-6)\n",
        "], device=device)\n",
        "\n",
        "print(pos_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea74a2d",
      "metadata": {
        "id": "aea74a2d"
      },
      "source": [
        "## Linear Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nm8yaHDRZrT1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Nm8yaHDRZrT1",
        "outputId": "c3eea671-d3e3-4eb3-a9c3-f47d1d2ae512"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▆▅▅▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▂▁▂▁▁▂▂▁▁▁▁▁▁▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.79019</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SHS_aug(T.N)_PT_128bs_top15_0.5ld_2507111608</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/m0d169z2' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/m0d169z2</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250711_070848-m0d169z2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c5369e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "e8c5369e",
        "outputId": "a0a2ecb9-c2cd-4dbb-a981-8f210694face"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250711_072523-xs6imddz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz' target=\"_blank\">SHS_aug(T.N)_LE_128bs_2507111625</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7e9bc8b72790>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Wandb 정의\n",
        "\n",
        "# import wandb\n",
        "finetune_project_name = f'SHS_aug(T.N)_LE_{args.batch_size}bs_{get_timestamp()}'\n",
        "\n",
        "wandb.init(\n",
        "    project=\"ICBHI_MSL_Ablation_all\",           # 프로젝트 이름\n",
        "    name=f\"{finetune_project_name}\", # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.ft_epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e2372b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "06e2372b",
        "outputId": "496ceb9b-53c2-4402-8845-cc42ae610591"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 44.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 0.8464\n",
            "4-Class Confusion Matrix:\n",
            " [[1564  442   26    6]\n",
            " [ 847  331   23    1]\n",
            " [ 393   98    2    0]\n",
            " [ 223  129    5    6]]\n",
            "Sensitivity: 0.1647, Specificity: 0.7674, ICBHI Score: 0.4661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1576    3    0    0]\n",
            " [ 647    2    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.1435\n",
            "[VALIDATION] Sensitivity: 0.0017, Specificity: 0.9981, Avg ICBHI Score: 0.4999\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 0, loss: 0.1435)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Train Loss: 0.7928\n",
            "4-Class Confusion Matrix:\n",
            " [[1846  186    6    0]\n",
            " [1021  177    3    1]\n",
            " [ 440   52    1    0]\n",
            " [ 293   70    0    0]]\n",
            "Sensitivity: 0.0865, Specificity: 0.9058, ICBHI Score: 0.4961\n",
            "[Validation] Confusion Matrix:\n",
            " [[1564   12    3    0]\n",
            " [ 644    5    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.1429\n",
            "[VALIDATION] Sensitivity: 0.0042, Specificity: 0.9905, Avg ICBHI Score: 0.4974\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 1, loss: 0.1429)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, Train Loss: 0.7755\n",
            "4-Class Confusion Matrix:\n",
            " [[1801  231    5    1]\n",
            " [ 966  234    2    0]\n",
            " [ 415   73    5    0]\n",
            " [ 263   99    1    0]]\n",
            "Sensitivity: 0.1161, Specificity: 0.8837, ICBHI Score: 0.4999\n",
            "[Validation] Confusion Matrix:\n",
            " [[1536   13   30    0]\n",
            " [ 636   11    2    0]\n",
            " [ 381    0    4    0]\n",
            " [ 139    0    4    0]]\n",
            "Test Loss: 0.1427\n",
            "[VALIDATION] Sensitivity: 0.0127, Specificity: 0.9728, Avg ICBHI Score: 0.4928\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 2, loss: 0.1427)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, Train Loss: 0.7645\n",
            "4-Class Confusion Matrix:\n",
            " [[1782  247    8    1]\n",
            " [ 936  261    4    1]\n",
            " [ 403   78   12    0]\n",
            " [ 247  110    6    0]]\n",
            "Sensitivity: 0.1327, Specificity: 0.8744, ICBHI Score: 0.5035\n",
            "[Validation] Confusion Matrix:\n",
            " [[1521   16   42    0]\n",
            " [ 635   12    2    0]\n",
            " [ 378    0    7    0]\n",
            " [ 138    0    5    0]]\n",
            "Test Loss: 0.1429\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9633, Avg ICBHI Score: 0.4897\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, Train Loss: 0.7561\n",
            "4-Class Confusion Matrix:\n",
            " [[1770  258    9    1]\n",
            " [ 899  295    7    1]\n",
            " [ 393   82   18    0]\n",
            " [ 235  118   10    0]]\n",
            "Sensitivity: 0.1521, Specificity: 0.8685, ICBHI Score: 0.5103\n",
            "[Validation] Confusion Matrix:\n",
            " [[1512   16   51    0]\n",
            " [ 634   11    4    0]\n",
            " [ 375    0   10    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1432\n",
            "[VALIDATION] Sensitivity: 0.0178, Specificity: 0.9576, Avg ICBHI Score: 0.4877\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, Train Loss: 0.7494\n",
            "4-Class Confusion Matrix:\n",
            " [[1757  266   13    2]\n",
            " [ 874  318    7    3]\n",
            " [ 382   84   25    2]\n",
            " [ 221  129   13    0]]\n",
            "Sensitivity: 0.1667, Specificity: 0.8621, ICBHI Score: 0.5144\n",
            "[Validation] Confusion Matrix:\n",
            " [[1510   15   54    0]\n",
            " [ 636    9    4    0]\n",
            " [ 373    0   12    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1435\n",
            "[VALIDATION] Sensitivity: 0.0178, Specificity: 0.9563, Avg ICBHI Score: 0.4871\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, Train Loss: 0.7437\n",
            "4-Class Confusion Matrix:\n",
            " [[1747  275   14    2]\n",
            " [ 844  348    7    3]\n",
            " [ 379   84   28    2]\n",
            " [ 214  133   16    0]]\n",
            "Sensitivity: 0.1827, Specificity: 0.8572, ICBHI Score: 0.5200\n",
            "[Validation] Confusion Matrix:\n",
            " [[1512   13   54    0]\n",
            " [ 635    9    5    0]\n",
            " [ 372    0   13    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1439\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9576, Avg ICBHI Score: 0.4881\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, Train Loss: 0.7388\n",
            "4-Class Confusion Matrix:\n",
            " [[1741  280   15    2]\n",
            " [ 825  368    6    3]\n",
            " [ 373   87   31    2]\n",
            " [ 201  144   17    1]]\n",
            "Sensitivity: 0.1944, Specificity: 0.8543, ICBHI Score: 0.5243\n",
            "[Validation] Confusion Matrix:\n",
            " [[1515   10   54    0]\n",
            " [ 635    8    6    0]\n",
            " [ 372    0   13    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1443\n",
            "[VALIDATION] Sensitivity: 0.0178, Specificity: 0.9595, Avg ICBHI Score: 0.4887\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, Train Loss: 0.7344\n",
            "4-Class Confusion Matrix:\n",
            " [[1738  283   15    2]\n",
            " [ 814  380    5    3]\n",
            " [ 369   87   35    2]\n",
            " [ 196  146   19    2]]\n",
            "Sensitivity: 0.2026, Specificity: 0.8528, ICBHI Score: 0.5277\n",
            "[Validation] Confusion Matrix:\n",
            " [[1515    9   55    0]\n",
            " [ 637    5    7    0]\n",
            " [ 371    0   14    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1448\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9595, Avg ICBHI Score: 0.4878\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train Loss: 0.7305\n",
            "4-Class Confusion Matrix:\n",
            " [[1739  284   13    2]\n",
            " [ 795  399    5    3]\n",
            " [ 366   84   40    3]\n",
            " [ 190  149   20    4]]\n",
            "Sensitivity: 0.2153, Specificity: 0.8533, ICBHI Score: 0.5343\n",
            "[Validation] Confusion Matrix:\n",
            " [[1517    7   55    0]\n",
            " [ 639    2    8    0]\n",
            " [ 370    0   15    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1453\n",
            "[VALIDATION] Sensitivity: 0.0144, Specificity: 0.9607, Avg ICBHI Score: 0.4876\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, Train Loss: 0.7269\n",
            "4-Class Confusion Matrix:\n",
            " [[1735  286   14    3]\n",
            " [ 778  414    5    5]\n",
            " [ 364   84   41    4]\n",
            " [ 184  154   19    6]]\n",
            "Sensitivity: 0.2240, Specificity: 0.8513, ICBHI Score: 0.5377\n",
            "[Validation] Confusion Matrix:\n",
            " [[1514    6   59    0]\n",
            " [ 639    2    8    0]\n",
            " [ 370    0   15    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1458\n",
            "[VALIDATION] Sensitivity: 0.0144, Specificity: 0.9588, Avg ICBHI Score: 0.4866\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 53.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, Train Loss: 0.7237\n",
            "4-Class Confusion Matrix:\n",
            " [[1733  288   14    3]\n",
            " [ 755  437    5    5]\n",
            " [ 358   86   45    4]\n",
            " [ 180  154   21    8]]\n",
            "Sensitivity: 0.2381, Specificity: 0.8503, ICBHI Score: 0.5442\n",
            "[Validation] Confusion Matrix:\n",
            " [[1513    4   62    0]\n",
            " [ 637    2   10    0]\n",
            " [ 369    0   16    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1464\n",
            "[VALIDATION] Sensitivity: 0.0153, Specificity: 0.9582, Avg ICBHI Score: 0.4867\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13, Train Loss: 0.7208\n",
            "4-Class Confusion Matrix:\n",
            " [[1735  285   15    3]\n",
            " [ 751  441    5    5]\n",
            " [ 356   86   47    4]\n",
            " [ 178  154   22    9]]\n",
            "Sensitivity: 0.2415, Specificity: 0.8513, ICBHI Score: 0.5464\n",
            "[Validation] Confusion Matrix:\n",
            " [[1511    2   66    0]\n",
            " [ 637    2   10    0]\n",
            " [ 368    0   17    0]\n",
            " [ 134    0    9    0]]\n",
            "Test Loss: 0.1470\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9569, Avg ICBHI Score: 0.4865\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14, Train Loss: 0.7181\n",
            "4-Class Confusion Matrix:\n",
            " [[1739  281   16    2]\n",
            " [ 742  450    5    5]\n",
            " [ 354   87   48    4]\n",
            " [ 178  154   22    9]]\n",
            "Sensitivity: 0.2464, Specificity: 0.8533, ICBHI Score: 0.5498\n",
            "[Validation] Confusion Matrix:\n",
            " [[1510    2   67    0]\n",
            " [ 636    2   11    0]\n",
            " [ 368    0   17    0]\n",
            " [ 134    0    9    0]]\n",
            "Test Loss: 0.1476\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9563, Avg ICBHI Score: 0.4862\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15, Train Loss: 0.7156\n",
            "4-Class Confusion Matrix:\n",
            " [[1736  284   16    2]\n",
            " [ 735  456    6    5]\n",
            " [ 351   88   50    4]\n",
            " [ 178  153   23    9]]\n",
            "Sensitivity: 0.2502, Specificity: 0.8518, ICBHI Score: 0.5510\n",
            "[Validation] Confusion Matrix:\n",
            " [[1503    2   74    0]\n",
            " [ 636    2   11    0]\n",
            " [ 367    0   18    0]\n",
            " [ 133    0   10    0]]\n",
            "Test Loss: 0.1482\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9519, Avg ICBHI Score: 0.4844\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16, Train Loss: 0.7133\n",
            "4-Class Confusion Matrix:\n",
            " [[1731  288   17    2]\n",
            " [ 733  458    6    5]\n",
            " [ 351   86   52    4]\n",
            " [ 179  153   22    9]]\n",
            "Sensitivity: 0.2522, Specificity: 0.8494, ICBHI Score: 0.5508\n",
            "[Validation] Confusion Matrix:\n",
            " [[1503    1   75    0]\n",
            " [ 637    1   11    0]\n",
            " [ 364    0   21    0]\n",
            " [ 132    0   11    0]]\n",
            "Test Loss: 0.1488\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9519, Avg ICBHI Score: 0.4853\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17, Train Loss: 0.7112\n",
            "4-Class Confusion Matrix:\n",
            " [[1734  284   18    2]\n",
            " [ 732  458    6    6]\n",
            " [ 346   88   55    4]\n",
            " [ 177  153   24    9]]\n",
            "Sensitivity: 0.2536, Specificity: 0.8508, ICBHI Score: 0.5522\n",
            "[Validation] Confusion Matrix:\n",
            " [[1504    0   75    0]\n",
            " [ 635    1   13    0]\n",
            " [ 364    0   21    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1495\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9525, Avg ICBHI Score: 0.4856\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18, Train Loss: 0.7092\n",
            "4-Class Confusion Matrix:\n",
            " [[1733  284   19    2]\n",
            " [ 726  463    6    7]\n",
            " [ 343   90   56    4]\n",
            " [ 177  153   24    9]]\n",
            "Sensitivity: 0.2566, Specificity: 0.8503, ICBHI Score: 0.5535\n",
            "[Validation] Confusion Matrix:\n",
            " [[1503    0   76    0]\n",
            " [ 632    1   16    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1502\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9519, Avg ICBHI Score: 0.4866\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19, Train Loss: 0.7074\n",
            "4-Class Confusion Matrix:\n",
            " [[1729  287   20    2]\n",
            " [ 722  467    6    7]\n",
            " [ 340   91   58    4]\n",
            " [ 176  151   25   11]]\n",
            "Sensitivity: 0.2604, Specificity: 0.8484, ICBHI Score: 0.5544\n",
            "[Validation] Confusion Matrix:\n",
            " [[1501    0   78    0]\n",
            " [ 629    1   19    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1509\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9506, Avg ICBHI Score: 0.4859\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20, Train Loss: 0.7057\n",
            "4-Class Confusion Matrix:\n",
            " [[1727  289   20    2]\n",
            " [ 718  471    6    7]\n",
            " [ 338   91   60    4]\n",
            " [ 175  151   25   12]]\n",
            "Sensitivity: 0.2638, Specificity: 0.8474, ICBHI Score: 0.5556\n",
            "[Validation] Confusion Matrix:\n",
            " [[1500    0   79    0]\n",
            " [ 627    1   21    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1517\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9500, Avg ICBHI Score: 0.4856\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 21, Train Loss: 0.7041\n",
            "4-Class Confusion Matrix:\n",
            " [[1727  289   20    2]\n",
            " [ 715  473    7    7]\n",
            " [ 335   91   62    5]\n",
            " [ 173  153   25   12]]\n",
            "Sensitivity: 0.2658, Specificity: 0.8474, ICBHI Score: 0.5566\n",
            "[Validation] Confusion Matrix:\n",
            " [[1499    0   80    0]\n",
            " [ 624    1   24    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1524\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9493, Avg ICBHI Score: 0.4853\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 22, Train Loss: 0.7026\n",
            "4-Class Confusion Matrix:\n",
            " [[1727  288   21    2]\n",
            " [ 709  477    9    7]\n",
            " [ 334   91   63    5]\n",
            " [ 171  155   25   12]]\n",
            "Sensitivity: 0.2682, Specificity: 0.8474, ICBHI Score: 0.5578\n",
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 620    1   28    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1532\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9487, Avg ICBHI Score: 0.4850\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 23, Train Loss: 0.7012\n",
            "4-Class Confusion Matrix:\n",
            " [[1728  287   21    2]\n",
            " [ 702  483   10    7]\n",
            " [ 334   91   62    6]\n",
            " [ 171  154   25   13]]\n",
            "Sensitivity: 0.2711, Specificity: 0.8479, ICBHI Score: 0.5595\n",
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 618    1   30    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1540\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9487, Avg ICBHI Score: 0.4850\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 24, Train Loss: 0.6999\n",
            "4-Class Confusion Matrix:\n",
            " [[1727  288   21    2]\n",
            " [ 697  487   10    8]\n",
            " [ 332   90   63    8]\n",
            " [ 170  153   27   13]]\n",
            "Sensitivity: 0.2736, Specificity: 0.8474, ICBHI Score: 0.5605\n",
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 618    1   30    0]\n",
            " [ 360    0   25    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1548\n",
            "[VALIDATION] Sensitivity: 0.0221, Specificity: 0.9487, Avg ICBHI Score: 0.4854\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 25, Train Loss: 0.6987\n",
            "4-Class Confusion Matrix:\n",
            " [[1724  294   18    2]\n",
            " [ 693  491   10    8]\n",
            " [ 329   90   65    9]\n",
            " [ 170  153   27   13]]\n",
            "Sensitivity: 0.2765, Specificity: 0.8459, ICBHI Score: 0.5612\n",
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 617    1   31    0]\n",
            " [ 359    0   26    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1556\n",
            "[VALIDATION] Sensitivity: 0.0229, Specificity: 0.9481, Avg ICBHI Score: 0.4855\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 26, Train Loss: 0.6976\n",
            "4-Class Confusion Matrix:\n",
            " [[1723  295   18    2]\n",
            " [ 687  496   10    9]\n",
            " [ 329   86   67   11]\n",
            " [ 168  154   27   14]]\n",
            "Sensitivity: 0.2804, Specificity: 0.8454, ICBHI Score: 0.5629\n",
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 617    1   31    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1564\n",
            "[VALIDATION] Sensitivity: 0.0238, Specificity: 0.9481, Avg ICBHI Score: 0.4859\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 27, Train Loss: 0.6966\n",
            "4-Class Confusion Matrix:\n",
            " [[1720  299   16    3]\n",
            " [ 681  501   11    9]\n",
            " [ 330   85   67   11]\n",
            " [ 168  154   27   14]]\n",
            "Sensitivity: 0.2828, Specificity: 0.8440, ICBHI Score: 0.5634\n",
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 618    1   30    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1572\n",
            "[VALIDATION] Sensitivity: 0.0238, Specificity: 0.9481, Avg ICBHI Score: 0.4859\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 28, Train Loss: 0.6957\n",
            "4-Class Confusion Matrix:\n",
            " [[1720  299   16    3]\n",
            " [ 674  508   11    9]\n",
            " [ 329   85   69   10]\n",
            " [ 165  152   29   17]]\n",
            "Sensitivity: 0.2886, Specificity: 0.8440, ICBHI Score: 0.5663\n",
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 619    1   29    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1580\n",
            "[VALIDATION] Sensitivity: 0.0238, Specificity: 0.9481, Avg ICBHI Score: 0.4859\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 52.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 29, Train Loss: 0.6948\n",
            "4-Class Confusion Matrix:\n",
            " [[1717  302   16    3]\n",
            " [ 673  508   12    9]\n",
            " [ 328   86   69   10]\n",
            " [ 163  153   27   20]]\n",
            "Sensitivity: 0.2901, Specificity: 0.8425, ICBHI Score: 0.5663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 620    0   29    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1589\n",
            "[VALIDATION] Sensitivity: 0.0229, Specificity: 0.9481, Avg ICBHI Score: 0.4855\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 30, Train Loss: 0.6941\n",
            "4-Class Confusion Matrix:\n",
            " [[1717  302   16    3]\n",
            " [ 674  508   11    9]\n",
            " [ 327   87   68   11]\n",
            " [ 163  152   27   21]]\n",
            "Sensitivity: 0.2901, Specificity: 0.8425, ICBHI Score: 0.5663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1497    0   82    0]\n",
            " [ 621    0   28    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1597\n",
            "[VALIDATION] Sensitivity: 0.0229, Specificity: 0.9481, Avg ICBHI Score: 0.4855\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 31, Train Loss: 0.6933\n",
            "4-Class Confusion Matrix:\n",
            " [[1715  304   16    3]\n",
            " [ 670  510   12   10]\n",
            " [ 324   86   71   12]\n",
            " [ 162  151   27   23]]\n",
            "Sensitivity: 0.2935, Specificity: 0.8415, ICBHI Score: 0.5675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 621    0   28    0]\n",
            " [ 359    0   26    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1606\n",
            "[VALIDATION] Sensitivity: 0.0221, Specificity: 0.9487, Avg ICBHI Score: 0.4854\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 32, Train Loss: 0.6927\n",
            "4-Class Confusion Matrix:\n",
            " [[1711  308   16    3]\n",
            " [ 667  513   12   10]\n",
            " [ 322   87   73   11]\n",
            " [ 161  150   27   25]]\n",
            "Sensitivity: 0.2969, Specificity: 0.8395, ICBHI Score: 0.5682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 623    0   26    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1614\n",
            "[VALIDATION] Sensitivity: 0.0229, Specificity: 0.9487, Avg ICBHI Score: 0.4858\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 33, Train Loss: 0.6921\n",
            "4-Class Confusion Matrix:\n",
            " [[1709  310   16    3]\n",
            " [ 669  511   12   10]\n",
            " [ 322   87   73   11]\n",
            " [ 162  148   27   26]]\n",
            "Sensitivity: 0.2964, Specificity: 0.8386, ICBHI Score: 0.5675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 625    0   24    0]\n",
            " [ 358    0   27    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1622\n",
            "[VALIDATION] Sensitivity: 0.0229, Specificity: 0.9487, Avg ICBHI Score: 0.4858\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 51.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 34, Train Loss: 0.6916\n",
            "4-Class Confusion Matrix:\n",
            " [[1706  313   16    3]\n",
            " [ 667  511   14   10]\n",
            " [ 321   86   73   13]\n",
            " [ 160  148   28   27]]\n",
            "Sensitivity: 0.2969, Specificity: 0.8371, ICBHI Score: 0.5670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 628    0   21    0]\n",
            " [ 359    0   26    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1630\n",
            "[VALIDATION] Sensitivity: 0.0221, Specificity: 0.9487, Avg ICBHI Score: 0.4854\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 35, Train Loss: 0.6911\n",
            "4-Class Confusion Matrix:\n",
            " [[1706  314   15    3]\n",
            " [ 671  507   14   10]\n",
            " [ 320   87   73   13]\n",
            " [ 161  148   27   27]]\n",
            "Sensitivity: 0.2949, Specificity: 0.8371, ICBHI Score: 0.5660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 631    0   18    0]\n",
            " [ 360    0   25    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1638\n",
            "[VALIDATION] Sensitivity: 0.0212, Specificity: 0.9487, Avg ICBHI Score: 0.4850\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 36, Train Loss: 0.6907\n",
            "4-Class Confusion Matrix:\n",
            " [[1703  317   15    3]\n",
            " [ 668  511   14    9]\n",
            " [ 318   87   74   14]\n",
            " [ 161  147   27   28]]\n",
            "Sensitivity: 0.2979, Specificity: 0.8356, ICBHI Score: 0.5667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 634    0   15    0]\n",
            " [ 361    0   24    0]\n",
            " [ 131    0   12    0]]\n",
            "Test Loss: 0.1646\n",
            "[VALIDATION] Sensitivity: 0.0204, Specificity: 0.9487, Avg ICBHI Score: 0.4845\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 37, Train Loss: 0.6903\n",
            "4-Class Confusion Matrix:\n",
            " [[1702  317   16    3]\n",
            " [ 668  511   14    9]\n",
            " [ 318   87   74   14]\n",
            " [ 159  147   28   29]]\n",
            "Sensitivity: 0.2983, Specificity: 0.8351, ICBHI Score: 0.5667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 635    0   14    0]\n",
            " [ 361    0   24    0]\n",
            " [ 132    0   11    0]]\n",
            "Test Loss: 0.1653\n",
            "[VALIDATION] Sensitivity: 0.0204, Specificity: 0.9487, Avg ICBHI Score: 0.4845\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 38, Train Loss: 0.6900\n",
            "4-Class Confusion Matrix:\n",
            " [[1694  325   17    2]\n",
            " [ 667  512   14    9]\n",
            " [ 318   87   74   14]\n",
            " [ 159  147   29   28]]\n",
            "Sensitivity: 0.2983, Specificity: 0.8312, ICBHI Score: 0.5648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1498    0   81    0]\n",
            " [ 635    0   14    0]\n",
            " [ 362    0   23    0]\n",
            " [ 132    0   11    0]]\n",
            "Test Loss: 0.1660\n",
            "[VALIDATION] Sensitivity: 0.0195, Specificity: 0.9487, Avg ICBHI Score: 0.4841\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 39, Train Loss: 0.6896\n",
            "4-Class Confusion Matrix:\n",
            " [[1691  328   17    2]\n",
            " [ 667  512   14    9]\n",
            " [ 317   87   75   14]\n",
            " [ 158  146   29   30]]\n",
            "Sensitivity: 0.2998, Specificity: 0.8297, ICBHI Score: 0.5648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1501    0   78    0]\n",
            " [ 636    0   13    0]\n",
            " [ 363    0   22    0]\n",
            " [ 133    0   10    0]]\n",
            "Test Loss: 0.1666\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9506, Avg ICBHI Score: 0.4846\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 40, Train Loss: 0.6893\n",
            "4-Class Confusion Matrix:\n",
            " [[1692  326   17    3]\n",
            " [ 666  513   15    8]\n",
            " [ 315   85   78   15]\n",
            " [ 158  145   29   31]]\n",
            "Sensitivity: 0.3022, Specificity: 0.8302, ICBHI Score: 0.5662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1501    0   78    0]\n",
            " [ 637    0   12    0]\n",
            " [ 363    0   22    0]\n",
            " [ 134    0    9    0]]\n",
            "Test Loss: 0.1671\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9506, Avg ICBHI Score: 0.4846\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 41, Train Loss: 0.6891\n",
            "4-Class Confusion Matrix:\n",
            " [[1691  327   17    3]\n",
            " [ 665  514   14    9]\n",
            " [ 316   84   77   16]\n",
            " [ 159  144   29   31]]\n",
            "Sensitivity: 0.3022, Specificity: 0.8297, ICBHI Score: 0.5660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1501    0   78    0]\n",
            " [ 638    0   11    0]\n",
            " [ 363    0   22    0]\n",
            " [ 134    0    9    0]]\n",
            "Test Loss: 0.1676\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9506, Avg ICBHI Score: 0.4846\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 42, Train Loss: 0.6888\n",
            "4-Class Confusion Matrix:\n",
            " [[1691  327   17    3]\n",
            " [ 665  515   13    9]\n",
            " [ 316   81   80   16]\n",
            " [ 157  145   30   31]]\n",
            "Sensitivity: 0.3042, Specificity: 0.8297, ICBHI Score: 0.5670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1502    0   77    0]\n",
            " [ 640    0    9    0]\n",
            " [ 363    0   22    0]\n",
            " [ 136    0    7    0]]\n",
            "Test Loss: 0.1680\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9512, Avg ICBHI Score: 0.4850\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 43, Train Loss: 0.6885\n",
            "4-Class Confusion Matrix:\n",
            " [[1689  329   17    3]\n",
            " [ 663  518   13    8]\n",
            " [ 316   80   81   16]\n",
            " [ 157  143   30   33]]\n",
            "Sensitivity: 0.3071, Specificity: 0.8288, ICBHI Score: 0.5679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1505    0   74    0]\n",
            " [ 640    0    9    0]\n",
            " [ 365    0   20    0]\n",
            " [ 136    0    7    0]]\n",
            "Test Loss: 0.1683\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9531, Avg ICBHI Score: 0.4851\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 44, Train Loss: 0.6882\n",
            "4-Class Confusion Matrix:\n",
            " [[1690  328   17    3]\n",
            " [ 667  514   13    8]\n",
            " [ 316   80   81   16]\n",
            " [ 156  142   31   34]]\n",
            "Sensitivity: 0.3056, Specificity: 0.8292, ICBHI Score: 0.5674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    0    9    0]\n",
            " [ 365    0   20    0]\n",
            " [ 136    0    7    0]]\n",
            "Test Loss: 0.1686\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9544, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 45, Train Loss: 0.6879\n",
            "4-Class Confusion Matrix:\n",
            " [[1687  332   17    2]\n",
            " [ 657  524   13    8]\n",
            " [ 316   78   81   18]\n",
            " [ 157  140   31   35]]\n",
            "Sensitivity: 0.3110, Specificity: 0.8278, ICBHI Score: 0.5694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    0    9    0]\n",
            " [ 365    0   20    0]\n",
            " [ 136    0    7    0]]\n",
            "Test Loss: 0.1687\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9544, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 46, Train Loss: 0.6876\n",
            "4-Class Confusion Matrix:\n",
            " [[1690  329   16    3]\n",
            " [ 657  524   13    8]\n",
            " [ 316   78   81   18]\n",
            " [ 159  138   31   35]]\n",
            "Sensitivity: 0.3110, Specificity: 0.8292, ICBHI Score: 0.5701\n",
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    0    9    0]\n",
            " [ 364    1   20    0]\n",
            " [ 136    0    7    0]]\n",
            "Test Loss: 0.1687\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9544, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 47, Train Loss: 0.6873\n",
            "4-Class Confusion Matrix:\n",
            " [[1687  330   17    4]\n",
            " [ 654  527   13    8]\n",
            " [ 316   77   82   18]\n",
            " [ 157  140   31   35]]\n",
            "Sensitivity: 0.3129, Specificity: 0.8278, ICBHI Score: 0.5703\n",
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    0    9    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1686\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9544, Avg ICBHI Score: 0.4853\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 48, Train Loss: 0.6869\n",
            "4-Class Confusion Matrix:\n",
            " [[1686  331   17    4]\n",
            " [ 659  523   13    7]\n",
            " [ 314   78   81   20]\n",
            " [ 153  144   31   35]]\n",
            "Sensitivity: 0.3105, Specificity: 0.8273, ICBHI Score: 0.5689\n",
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    0    9    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1683\n",
            "[VALIDATION] Sensitivity: 0.0161, Specificity: 0.9544, Avg ICBHI Score: 0.4853\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 49, Train Loss: 0.6865\n",
            "4-Class Confusion Matrix:\n",
            " [[1685  332   17    4]\n",
            " [ 658  524   13    7]\n",
            " [ 315   77   81   20]\n",
            " [ 152  144   31   36]]\n",
            "Sensitivity: 0.3115, Specificity: 0.8268, ICBHI Score: 0.5691\n",
            "[Validation] Confusion Matrix:\n",
            " [[1507    0   72    0]\n",
            " [ 640    1    8    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1679\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9544, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 50, Train Loss: 0.6860\n",
            "4-Class Confusion Matrix:\n",
            " [[1687  329   18    4]\n",
            " [ 656  526   13    7]\n",
            " [ 314   78   81   20]\n",
            " [ 153  143   30   37]]\n",
            "Sensitivity: 0.3129, Specificity: 0.8278, ICBHI Score: 0.5703\n",
            "[Validation] Confusion Matrix:\n",
            " [[1508    0   71    0]\n",
            " [ 640    1    8    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1674\n",
            "[VALIDATION] Sensitivity: 0.0170, Specificity: 0.9550, Avg ICBHI Score: 0.4860\n",
            "##################################################\n",
            "💾 Saved checkpoint to /content/drive/MyDrive/ADV 프로젝트/checkpoints/LE_pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 50.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 51, Train Loss: 0.6855\n",
            "4-Class Confusion Matrix:\n",
            " [[1691  324   18    5]\n",
            " [ 660  522   13    7]\n",
            " [ 313   78   81   21]\n",
            " [ 154  143   31   35]]\n",
            "Sensitivity: 0.3100, Specificity: 0.8297, ICBHI Score: 0.5699\n",
            "[Validation] Confusion Matrix:\n",
            " [[1508    1   70    0]\n",
            " [ 639    2    8    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1667\n",
            "[VALIDATION] Sensitivity: 0.0178, Specificity: 0.9550, Avg ICBHI Score: 0.4864\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 52, Train Loss: 0.6849\n",
            "4-Class Confusion Matrix:\n",
            " [[1690  325   18    5]\n",
            " [ 664  518   13    7]\n",
            " [ 308   83   81   21]\n",
            " [ 154  142   31   36]]\n",
            "Sensitivity: 0.3086, Specificity: 0.8292, ICBHI Score: 0.5689\n",
            "[Validation] Confusion Matrix:\n",
            " [[1507    2   70    0]\n",
            " [ 638    3    8    0]\n",
            " [ 365    1   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1659\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9544, Avg ICBHI Score: 0.4865\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 53, Train Loss: 0.6843\n",
            "4-Class Confusion Matrix:\n",
            " [[1690  325   18    5]\n",
            " [ 675  507   13    7]\n",
            " [ 308   82   81   22]\n",
            " [ 153  142   32   36]]\n",
            "Sensitivity: 0.3032, Specificity: 0.8292, ICBHI Score: 0.5662\n",
            "[Validation] Confusion Matrix:\n",
            " [[1504    4   71    0]\n",
            " [ 638    3    8    0]\n",
            " [ 364    2   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1650\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9525, Avg ICBHI Score: 0.4856\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 54, Train Loss: 0.6836\n",
            "4-Class Confusion Matrix:\n",
            " [[1692  322   18    6]\n",
            " [ 688  496   11    7]\n",
            " [ 308   81   82   22]\n",
            " [ 152  142   33   36]]\n",
            "Sensitivity: 0.2983, Specificity: 0.8302, ICBHI Score: 0.5643\n",
            "[Validation] Confusion Matrix:\n",
            " [[1504    4   71    0]\n",
            " [ 638    3    8    0]\n",
            " [ 364    2   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1639\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9525, Avg ICBHI Score: 0.4856\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 55, Train Loss: 0.6828\n",
            "4-Class Confusion Matrix:\n",
            " [[1693  321   17    7]\n",
            " [ 695  489   11    7]\n",
            " [ 307   80   84   22]\n",
            " [ 151  141   33   38]]\n",
            "Sensitivity: 0.2969, Specificity: 0.8307, ICBHI Score: 0.5638\n",
            "[Validation] Confusion Matrix:\n",
            " [[1503    5   71    0]\n",
            " [ 638    3    8    0]\n",
            " [ 363    3   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1628\n",
            "[VALIDATION] Sensitivity: 0.0187, Specificity: 0.9519, Avg ICBHI Score: 0.4853\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 56, Train Loss: 0.6820\n",
            "4-Class Confusion Matrix:\n",
            " [[1700  317   14    7]\n",
            " [ 698  487   10    7]\n",
            " [ 308   79   84   22]\n",
            " [ 151  141   34   37]]\n",
            "Sensitivity: 0.2954, Specificity: 0.8342, ICBHI Score: 0.5648\n",
            "[Validation] Confusion Matrix:\n",
            " [[1503    5   71    0]\n",
            " [ 637    4    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 137    0    6    0]]\n",
            "Test Loss: 0.1615\n",
            "[VALIDATION] Sensitivity: 0.0195, Specificity: 0.9519, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 57, Train Loss: 0.6811\n",
            "4-Class Confusion Matrix:\n",
            " [[1701  316   14    7]\n",
            " [ 702  485    8    7]\n",
            " [ 310   77   83   23]\n",
            " [ 152  140   34   37]]\n",
            "Sensitivity: 0.2940, Specificity: 0.8346, ICBHI Score: 0.5643\n",
            "[Validation] Confusion Matrix:\n",
            " [[1501    6   72    0]\n",
            " [ 636    5    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1601\n",
            "[VALIDATION] Sensitivity: 0.0204, Specificity: 0.9506, Avg ICBHI Score: 0.4855\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 58, Train Loss: 0.6801\n",
            "4-Class Confusion Matrix:\n",
            " [[1701  316   14    7]\n",
            " [ 703  484    7    8]\n",
            " [ 313   73   83   24]\n",
            " [ 150  141   34   38]]\n",
            "Sensitivity: 0.2940, Specificity: 0.8346, ICBHI Score: 0.5643\n",
            "[Validation] Confusion Matrix:\n",
            " [[1498    9   72    0]\n",
            " [ 632    9    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1587\n",
            "[VALIDATION] Sensitivity: 0.0238, Specificity: 0.9487, Avg ICBHI Score: 0.4862\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 59, Train Loss: 0.6791\n",
            "4-Class Confusion Matrix:\n",
            " [[1706  311   14    7]\n",
            " [ 705  482    7    8]\n",
            " [ 312   74   84   23]\n",
            " [ 150  141   33   39]]\n",
            "Sensitivity: 0.2940, Specificity: 0.8371, ICBHI Score: 0.5655\n",
            "[Validation] Confusion Matrix:\n",
            " [[1496   11   72    0]\n",
            " [ 630   11    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1573\n",
            "[VALIDATION] Sensitivity: 0.0255, Specificity: 0.9474, Avg ICBHI Score: 0.4865\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 60, Train Loss: 0.6780\n",
            "4-Class Confusion Matrix:\n",
            " [[1710  307   14    7]\n",
            " [ 709  478    7    8]\n",
            " [ 311   72   85   25]\n",
            " [ 150  141   32   40]]\n",
            "Sensitivity: 0.2930, Specificity: 0.8391, ICBHI Score: 0.5660\n",
            "[Validation] Confusion Matrix:\n",
            " [[1489   18   72    0]\n",
            " [ 629   12    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1559\n",
            "[VALIDATION] Sensitivity: 0.0263, Specificity: 0.9430, Avg ICBHI Score: 0.4847\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 61, Train Loss: 0.6768\n",
            "4-Class Confusion Matrix:\n",
            " [[1715  302   14    7]\n",
            " [ 705  483    7    7]\n",
            " [ 311   72   85   25]\n",
            " [ 150  141   32   40]]\n",
            "Sensitivity: 0.2954, Specificity: 0.8415, ICBHI Score: 0.5685\n",
            "[Validation] Confusion Matrix:\n",
            " [[1487   20   72    0]\n",
            " [ 629   12    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1545\n",
            "[VALIDATION] Sensitivity: 0.0263, Specificity: 0.9417, Avg ICBHI Score: 0.4840\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 62, Train Loss: 0.6756\n",
            "4-Class Confusion Matrix:\n",
            " [[1721  295   15    7]\n",
            " [ 706  482    8    6]\n",
            " [ 312   71   85   25]\n",
            " [ 152  139   30   42]]\n",
            "Sensitivity: 0.2959, Specificity: 0.8445, ICBHI Score: 0.5702\n",
            "[Validation] Confusion Matrix:\n",
            " [[1485   22   72    0]\n",
            " [ 625   16    8    0]\n",
            " [ 362    4   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1531\n",
            "[VALIDATION] Sensitivity: 0.0297, Specificity: 0.9405, Avg ICBHI Score: 0.4851\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 63, Train Loss: 0.6744\n",
            "4-Class Confusion Matrix:\n",
            " [[1725  291   15    7]\n",
            " [ 704  484    8    6]\n",
            " [ 312   70   86   25]\n",
            " [ 154  137   29   43]]\n",
            "Sensitivity: 0.2979, Specificity: 0.8464, ICBHI Score: 0.5721\n",
            "[Validation] Confusion Matrix:\n",
            " [[1481   25   73    0]\n",
            " [ 623   18    8    0]\n",
            " [ 361    5   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1518\n",
            "[VALIDATION] Sensitivity: 0.0314, Specificity: 0.9379, Avg ICBHI Score: 0.4847\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 64, Train Loss: 0.6732\n",
            "4-Class Confusion Matrix:\n",
            " [[1727  289   16    6]\n",
            " [ 701  487    8    6]\n",
            " [ 313   68   87   25]\n",
            " [ 152  138   29   44]]\n",
            "Sensitivity: 0.3003, Specificity: 0.8474, ICBHI Score: 0.5738\n",
            "[Validation] Confusion Matrix:\n",
            " [[1478   28   73    0]\n",
            " [ 621   20    8    0]\n",
            " [ 361    5   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1506\n",
            "[VALIDATION] Sensitivity: 0.0331, Specificity: 0.9360, Avg ICBHI Score: 0.4846\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 65, Train Loss: 0.6720\n",
            "4-Class Confusion Matrix:\n",
            " [[1731  285   16    6]\n",
            " [ 699  489    8    6]\n",
            " [ 313   68   86   26]\n",
            " [ 151  139   28   45]]\n",
            "Sensitivity: 0.3013, Specificity: 0.8494, ICBHI Score: 0.5753\n",
            "[Validation] Confusion Matrix:\n",
            " [[1473   33   73    0]\n",
            " [ 620   21    8    0]\n",
            " [ 361    5   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1495\n",
            "[VALIDATION] Sensitivity: 0.0340, Specificity: 0.9329, Avg ICBHI Score: 0.4834\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 49.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 66, Train Loss: 0.6708\n",
            "4-Class Confusion Matrix:\n",
            " [[1732  284   17    5]\n",
            " [ 696  492    8    6]\n",
            " [ 312   68   88   25]\n",
            " [ 153  136   28   46]]\n",
            "Sensitivity: 0.3042, Specificity: 0.8499, ICBHI Score: 0.5770\n",
            "[Validation] Confusion Matrix:\n",
            " [[1471   35   73    0]\n",
            " [ 620   21    8    0]\n",
            " [ 361    5   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1485\n",
            "[VALIDATION] Sensitivity: 0.0340, Specificity: 0.9316, Avg ICBHI Score: 0.4828\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 67, Train Loss: 0.6697\n",
            "4-Class Confusion Matrix:\n",
            " [[1742  275   16    5]\n",
            " [ 692  496    8    6]\n",
            " [ 310   70   88   25]\n",
            " [ 153  136   28   46]]\n",
            "Sensitivity: 0.3061, Specificity: 0.8548, ICBHI Score: 0.5804\n",
            "[Validation] Confusion Matrix:\n",
            " [[1465   41   73    0]\n",
            " [ 620   21    8    0]\n",
            " [ 361    5   19    0]\n",
            " [ 136    1    6    0]]\n",
            "Test Loss: 0.1476\n",
            "[VALIDATION] Sensitivity: 0.0340, Specificity: 0.9278, Avg ICBHI Score: 0.4809\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 68, Train Loss: 0.6686\n",
            "4-Class Confusion Matrix:\n",
            " [[1746  271   17    4]\n",
            " [ 685  503    8    6]\n",
            " [ 311   69   88   25]\n",
            " [ 153  136   29   45]]\n",
            "Sensitivity: 0.3090, Specificity: 0.8567, ICBHI Score: 0.5829\n",
            "[Validation] Confusion Matrix:\n",
            " [[1460   46   73    0]\n",
            " [ 619   22    8    0]\n",
            " [ 360    6   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1468\n",
            "[VALIDATION] Sensitivity: 0.0348, Specificity: 0.9246, Avg ICBHI Score: 0.4797\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 69, Train Loss: 0.6675\n",
            "4-Class Confusion Matrix:\n",
            " [[1753  264   17    4]\n",
            " [ 687  500    8    7]\n",
            " [ 310   68   90   25]\n",
            " [ 151  138   29   45]]\n",
            "Sensitivity: 0.3086, Specificity: 0.8602, ICBHI Score: 0.5844\n",
            "[Validation] Confusion Matrix:\n",
            " [[1460   46   73    0]\n",
            " [ 618   23    8    0]\n",
            " [ 360    6   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1461\n",
            "[VALIDATION] Sensitivity: 0.0357, Specificity: 0.9246, Avg ICBHI Score: 0.4802\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 70, Train Loss: 0.6665\n",
            "4-Class Confusion Matrix:\n",
            " [[1760  257   17    4]\n",
            " [ 688  499    8    7]\n",
            " [ 308   67   91   27]\n",
            " [ 154  134   28   47]]\n",
            "Sensitivity: 0.3095, Specificity: 0.8636, ICBHI Score: 0.5866\n",
            "[Validation] Confusion Matrix:\n",
            " [[1453   53   73    0]\n",
            " [ 616   25    8    0]\n",
            " [ 359    7   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1455\n",
            "[VALIDATION] Sensitivity: 0.0374, Specificity: 0.9202, Avg ICBHI Score: 0.4788\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 71, Train Loss: 0.6655\n",
            "4-Class Confusion Matrix:\n",
            " [[1764  252   18    4]\n",
            " [ 687  500    8    7]\n",
            " [ 307   68   91   27]\n",
            " [ 154  134   28   47]]\n",
            "Sensitivity: 0.3100, Specificity: 0.8656, ICBHI Score: 0.5878\n",
            "[Validation] Confusion Matrix:\n",
            " [[1451   55   73    0]\n",
            " [ 613   27    9    0]\n",
            " [ 358    8   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1450\n",
            "[VALIDATION] Sensitivity: 0.0391, Specificity: 0.9189, Avg ICBHI Score: 0.4790\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 72, Train Loss: 0.6646\n",
            "4-Class Confusion Matrix:\n",
            " [[1768  248   18    4]\n",
            " [ 683  504    9    6]\n",
            " [ 306   68   91   28]\n",
            " [ 154  134   29   46]]\n",
            "Sensitivity: 0.3115, Specificity: 0.8675, ICBHI Score: 0.5895\n",
            "[Validation] Confusion Matrix:\n",
            " [[1450   56   73    0]\n",
            " [ 613   27    9    0]\n",
            " [ 358    8   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1445\n",
            "[VALIDATION] Sensitivity: 0.0391, Specificity: 0.9183, Avg ICBHI Score: 0.4787\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 48.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 73, Train Loss: 0.6637\n",
            "4-Class Confusion Matrix:\n",
            " [[1767  249   18    4]\n",
            " [ 685  502    9    6]\n",
            " [ 307   66   92   28]\n",
            " [ 156  132   30   45]]\n",
            "Sensitivity: 0.3105, Specificity: 0.8670, ICBHI Score: 0.5888\n",
            "[Validation] Confusion Matrix:\n",
            " [[1447   59   73    0]\n",
            " [ 613   27    9    0]\n",
            " [ 358    8   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1441\n",
            "[VALIDATION] Sensitivity: 0.0391, Specificity: 0.9164, Avg ICBHI Score: 0.4777\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 74, Train Loss: 0.6629\n",
            "4-Class Confusion Matrix:\n",
            " [[1768  248   18    4]\n",
            " [ 681  506    9    6]\n",
            " [ 308   65   90   30]\n",
            " [ 156  132   30   45]]\n",
            "Sensitivity: 0.3115, Specificity: 0.8675, ICBHI Score: 0.5895\n",
            "[Validation] Confusion Matrix:\n",
            " [[1444   62   73    0]\n",
            " [ 612   28    9    0]\n",
            " [ 357    9   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1438\n",
            "[VALIDATION] Sensitivity: 0.0399, Specificity: 0.9145, Avg ICBHI Score: 0.4772\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 75, Train Loss: 0.6622\n",
            "4-Class Confusion Matrix:\n",
            " [[1768  248   18    4]\n",
            " [ 674  514    9    5]\n",
            " [ 308   64   91   30]\n",
            " [ 154  134   28   47]]\n",
            "Sensitivity: 0.3168, Specificity: 0.8675, ICBHI Score: 0.5922\n",
            "[Validation] Confusion Matrix:\n",
            " [[1437   69   73    0]\n",
            " [ 609   31    9    0]\n",
            " [ 356   10   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1435\n",
            "[VALIDATION] Sensitivity: 0.0425, Specificity: 0.9101, Avg ICBHI Score: 0.4763\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 76, Train Loss: 0.6615\n",
            "4-Class Confusion Matrix:\n",
            " [[1769  247   18    4]\n",
            " [ 675  513    9    5]\n",
            " [ 307   65   91   30]\n",
            " [ 155  133   28   47]]\n",
            "Sensitivity: 0.3163, Specificity: 0.8680, ICBHI Score: 0.5922\n",
            "[Validation] Confusion Matrix:\n",
            " [[1434   71   74    0]\n",
            " [ 607   33    9    0]\n",
            " [ 356   10   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1433\n",
            "[VALIDATION] Sensitivity: 0.0442, Specificity: 0.9082, Avg ICBHI Score: 0.4762\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 77, Train Loss: 0.6608\n",
            "4-Class Confusion Matrix:\n",
            " [[1773  243   18    4]\n",
            " [ 668  520    9    5]\n",
            " [ 307   64   91   31]\n",
            " [ 155  133   29   46]]\n",
            "Sensitivity: 0.3192, Specificity: 0.8700, ICBHI Score: 0.5946\n",
            "[Validation] Confusion Matrix:\n",
            " [[1431   74   74    0]\n",
            " [ 606   34    9    0]\n",
            " [ 356   10   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1431\n",
            "[VALIDATION] Sensitivity: 0.0450, Specificity: 0.9063, Avg ICBHI Score: 0.4756\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 78, Train Loss: 0.6602\n",
            "4-Class Confusion Matrix:\n",
            " [[1776  240   18    4]\n",
            " [ 664  525    9    4]\n",
            " [ 306   65   93   29]\n",
            " [ 156  132   29   46]]\n",
            "Sensitivity: 0.3226, Specificity: 0.8714, ICBHI Score: 0.5970\n",
            "[Validation] Confusion Matrix:\n",
            " [[1428   77   74    0]\n",
            " [ 605   35    9    0]\n",
            " [ 355   11   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1429\n",
            "[VALIDATION] Sensitivity: 0.0459, Specificity: 0.9044, Avg ICBHI Score: 0.4751\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 79, Train Loss: 0.6596\n",
            "4-Class Confusion Matrix:\n",
            " [[1779  237   18    4]\n",
            " [ 661  528    9    4]\n",
            " [ 306   65   93   29]\n",
            " [ 158  130   29   46]]\n",
            "Sensitivity: 0.3241, Specificity: 0.8729, ICBHI Score: 0.5985\n",
            "[Validation] Confusion Matrix:\n",
            " [[1426   78   75    0]\n",
            " [ 603   37    9    0]\n",
            " [ 355   11   19    0]\n",
            " [ 134    3    6    0]]\n",
            "Test Loss: 0.1428\n",
            "[VALIDATION] Sensitivity: 0.0476, Specificity: 0.9031, Avg ICBHI Score: 0.4753\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 80, Train Loss: 0.6591\n",
            "4-Class Confusion Matrix:\n",
            " [[1782  234   18    4]\n",
            " [ 659  530    9    4]\n",
            " [ 306   65   93   29]\n",
            " [ 157  131   29   46]]\n",
            "Sensitivity: 0.3251, Specificity: 0.8744, ICBHI Score: 0.5997\n",
            "[Validation] Confusion Matrix:\n",
            " [[1425   79   75    0]\n",
            " [ 602   38    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 133    4    6    0]]\n",
            "Test Loss: 0.1427\n",
            "[VALIDATION] Sensitivity: 0.0484, Specificity: 0.9025, Avg ICBHI Score: 0.4754\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 79, loss: 0.1427)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 81, Train Loss: 0.6586\n",
            "4-Class Confusion Matrix:\n",
            " [[1785  231   18    4]\n",
            " [ 657  533    8    4]\n",
            " [ 306   65   96   26]\n",
            " [ 157  131   29   46]]\n",
            "Sensitivity: 0.3280, Specificity: 0.8759, ICBHI Score: 0.6019\n",
            "[Validation] Confusion Matrix:\n",
            " [[1422   82   75    0]\n",
            " [ 599   41    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 133    4    6    0]]\n",
            "Test Loss: 0.1425\n",
            "[VALIDATION] Sensitivity: 0.0510, Specificity: 0.9006, Avg ICBHI Score: 0.4758\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 80, loss: 0.1425)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 82, Train Loss: 0.6581\n",
            "4-Class Confusion Matrix:\n",
            " [[1786  230   18    4]\n",
            " [ 656  534    8    4]\n",
            " [ 304   66   97   26]\n",
            " [ 157  131   29   46]]\n",
            "Sensitivity: 0.3290, Specificity: 0.8763, ICBHI Score: 0.6027\n",
            "[Validation] Confusion Matrix:\n",
            " [[1421   83   75    0]\n",
            " [ 599   41    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 133    4    6    0]]\n",
            "Test Loss: 0.1425\n",
            "[VALIDATION] Sensitivity: 0.0510, Specificity: 0.8999, Avg ICBHI Score: 0.4755\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 81, loss: 0.1425)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 83, Train Loss: 0.6577\n",
            "4-Class Confusion Matrix:\n",
            " [[1787  229   18    4]\n",
            " [ 657  533    8    4]\n",
            " [ 303   67   97   26]\n",
            " [ 156  132   29   46]]\n",
            "Sensitivity: 0.3285, Specificity: 0.8768, ICBHI Score: 0.6027\n",
            "[Validation] Confusion Matrix:\n",
            " [[1419   84   76    0]\n",
            " [ 595   45    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 133    4    6    0]]\n",
            "Test Loss: 0.1424\n",
            "[VALIDATION] Sensitivity: 0.0544, Specificity: 0.8987, Avg ICBHI Score: 0.4765\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 82, loss: 0.1424)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 84, Train Loss: 0.6573\n",
            "4-Class Confusion Matrix:\n",
            " [[1787  229   18    4]\n",
            " [ 656  534    8    4]\n",
            " [ 304   66   97   26]\n",
            " [ 156  132   29   46]]\n",
            "Sensitivity: 0.3290, Specificity: 0.8768, ICBHI Score: 0.6029\n",
            "[Validation] Confusion Matrix:\n",
            " [[1417   86   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 133    4    6    0]]\n",
            "Test Loss: 0.1423\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8974, Avg ICBHI Score: 0.4763\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 83, loss: 0.1423)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 47.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 85, Train Loss: 0.6570\n",
            "4-Class Confusion Matrix:\n",
            " [[1788  228   18    4]\n",
            " [ 655  535    8    4]\n",
            " [ 304   66   97   26]\n",
            " [ 156  132   29   46]]\n",
            "Sensitivity: 0.3294, Specificity: 0.8773, ICBHI Score: 0.6034\n",
            "[Validation] Confusion Matrix:\n",
            " [[1416   87   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 131    6    6    0]]\n",
            "Test Loss: 0.1423\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8968, Avg ICBHI Score: 0.4760\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 84, loss: 0.1423)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 86, Train Loss: 0.6566\n",
            "4-Class Confusion Matrix:\n",
            " [[1789  227   18    4]\n",
            " [ 656  534    8    4]\n",
            " [ 304   66   97   26]\n",
            " [ 155  133   29   46]]\n",
            "Sensitivity: 0.3290, Specificity: 0.8778, ICBHI Score: 0.6034\n",
            "[Validation] Confusion Matrix:\n",
            " [[1416   87   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1422\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8968, Avg ICBHI Score: 0.4760\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 85, loss: 0.1422)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 87, Train Loss: 0.6563\n",
            "4-Class Confusion Matrix:\n",
            " [[1792  224   18    4]\n",
            " [ 653  537    8    4]\n",
            " [ 301   69   97   26]\n",
            " [ 155  133   29   46]]\n",
            "Sensitivity: 0.3304, Specificity: 0.8793, ICBHI Score: 0.6049\n",
            "[Validation] Confusion Matrix:\n",
            " [[1416   87   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1422\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8968, Avg ICBHI Score: 0.4760\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 86, loss: 0.1422)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 88, Train Loss: 0.6561\n",
            "4-Class Confusion Matrix:\n",
            " [[1793  223   18    4]\n",
            " [ 651  539    8    4]\n",
            " [ 301   69   97   26]\n",
            " [ 155  133   29   46]]\n",
            "Sensitivity: 0.3314, Specificity: 0.8798, ICBHI Score: 0.6056\n",
            "[Validation] Confusion Matrix:\n",
            " [[1415   88   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1421\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8961, Avg ICBHI Score: 0.4757\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 87, loss: 0.1421)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 89, Train Loss: 0.6558\n",
            "4-Class Confusion Matrix:\n",
            " [[1792  224   18    4]\n",
            " [ 650  540    8    4]\n",
            " [ 301   69   97   26]\n",
            " [ 154  134   29   46]]\n",
            "Sensitivity: 0.3319, Specificity: 0.8793, ICBHI Score: 0.6056\n",
            "[Validation] Confusion Matrix:\n",
            " [[1415   88   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1421\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8961, Avg ICBHI Score: 0.4757\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 88, loss: 0.1421)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 90, Train Loss: 0.6556\n",
            "4-Class Confusion Matrix:\n",
            " [[1795  221   18    4]\n",
            " [ 649  542    7    4]\n",
            " [ 301   70   96   26]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3324, Specificity: 0.8808, ICBHI Score: 0.6066\n",
            "[Validation] Confusion Matrix:\n",
            " [[1414   89   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1421\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8955, Avg ICBHI Score: 0.4754\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 89, loss: 0.1421)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 46.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 91, Train Loss: 0.6554\n",
            "4-Class Confusion Matrix:\n",
            " [[1796  220   18    4]\n",
            " [ 651  540    7    4]\n",
            " [ 301   70   96   26]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3314, Specificity: 0.8813, ICBHI Score: 0.6063\n",
            "[Validation] Confusion Matrix:\n",
            " [[1413   90   75    1]\n",
            " [ 594   46    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1421\n",
            "[VALIDATION] Sensitivity: 0.0552, Specificity: 0.8949, Avg ICBHI Score: 0.4750\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 90, loss: 0.1421)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 44.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 92, Train Loss: 0.6552\n",
            "4-Class Confusion Matrix:\n",
            " [[1796  220   18    4]\n",
            " [ 650  541    7    4]\n",
            " [ 301   70   96   26]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3319, Specificity: 0.8813, ICBHI Score: 0.6066\n",
            "[Validation] Confusion Matrix:\n",
            " [[1413   90   75    1]\n",
            " [ 593   47    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0561, Specificity: 0.8949, Avg ICBHI Score: 0.4755\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 91, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 93, Train Loss: 0.6550\n",
            "4-Class Confusion Matrix:\n",
            " [[1795  220   19    4]\n",
            " [ 650  541    7    4]\n",
            " [ 301   70   96   26]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3319, Specificity: 0.8808, ICBHI Score: 0.6063\n",
            "[Validation] Confusion Matrix:\n",
            " [[1413   90   75    1]\n",
            " [ 593   47    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0561, Specificity: 0.8949, Avg ICBHI Score: 0.4755\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 92, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 94, Train Loss: 0.6549\n",
            "4-Class Confusion Matrix:\n",
            " [[1796  219   19    4]\n",
            " [ 648  543    7    4]\n",
            " [ 301   70   96   26]\n",
            " [ 154  134   29   46]]\n",
            "Sensitivity: 0.3328, Specificity: 0.8813, ICBHI Score: 0.6071\n",
            "[Validation] Confusion Matrix:\n",
            " [[1413   90   75    1]\n",
            " [ 593   47    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0561, Specificity: 0.8949, Avg ICBHI Score: 0.4755\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 93, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 95, Train Loss: 0.6548\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 648  543    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3328, Specificity: 0.8817, ICBHI Score: 0.6073\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 593   47    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0561, Specificity: 0.8942, Avg ICBHI Score: 0.4752\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 94, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 96, Train Loss: 0.6547\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 647  544    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3333, Specificity: 0.8817, ICBHI Score: 0.6075\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 592   48    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0569, Specificity: 0.8942, Avg ICBHI Score: 0.4756\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 95, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 44.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 97, Train Loss: 0.6546\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 646  545    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3338, Specificity: 0.8817, ICBHI Score: 0.6078\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 592   48    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0569, Specificity: 0.8942, Avg ICBHI Score: 0.4756\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 96, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 98, Train Loss: 0.6545\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 646  545    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3338, Specificity: 0.8817, ICBHI Score: 0.6078\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 592   48    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0569, Specificity: 0.8942, Avg ICBHI Score: 0.4756\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 97, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 44.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 99, Train Loss: 0.6545\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 646  545    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3338, Specificity: 0.8817, ICBHI Score: 0.6078\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 592   48    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0569, Specificity: 0.8942, Avg ICBHI Score: 0.4756\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 98, loss: 0.1420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 45.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Train Loss: 0.6545\n",
            "4-Class Confusion Matrix:\n",
            " [[1797  218   19    4]\n",
            " [ 646  545    7    4]\n",
            " [ 301   68   96   28]\n",
            " [ 153  135   29   46]]\n",
            "Sensitivity: 0.3338, Specificity: 0.8817, ICBHI Score: 0.6078\n",
            "[Validation] Confusion Matrix:\n",
            " [[1412   90   76    1]\n",
            " [ 592   48    9    0]\n",
            " [ 354   12   19    0]\n",
            " [ 130    7    6    0]]\n",
            "Test Loss: 0.1420\n",
            "[VALIDATION] Sensitivity: 0.0569, Specificity: 0.8942, Avg ICBHI Score: 0.4756\n",
            "##################################################\n",
            "💾 Saved checkpoint to /content/drive/MyDrive/ADV 프로젝트/checkpoints/LE_pth\n",
            "=> Saved best checkpoint (epoch: 99, loss: 0.1420)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Finetune/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>Finetune/icbhi_score</td><td>▁▁▁▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▅▅▅▆▆▇▇▇▇██████</td></tr><tr><td>Finetune/test_loss</td><td>▁▁▁▂▂▃▃▄▅▅▅▆▇▇▇█████▇▆▆▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Finetune/train_loss</td><td>█▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Finetune/train_sens</td><td>▃▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>Finetune/train_spec</td><td>█▆▅▅▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▂▂▂▂▃▃▄▅▅▅▅▅▅▅▆▆▆▆▆</td></tr><tr><td>Test/icbhi_score</td><td>█▇▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test/loss</td><td>▁▁▁▁▂▂▃▄▄▄▅▆▆▆▇▇▇█████▇▇▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test/sensitivity</td><td>▁▂▃▃▃▃▃▃▃▃▄▄▄▃▃▃▃▃▃▃▃▃▄▅▅▅▅▆▆▆▇▇▇███████</td></tr><tr><td>Test/specificity</td><td>█▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Finetune/epoch</td><td>99</td></tr><tr><td>Finetune/icbhi_score</td><td>0.60778</td></tr><tr><td>Finetune/test_loss</td><td>0.14199</td></tr><tr><td>Finetune/train_loss</td><td>0.65447</td></tr><tr><td>Finetune/train_sens</td><td>0.33382</td></tr><tr><td>Finetune/train_spec</td><td>0.88175</td></tr><tr><td>Test/icbhi_score</td><td>0.47558</td></tr><tr><td>Test/loss</td><td>0.14199</td></tr><tr><td>Test/sensitivity</td><td>0.05692</td></tr><tr><td>Test/specificity</td><td>0.89424</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SHS_aug(T.N)_LE_128bs_2507111625</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all/runs/xs6imddz</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/ICBHI_MSL_Ablation_all</a><br>Synced 5 W&B file(s), 450 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250711_072523-xs6imddz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Model Load\n",
        "# 위에서부터 했다면\n",
        "load_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "# 중간부터 이어서 한다면\n",
        "# load_ckpt_path = CHECKPOINT_PATH + \"/SHS_aug(T.N)_PT_128bs_top15_0.5ld_2507110810_best_checkpoint.pth.tar\"\n",
        "\n",
        "# 저장 경로\n",
        "save_ckpt_path = CHECKPOINT_PATH+\"/LE_pth\"\n",
        "\n",
        "# 재현성을 위한 시드 재설정\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# MoCo 모델 생성 및 체크포인트 로드\n",
        "model_eval = MoCo(\n",
        "    base_encoder=backbone_resnet,\n",
        "    dim_enc = args.out_dim,\n",
        "    dim_prj=args.dim_prj,\n",
        "    K=args.K,\n",
        "    m=args.momentum,\n",
        "    T=args.T,\n",
        "    top_k=args.top_k,\n",
        "    lambda_bce=args.lambda_bce\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(load_ckpt_path, map_location=device)\n",
        "model_eval.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "# 사전 학습된 encoder 추출\n",
        "encoder = model_eval.encoder_q.to(device)\n",
        "\n",
        "# 2. Dataset 정의\n",
        "# Dataset 정의는 이미 되어있음 - test_loader\n",
        "\n",
        "# 3. Fine-tuning을 위한 분류 모델 정의 ( Data 개수 작으므로, encoder 파라미터 frozen )\n",
        "class FineTuningModel(nn.Module):\n",
        "    def __init__(self, encoder, out_dim=args.out_dim, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        # 마지막 FC layer를 제외한 encoder의 모든 레이어 freeze\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 새로운 분류 헤드 추가\n",
        "        self.classifier = nn.Linear(out_dim, num_classes)\n",
        "        # self.classifier = nn.Sequential(\n",
        "        #     # nn.Linear(out_dim, out_dim),\n",
        "        #     # # nn.BatchNorm1d(512),\n",
        "        #     # nn.GELU(),\n",
        "        #     # nn.Dropout(0.5),\n",
        "        #     # nn.Linear(out_dim, 256),\n",
        "        #     # # nn.BatchNorm1d(512),\n",
        "        #     # nn.GELU(),\n",
        "        #     # nn.Dropout(0.5),\n",
        "        #     nn.Linear(out_dim, 64),\n",
        "        #     # nn.BatchNorm1d(256),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.5),\n",
        "        #     nn.Linear(64, num_classes)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.classifier(features)\n",
        "\n",
        "# 재현성을 위한 시드 재설정\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# 4. 모델, 손실 함수, 옵티마이저 설정\n",
        "model = FineTuningModel(encoder, out_dim = args.out_dim).to(device)\n",
        "##############################\n",
        "\n",
        "# # Ablation(3-1) LE -> BCE Loss\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "\n",
        "# # Ablation(3-2) LE -> Multi-label Focal Loss\n",
        "# criterion = MultiLabelFocalLoss(\n",
        "#     alpha=alpha_norm.to(device),  # 정규화된 값\n",
        "#     gamma=2.0,                    # hard label일 경우\n",
        "#     reduction='mean'\n",
        "# )\n",
        "# Ablation(3-2) LE -> Multi-label Focal Loss\n",
        "criterion = MultiLabelFocalLoss(\n",
        "    # alpha=alpha_norm.to(device),  # 정규화된 값\n",
        "    gamma=2.0,                    # hard label일 경우\n",
        "    reduction='mean'\n",
        ")\n",
        "\n",
        "############################\n",
        "# optimizer = optim.AdamW(model.classifier.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=args.lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=args.weight_decay,\n",
        "    nesterov=True\n",
        ")\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.ft_epochs, eta_min=1e-6)  # Linear Evaluation에서 epochs는 다르게 적용\n",
        "\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "######################### train_loader로 변경하였음 #########################\n",
        "######################### train_loader로 변경하였음 #########################\n",
        "######################### train_loader로 변경하였음 #########################\n",
        "\n",
        "# 5. Linear Evaluation\n",
        "for epoch in range(args.ft_epochs):\n",
        "\n",
        "    # ===============================\n",
        "    # 1. Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    pbar = tqdm(train_loader, desc='Linear Evaluation')\n",
        "    for i, (cycle, labels, _) in enumerate(pbar):\n",
        "        # Forward pass\n",
        "        cycle = cycle.cuda(args.gpu)\n",
        "        labels = labels.cuda(args.gpu)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        output = model(cycle)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss 계산\n",
        "        total_loss += loss.item() # loss : -> float\n",
        "\n",
        "        # 예측값과 실제값 저장 ( Ablation(4-1) threshold ?? )\n",
        "        predicted = (torch.sigmoid(output) > 0.5).float()\n",
        "        all_preds.append(predicted.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "        all_outputs.append(output.detach().cpu())\n",
        "\n",
        "    # train loss\n",
        "    train_loss = total_loss / len(finetune_loader)\n",
        "\n",
        "    # Concatenate\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()    # shape: [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy()  # shape: [N, 2]\n",
        "    all_output = torch.cat(all_outputs, dim=0).numpy()\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 2. 민감도/특이도 계산 (-> crakle+wheee 만 고려 = X)\n",
        "    # ===============================\n",
        "\n",
        "    #- origin-\n",
        "    # crackle_sens = crackle_spec = wheeze_sens = wheeze_spec = 0\n",
        "\n",
        "    # for i, label_name in enumerate(['Crackle', 'Wheeze']):\n",
        "    #     y_true = all_labels[:, i]\n",
        "    #     y_pred = all_preds[:, i]\n",
        "\n",
        "    #     cm = confusion_matrix(y_true, y_pred)  # [[TN, FP], [FN, TP]]\n",
        "    #     TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "    #     sensitivity = TP / (TP + FN + 1e-6)\n",
        "    #     specificity = TN / (TN + FP + 1e-6)\n",
        "\n",
        "    #     if i == 0:\n",
        "    #         crackle_sens = sensitivity\n",
        "    #         crackle_spec = specificity\n",
        "    #     elif i == 1:\n",
        "    #         wheeze_sens = sensitivity\n",
        "    #         wheeze_spec = specificity\n",
        "\n",
        "\n",
        "    # finetune_train_sens = (crackle_sens + wheeze_sens) / 2\n",
        "    # finetune_train_spec = (crackle_spec + wheeze_spec) / 2\n",
        "    # finetune_icbhi_score = (finetune_train_sens + finetune_train_spec) / 2\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
        "    # print(f\"  [Average] Sens: {(crackle_sens+wheeze_sens)/2:.4f}, Spec: {(crackle_spec+wheeze_spec)/2:.4f}, Score: {(crackle_sens+crackle_spec+wheeze_sens+wheeze_spec)/4:.4f}\")\n",
        "    # print(f\"  [Crackle] Sens: {crackle_sens:.4f}, Spec: {crackle_spec:.4f}, Score: {(crackle_sens+crackle_spec)/2:.4f}\")\n",
        "    # print(f\"  [Wheeze]  Sens: {wheeze_sens:.4f}, Spec: {wheeze_spec:.4f}, Score: {(wheeze_sens+wheeze_spec)/2:.4f}\")\n",
        "\n",
        "    # =====================================\n",
        "    # 2-Edited. Multi-class 민감도/특이도 계산\n",
        "    # =====================================\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import wandb\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    def multilabel_to_multiclass(y):\n",
        "        # Crackle → 1, Wheeze → 2, Both → 3, None → 0\n",
        "        y = np.array(y)\n",
        "        return y[:, 0] + y[:, 1]*2\n",
        "\n",
        "    def evaluate_multiclass_confusion(y_true, y_pred, class_names=[\"Normal\", \"Wheeze\", \"Crackle\", \"Both\"]):\n",
        "        y_true_cls = multilabel_to_multiclass(y_true)\n",
        "        y_pred_cls = multilabel_to_multiclass(y_pred)\n",
        "\n",
        "        cm = confusion_matrix(y_true_cls, y_pred_cls, labels=[0, 1, 2, 3])\n",
        "\n",
        "        # N_n: 정상 → 정상\n",
        "        N_n = cm[0, 0]\n",
        "        N_total = cm[0].sum()\n",
        "\n",
        "        # 이상 클래스 정답 수: W, C, B\n",
        "        W_total = cm[1].sum()\n",
        "        C_total = cm[2].sum()\n",
        "        B_total = cm[3].sum()\n",
        "\n",
        "        # 각각의 정답 → 정확한 예측만 고려\n",
        "        W_w = cm[1, 1]\n",
        "        C_c = cm[2, 2]\n",
        "        B_b = cm[3, 3]\n",
        "\n",
        "        SP = N_n / (N_total + 1e-6) #spec\n",
        "        SE = (W_w + C_c + B_b) / (W_total + C_total + B_total + 1e-6) #sense\n",
        "\n",
        "        AS = (SP + SE) / 2\n",
        "        HS = 2 * SP * SE / (SP + SE + 1e-6)\n",
        "\n",
        "        return cm, SE, SP, y_true_cls, y_pred_cls\n",
        "\n",
        "    def log_multiclass_conf_matrix_wandb(cm, class_names, sens, spec, normalize, tag):\n",
        "        # Normalize (비율) 옵션\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "            fmt = '.2f'\n",
        "            title = \"Confusion Matrix (Normalized %)\"\n",
        "        else:\n",
        "            fmt = 'd'\n",
        "            title = \"Confusion Matrix (Raw Count)\"\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(title)\n",
        "\n",
        "        icbhi_score = (sens + spec) / 2\n",
        "        # 우하단에 성능 출력\n",
        "        ax.text(\n",
        "            0.99, 0.15,\n",
        "            f\"Sensitivity: {sens*100:.2f}%\\nSpecificity: {spec*100:.2f}%\\nICBHI Score: {icbhi_score*100:.2f}%\",\n",
        "            ha='right', va='bottom',\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        # wandb.log({tag: wandb.Image(fig)})\n",
        "        # plt.close(fig)\n",
        "        return fig\n",
        "\n",
        "    # 1. 4-class Confusion Matrix 평가\n",
        "    class_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "    cm_4x4, finetune_train_sens, finetune_train_spec, y_true_cls, y_pred_cls = evaluate_multiclass_confusion(all_labels, all_preds, class_names)\n",
        "    finetune_icbhi_score = (finetune_train_sens + finetune_train_spec)/2\n",
        "\n",
        "    print(\"4-Class Confusion Matrix:\\n\", cm_4x4)\n",
        "    print(f\"Sensitivity: {finetune_train_sens:.4f}, Specificity: {finetune_train_spec:.4f}, ICBHI Score: {finetune_icbhi_score:.4f}\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Validation\n",
        "    # ===============================\n",
        "    test_loss, test_labels, test_preds = validate(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    precision = precision_score(test_labels, test_preds, average='macro')\n",
        "    recall = recall_score(test_labels, test_preds, average='macro')\n",
        "    f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "    test_cm_4x4, test_sens, test_spec, test_y_true_cls, test_y_pred_cls = evaluate_multiclass_confusion(test_labels, test_preds)\n",
        "    test_icbhi_score = (test_sens+test_spec)/2\n",
        "\n",
        "    print(\"[Validation] Confusion Matrix:\\n\", test_cm_4x4)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"[VALIDATION] Sensitivity: {test_sens:.4f}, Specificity: {test_spec:.4f}, Avg ICBHI Score: {(test_sens+test_spec)/2:.4f}\")\n",
        "    print(\"##################################################\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 4. Confusion Matrix\n",
        "    # ===============================\n",
        "\n",
        "    # 2. Finetune Count Confusion Matrix 시각화\n",
        "    fig_finetune_raw = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, finetune_train_sens, finetune_train_spec, normalize=False, tag=\"finetune_conf_matrix_raw\")\n",
        "    fig_finetune_norm = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, finetune_train_sens, finetune_train_spec, normalize=True, tag=\"finetune_conf_matrix_norm\")\n",
        "\n",
        "    # 3. Test Confusion Matrix 시각화\n",
        "    fig_test_raw = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=False, tag=\"test_conf_matrix_raw\")\n",
        "    fig_test_norm = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=True, tag=\"test_conf_matrix_norm\")\n",
        "\n",
        "    # 4. log dictionary 생성\n",
        "    wandb_log_dict = {\n",
        "        \"finetune_conf_matrix_raw\": wandb.Image(fig_finetune_raw),\n",
        "        \"finetune_conf_matrix_norm\": wandb.Image(fig_finetune_norm),\n",
        "        \"test_conf_matrix_raw\": wandb.Image(fig_test_raw),\n",
        "        \"test_conf_matrix_norm\": wandb.Image(fig_test_norm)\n",
        "    }\n",
        "\n",
        "    # =====================================\n",
        "    # 5. Checkpoint (Every 50 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        ckpt_path = save_ckpt_path + f\"{finetune_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"💾 Saved checkpoint to {save_ckpt_path}\")\n",
        "\n",
        "    # ===============================\n",
        "    # 6. Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = save_ckpt_path + f\"{finetune_project_name}_best.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")\n",
        "\n",
        "\n",
        "        # 🔹 Confusion Matrix Logging for Best\n",
        "        cm_best, sens_best, spec_best,_, _ = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_best_raw = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=False, tag=\"best_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_best_norm = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=True, tag=\"best_test_conf_matrix_norm\")\n",
        "\n",
        "        wandb_log_dict.update({\n",
        "            \"best_test_conf_matrix_raw\": wandb.Image(fig_best_raw),\n",
        "            \"best_test_conf_matrix_norm\": wandb.Image(fig_best_norm)\n",
        "        })\n",
        "\n",
        "\n",
        "    if epoch == args.ft_epochs - 1:\n",
        "        # 🔸 Confusion Matrix Logging for Last Epoch\n",
        "        cm_last, sens_last, spec_last, _, _  = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_last_raw = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=False, tag=\"last_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_last_norm = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=True, tag=\"last_test_conf_matrix_norm\")\n",
        "\n",
        "        wandb_log_dict.update({\n",
        "            \"last_test_conf_matrix_raw\": wandb.Image(fig_last_raw),\n",
        "            \"last_test_conf_matrix_norm\": wandb.Image(fig_last_norm)\n",
        "        })\n",
        "    # =====================================\n",
        "    # 7. Logging with wandb confusion matrix\n",
        "    # =====================================\n",
        "\n",
        "    # step 1. metrics\n",
        "    wandb.log({\n",
        "        # Train metrics\n",
        "        \"Finetune/epoch\": epoch,\n",
        "        \"Finetune/train_loss\": train_loss,\n",
        "        \"Finetune/test_loss\": test_loss,\n",
        "        \"Finetune/train_sens\": finetune_train_sens,\n",
        "        \"Finetune/train_spec\": finetune_train_spec,\n",
        "        \"Finetune/icbhi_score\": finetune_icbhi_score,\n",
        "\n",
        "        # Test metrics\n",
        "        \"Test/loss\": test_loss,\n",
        "        \"Test/sensitivity\": test_sens,\n",
        "        \"Test/specificity\": test_spec,\n",
        "        \"Test/icbhi_score\": test_icbhi_score\n",
        "    })\n",
        "\n",
        "    # step 2. Confusion matrix\n",
        "    wandb.log(wandb_log_dict)\n",
        "\n",
        "    plt.close(fig_finetune_raw)\n",
        "    plt.close(fig_finetune_norm)\n",
        "    plt.close(fig_test_raw)\n",
        "    plt.close(fig_test_norm)\n",
        "    if 'fig_best_raw' in locals(): plt.close(fig_best_raw)\n",
        "    if 'fig_best_norm' in locals(): plt.close(fig_best_norm)\n",
        "    if 'fig_last_raw' in locals(): plt.close(fig_last_raw)\n",
        "    if 'fig_last_norm' in locals(): plt.close(fig_last_norm)\n",
        "\n",
        "    # ===============================\n",
        "    # 8. Scheduler Step\n",
        "    # ===============================\n",
        "    scheduler.step()\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tvx1gKm9aOb6",
      "metadata": {
        "id": "tvx1gKm9aOb6"
      },
      "outputs": [],
      "source": [
        "#cm_last, class_names, sens_last, spec_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LQVziM_eb4SL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQVziM_eb4SL",
        "outputId": "648956b3-2310-4a65-9bca-8a3c7de8777a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101/1076/167/1412\n",
            "101/1177\n",
            "1412/1579\n",
            "0.9141886143464837/0.8942368582050431\n",
            "0.6021184291025216\n"
          ]
        }
      ],
      "source": [
        "TP = cm_last[1:, 1:].sum()\n",
        "FN = cm_last[1:, 0].sum()\n",
        "FP = cm_last[0, 1:].sum()\n",
        "TN = cm_last[0, 0]\n",
        "print( f\"{TP}/{FN}/{FP}/{TN}\" )\n",
        "\n",
        "sens =FN / (TP + FN + 1e-6)\n",
        "spec = TN / (TN + FP + 1e-6)\n",
        "\n",
        "print(f\"{TP}/{TP + FN}\")\n",
        "print(f\"{TN}/{TN + FP}\")\n",
        "print(f\"{sens}/{spec}\")\n",
        "print(f\"{(0.31+spec)/2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZO5KTgoxl1CN",
      "metadata": {
        "id": "ZO5KTgoxl1CN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r4Gl8GceqNA2",
      "metadata": {
        "id": "r4Gl8GceqNA2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# sigmoid 적용\n",
        "sigmoid_output = sigmoid(all_output)  # shape: (N, 2)\n",
        "all_preds = (sigmoid_output > 0.5).astype(int)  # binary prediction\n",
        "all_labels = all_labels.astype(int)  # 정수형으로 일치\n",
        "\n",
        "# 맞춘 것들\n",
        "correct_mask = np.all(all_preds == all_labels, axis=1)\n",
        "correct = np.concatenate([sigmoid_output, all_preds, all_labels], axis=1)[correct_mask]\n",
        "\n",
        "# 틀린 것들\n",
        "incorrect_mask = ~correct_mask\n",
        "incorrect_preds = all_preds[incorrect_mask]\n",
        "incorrect_labels = all_labels[incorrect_mask]\n",
        "incorrect_sigmoid = sigmoid_output[incorrect_mask]\n",
        "incorrect_concat = np.concatenate([incorrect_sigmoid, incorrect_preds, incorrect_labels], axis=1)\n",
        "\n",
        "# 그룹별 필터링\n",
        "def get_mismatched_by_label(target_label):\n",
        "    mask = np.all(incorrect_labels == target_label, axis=1)\n",
        "    return incorrect_concat[mask]\n",
        "\n",
        "# 각 그룹 추출\n",
        "wrong_10 = get_mismatched_by_label([1, 0])  # crackle\n",
        "wrong_01 = get_mismatched_by_label([0, 1])  # wheeze\n",
        "wrong_11 = get_mismatched_by_label([1, 1])  # both\n",
        "wrong_00 = get_mismatched_by_label([0, 0])  # normal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mXw6GqeTqzhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXw6GqeTqzhR",
        "outputId": "b37fe445-d593-4453-fa5b-a7d7a461ee76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ 맞춘 것들 (예: [sigmoid1, sigmoid2, pred1, pred2, label1, label2])\n",
            "[[0.32172132 0.1629401  0.         0.         0.         0.        ]\n",
            " [0.32437059 0.2771529  0.         0.         0.         0.        ]\n",
            " [0.17816621 0.22538932 0.         0.         0.         0.        ]\n",
            " ...\n",
            " [0.50630099 0.43154746 1.         0.         1.         0.        ]\n",
            " [0.47595024 0.27476594 0.         0.         0.         0.        ]\n",
            " [0.41970623 0.24918999 0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n✅ 맞춘 것들 (예: [sigmoid1, sigmoid2, pred1, pred2, label1, label2])\")\n",
        "print(correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15BfpFS8j3BR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15BfpFS8j3BR",
        "outputId": "d3e3bb17-cc81-4e6f-ed48-7aa640d30d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.29593617 0.34777364 0.         0.         0.         1.        ]\n",
            " [0.32172132 0.1629401  0.         0.         0.         0.        ]\n",
            " [0.13204643 0.40181404 0.         0.         0.         1.        ]\n",
            " [0.31525818 0.23810247 0.         0.         0.         1.        ]\n",
            " [0.30593544 0.38852662 0.         0.         0.         1.        ]\n",
            " [0.32437059 0.2771529  0.         0.         0.         0.        ]\n",
            " [0.17816621 0.22538932 0.         0.         0.         0.        ]\n",
            " [0.11464493 0.17234717 0.         0.         0.         0.        ]\n",
            " [0.14072876 0.2327621  0.         0.         0.         0.        ]\n",
            " [0.35452357 0.25264499 0.         0.         0.         0.        ]\n",
            " [0.34502637 0.32430628 0.         0.         0.         0.        ]\n",
            " [0.43028495 0.27930132 0.         0.         0.         0.        ]\n",
            " [0.35282046 0.25177518 0.         0.         0.         0.        ]\n",
            " [0.4255417  0.42603865 0.         0.         0.         0.        ]\n",
            " [0.4827233  0.25606814 0.         0.         1.         0.        ]\n",
            " [0.47433722 0.33466423 0.         0.         1.         0.        ]\n",
            " [0.39984882 0.22143947 0.         0.         0.         0.        ]\n",
            " [0.48177707 0.34183699 0.         0.         1.         0.        ]\n",
            " [0.48857078 0.33135709 0.         0.         1.         0.        ]\n",
            " [0.4987655  0.33870617 0.         0.         1.         0.        ]\n",
            " [0.49098763 0.32911798 0.         0.         1.         0.        ]\n",
            " [0.50764591 0.36238223 1.         0.         1.         0.        ]\n",
            " [0.49920484 0.34305003 0.         0.         1.         0.        ]\n",
            " [0.26811546 0.31627294 0.         0.         0.         1.        ]\n",
            " [0.4330045  0.27194044 0.         0.         0.         1.        ]\n",
            " [0.43022782 0.29101348 0.         0.         0.         0.        ]\n",
            " [0.46600798 0.3038004  0.         0.         0.         1.        ]\n",
            " [0.37791023 0.29359448 0.         0.         0.         1.        ]\n",
            " [0.40485591 0.36958778 0.         0.         0.         1.        ]\n",
            " [0.40391997 0.28342909 0.         0.         0.         1.        ]\n",
            " [0.32837459 0.31989953 0.         0.         0.         1.        ]\n",
            " [0.46108592 0.32025719 0.         0.         0.         0.        ]\n",
            " [0.38073364 0.22520986 0.         0.         1.         0.        ]\n",
            " [0.46572268 0.27899006 0.         0.         1.         0.        ]\n",
            " [0.43360496 0.39285687 0.         0.         1.         0.        ]\n",
            " [0.4381274  0.39499918 0.         0.         1.         0.        ]\n",
            " [0.44804823 0.35664952 0.         0.         1.         0.        ]\n",
            " [0.4389632  0.331352   0.         0.         1.         0.        ]\n",
            " [0.43821254 0.30874828 0.         0.         1.         0.        ]\n",
            " [0.44566604 0.35189784 0.         0.         0.         0.        ]\n",
            " [0.40958413 0.29670826 0.         0.         1.         0.        ]\n",
            " [0.52030218 0.28857327 1.         0.         1.         1.        ]\n",
            " [0.43422487 0.41685647 0.         0.         1.         1.        ]\n",
            " [0.39770851 0.38830006 0.         0.         1.         1.        ]\n",
            " [0.43059394 0.35844746 0.         0.         1.         1.        ]\n",
            " [0.46975848 0.35497227 0.         0.         1.         1.        ]\n",
            " [0.43102416 0.30612263 0.         0.         1.         1.        ]\n",
            " [0.43840545 0.33919388 0.         0.         1.         1.        ]\n",
            " [0.48529243 0.2932803  0.         0.         1.         0.        ]\n",
            " [0.56611335 0.23716316 1.         0.         1.         0.        ]\n",
            " [0.47135243 0.35506064 0.         0.         1.         0.        ]\n",
            " [0.47890854 0.32172158 0.         0.         1.         0.        ]\n",
            " [0.4639878  0.37064677 0.         0.         1.         0.        ]\n",
            " [0.49335036 0.35558799 0.         0.         1.         0.        ]\n",
            " [0.49339169 0.30578369 0.         0.         1.         0.        ]\n",
            " [0.49727136 0.32482669 0.         0.         1.         0.        ]\n",
            " [0.40807989 0.19489554 0.         0.         0.         0.        ]\n",
            " [0.54854435 0.24136367 1.         0.         1.         0.        ]\n",
            " [0.46703541 0.33490479 0.         0.         1.         0.        ]\n",
            " [0.42337644 0.28988981 0.         0.         1.         0.        ]\n",
            " [0.52086419 0.31086817 1.         0.         1.         0.        ]\n",
            " [0.46271744 0.27416703 0.         0.         1.         0.        ]\n",
            " [0.4856478  0.23182869 0.         0.         1.         0.        ]\n",
            " [0.51138729 0.28690818 1.         0.         1.         0.        ]\n",
            " [0.33709505 0.29360795 0.         0.         0.         0.        ]\n",
            " [0.56854212 0.31379873 1.         0.         0.         0.        ]\n",
            " [0.41848513 0.46476039 0.         0.         0.         0.        ]\n",
            " [0.38317499 0.42891404 0.         0.         0.         0.        ]\n",
            " [0.37975016 0.3466427  0.         0.         0.         0.        ]\n",
            " [0.32768196 0.35952234 0.         0.         0.         0.        ]\n",
            " [0.42798924 0.34549507 0.         0.         0.         0.        ]\n",
            " [0.33507261 0.33851475 0.         0.         0.         0.        ]\n",
            " [0.40279672 0.30421993 0.         0.         0.         0.        ]\n",
            " [0.56410903 0.26343635 1.         0.         1.         0.        ]\n",
            " [0.44492751 0.41802391 0.         0.         1.         1.        ]\n",
            " [0.3777352  0.38338766 0.         0.         0.         0.        ]\n",
            " [0.36937016 0.35023445 0.         0.         1.         0.        ]\n",
            " [0.4298785  0.35139382 0.         0.         1.         1.        ]\n",
            " [0.42811435 0.34049368 0.         0.         1.         0.        ]\n",
            " [0.37968525 0.36203229 0.         0.         1.         1.        ]\n",
            " [0.32757092 0.28199044 0.         0.         0.         0.        ]\n",
            " [0.47033715 0.28583589 0.         0.         0.         0.        ]\n",
            " [0.38920397 0.39039841 0.         0.         0.         0.        ]\n",
            " [0.32609838 0.35655504 0.         0.         1.         0.        ]\n",
            " [0.32738024 0.31015614 0.         0.         0.         0.        ]\n",
            " [0.35490185 0.32058522 0.         0.         0.         0.        ]\n",
            " [0.42100996 0.32439652 0.         0.         0.         0.        ]\n",
            " [0.43653643 0.35006154 0.         0.         1.         0.        ]\n",
            " [0.44862369 0.32881266 0.         0.         1.         0.        ]\n",
            " [0.44494838 0.33337694 0.         0.         1.         0.        ]\n",
            " [0.43731847 0.29380614 0.         0.         1.         1.        ]\n",
            " [0.48210624 0.28452292 0.         0.         1.         0.        ]\n",
            " [0.44489339 0.3342694  0.         0.         0.         1.        ]\n",
            " [0.46580651 0.27929065 0.         0.         1.         0.        ]\n",
            " [0.44294405 0.31633633 0.         0.         1.         0.        ]\n",
            " [0.45761847 0.34147581 0.         0.         1.         0.        ]\n",
            " [0.44343463 0.33016512 0.         0.         1.         0.        ]\n",
            " [0.44697306 0.33372417 0.         0.         1.         0.        ]\n",
            " [0.42793718 0.28159648 0.         0.         1.         0.        ]\n",
            " [0.48260704 0.28958678 0.         0.         1.         0.        ]\n",
            " [0.43601596 0.32972044 0.         0.         1.         0.        ]\n",
            " [0.50989664 0.28462768 1.         0.         1.         0.        ]\n",
            " [0.43958199 0.31605011 0.         0.         1.         0.        ]\n",
            " [0.38738126 0.27976537 0.         0.         1.         0.        ]\n",
            " [0.47452223 0.30775806 0.         0.         1.         0.        ]\n",
            " [0.50247473 0.3109788  1.         0.         1.         0.        ]\n",
            " [0.4511928  0.26532    0.         0.         1.         0.        ]\n",
            " [0.40527198 0.27841744 0.         0.         1.         0.        ]\n",
            " [0.4716906  0.32380477 0.         0.         1.         0.        ]\n",
            " [0.56464159 0.23855519 1.         0.         1.         0.        ]\n",
            " [0.50350529 0.2974841  1.         0.         1.         0.        ]\n",
            " [0.49513987 0.30389729 0.         0.         1.         0.        ]\n",
            " [0.49233544 0.26805329 0.         0.         1.         0.        ]\n",
            " [0.49813274 0.25004351 0.         0.         1.         0.        ]\n",
            " [0.42043364 0.22269689 0.         0.         1.         0.        ]\n",
            " [0.38946044 0.24892668 0.         0.         1.         0.        ]\n",
            " [0.47667968 0.27597487 0.         0.         1.         0.        ]\n",
            " [0.55053401 0.24264634 1.         0.         1.         0.        ]\n",
            " [0.48707703 0.21558635 0.         0.         1.         0.        ]\n",
            " [0.50910938 0.26484916 1.         0.         1.         0.        ]\n",
            " [0.46274954 0.34669128 0.         0.         1.         0.        ]\n",
            " [0.43517381 0.35561118 0.         0.         0.         0.        ]\n",
            " [0.44139668 0.33854532 0.         0.         1.         0.        ]\n",
            " [0.46039799 0.265737   0.         0.         0.         0.        ]\n",
            " [0.43222931 0.34084079 0.         0.         0.         0.        ]\n",
            " [0.53677279 0.32426155 1.         0.         1.         0.        ]\n",
            " [0.44988212 0.36107573 0.         0.         0.         0.        ]\n",
            " [0.43249512 0.34718803 0.         0.         0.         0.        ]\n",
            " [0.52857625 0.37043491 1.         0.         1.         0.        ]\n",
            " [0.50438958 0.35791418 1.         0.         1.         0.        ]\n",
            " [0.40914246 0.39323568 0.         0.         1.         0.        ]\n",
            " [0.53772581 0.4820618  1.         0.         1.         0.        ]\n",
            " [0.47286361 0.36939073 0.         0.         1.         0.        ]\n",
            " [0.4467788  0.37221289 0.         0.         1.         0.        ]\n",
            " [0.47173601 0.38625595 0.         0.         1.         0.        ]\n",
            " [0.43681166 0.35900411 0.         0.         1.         0.        ]\n",
            " [0.41921324 0.36103141 0.         0.         0.         0.        ]\n",
            " [0.39843822 0.35281166 0.         0.         0.         0.        ]\n",
            " [0.40001091 0.38226047 0.         0.         0.         0.        ]\n",
            " [0.28366202 0.29575294 0.         0.         0.         0.        ]\n",
            " [0.4237276  0.38747236 0.         0.         0.         0.        ]\n",
            " [0.38160381 0.39196178 0.         0.         0.         0.        ]\n",
            " [0.41217366 0.36968389 0.         0.         0.         0.        ]\n",
            " [0.4215391  0.39281249 0.         0.         0.         0.        ]\n",
            " [0.46305153 0.4663704  0.         0.         0.         0.        ]\n",
            " [0.48568571 0.34275103 0.         0.         1.         0.        ]\n",
            " [0.48527977 0.35424402 0.         0.         1.         0.        ]\n",
            " [0.52980477 0.37943888 1.         0.         1.         0.        ]\n",
            " [0.56493038 0.37406546 1.         0.         1.         0.        ]\n",
            " [0.45302144 0.32469282 0.         0.         1.         0.        ]\n",
            " [0.58204192 0.36947858 1.         0.         1.         0.        ]\n",
            " [0.53238922 0.35363322 1.         0.         1.         0.        ]\n",
            " [0.46247977 0.43778786 0.         0.         0.         0.        ]\n",
            " [0.41864064 0.30296779 0.         0.         0.         0.        ]\n",
            " [0.48485881 0.30096459 0.         0.         1.         0.        ]\n",
            " [0.45746481 0.36299077 0.         0.         0.         0.        ]\n",
            " [0.53712642 0.39984176 1.         0.         1.         1.        ]\n",
            " [0.47003987 0.3499079  0.         0.         1.         0.        ]\n",
            " [0.57247937 0.32894096 1.         0.         0.         0.        ]\n",
            " [0.5657348  0.34581834 1.         0.         0.         1.        ]\n",
            " [0.48257145 0.36772779 0.         0.         0.         0.        ]\n",
            " [0.53828835 0.3681668  1.         0.         1.         0.        ]\n",
            " [0.56258804 0.28990683 1.         0.         1.         0.        ]\n",
            " [0.59382164 0.43162429 1.         0.         1.         0.        ]\n",
            " [0.6084429  0.26982614 1.         0.         1.         0.        ]\n",
            " [0.50383723 0.33627769 1.         0.         1.         0.        ]\n",
            " [0.61447191 0.33697605 1.         0.         0.         0.        ]\n",
            " [0.57575279 0.26971924 1.         0.         1.         0.        ]\n",
            " [0.39378443 0.36909187 0.         0.         0.         0.        ]\n",
            " [0.48172799 0.28372449 0.         0.         1.         0.        ]\n",
            " [0.5510444  0.34803665 1.         0.         1.         0.        ]\n",
            " [0.55023223 0.33864802 1.         0.         1.         0.        ]\n",
            " [0.57274729 0.22960833 1.         0.         1.         0.        ]\n",
            " [0.49179405 0.27202356 0.         0.         1.         0.        ]\n",
            " [0.62083757 0.2569558  1.         0.         1.         0.        ]\n",
            " [0.58970839 0.30798313 1.         0.         1.         0.        ]\n",
            " [0.2644864  0.4394823  0.         0.         0.         0.        ]\n",
            " [0.33804187 0.32625523 0.         0.         0.         0.        ]\n",
            " [0.39339378 0.44652796 0.         0.         0.         0.        ]\n",
            " [0.29667753 0.33600336 0.         0.         0.         0.        ]\n",
            " [0.37214214 0.37283942 0.         0.         0.         0.        ]\n",
            " [0.32371676 0.34797505 0.         0.         0.         0.        ]\n",
            " [0.41368505 0.38122869 0.         0.         0.         0.        ]\n",
            " [0.41148278 0.40234336 0.         0.         0.         0.        ]\n",
            " [0.35693756 0.41494641 0.         0.         0.         0.        ]\n",
            " [0.3582724  0.28777945 0.         0.         1.         0.        ]\n",
            " [0.42907435 0.38786638 0.         0.         0.         0.        ]\n",
            " [0.3359766  0.33921528 0.         0.         1.         0.        ]\n",
            " [0.54856288 0.4387449  1.         0.         1.         0.        ]\n",
            " [0.39163306 0.38384283 0.         0.         0.         0.        ]\n",
            " [0.45675895 0.42119572 0.         0.         1.         0.        ]\n",
            " [0.47281882 0.32747707 0.         0.         1.         1.        ]\n",
            " [0.32583562 0.47487426 0.         0.         0.         0.        ]\n",
            " [0.42248327 0.3374086  0.         0.         0.         0.        ]\n",
            " [0.37239358 0.39973292 0.         0.         1.         0.        ]\n",
            " [0.42874032 0.38826549 0.         0.         1.         0.        ]\n",
            " [0.40003181 0.36010993 0.         0.         0.         0.        ]\n",
            " [0.40074289 0.37712988 0.         0.         0.         0.        ]\n",
            " [0.39130211 0.35446113 0.         0.         0.         0.        ]\n",
            " [0.39633372 0.3779923  0.         0.         0.         0.        ]\n",
            " [0.49109977 0.29894865 0.         0.         1.         1.        ]\n",
            " [0.55125076 0.42206407 1.         0.         1.         1.        ]\n",
            " [0.51698411 0.37091357 1.         0.         1.         1.        ]\n",
            " [0.48967758 0.39862475 0.         0.         1.         0.        ]\n",
            " [0.51028842 0.30115575 1.         0.         1.         0.        ]\n",
            " [0.50664258 0.3298519  1.         0.         1.         0.        ]\n",
            " [0.46462914 0.39964053 0.         0.         1.         0.        ]\n",
            " [0.49043235 0.40460402 0.         0.         1.         0.        ]\n",
            " [0.49551791 0.37634939 0.         0.         1.         0.        ]\n",
            " [0.39158612 0.33188188 0.         0.         0.         1.        ]\n",
            " [0.47144851 0.4226062  0.         0.         0.         1.        ]\n",
            " [0.45832697 0.3541863  0.         0.         0.         1.        ]\n",
            " [0.44889054 0.41904244 0.         0.         1.         1.        ]\n",
            " [0.41041249 0.44514301 0.         0.         0.         1.        ]\n",
            " [0.48654467 0.34307548 0.         0.         1.         1.        ]\n",
            " [0.44627699 0.40329382 0.         0.         1.         1.        ]\n",
            " [0.46675351 0.45412853 0.         0.         1.         1.        ]\n",
            " [0.4073548  0.36464992 0.         0.         0.         1.        ]\n",
            " [0.4856098  0.28982595 0.         0.         1.         0.        ]\n",
            " [0.46445715 0.33972308 0.         0.         1.         0.        ]\n",
            " [0.44417933 0.33207321 0.         0.         1.         0.        ]\n",
            " [0.44448924 0.4152182  0.         0.         1.         0.        ]\n",
            " [0.50057483 0.32700247 1.         0.         1.         0.        ]\n",
            " [0.49146843 0.3019532  0.         0.         1.         0.        ]\n",
            " [0.44038442 0.4041045  0.         0.         1.         0.        ]\n",
            " [0.45663154 0.41859162 0.         0.         1.         0.        ]\n",
            " [0.55997187 0.34397924 1.         0.         1.         0.        ]\n",
            " [0.51839268 0.31164363 1.         0.         0.         1.        ]\n",
            " [0.45988369 0.35062635 0.         0.         0.         1.        ]\n",
            " [0.4667477  0.36021426 0.         0.         0.         1.        ]\n",
            " [0.44983086 0.4441376  0.         0.         0.         1.        ]\n",
            " [0.51649773 0.31771618 1.         0.         0.         1.        ]\n",
            " [0.50112754 0.29923385 1.         0.         1.         0.        ]\n",
            " [0.44454727 0.42241094 0.         0.         1.         0.        ]\n",
            " [0.45214388 0.42675057 0.         0.         1.         0.        ]\n",
            " [0.55241114 0.33793584 1.         0.         1.         1.        ]\n",
            " [0.49446148 0.33774239 0.         0.         1.         0.        ]\n",
            " [0.57750994 0.37651098 1.         0.         1.         0.        ]\n",
            " [0.57415676 0.40274647 1.         0.         1.         0.        ]\n",
            " [0.5154193  0.46175516 1.         0.         1.         0.        ]\n",
            " [0.46138394 0.43681449 0.         0.         1.         0.        ]\n",
            " [0.52556145 0.29529977 1.         0.         1.         0.        ]\n",
            " [0.55047518 0.417303   1.         0.         1.         0.        ]\n",
            " [0.51537901 0.44928321 1.         0.         1.         0.        ]\n",
            " [0.51483864 0.31575346 1.         0.         1.         0.        ]\n",
            " [0.45274773 0.34962007 0.         0.         1.         1.        ]\n",
            " [0.49318039 0.47773966 0.         0.         1.         1.        ]\n",
            " [0.53725898 0.47308943 1.         0.         1.         1.        ]\n",
            " [0.47124809 0.45126137 0.         0.         1.         1.        ]\n",
            " [0.47226632 0.423893   0.         0.         1.         1.        ]\n",
            " [0.55249107 0.37511113 1.         0.         1.         0.        ]\n",
            " [0.42989835 0.45284185 0.         0.         1.         0.        ]\n",
            " [0.44686297 0.47277728 0.         0.         1.         0.        ]\n",
            " [0.51702863 0.40867668 1.         0.         1.         0.        ]\n",
            " [0.40384862 0.35527283 0.         0.         1.         1.        ]\n",
            " [0.48788381 0.49362716 0.         0.         1.         1.        ]\n",
            " [0.48905537 0.43694603 0.         0.         1.         1.        ]\n",
            " [0.49776179 0.41313666 0.         0.         1.         1.        ]\n",
            " [0.500247   0.45035774 1.         0.         1.         1.        ]\n",
            " [0.56180125 0.37785569 1.         0.         1.         1.        ]\n",
            " [0.48703459 0.43753532 0.         0.         0.         1.        ]\n",
            " [0.50471956 0.44529709 1.         0.         0.         1.        ]\n",
            " [0.4805814  0.31499872 0.         0.         0.         0.        ]\n",
            " [0.46079236 0.49951968 0.         0.         0.         0.        ]\n",
            " [0.53855258 0.50471503 1.         1.         0.         0.        ]\n",
            " [0.40151697 0.37820438 0.         0.         0.         0.        ]\n",
            " [0.4718298  0.39687535 0.         0.         0.         0.        ]\n",
            " [0.35004744 0.31426162 0.         0.         0.         0.        ]\n",
            " [0.36189479 0.33257815 0.         0.         0.         0.        ]\n",
            " [0.3076635  0.26997098 0.         0.         0.         0.        ]\n",
            " [0.53452027 0.3920671  1.         0.         0.         0.        ]\n",
            " [0.44226405 0.41874459 0.         0.         1.         0.        ]\n",
            " [0.4571878  0.31493425 0.         0.         1.         0.        ]\n",
            " [0.48939344 0.34106517 0.         0.         0.         0.        ]\n",
            " [0.47584453 0.30410779 0.         0.         0.         0.        ]\n",
            " [0.46114543 0.32173067 0.         0.         0.         0.        ]\n",
            " [0.43126091 0.29278368 0.         0.         0.         0.        ]\n",
            " [0.46279913 0.32718715 0.         0.         0.         0.        ]\n",
            " [0.44821528 0.32496327 0.         0.         0.         0.        ]\n",
            " [0.45152137 0.33502164 0.         0.         0.         0.        ]\n",
            " [0.46364078 0.44193903 0.         0.         0.         0.        ]\n",
            " [0.48249233 0.39285952 0.         0.         0.         0.        ]\n",
            " [0.46770641 0.3462764  0.         0.         0.         0.        ]\n",
            " [0.43981448 0.26195782 0.         0.         0.         0.        ]\n",
            " [0.49526674 0.32909003 0.         0.         0.         0.        ]\n",
            " [0.38929281 0.27113837 0.         0.         0.         0.        ]\n",
            " [0.51216137 0.47892565 1.         0.         1.         1.        ]\n",
            " [0.52188271 0.40117589 1.         0.         1.         1.        ]\n",
            " [0.54223663 0.46040922 1.         0.         1.         1.        ]\n",
            " [0.59424603 0.47775066 1.         0.         1.         0.        ]\n",
            " [0.5195086  0.41376898 1.         0.         0.         0.        ]\n",
            " [0.48216167 0.41138446 0.         0.         1.         0.        ]\n",
            " [0.4241448  0.34488395 0.         0.         1.         0.        ]\n",
            " [0.49966881 0.3066358  0.         0.         0.         1.        ]\n",
            " [0.47287503 0.44192818 0.         0.         0.         1.        ]\n",
            " [0.55912369 0.45504999 1.         0.         0.         0.        ]\n",
            " [0.44672531 0.37449533 0.         0.         0.         0.        ]\n",
            " [0.45071381 0.3797791  0.         0.         0.         1.        ]\n",
            " [0.46028805 0.37671295 0.         0.         0.         0.        ]\n",
            " [0.45927158 0.36151487 0.         0.         0.         0.        ]\n",
            " [0.51000249 0.38625902 1.         0.         1.         0.        ]\n",
            " [0.43874812 0.32239074 0.         0.         1.         0.        ]\n",
            " [0.51995462 0.39018843 1.         0.         1.         0.        ]\n",
            " [0.59839904 0.49159786 1.         0.         1.         0.        ]\n",
            " [0.4820891  0.38446411 0.         0.         1.         0.        ]\n",
            " [0.56092346 0.44799301 1.         0.         1.         0.        ]\n",
            " [0.49573937 0.3800759  0.         0.         1.         0.        ]\n",
            " [0.39549607 0.30990106 0.         0.         0.         0.        ]\n",
            " [0.4874121  0.38203067 0.         0.         0.         0.        ]\n",
            " [0.43979922 0.27139413 0.         0.         0.         0.        ]\n",
            " [0.5615539  0.45659038 1.         0.         0.         0.        ]\n",
            " [0.42526719 0.33312136 0.         0.         0.         0.        ]\n",
            " [0.49701539 0.39157957 0.         0.         0.         0.        ]\n",
            " [0.41797471 0.23733816 0.         0.         0.         0.        ]\n",
            " [0.40433767 0.31182426 0.         0.         0.         0.        ]\n",
            " [0.460783   0.35339645 0.         0.         0.         0.        ]\n",
            " [0.4570224  0.34278062 0.         0.         0.         0.        ]\n",
            " [0.43824843 0.31167921 0.         0.         0.         0.        ]\n",
            " [0.4308717  0.28063756 0.         0.         0.         0.        ]\n",
            " [0.47907269 0.32017371 0.         0.         0.         0.        ]\n",
            " [0.56635278 0.34420913 1.         0.         0.         0.        ]\n",
            " [0.47466874 0.26966208 0.         0.         0.         0.        ]\n",
            " [0.51331282 0.28366396 1.         0.         0.         0.        ]\n",
            " [0.225383   0.39086547 0.         0.         0.         0.        ]\n",
            " [0.3288902  0.14736404 0.         0.         0.         0.        ]\n",
            " [0.40270883 0.31659096 0.         0.         0.         0.        ]\n",
            " [0.25361204 0.38712734 0.         0.         0.         0.        ]\n",
            " [0.25572979 0.36002916 0.         0.         0.         0.        ]\n",
            " [0.26907289 0.25693977 0.         0.         0.         0.        ]\n",
            " [0.32388529 0.19713072 0.         0.         0.         0.        ]\n",
            " [0.42991358 0.36797601 0.         0.         0.         0.        ]\n",
            " [0.46735576 0.43380475 0.         0.         0.         0.        ]\n",
            " [0.26309279 0.36631408 0.         0.         0.         0.        ]\n",
            " [0.3105534  0.2466688  0.         0.         0.         0.        ]\n",
            " [0.333112   0.28452212 0.         0.         0.         0.        ]\n",
            " [0.30453616 0.25259805 0.         0.         0.         0.        ]\n",
            " [0.25131968 0.21013771 0.         0.         0.         0.        ]\n",
            " [0.22715439 0.42068303 0.         0.         0.         0.        ]\n",
            " [0.24414971 0.24765898 0.         0.         0.         0.        ]\n",
            " [0.27887568 0.26372185 0.         0.         0.         0.        ]\n",
            " [0.43018088 0.27969676 0.         0.         0.         0.        ]\n",
            " [0.51442307 0.38253906 1.         0.         0.         0.        ]\n",
            " [0.43566963 0.31892765 0.         0.         0.         0.        ]\n",
            " [0.44565898 0.32268003 0.         0.         0.         0.        ]\n",
            " [0.41210216 0.27340594 0.         0.         0.         0.        ]\n",
            " [0.42456016 0.28920567 0.         0.         0.         0.        ]\n",
            " [0.46067864 0.26416427 0.         0.         0.         0.        ]\n",
            " [0.44917798 0.3413595  0.         0.         0.         0.        ]\n",
            " [0.42327523 0.36504346 0.         0.         1.         0.        ]\n",
            " [0.42482737 0.34431526 0.         0.         0.         0.        ]\n",
            " [0.43829149 0.37567291 0.         0.         0.         0.        ]\n",
            " [0.42080161 0.32219413 0.         0.         0.         0.        ]\n",
            " [0.41852069 0.3348586  0.         0.         0.         0.        ]\n",
            " [0.42101738 0.30666286 0.         0.         0.         0.        ]\n",
            " [0.44647765 0.30136096 0.         0.         0.         0.        ]\n",
            " [0.45868212 0.42906004 0.         0.         0.         0.        ]\n",
            " [0.45219889 0.40221649 0.         0.         0.         0.        ]\n",
            " [0.45529053 0.2773504  0.         0.         1.         1.        ]\n",
            " [0.44367597 0.28436854 0.         0.         1.         0.        ]\n",
            " [0.42376596 0.31631041 0.         0.         1.         1.        ]\n",
            " [0.42002344 0.32556552 0.         0.         1.         0.        ]\n",
            " [0.54218984 0.38168007 1.         0.         1.         0.        ]\n",
            " [0.54577291 0.3943302  1.         0.         0.         0.        ]\n",
            " [0.56016004 0.46103927 1.         0.         0.         1.        ]\n",
            " [0.55305755 0.45183346 1.         0.         0.         1.        ]\n",
            " [0.52789629 0.3972677  1.         0.         0.         1.        ]\n",
            " [0.41992289 0.33774346 0.         0.         0.         1.        ]\n",
            " [0.50170934 0.39367265 1.         0.         0.         1.        ]\n",
            " [0.53613406 0.43918282 1.         0.         0.         1.        ]\n",
            " [0.48934531 0.56588936 0.         1.         0.         0.        ]\n",
            " [0.31803942 0.3282018  0.         0.         0.         0.        ]\n",
            " [0.44257456 0.49290499 0.         0.         0.         0.        ]\n",
            " [0.50843221 0.4588933  1.         0.         0.         1.        ]\n",
            " [0.48905301 0.47156078 0.         0.         0.         1.        ]\n",
            " [0.4419795  0.36605299 0.         0.         0.         1.        ]\n",
            " [0.483372   0.47527379 0.         0.         0.         0.        ]\n",
            " [0.52677888 0.53232098 1.         1.         0.         1.        ]\n",
            " [0.43443871 0.39513713 0.         0.         0.         1.        ]\n",
            " [0.41788161 0.44681984 0.         0.         0.         0.        ]\n",
            " [0.56491977 0.55408138 1.         1.         1.         0.        ]\n",
            " [0.57011932 0.5801174  1.         1.         0.         0.        ]\n",
            " [0.56451243 0.63262075 1.         1.         1.         1.        ]\n",
            " [0.54980505 0.58211261 1.         1.         1.         1.        ]\n",
            " [0.53878868 0.5662306  1.         1.         1.         1.        ]\n",
            " [0.46832117 0.52921146 0.         1.         1.         1.        ]\n",
            " [0.45956948 0.53052503 0.         1.         0.         1.        ]\n",
            " [0.46256119 0.52150029 0.         1.         0.         1.        ]\n",
            " [0.46058464 0.52488571 0.         1.         0.         1.        ]\n",
            " [0.41901314 0.49690145 0.         0.         0.         0.        ]\n",
            " [0.38158739 0.50421077 0.         1.         0.         1.        ]\n",
            " [0.46945223 0.52171469 0.         1.         0.         1.        ]\n",
            " [0.44907025 0.3751919  0.         0.         0.         1.        ]\n",
            " [0.43152323 0.51010674 0.         1.         0.         1.        ]\n",
            " [0.43192852 0.53474641 0.         1.         0.         1.        ]\n",
            " [0.45956665 0.52565545 0.         1.         0.         1.        ]\n",
            " [0.36685058 0.48605767 0.         0.         0.         1.        ]\n",
            " [0.43724352 0.47345984 0.         0.         0.         1.        ]\n",
            " [0.40443361 0.38113496 0.         0.         0.         1.        ]\n",
            " [0.49626222 0.41454548 0.         0.         1.         1.        ]\n",
            " [0.50071281 0.40643466 1.         0.         1.         1.        ]\n",
            " [0.52650774 0.29844671 1.         0.         1.         1.        ]\n",
            " [0.51940638 0.26119247 1.         0.         1.         0.        ]\n",
            " [0.48176718 0.37855098 0.         0.         1.         1.        ]\n",
            " [0.52234238 0.2947655  1.         0.         1.         0.        ]\n",
            " [0.38901922 0.43817133 0.         0.         0.         1.        ]\n",
            " [0.48253885 0.44854933 0.         0.         1.         1.        ]\n",
            " [0.46646872 0.46743983 0.         0.         1.         1.        ]\n",
            " [0.49821103 0.40618172 0.         0.         1.         1.        ]\n",
            " [0.49552125 0.28225717 0.         0.         1.         0.        ]\n",
            " [0.45206934 0.48024067 0.         0.         1.         1.        ]\n",
            " [0.51573598 0.36368883 1.         0.         0.         0.        ]\n",
            " [0.40411493 0.36005855 0.         0.         1.         1.        ]\n",
            " [0.45364308 0.38449022 0.         0.         1.         1.        ]\n",
            " [0.45766503 0.4056496  0.         0.         1.         1.        ]\n",
            " [0.46640116 0.3170602  0.         0.         1.         1.        ]\n",
            " [0.49520719 0.28390887 0.         0.         1.         0.        ]\n",
            " [0.45291427 0.33499128 0.         0.         1.         1.        ]\n",
            " [0.51510972 0.26528746 1.         0.         1.         0.        ]\n",
            " [0.50388843 0.47543275 1.         0.         1.         1.        ]\n",
            " [0.47712013 0.45786712 0.         0.         1.         1.        ]\n",
            " [0.48342338 0.45009115 0.         0.         1.         1.        ]\n",
            " [0.51016134 0.43522045 1.         0.         1.         1.        ]\n",
            " [0.55637461 0.40625837 1.         0.         1.         0.        ]\n",
            " [0.50316972 0.43686816 1.         0.         1.         1.        ]\n",
            " [0.45249537 0.30701762 0.         0.         1.         0.        ]\n",
            " [0.49247208 0.38737196 0.         0.         0.         1.        ]\n",
            " [0.46593106 0.4412705  0.         0.         1.         1.        ]\n",
            " [0.47726619 0.42320839 0.         0.         1.         1.        ]\n",
            " [0.47840774 0.41303489 0.         0.         1.         1.        ]\n",
            " [0.46646148 0.37413666 0.         0.         1.         0.        ]\n",
            " [0.46704191 0.41938415 0.         0.         1.         1.        ]\n",
            " [0.48213384 0.29811493 0.         0.         1.         0.        ]\n",
            " [0.45596009 0.18412352 0.         0.         0.         0.        ]\n",
            " [0.35950395 0.28655609 0.         0.         0.         0.        ]\n",
            " [0.40659556 0.32631847 0.         0.         0.         0.        ]\n",
            " [0.42757738 0.31817368 0.         0.         0.         0.        ]\n",
            " [0.35252237 0.27880868 0.         0.         0.         0.        ]\n",
            " [0.3892405  0.28103203 0.         0.         0.         0.        ]\n",
            " [0.37839639 0.29834795 0.         0.         0.         0.        ]\n",
            " [0.33846    0.27787715 0.         0.         0.         0.        ]\n",
            " [0.37958127 0.3341921  0.         0.         0.         0.        ]\n",
            " [0.3293668  0.25896695 0.         0.         0.         0.        ]\n",
            " [0.34224933 0.31073385 0.         0.         0.         0.        ]\n",
            " [0.37400001 0.30304193 0.         0.         0.         0.        ]\n",
            " [0.42741016 0.307661   0.         0.         0.         1.        ]\n",
            " [0.4479382  0.31818849 0.         0.         0.         0.        ]\n",
            " [0.32045075 0.23381117 0.         0.         0.         0.        ]\n",
            " [0.35434005 0.20035371 0.         0.         0.         0.        ]\n",
            " [0.31455007 0.25405341 0.         0.         0.         0.        ]\n",
            " [0.33092785 0.27260074 0.         0.         0.         0.        ]\n",
            " [0.38362163 0.29997805 0.         0.         0.         0.        ]\n",
            " [0.34789342 0.26486525 0.         0.         0.         0.        ]\n",
            " [0.33507955 0.33912554 0.         0.         0.         0.        ]\n",
            " [0.32051495 0.25105631 0.         0.         0.         0.        ]\n",
            " [0.34419858 0.2811119  0.         0.         0.         0.        ]\n",
            " [0.39442548 0.42717054 0.         0.         0.         0.        ]\n",
            " [0.34400746 0.33603984 0.         0.         0.         0.        ]\n",
            " [0.27740046 0.29459125 0.         0.         0.         1.        ]\n",
            " [0.35960019 0.35315761 0.         0.         0.         1.        ]\n",
            " [0.39393109 0.36338836 0.         0.         0.         0.        ]\n",
            " [0.43157127 0.34524968 0.         0.         0.         0.        ]\n",
            " [0.41838452 0.2637234  0.         0.         0.         0.        ]\n",
            " [0.41239122 0.35575694 0.         0.         0.         0.        ]\n",
            " [0.33606848 0.43823603 0.         0.         0.         0.        ]\n",
            " [0.38852164 0.41405174 0.         0.         0.         0.        ]\n",
            " [0.38482183 0.3377375  0.         0.         0.         0.        ]\n",
            " [0.36259601 0.37367851 0.         0.         0.         0.        ]\n",
            " [0.36648184 0.35307592 0.         0.         0.         0.        ]\n",
            " [0.35533366 0.37058082 0.         0.         0.         0.        ]\n",
            " [0.4017421  0.37491891 0.         0.         0.         0.        ]\n",
            " [0.2736927  0.25390229 0.         0.         0.         0.        ]\n",
            " [0.41130555 0.40003204 0.         0.         0.         1.        ]\n",
            " [0.34358114 0.29508728 0.         0.         0.         1.        ]\n",
            " [0.30699617 0.38432077 0.         0.         0.         1.        ]\n",
            " [0.35356835 0.39474881 0.         0.         0.         1.        ]\n",
            " [0.37434036 0.35683206 0.         0.         0.         1.        ]\n",
            " [0.30196339 0.18209194 0.         0.         0.         0.        ]\n",
            " [0.36748216 0.28465298 0.         0.         0.         0.        ]\n",
            " [0.3359299  0.27596664 0.         0.         0.         0.        ]\n",
            " [0.31987259 0.21263202 0.         0.         0.         0.        ]\n",
            " [0.30192646 0.22678263 0.         0.         0.         0.        ]\n",
            " [0.4019815  0.23478976 0.         0.         0.         0.        ]\n",
            " [0.26839471 0.23279534 0.         0.         0.         0.        ]\n",
            " [0.31951657 0.24692637 0.         0.         0.         0.        ]\n",
            " [0.28507891 0.26643598 0.         0.         0.         0.        ]\n",
            " [0.48299941 0.2391208  0.         0.         0.         0.        ]\n",
            " [0.48656607 0.25799653 0.         0.         0.         0.        ]\n",
            " [0.4345907  0.26501882 0.         0.         0.         0.        ]\n",
            " [0.38552803 0.24698851 0.         0.         0.         0.        ]\n",
            " [0.30215666 0.25978616 0.         0.         0.         0.        ]\n",
            " [0.34936154 0.30008709 0.         0.         0.         0.        ]\n",
            " [0.38309386 0.29230234 0.         0.         0.         0.        ]\n",
            " [0.35266802 0.20756029 0.         0.         0.         0.        ]\n",
            " [0.42981756 0.17977406 0.         0.         0.         0.        ]\n",
            " [0.48886177 0.23879831 0.         0.         0.         0.        ]\n",
            " [0.49328667 0.26219991 0.         0.         0.         0.        ]\n",
            " [0.3244004  0.21663266 0.         0.         0.         0.        ]\n",
            " [0.40386528 0.25947142 0.         0.         0.         0.        ]\n",
            " [0.27771655 0.25051349 0.         0.         0.         0.        ]\n",
            " [0.50386971 0.2383617  1.         0.         0.         0.        ]\n",
            " [0.45727614 0.23032591 0.         0.         0.         0.        ]\n",
            " [0.30214968 0.23814715 0.         0.         0.         0.        ]\n",
            " [0.36296746 0.20600878 0.         0.         0.         0.        ]\n",
            " [0.35125792 0.20503655 0.         0.         0.         0.        ]\n",
            " [0.24723671 0.26389554 0.         0.         0.         0.        ]\n",
            " [0.26182532 0.27583855 0.         0.         0.         0.        ]\n",
            " [0.49379253 0.24261214 0.         0.         0.         0.        ]\n",
            " [0.28872901 0.20021458 0.         0.         0.         0.        ]\n",
            " [0.2903361  0.21559398 0.         0.         0.         0.        ]\n",
            " [0.30037618 0.23561306 0.         0.         0.         0.        ]\n",
            " [0.10635775 0.29306978 0.         0.         0.         0.        ]\n",
            " [0.48847178 0.23443966 0.         0.         0.         0.        ]\n",
            " [0.41091427 0.32935092 0.         0.         0.         0.        ]\n",
            " [0.45373312 0.34767076 0.         0.         0.         0.        ]\n",
            " [0.3844223  0.307852   0.         0.         0.         0.        ]\n",
            " [0.4379597  0.30745074 0.         0.         0.         0.        ]\n",
            " [0.450351   0.32283053 0.         0.         0.         0.        ]\n",
            " [0.46622545 0.32925498 0.         0.         0.         0.        ]\n",
            " [0.45561954 0.33542874 0.         0.         0.         0.        ]\n",
            " [0.48635685 0.34047499 0.         0.         0.         0.        ]\n",
            " [0.48425835 0.3688347  0.         0.         0.         0.        ]\n",
            " [0.45887226 0.32442665 0.         0.         0.         0.        ]\n",
            " [0.42761791 0.29104221 0.         0.         0.         0.        ]\n",
            " [0.33935347 0.28900808 0.         0.         0.         0.        ]\n",
            " [0.45816684 0.31109762 0.         0.         0.         0.        ]\n",
            " [0.46818995 0.37636164 0.         0.         0.         0.        ]\n",
            " [0.48079604 0.33576921 0.         0.         0.         0.        ]\n",
            " [0.44381583 0.3046588  0.         0.         0.         0.        ]\n",
            " [0.48065123 0.3811031  0.         0.         0.         0.        ]\n",
            " [0.46382135 0.35122645 0.         0.         0.         0.        ]\n",
            " [0.49986979 0.32388273 0.         0.         0.         0.        ]\n",
            " [0.40060678 0.35814628 0.         0.         0.         0.        ]\n",
            " [0.44856966 0.32677639 0.         0.         0.         0.        ]\n",
            " [0.46329162 0.27154016 0.         0.         0.         0.        ]\n",
            " [0.43330401 0.26336744 0.         0.         0.         0.        ]\n",
            " [0.4460583  0.25553089 0.         0.         0.         0.        ]\n",
            " [0.46391812 0.37001181 0.         0.         0.         0.        ]\n",
            " [0.45475602 0.35757384 0.         0.         0.         0.        ]\n",
            " [0.47100708 0.32839164 0.         0.         0.         0.        ]\n",
            " [0.44721231 0.33317575 0.         0.         0.         0.        ]\n",
            " [0.47195524 0.38652906 0.         0.         0.         0.        ]\n",
            " [0.37346116 0.24685436 0.         0.         0.         0.        ]\n",
            " [0.4612107  0.37866348 0.         0.         0.         0.        ]\n",
            " [0.40455398 0.32249716 0.         0.         0.         0.        ]\n",
            " [0.41106695 0.40708363 0.         0.         0.         0.        ]\n",
            " [0.4733668  0.36684296 0.         0.         0.         0.        ]\n",
            " [0.4189944  0.30900136 0.         0.         0.         0.        ]\n",
            " [0.43269792 0.32284632 0.         0.         0.         0.        ]\n",
            " [0.39618599 0.33948433 0.         0.         0.         0.        ]\n",
            " [0.47705677 0.35055614 0.         0.         0.         0.        ]\n",
            " [0.34487107 0.22266199 0.         0.         0.         0.        ]\n",
            " [0.44336575 0.44377783 0.         0.         0.         0.        ]\n",
            " [0.43506074 0.32188693 0.         0.         0.         0.        ]\n",
            " [0.34857365 0.23436852 0.         0.         0.         0.        ]\n",
            " [0.35186079 0.2919713  0.         0.         0.         0.        ]\n",
            " [0.43240184 0.4117586  0.         0.         0.         0.        ]\n",
            " [0.44051179 0.33707145 0.         0.         0.         0.        ]\n",
            " [0.43502221 0.40731043 0.         0.         0.         0.        ]\n",
            " [0.43523815 0.32226562 0.         0.         0.         0.        ]\n",
            " [0.46204591 0.43180996 0.         0.         0.         0.        ]\n",
            " [0.34370324 0.19273649 0.         0.         0.         0.        ]\n",
            " [0.44478369 0.37192476 0.         0.         0.         0.        ]\n",
            " [0.45879972 0.29170525 0.         0.         0.         0.        ]\n",
            " [0.43125641 0.32617083 0.         0.         1.         0.        ]\n",
            " [0.48828378 0.33844748 0.         0.         1.         0.        ]\n",
            " [0.47350207 0.33285034 0.         0.         1.         0.        ]\n",
            " [0.46006668 0.34065247 0.         0.         1.         0.        ]\n",
            " [0.46595261 0.26697603 0.         0.         0.         0.        ]\n",
            " [0.47842246 0.34465337 0.         0.         1.         0.        ]\n",
            " [0.44629821 0.22715217 0.         0.         1.         0.        ]\n",
            " [0.40911689 0.26252586 0.         0.         1.         0.        ]\n",
            " [0.42684963 0.28795484 0.         0.         1.         0.        ]\n",
            " [0.4513725  0.30185372 0.         0.         1.         0.        ]\n",
            " [0.43710259 0.31290561 0.         0.         1.         0.        ]\n",
            " [0.41529974 0.24175555 0.         0.         1.         0.        ]\n",
            " [0.44146079 0.32530817 0.         0.         1.         0.        ]\n",
            " [0.39234471 0.24801156 0.         0.         1.         0.        ]\n",
            " [0.43236667 0.28668013 0.         0.         1.         0.        ]\n",
            " [0.44065583 0.28994811 0.         0.         1.         0.        ]\n",
            " [0.4522526  0.25857753 0.         0.         0.         0.        ]\n",
            " [0.44315797 0.29308659 0.         0.         0.         0.        ]\n",
            " [0.44572559 0.38703588 0.         0.         0.         0.        ]\n",
            " [0.4465656  0.37576815 0.         0.         0.         0.        ]\n",
            " [0.45076618 0.33186659 0.         0.         0.         0.        ]\n",
            " [0.34131503 0.2185905  0.         0.         0.         0.        ]\n",
            " [0.39157698 0.24728326 0.         0.         0.         0.        ]\n",
            " [0.49101096 0.3675403  0.         0.         0.         0.        ]\n",
            " [0.45807588 0.24749577 0.         0.         0.         0.        ]\n",
            " [0.46830475 0.3198716  0.         0.         0.         0.        ]\n",
            " [0.52126986 0.20414034 1.         0.         0.         0.        ]\n",
            " [0.37447035 0.36723912 0.         0.         0.         0.        ]\n",
            " [0.50303549 0.23260528 1.         0.         0.         0.        ]\n",
            " [0.46006387 0.34296352 0.         0.         0.         0.        ]\n",
            " [0.47327873 0.34791404 0.         0.         0.         0.        ]\n",
            " [0.49735403 0.2208861  0.         0.         0.         0.        ]\n",
            " [0.45664465 0.35437471 0.         0.         0.         0.        ]\n",
            " [0.49202275 0.27470186 0.         0.         0.         0.        ]\n",
            " [0.46316111 0.38155475 0.         0.         0.         0.        ]\n",
            " [0.47182983 0.36804175 0.         0.         0.         0.        ]\n",
            " [0.30264321 0.39970371 0.         0.         0.         0.        ]\n",
            " [0.38132015 0.26268789 0.         0.         0.         0.        ]\n",
            " [0.37070709 0.36055633 0.         0.         0.         0.        ]\n",
            " [0.4102878  0.27593529 0.         0.         0.         0.        ]\n",
            " [0.41556296 0.29857978 0.         0.         0.         0.        ]\n",
            " [0.49181056 0.28131479 0.         0.         0.         0.        ]\n",
            " [0.39314979 0.31994808 0.         0.         0.         0.        ]\n",
            " [0.22482489 0.18518223 0.         0.         0.         0.        ]\n",
            " [0.35806888 0.31000084 0.         0.         0.         0.        ]\n",
            " [0.38083458 0.25853333 0.         0.         0.         0.        ]\n",
            " [0.25849968 0.14311607 0.         0.         0.         0.        ]\n",
            " [0.42144826 0.34212443 0.         0.         0.         0.        ]\n",
            " [0.36446738 0.31414491 0.         0.         0.         0.        ]\n",
            " [0.36712024 0.32343331 0.         0.         0.         0.        ]\n",
            " [0.42607722 0.33218184 0.         0.         0.         0.        ]\n",
            " [0.3014234  0.3919538  0.         0.         0.         1.        ]\n",
            " [0.48059562 0.41992995 0.         0.         0.         1.        ]\n",
            " [0.36669272 0.27970114 0.         0.         0.         0.        ]\n",
            " [0.36700812 0.26109031 0.         0.         0.         0.        ]\n",
            " [0.47505164 0.39714634 0.         0.         0.         0.        ]\n",
            " [0.41474083 0.32105616 0.         0.         0.         0.        ]\n",
            " [0.33077955 0.28831336 0.         0.         0.         1.        ]\n",
            " [0.45897987 0.3960788  0.         0.         0.         0.        ]\n",
            " [0.36138105 0.27107224 0.         0.         0.         0.        ]\n",
            " [0.34983897 0.24412012 0.         0.         0.         0.        ]\n",
            " [0.39357704 0.32060441 0.         0.         0.         0.        ]\n",
            " [0.45632213 0.42583582 0.         0.         0.         1.        ]\n",
            " [0.32107124 0.50673759 0.         1.         0.         1.        ]\n",
            " [0.40077725 0.46033704 0.         0.         0.         1.        ]\n",
            " [0.49166125 0.42463052 0.         0.         0.         1.        ]\n",
            " [0.44011372 0.37204847 0.         0.         0.         1.        ]\n",
            " [0.48807594 0.44000748 0.         0.         0.         0.        ]\n",
            " [0.43126261 0.30234104 0.         0.         0.         0.        ]\n",
            " [0.46786916 0.3634764  0.         0.         0.         0.        ]\n",
            " [0.37379649 0.27437973 0.         0.         0.         0.        ]\n",
            " [0.34155849 0.32905304 0.         0.         0.         0.        ]\n",
            " [0.26588485 0.18572177 0.         0.         0.         0.        ]\n",
            " [0.38715419 0.35006639 0.         0.         0.         0.        ]\n",
            " [0.43956557 0.31543157 0.         0.         0.         0.        ]\n",
            " [0.34996241 0.29095137 0.         0.         0.         0.        ]\n",
            " [0.35964108 0.27153385 0.         0.         0.         0.        ]\n",
            " [0.32907873 0.21611452 0.         0.         0.         0.        ]\n",
            " [0.35256505 0.22082774 0.         0.         0.         0.        ]\n",
            " [0.29372707 0.16748448 0.         0.         0.         0.        ]\n",
            " [0.38800859 0.22117576 0.         0.         0.         0.        ]\n",
            " [0.42283502 0.27290195 0.         0.         0.         0.        ]\n",
            " [0.47332019 0.43505514 0.         0.         0.         1.        ]\n",
            " [0.45849931 0.38759908 0.         0.         0.         1.        ]\n",
            " [0.42237779 0.37550911 0.         0.         0.         1.        ]\n",
            " [0.44608516 0.42938131 0.         0.         0.         1.        ]\n",
            " [0.34175146 0.2448335  0.         0.         0.         1.        ]\n",
            " [0.35442555 0.24058947 0.         0.         0.         0.        ]\n",
            " [0.44647622 0.31033915 0.         0.         0.         1.        ]\n",
            " [0.29439247 0.26354405 0.         0.         0.         0.        ]\n",
            " [0.29364437 0.25542518 0.         0.         0.         0.        ]\n",
            " [0.41780263 0.35067543 0.         0.         0.         0.        ]\n",
            " [0.34718767 0.26314762 0.         0.         0.         0.        ]\n",
            " [0.40945816 0.2802124  0.         0.         0.         1.        ]\n",
            " [0.29882219 0.2535587  0.         0.         0.         0.        ]\n",
            " [0.28248519 0.2653822  0.         0.         0.         0.        ]\n",
            " [0.39938158 0.35434219 0.         0.         0.         0.        ]\n",
            " [0.32948673 0.29886568 0.         0.         0.         0.        ]\n",
            " [0.39686662 0.33560598 0.         0.         0.         0.        ]\n",
            " [0.39024135 0.27837858 0.         0.         0.         0.        ]\n",
            " [0.35077968 0.24869448 0.         0.         0.         0.        ]\n",
            " [0.50677645 0.46097904 1.         0.         0.         0.        ]\n",
            " [0.24791311 0.10008962 0.         0.         0.         0.        ]\n",
            " [0.44925499 0.20315289 0.         0.         0.         0.        ]\n",
            " [0.34037703 0.18744609 0.         0.         1.         0.        ]\n",
            " [0.4664351  0.34225482 0.         0.         0.         0.        ]\n",
            " [0.32216319 0.2090088  0.         0.         1.         0.        ]\n",
            " [0.31284145 0.20986161 0.         0.         0.         0.        ]\n",
            " [0.44548646 0.31046662 0.         0.         0.         0.        ]\n",
            " [0.51625353 0.36245394 1.         0.         0.         0.        ]\n",
            " [0.37346986 0.26459345 0.         0.         0.         0.        ]\n",
            " [0.43893969 0.31090477 0.         0.         0.         0.        ]\n",
            " [0.51228285 0.33061162 1.         0.         1.         0.        ]\n",
            " [0.5072419  0.32399288 1.         0.         0.         0.        ]\n",
            " [0.51056969 0.3557449  1.         0.         1.         0.        ]\n",
            " [0.41729343 0.26166436 0.         0.         0.         0.        ]\n",
            " [0.48686939 0.36043522 0.         0.         1.         0.        ]\n",
            " [0.39161119 0.26117694 0.         0.         0.         0.        ]\n",
            " [0.47505012 0.47844616 0.         0.         1.         0.        ]\n",
            " [0.47741607 0.41336298 0.         0.         0.         0.        ]\n",
            " [0.50604433 0.45275411 1.         0.         1.         0.        ]\n",
            " [0.51031816 0.45687106 1.         0.         1.         0.        ]\n",
            " [0.33637929 0.29308888 0.         0.         0.         0.        ]\n",
            " [0.40763277 0.31409022 0.         0.         0.         0.        ]\n",
            " [0.47890165 0.50073469 0.         1.         1.         0.        ]\n",
            " [0.41769886 0.29128787 0.         0.         0.         0.        ]\n",
            " [0.40488568 0.43386415 0.         0.         1.         0.        ]\n",
            " [0.39088213 0.33028427 0.         0.         1.         0.        ]\n",
            " [0.4056772  0.28848726 0.         0.         1.         0.        ]\n",
            " [0.42375281 0.30957872 0.         0.         1.         0.        ]\n",
            " [0.37846982 0.32421768 0.         0.         0.         0.        ]\n",
            " [0.43444058 0.36243746 0.         0.         0.         0.        ]\n",
            " [0.53312391 0.44174457 1.         0.         0.         0.        ]\n",
            " [0.48921895 0.37324587 0.         0.         0.         0.        ]\n",
            " [0.51673377 0.52201915 1.         1.         1.         1.        ]\n",
            " [0.51229042 0.4163796  1.         0.         1.         0.        ]\n",
            " [0.51787138 0.45514143 1.         0.         1.         1.        ]\n",
            " [0.49429551 0.38424295 0.         0.         0.         0.        ]\n",
            " [0.40284225 0.43711913 0.         0.         0.         1.        ]\n",
            " [0.48768532 0.44287932 0.         0.         1.         0.        ]\n",
            " [0.515499   0.4679881  1.         0.         1.         0.        ]\n",
            " [0.49876887 0.53184283 0.         1.         1.         1.        ]\n",
            " [0.52900839 0.52436996 1.         1.         1.         0.        ]\n",
            " [0.51545954 0.53951025 1.         1.         1.         1.        ]\n",
            " [0.51295781 0.47374529 1.         0.         1.         1.        ]\n",
            " [0.3877472  0.43941915 0.         0.         1.         1.        ]\n",
            " [0.51358223 0.35496354 1.         0.         1.         1.        ]\n",
            " [0.53074819 0.28667322 1.         0.         1.         1.        ]\n",
            " [0.51133871 0.39589977 1.         0.         1.         1.        ]\n",
            " [0.5049538  0.29756409 1.         0.         1.         1.        ]\n",
            " [0.49702317 0.33243486 0.         0.         1.         1.        ]\n",
            " [0.52970105 0.28564429 1.         0.         1.         1.        ]\n",
            " [0.48138514 0.3486084  0.         0.         1.         1.        ]\n",
            " [0.51597416 0.40160555 1.         0.         1.         0.        ]\n",
            " [0.53897876 0.28856754 1.         0.         1.         0.        ]\n",
            " [0.53117645 0.46343356 1.         0.         1.         0.        ]\n",
            " [0.51512432 0.33944929 1.         0.         1.         0.        ]\n",
            " [0.50901216 0.37351301 1.         0.         1.         1.        ]\n",
            " [0.52172351 0.31230906 1.         0.         1.         1.        ]\n",
            " [0.42653164 0.40654102 0.         0.         1.         1.        ]\n",
            " [0.4862     0.44226322 0.         0.         1.         0.        ]\n",
            " [0.47917044 0.41956353 0.         0.         1.         0.        ]\n",
            " [0.49644831 0.51010507 0.         1.         1.         1.        ]\n",
            " [0.50317812 0.43551177 1.         0.         1.         0.        ]\n",
            " [0.50423855 0.45951957 1.         0.         1.         1.        ]\n",
            " [0.48134881 0.41645458 0.         0.         1.         1.        ]\n",
            " [0.39346796 0.43328038 0.         0.         1.         1.        ]\n",
            " [0.37870932 0.33635613 0.         0.         0.         0.        ]\n",
            " [0.4211401  0.36502966 0.         0.         1.         0.        ]\n",
            " [0.47388178 0.38475397 0.         0.         1.         1.        ]\n",
            " [0.48351476 0.32310534 0.         0.         1.         0.        ]\n",
            " [0.50152755 0.33787331 1.         0.         1.         1.        ]\n",
            " [0.4477815  0.36264336 0.         0.         1.         1.        ]\n",
            " [0.40998435 0.37592092 0.         0.         0.         0.        ]\n",
            " [0.36164781 0.37112862 0.         0.         1.         0.        ]\n",
            " [0.52645856 0.28527376 1.         0.         1.         0.        ]\n",
            " [0.40242764 0.35458305 0.         0.         1.         1.        ]\n",
            " [0.43759614 0.34124669 0.         0.         1.         0.        ]\n",
            " [0.3913224  0.37672517 0.         0.         1.         1.        ]\n",
            " [0.43608043 0.31613308 0.         0.         1.         1.        ]\n",
            " [0.41916963 0.30368182 0.         0.         1.         1.        ]\n",
            " [0.3914873  0.36957747 0.         0.         1.         1.        ]\n",
            " [0.51240313 0.49489647 1.         0.         1.         1.        ]\n",
            " [0.51386333 0.44556719 1.         0.         1.         1.        ]\n",
            " [0.5156247  0.46010768 1.         0.         1.         1.        ]\n",
            " [0.51798785 0.49380249 1.         0.         1.         1.        ]\n",
            " [0.36262241 0.28674969 0.         0.         0.         0.        ]\n",
            " [0.41229603 0.46336725 0.         0.         0.         1.        ]\n",
            " [0.48752779 0.50296199 0.         1.         1.         1.        ]\n",
            " [0.50907141 0.5159381  1.         1.         1.         1.        ]\n",
            " [0.50970709 0.51225317 1.         1.         0.         1.        ]\n",
            " [0.48782304 0.51230717 0.         1.         1.         1.        ]\n",
            " [0.35340714 0.30626732 0.         0.         1.         0.        ]\n",
            " [0.44940794 0.29308924 0.         0.         0.         1.        ]\n",
            " [0.53115094 0.4005433  1.         0.         0.         1.        ]\n",
            " [0.52810782 0.39525533 1.         0.         1.         1.        ]\n",
            " [0.53152388 0.38870728 1.         0.         0.         1.        ]\n",
            " [0.52586985 0.411183   1.         0.         0.         1.        ]\n",
            " [0.41373628 0.31632355 0.         0.         0.         0.        ]\n",
            " [0.51067436 0.34167665 1.         0.         0.         1.        ]\n",
            " [0.36388296 0.43413273 0.         0.         0.         0.        ]\n",
            " [0.35995424 0.43825412 0.         0.         0.         1.        ]\n",
            " [0.38190559 0.4547793  0.         0.         0.         0.        ]\n",
            " [0.34874049 0.42570862 0.         0.         0.         1.        ]\n",
            " [0.28076458 0.2212196  0.         0.         0.         0.        ]\n",
            " [0.50557327 0.45471111 1.         0.         0.         1.        ]\n",
            " [0.39430037 0.5015083  0.         1.         0.         1.        ]\n",
            " [0.46676603 0.52731484 0.         1.         0.         1.        ]\n",
            " [0.42245799 0.50484037 0.         1.         0.         1.        ]\n",
            " [0.39725494 0.51063657 0.         1.         0.         1.        ]\n",
            " [0.32055718 0.43177119 0.         0.         0.         0.        ]\n",
            " [0.44420198 0.43512565 0.         0.         0.         1.        ]\n",
            " [0.3614586  0.46021098 0.         0.         0.         0.        ]\n",
            " [0.42813    0.43573862 0.         0.         0.         1.        ]\n",
            " [0.46328393 0.438811   0.         0.         0.         0.        ]\n",
            " [0.4136419  0.52316087 0.         1.         0.         0.        ]\n",
            " [0.32717139 0.30065095 0.         0.         0.         0.        ]\n",
            " [0.59500408 0.51686829 1.         1.         0.         1.        ]\n",
            " [0.38545346 0.59720314 0.         1.         0.         1.        ]\n",
            " [0.45589668 0.58934027 0.         1.         0.         1.        ]\n",
            " [0.41289026 0.57667077 0.         1.         0.         1.        ]\n",
            " [0.37245008 0.64743215 0.         1.         0.         1.        ]\n",
            " [0.35849041 0.38018119 0.         0.         0.         0.        ]\n",
            " [0.42364722 0.46290249 0.         0.         0.         1.        ]\n",
            " [0.42207402 0.45095202 0.         0.         0.         1.        ]\n",
            " [0.44280156 0.49980813 0.         0.         0.         1.        ]\n",
            " [0.45434725 0.4891327  0.         0.         0.         1.        ]\n",
            " [0.35710025 0.38159916 0.         0.         0.         1.        ]\n",
            " [0.39499339 0.43448275 0.         0.         0.         1.        ]\n",
            " [0.42322251 0.46550113 0.         0.         0.         1.        ]\n",
            " [0.35039079 0.40732881 0.         0.         0.         1.        ]\n",
            " [0.3582291  0.45904949 0.         0.         0.         1.        ]\n",
            " [0.34468997 0.4588553  0.         0.         0.         1.        ]\n",
            " [0.34645233 0.45744041 0.         0.         0.         1.        ]\n",
            " [0.32876843 0.36837566 0.         0.         0.         0.        ]\n",
            " [0.34472454 0.37229753 0.         0.         0.         1.        ]\n",
            " [0.3498092  0.40880436 0.         0.         0.         0.        ]\n",
            " [0.4341172  0.48820037 0.         0.         0.         1.        ]\n",
            " [0.38692856 0.3490788  0.         0.         0.         1.        ]\n",
            " [0.4491359  0.50903231 0.         1.         0.         1.        ]\n",
            " [0.47170419 0.50869161 0.         1.         0.         1.        ]\n",
            " [0.3735958  0.41567716 0.         0.         0.         1.        ]\n",
            " [0.47103307 0.34833336 0.         0.         0.         1.        ]\n",
            " [0.44363147 0.48515177 0.         0.         0.         1.        ]\n",
            " [0.50333738 0.35971707 1.         0.         0.         0.        ]\n",
            " [0.4738017  0.4393824  0.         0.         0.         1.        ]\n",
            " [0.50641489 0.47639391 1.         0.         0.         1.        ]\n",
            " [0.51665086 0.4529027  1.         0.         0.         1.        ]\n",
            " [0.44959307 0.37957075 0.         0.         0.         1.        ]\n",
            " [0.46890628 0.37929645 0.         0.         0.         1.        ]\n",
            " [0.49736336 0.38637367 0.         0.         0.         0.        ]\n",
            " [0.37938571 0.43613347 0.         0.         0.         1.        ]\n",
            " [0.38772246 0.44459227 0.         0.         0.         1.        ]\n",
            " [0.40377393 0.47254577 0.         0.         0.         1.        ]\n",
            " [0.4086377  0.47661495 0.         0.         0.         1.        ]\n",
            " [0.38091329 0.38191828 0.         0.         0.         1.        ]\n",
            " [0.40646335 0.27607587 0.         0.         0.         0.        ]\n",
            " [0.40231052 0.42008165 0.         0.         0.         1.        ]\n",
            " [0.40507901 0.428388   0.         0.         0.         0.        ]\n",
            " [0.34930956 0.46725628 0.         0.         0.         0.        ]\n",
            " [0.45333311 0.45081943 0.         0.         0.         0.        ]\n",
            " [0.44587591 0.44981882 0.         0.         0.         0.        ]\n",
            " [0.38578221 0.37528917 0.         0.         0.         0.        ]\n",
            " [0.33388025 0.39537603 0.         0.         0.         0.        ]\n",
            " [0.3996079  0.42927971 0.         0.         0.         0.        ]\n",
            " [0.10488295 0.18084192 0.         0.         0.         1.        ]\n",
            " [0.40135613 0.6179812  0.         1.         0.         1.        ]\n",
            " [0.29416278 0.62602818 0.         1.         0.         1.        ]\n",
            " [0.48878783 0.48699701 0.         0.         0.         1.        ]\n",
            " [0.50624102 0.48255345 1.         0.         0.         1.        ]\n",
            " [0.46941808 0.47566703 0.         0.         0.         1.        ]\n",
            " [0.18507653 0.17753978 0.         0.         0.         0.        ]\n",
            " [0.46641371 0.36004153 0.         0.         0.         1.        ]\n",
            " [0.5114345  0.30925873 1.         0.         1.         0.        ]\n",
            " [0.53942752 0.25516689 1.         0.         1.         0.        ]\n",
            " [0.51375532 0.28770408 1.         0.         1.         0.        ]\n",
            " [0.5734973  0.27268088 1.         0.         1.         0.        ]\n",
            " [0.52744263 0.24886003 1.         0.         1.         0.        ]\n",
            " [0.56791878 0.25313413 1.         0.         1.         0.        ]\n",
            " [0.52327925 0.24362735 1.         0.         1.         0.        ]\n",
            " [0.54692203 0.26209411 1.         0.         1.         0.        ]\n",
            " [0.50262666 0.31856698 1.         0.         1.         0.        ]\n",
            " [0.47345257 0.29397207 0.         0.         1.         0.        ]\n",
            " [0.50153106 0.30338687 1.         0.         1.         0.        ]\n",
            " [0.55238879 0.29558638 1.         0.         1.         0.        ]\n",
            " [0.51585323 0.2903761  1.         0.         0.         0.        ]\n",
            " [0.5340203  0.26378644 1.         0.         0.         0.        ]\n",
            " [0.50127852 0.25286412 1.         0.         1.         0.        ]\n",
            " [0.49491352 0.29962891 0.         0.         1.         0.        ]\n",
            " [0.54325724 0.26095107 1.         0.         1.         0.        ]\n",
            " [0.59082419 0.21913585 1.         0.         1.         0.        ]\n",
            " [0.54558688 0.22685912 1.         0.         1.         0.        ]\n",
            " [0.61502397 0.24815072 1.         0.         1.         0.        ]\n",
            " [0.51544201 0.17322619 1.         0.         1.         0.        ]\n",
            " [0.605663   0.22392532 1.         0.         1.         0.        ]\n",
            " [0.54487199 0.21285062 1.         0.         1.         0.        ]\n",
            " [0.56373948 0.23283419 1.         0.         1.         0.        ]\n",
            " [0.51521939 0.27960002 1.         0.         1.         0.        ]\n",
            " [0.51315361 0.21512389 1.         0.         1.         0.        ]\n",
            " [0.51059908 0.24788983 1.         0.         1.         0.        ]\n",
            " [0.59737349 0.25226027 1.         0.         1.         0.        ]\n",
            " [0.4709487  0.20694843 0.         0.         1.         0.        ]\n",
            " [0.54772681 0.22105485 1.         0.         1.         0.        ]\n",
            " [0.52938491 0.22192836 1.         0.         1.         0.        ]\n",
            " [0.49615806 0.21231031 0.         0.         1.         0.        ]\n",
            " [0.53796595 0.41079587 1.         0.         1.         0.        ]\n",
            " [0.61460567 0.28139934 1.         0.         1.         0.        ]\n",
            " [0.51993465 0.2328648  1.         0.         1.         0.        ]\n",
            " [0.54688096 0.37005663 1.         0.         1.         0.        ]\n",
            " [0.53747487 0.22844355 1.         0.         1.         0.        ]\n",
            " [0.62569195 0.2591086  1.         0.         1.         0.        ]\n",
            " [0.5189411  0.22345634 1.         0.         1.         0.        ]\n",
            " [0.58697402 0.31126377 1.         0.         1.         0.        ]\n",
            " [0.50477988 0.37307242 1.         0.         1.         0.        ]\n",
            " [0.53893    0.28893083 1.         0.         1.         0.        ]\n",
            " [0.48779058 0.3236388  0.         0.         1.         0.        ]\n",
            " [0.5379591  0.32115942 1.         0.         1.         0.        ]\n",
            " [0.52699643 0.27460137 1.         0.         1.         0.        ]\n",
            " [0.55715746 0.28855208 1.         0.         1.         0.        ]\n",
            " [0.48654544 0.24237025 0.         0.         1.         0.        ]\n",
            " [0.54470271 0.3009333  1.         0.         1.         0.        ]\n",
            " [0.42476803 0.29953694 0.         0.         0.         0.        ]\n",
            " [0.42255884 0.3255944  0.         0.         0.         0.        ]\n",
            " [0.33598706 0.28247604 0.         0.         0.         0.        ]\n",
            " [0.36075503 0.37192073 0.         0.         0.         0.        ]\n",
            " [0.41324788 0.29694399 0.         0.         0.         0.        ]\n",
            " [0.29399464 0.25149634 0.         0.         0.         0.        ]\n",
            " [0.43432003 0.26309282 0.         0.         0.         0.        ]\n",
            " [0.33578631 0.21169762 0.         0.         0.         0.        ]\n",
            " [0.55029958 0.17919835 1.         0.         0.         0.        ]\n",
            " [0.50040931 0.30370522 1.         0.         1.         0.        ]\n",
            " [0.49328306 0.29914489 0.         0.         1.         0.        ]\n",
            " [0.40924641 0.36447063 0.         0.         1.         0.        ]\n",
            " [0.53857827 0.45367149 1.         0.         1.         0.        ]\n",
            " [0.54454714 0.44460094 1.         0.         1.         0.        ]\n",
            " [0.52949274 0.42940584 1.         0.         1.         0.        ]\n",
            " [0.52718675 0.43030691 1.         0.         1.         0.        ]\n",
            " [0.54769236 0.44507784 1.         0.         1.         0.        ]\n",
            " [0.41881093 0.37841839 0.         0.         0.         0.        ]\n",
            " [0.52819371 0.42787161 1.         0.         1.         0.        ]\n",
            " [0.52448756 0.42737025 1.         0.         1.         0.        ]\n",
            " [0.5038783  0.44814757 1.         0.         1.         0.        ]\n",
            " [0.51430809 0.4551959  1.         0.         1.         0.        ]\n",
            " [0.51000804 0.44048154 1.         0.         1.         0.        ]\n",
            " [0.43863833 0.35701746 0.         0.         1.         0.        ]\n",
            " [0.513767   0.42965823 1.         0.         1.         0.        ]\n",
            " [0.52250654 0.44222233 1.         0.         1.         0.        ]\n",
            " [0.43504441 0.37643296 0.         0.         1.         0.        ]\n",
            " [0.54043138 0.44560701 1.         0.         1.         0.        ]\n",
            " [0.54037255 0.44294742 1.         0.         1.         0.        ]\n",
            " [0.53916484 0.43621099 1.         0.         1.         0.        ]\n",
            " [0.54081351 0.4329007  1.         0.         1.         0.        ]\n",
            " [0.54003555 0.43505558 1.         0.         1.         0.        ]\n",
            " [0.51557636 0.36244911 1.         0.         1.         0.        ]\n",
            " [0.54874909 0.48130062 1.         0.         1.         0.        ]\n",
            " [0.53563339 0.435352   1.         0.         1.         0.        ]\n",
            " [0.41972092 0.45167202 0.         0.         0.         0.        ]\n",
            " [0.54288489 0.44546503 1.         0.         1.         0.        ]\n",
            " [0.5482139  0.43741325 1.         0.         1.         0.        ]\n",
            " [0.53984052 0.42713386 1.         0.         1.         0.        ]\n",
            " [0.54492474 0.43232483 1.         0.         1.         0.        ]\n",
            " [0.54469198 0.4284507  1.         0.         1.         0.        ]\n",
            " [0.55967242 0.33001697 1.         0.         1.         0.        ]\n",
            " [0.52804971 0.45802751 1.         0.         1.         0.        ]\n",
            " [0.5448302  0.42734048 1.         0.         1.         0.        ]\n",
            " [0.42531419 0.45292032 0.         0.         1.         0.        ]\n",
            " [0.51585209 0.46711135 1.         0.         1.         0.        ]\n",
            " [0.51404482 0.46754768 1.         0.         1.         0.        ]\n",
            " [0.5195902  0.46483135 1.         0.         1.         0.        ]\n",
            " [0.51621997 0.44685295 1.         0.         1.         0.        ]\n",
            " [0.51477921 0.44193777 1.         0.         1.         0.        ]\n",
            " [0.62075877 0.4858     1.         0.         1.         0.        ]\n",
            " [0.52219534 0.47744611 1.         0.         1.         0.        ]\n",
            " [0.51792508 0.45564917 1.         0.         1.         0.        ]\n",
            " [0.39934143 0.41922933 0.         0.         1.         0.        ]\n",
            " [0.50545716 0.44556677 1.         0.         1.         0.        ]\n",
            " [0.51123738 0.43905404 1.         0.         1.         0.        ]\n",
            " [0.53364807 0.42450377 1.         0.         1.         0.        ]\n",
            " [0.52651286 0.44279757 1.         0.         1.         0.        ]\n",
            " [0.53743792 0.43526435 1.         0.         1.         0.        ]\n",
            " [0.62688166 0.45359343 1.         0.         1.         0.        ]\n",
            " [0.52054191 0.47839954 1.         0.         1.         0.        ]\n",
            " [0.53060228 0.42775115 1.         0.         1.         0.        ]\n",
            " [0.33163056 0.23745105 0.         0.         0.         0.        ]\n",
            " [0.42159674 0.44915408 0.         0.         0.         0.        ]\n",
            " [0.37634242 0.31101763 0.         0.         0.         0.        ]\n",
            " [0.40500298 0.29965621 0.         0.         0.         0.        ]\n",
            " [0.40435177 0.3155131  0.         0.         0.         0.        ]\n",
            " [0.36671922 0.23555049 0.         0.         0.         0.        ]\n",
            " [0.26203784 0.19482452 0.         0.         0.         0.        ]\n",
            " [0.41188943 0.35279259 0.         0.         0.         0.        ]\n",
            " [0.37517646 0.24845929 0.         0.         0.         0.        ]\n",
            " [0.37858737 0.33730131 0.         0.         0.         0.        ]\n",
            " [0.49571711 0.44227684 0.         0.         1.         0.        ]\n",
            " [0.53298426 0.4230009  1.         0.         1.         0.        ]\n",
            " [0.54602361 0.45508903 1.         0.         1.         0.        ]\n",
            " [0.50012523 0.4363941  1.         0.         1.         0.        ]\n",
            " [0.5365721  0.42284998 1.         0.         1.         0.        ]\n",
            " [0.49531493 0.43849242 0.         0.         1.         0.        ]\n",
            " [0.53802049 0.43526202 1.         0.         1.         0.        ]\n",
            " [0.53104585 0.4270933  1.         0.         1.         0.        ]\n",
            " [0.37385115 0.29738224 0.         0.         1.         0.        ]\n",
            " [0.47494909 0.41473022 0.         0.         1.         0.        ]\n",
            " [0.5276556  0.41592407 1.         0.         1.         0.        ]\n",
            " [0.51607823 0.4357723  1.         0.         1.         0.        ]\n",
            " [0.44271907 0.38055509 0.         0.         1.         0.        ]\n",
            " [0.49428037 0.37873524 0.         0.         1.         0.        ]\n",
            " [0.4529753  0.39079091 0.         0.         1.         0.        ]\n",
            " [0.49214721 0.43608645 0.         0.         1.         0.        ]\n",
            " [0.50390774 0.42519459 1.         0.         1.         0.        ]\n",
            " [0.41843849 0.25716063 0.         0.         0.         0.        ]\n",
            " [0.51571667 0.43526408 1.         0.         1.         0.        ]\n",
            " [0.53072667 0.45414123 1.         0.         1.         0.        ]\n",
            " [0.54418308 0.44359648 1.         0.         1.         0.        ]\n",
            " [0.51059771 0.43954429 1.         0.         1.         0.        ]\n",
            " [0.52666801 0.45181778 1.         0.         1.         0.        ]\n",
            " [0.51731813 0.43442124 1.         0.         1.         0.        ]\n",
            " [0.53913677 0.43133703 1.         0.         1.         0.        ]\n",
            " [0.53768629 0.43408206 1.         0.         1.         0.        ]\n",
            " [0.38547599 0.31143126 0.         0.         0.         0.        ]\n",
            " [0.50208497 0.45263839 1.         0.         1.         0.        ]\n",
            " [0.5175451  0.48957831 1.         0.         1.         0.        ]\n",
            " [0.55421585 0.43594712 1.         0.         1.         0.        ]\n",
            " [0.51229709 0.43531319 1.         0.         1.         0.        ]\n",
            " [0.53897113 0.44740444 1.         0.         1.         0.        ]\n",
            " [0.50698006 0.43212315 1.         0.         1.         0.        ]\n",
            " [0.54556262 0.4246619  1.         0.         1.         0.        ]\n",
            " [0.53515446 0.43842527 1.         0.         1.         0.        ]\n",
            " [0.43560892 0.4554252  0.         0.         0.         0.        ]\n",
            " [0.52273911 0.46613249 1.         0.         1.         0.        ]\n",
            " [0.51856989 0.4605259  1.         0.         1.         0.        ]\n",
            " [0.50642395 0.47818729 1.         0.         1.         0.        ]\n",
            " [0.50697404 0.46587539 1.         0.         1.         0.        ]\n",
            " [0.49704248 0.43973315 0.         0.         0.         1.        ]\n",
            " [0.50760531 0.47224462 1.         0.         1.         0.        ]\n",
            " [0.51677966 0.46578604 1.         0.         1.         0.        ]\n",
            " [0.50708646 0.45251143 1.         0.         0.         0.        ]\n",
            " [0.36567211 0.30779639 0.         0.         1.         0.        ]\n",
            " [0.53126478 0.40442285 1.         0.         1.         0.        ]\n",
            " [0.47911882 0.35644212 0.         0.         1.         0.        ]\n",
            " [0.39851195 0.42897272 0.         0.         1.         0.        ]\n",
            " [0.46947289 0.48827481 0.         0.         1.         0.        ]\n",
            " [0.49520603 0.4791497  0.         0.         1.         0.        ]\n",
            " [0.49588969 0.44372028 0.         0.         1.         0.        ]\n",
            " [0.53040922 0.39659369 1.         0.         1.         0.        ]\n",
            " [0.40425858 0.43723059 0.         0.         1.         0.        ]\n",
            " [0.43077528 0.47646853 0.         0.         1.         0.        ]\n",
            " [0.41586965 0.35588935 0.         0.         1.         0.        ]\n",
            " [0.50952148 0.42171264 1.         0.         1.         0.        ]\n",
            " [0.47051844 0.40368834 0.         0.         1.         0.        ]\n",
            " [0.46904179 0.50503159 0.         1.         1.         0.        ]\n",
            " [0.44973731 0.08368655 0.         0.         1.         0.        ]\n",
            " [0.43303499 0.36368838 0.         0.         1.         0.        ]\n",
            " [0.42023221 0.40715295 0.         0.         1.         0.        ]\n",
            " [0.46956879 0.41200456 0.         0.         1.         0.        ]\n",
            " [0.44091898 0.23051508 0.         0.         1.         0.        ]\n",
            " [0.42749482 0.40249497 0.         0.         1.         0.        ]\n",
            " [0.50393796 0.3182568  1.         0.         1.         1.        ]\n",
            " [0.37116247 0.31891921 0.         0.         1.         0.        ]\n",
            " [0.42133662 0.3074013  0.         0.         1.         0.        ]\n",
            " [0.41734767 0.56727302 0.         1.         1.         0.        ]\n",
            " [0.3352792  0.27121645 0.         0.         1.         0.        ]\n",
            " [0.36470887 0.20475265 0.         0.         1.         0.        ]\n",
            " [0.36517486 0.28583944 0.         0.         1.         0.        ]\n",
            " [0.39897972 0.31125301 0.         0.         1.         0.        ]\n",
            " [0.44948214 0.34701705 0.         0.         1.         0.        ]\n",
            " [0.32363188 0.18531182 0.         0.         1.         0.        ]\n",
            " [0.37241587 0.26073298 0.         0.         1.         0.        ]\n",
            " [0.42922118 0.34615636 0.         0.         0.         0.        ]\n",
            " [0.49557745 0.3580004  0.         0.         1.         0.        ]\n",
            " [0.5317415  0.393123   1.         0.         1.         0.        ]\n",
            " [0.51025856 0.38269204 1.         0.         1.         0.        ]\n",
            " [0.43637574 0.38128567 0.         0.         1.         0.        ]\n",
            " [0.42946616 0.35690778 0.         0.         1.         0.        ]\n",
            " [0.48414198 0.38442138 0.         0.         1.         0.        ]\n",
            " [0.48251778 0.3717325  0.         0.         0.         0.        ]\n",
            " [0.50830388 0.39152768 1.         0.         1.         0.        ]\n",
            " [0.44381583 0.36964694 0.         0.         1.         0.        ]\n",
            " [0.44494927 0.33265954 0.         0.         1.         0.        ]\n",
            " [0.47701481 0.42566383 0.         0.         0.         0.        ]\n",
            " [0.48662132 0.50205415 0.         1.         1.         0.        ]\n",
            " [0.49802598 0.47009429 0.         0.         1.         0.        ]\n",
            " [0.51502848 0.47810203 1.         0.         1.         0.        ]\n",
            " [0.44316348 0.49902457 0.         0.         1.         0.        ]\n",
            " [0.46936181 0.27243194 0.         0.         1.         0.        ]\n",
            " [0.46199012 0.36973441 0.         0.         1.         1.        ]\n",
            " [0.44604406 0.40083343 0.         0.         1.         0.        ]\n",
            " [0.48130009 0.3766661  0.         0.         1.         1.        ]\n",
            " [0.43052661 0.33483052 0.         0.         1.         0.        ]\n",
            " [0.42530209 0.34132579 0.         0.         1.         0.        ]\n",
            " [0.48049474 0.4955931  0.         0.         1.         0.        ]\n",
            " [0.48315001 0.38422135 0.         0.         1.         0.        ]\n",
            " [0.52993566 0.4065704  1.         0.         1.         1.        ]\n",
            " [0.52535063 0.38051817 1.         0.         1.         0.        ]\n",
            " [0.47212854 0.37635815 0.         0.         1.         0.        ]\n",
            " [0.44825959 0.34914052 0.         0.         1.         0.        ]\n",
            " [0.51699036 0.38005331 1.         0.         1.         0.        ]\n",
            " [0.48809853 0.36096865 0.         0.         1.         0.        ]\n",
            " [0.52249902 0.38956711 1.         0.         1.         0.        ]\n",
            " [0.45304742 0.36418733 0.         0.         1.         0.        ]\n",
            " [0.48873439 0.35140505 0.         0.         1.         0.        ]\n",
            " [0.36890179 0.42214614 0.         0.         1.         0.        ]\n",
            " [0.50501132 0.42588168 1.         0.         0.         0.        ]\n",
            " [0.54571444 0.41467819 1.         0.         1.         0.        ]\n",
            " [0.53716433 0.37578663 1.         0.         1.         0.        ]\n",
            " [0.48330444 0.38328686 0.         0.         1.         0.        ]\n",
            " [0.47605819 0.33493936 0.         0.         1.         0.        ]\n",
            " [0.51727319 0.43200818 1.         0.         1.         0.        ]\n",
            " [0.5004707  0.40343198 1.         0.         1.         0.        ]\n",
            " [0.54382849 0.37497586 1.         0.         1.         1.        ]\n",
            " [0.47251475 0.36532673 0.         0.         1.         0.        ]\n",
            " [0.49879527 0.37494785 0.         0.         0.         0.        ]\n",
            " [0.35068727 0.41007462 0.         0.         0.         0.        ]\n",
            " [0.4762882  0.45186257 0.         0.         1.         0.        ]\n",
            " [0.48254019 0.46158686 0.         0.         1.         0.        ]\n",
            " [0.51920646 0.47313654 1.         0.         1.         0.        ]\n",
            " [0.47136778 0.43043137 0.         0.         1.         0.        ]\n",
            " [0.47643921 0.48601303 0.         0.         1.         0.        ]\n",
            " [0.40843478 0.27680156 0.         0.         0.         0.        ]\n",
            " [0.41478562 0.38218662 0.         0.         0.         0.        ]\n",
            " [0.44672161 0.39058822 0.         0.         0.         0.        ]\n",
            " [0.43403435 0.37499702 0.         0.         0.         0.        ]\n",
            " [0.40069428 0.35648391 0.         0.         0.         0.        ]\n",
            " [0.39236656 0.36090156 0.         0.         0.         0.        ]\n",
            " [0.40169793 0.26769456 0.         0.         0.         0.        ]\n",
            " [0.36625302 0.27974156 0.         0.         0.         0.        ]\n",
            " [0.34782204 0.26018885 0.         0.         0.         0.        ]\n",
            " [0.37165335 0.28630379 0.         0.         0.         0.        ]\n",
            " [0.38276929 0.35330829 0.         0.         0.         0.        ]\n",
            " [0.42462981 0.25327    0.         0.         1.         0.        ]\n",
            " [0.36725885 0.27630147 0.         0.         1.         0.        ]\n",
            " [0.35482964 0.25219911 0.         0.         1.         0.        ]\n",
            " [0.47068888 0.4009048  0.         0.         1.         0.        ]\n",
            " [0.42228505 0.35483024 0.         0.         1.         0.        ]\n",
            " [0.43314597 0.42640737 0.         0.         1.         0.        ]\n",
            " [0.45571154 0.42171234 0.         0.         1.         0.        ]\n",
            " [0.44472229 0.42932567 0.         0.         1.         0.        ]\n",
            " [0.47732854 0.3875939  0.         0.         1.         0.        ]\n",
            " [0.43587342 0.3387374  0.         0.         1.         0.        ]\n",
            " [0.40713343 0.35620439 0.         0.         1.         0.        ]\n",
            " [0.44203642 0.34972408 0.         0.         1.         0.        ]\n",
            " [0.428532   0.35053641 0.         0.         1.         0.        ]\n",
            " [0.45845556 0.37055349 0.         0.         1.         0.        ]\n",
            " [0.41896343 0.37427181 0.         0.         1.         0.        ]\n",
            " [0.46419618 0.33231139 0.         0.         1.         0.        ]\n",
            " [0.53543133 0.35465571 1.         0.         1.         0.        ]\n",
            " [0.53555697 0.32781836 1.         0.         1.         0.        ]\n",
            " [0.55630791 0.36272371 1.         0.         1.         0.        ]\n",
            " [0.52965093 0.32965076 1.         0.         1.         0.        ]\n",
            " [0.53031147 0.33450904 1.         0.         1.         0.        ]\n",
            " [0.46817145 0.42266786 0.         0.         1.         0.        ]\n",
            " [0.42739865 0.41836545 0.         0.         0.         0.        ]\n",
            " [0.49243039 0.42746502 0.         0.         1.         0.        ]\n",
            " [0.51854903 0.48945948 1.         0.         0.         0.        ]\n",
            " [0.47599486 0.40986183 0.         0.         1.         0.        ]\n",
            " [0.50976253 0.45391005 1.         0.         1.         0.        ]\n",
            " [0.50199193 0.43581021 1.         0.         0.         0.        ]\n",
            " [0.36476383 0.2469043  0.         0.         0.         0.        ]\n",
            " [0.42683548 0.36648601 0.         0.         1.         0.        ]\n",
            " [0.53398484 0.42779604 1.         0.         1.         0.        ]\n",
            " [0.51226604 0.44888103 1.         0.         1.         0.        ]\n",
            " [0.53105485 0.42004484 1.         0.         1.         0.        ]\n",
            " [0.52849245 0.4449513  1.         0.         1.         0.        ]\n",
            " [0.53581399 0.43253347 1.         0.         1.         0.        ]\n",
            " [0.46901503 0.43930775 0.         0.         1.         0.        ]\n",
            " [0.43186608 0.3390651  0.         0.         1.         0.        ]\n",
            " [0.50233144 0.39389539 1.         0.         1.         0.        ]\n",
            " [0.50180817 0.37081462 1.         0.         1.         0.        ]\n",
            " [0.51219869 0.41757238 1.         0.         1.         0.        ]\n",
            " [0.49990728 0.3830933  0.         0.         1.         0.        ]\n",
            " [0.50187588 0.38587704 1.         0.         1.         0.        ]\n",
            " [0.53843361 0.3958964  1.         0.         1.         0.        ]\n",
            " [0.43049389 0.34775704 0.         0.         1.         0.        ]\n",
            " [0.49603784 0.39406121 0.         0.         1.         0.        ]\n",
            " [0.48735711 0.39888799 0.         0.         1.         0.        ]\n",
            " [0.50072622 0.39655569 1.         0.         1.         0.        ]\n",
            " [0.49284115 0.39449397 0.         0.         1.         0.        ]\n",
            " [0.49655545 0.39703816 0.         0.         1.         0.        ]\n",
            " [0.49964067 0.38702792 0.         0.         1.         0.        ]\n",
            " [0.44181487 0.30066761 0.         0.         1.         0.        ]\n",
            " [0.52355927 0.33077341 1.         0.         1.         0.        ]\n",
            " [0.53779393 0.31387761 1.         0.         1.         0.        ]\n",
            " [0.53322172 0.35103932 1.         0.         1.         0.        ]\n",
            " [0.53092647 0.32185727 1.         0.         1.         0.        ]\n",
            " [0.53822017 0.31523255 1.         0.         1.         0.        ]\n",
            " [0.53416812 0.31484333 1.         0.         1.         1.        ]\n",
            " [0.46596581 0.43468064 0.         0.         1.         0.        ]\n",
            " [0.52027589 0.44519186 1.         0.         1.         0.        ]\n",
            " [0.52296406 0.44614711 1.         0.         1.         0.        ]\n",
            " [0.52260846 0.37657762 1.         0.         1.         0.        ]\n",
            " [0.53175485 0.42009339 1.         0.         1.         0.        ]\n",
            " [0.51702267 0.41416773 1.         0.         1.         0.        ]\n",
            " [0.50952119 0.41317728 1.         0.         1.         1.        ]\n",
            " [0.51165134 0.31029546 1.         0.         1.         0.        ]\n",
            " [0.56607848 0.32344416 1.         0.         1.         0.        ]\n",
            " [0.55960441 0.32746658 1.         0.         1.         0.        ]\n",
            " [0.5817827  0.33853233 1.         0.         1.         1.        ]\n",
            " [0.5584054  0.31634414 1.         0.         1.         0.        ]\n",
            " [0.57006091 0.32471308 1.         0.         1.         0.        ]\n",
            " [0.5714469  0.32509822 1.         0.         1.         0.        ]\n",
            " [0.51716274 0.28969464 1.         0.         0.         0.        ]\n",
            " [0.56771362 0.3364543  1.         0.         1.         0.        ]\n",
            " [0.56799066 0.33107939 1.         0.         1.         0.        ]\n",
            " [0.58224922 0.35006613 1.         0.         1.         0.        ]\n",
            " [0.56129777 0.33401486 1.         0.         1.         0.        ]\n",
            " [0.56668776 0.33788508 1.         0.         1.         0.        ]\n",
            " [0.56100291 0.34894568 1.         0.         1.         1.        ]\n",
            " [0.44446442 0.29678926 0.         0.         1.         1.        ]\n",
            " [0.42577946 0.3776677  0.         0.         1.         1.        ]\n",
            " [0.51881051 0.22347391 1.         0.         1.         0.        ]\n",
            " [0.4624396  0.3500396  0.         0.         1.         0.        ]\n",
            " [0.47238219 0.282767   0.         0.         1.         0.        ]\n",
            " [0.58697665 0.43479419 1.         0.         0.         0.        ]\n",
            " [0.58003736 0.45230532 1.         0.         1.         0.        ]\n",
            " [0.53707355 0.40644246 1.         0.         0.         0.        ]\n",
            " [0.40738279 0.33006781 0.         0.         1.         0.        ]\n",
            " [0.5007323  0.40112922 1.         0.         1.         0.        ]\n",
            " [0.42902371 0.267028   0.         0.         1.         1.        ]\n",
            " [0.50875545 0.41104496 1.         0.         1.         1.        ]\n",
            " [0.40380242 0.33472824 0.         0.         1.         1.        ]\n",
            " [0.46491075 0.28171694 0.         0.         1.         0.        ]\n",
            " [0.45428315 0.27723208 0.         0.         1.         0.        ]\n",
            " [0.4505344  0.29859602 0.         0.         1.         0.        ]\n",
            " [0.43820539 0.38295674 0.         0.         1.         1.        ]\n",
            " [0.55485988 0.31528506 1.         0.         1.         1.        ]\n",
            " [0.56153083 0.27983642 1.         0.         1.         0.        ]\n",
            " [0.55592746 0.3137925  1.         0.         1.         0.        ]\n",
            " [0.42063174 0.33073595 0.         0.         1.         0.        ]\n",
            " [0.58264881 0.36598885 1.         0.         1.         0.        ]\n",
            " [0.57557511 0.3596555  1.         0.         1.         0.        ]\n",
            " [0.50907493 0.3139489  1.         0.         1.         0.        ]\n",
            " [0.37407246 0.36925954 0.         0.         1.         1.        ]\n",
            " [0.55910861 0.33471614 1.         0.         1.         1.        ]\n",
            " [0.48765635 0.27501833 0.         0.         1.         1.        ]\n",
            " [0.55270833 0.34844232 1.         0.         1.         1.        ]\n",
            " [0.39252967 0.35934949 0.         0.         1.         1.        ]\n",
            " [0.52996314 0.31358382 1.         0.         1.         0.        ]\n",
            " [0.54164779 0.32857642 1.         0.         1.         0.        ]\n",
            " [0.50672674 0.27087754 1.         0.         1.         0.        ]\n",
            " [0.39595741 0.31120709 0.         0.         0.         0.        ]\n",
            " [0.25958276 0.30544716 0.         0.         0.         0.        ]\n",
            " [0.27561975 0.32757893 0.         0.         0.         1.        ]\n",
            " [0.36105967 0.28927672 0.         0.         0.         0.        ]\n",
            " [0.36597097 0.29205015 0.         0.         0.         0.        ]\n",
            " [0.29668772 0.35477343 0.         0.         0.         0.        ]\n",
            " [0.36187056 0.29578796 0.         0.         0.         0.        ]\n",
            " [0.37109229 0.30204332 0.         0.         0.         0.        ]\n",
            " [0.37969744 0.2759735  0.         0.         0.         0.        ]\n",
            " [0.34858069 0.28312287 0.         0.         0.         1.        ]\n",
            " [0.25162649 0.19102724 0.         0.         0.         0.        ]\n",
            " [0.34133855 0.36288679 0.         0.         1.         0.        ]\n",
            " [0.38386354 0.32313788 0.         0.         1.         0.        ]\n",
            " [0.39798656 0.31058192 0.         0.         0.         0.        ]\n",
            " [0.38655248 0.39062944 0.         0.         1.         0.        ]\n",
            " [0.36383641 0.33632281 0.         0.         1.         0.        ]\n",
            " [0.41266224 0.31220782 0.         0.         1.         0.        ]\n",
            " [0.37557197 0.30278462 0.         0.         1.         0.        ]\n",
            " [0.36645815 0.35716063 0.         0.         1.         0.        ]\n",
            " [0.36220434 0.29619274 0.         0.         1.         0.        ]\n",
            " [0.36107266 0.27872828 0.         0.         0.         0.        ]\n",
            " [0.36312699 0.29482934 0.         0.         1.         0.        ]\n",
            " [0.36143923 0.30774754 0.         0.         1.         0.        ]\n",
            " [0.37697589 0.3104389  0.         0.         1.         0.        ]\n",
            " [0.37394461 0.33009374 0.         0.         1.         0.        ]\n",
            " [0.43158725 0.32381472 0.         0.         1.         0.        ]\n",
            " [0.39128914 0.38747939 0.         0.         1.         0.        ]\n",
            " [0.3938511  0.38824975 0.         0.         1.         0.        ]\n",
            " [0.3924064  0.39963585 0.         0.         1.         0.        ]\n",
            " [0.40780586 0.22778971 0.         0.         1.         0.        ]\n",
            " [0.34345573 0.24731252 0.         0.         0.         0.        ]\n",
            " [0.30095062 0.31620428 0.         0.         0.         0.        ]\n",
            " [0.24167898 0.22978395 0.         0.         0.         0.        ]\n",
            " [0.24937405 0.23730993 0.         0.         0.         0.        ]\n",
            " [0.31653851 0.23670229 0.         0.         0.         0.        ]\n",
            " [0.39636242 0.19064592 0.         0.         0.         0.        ]\n",
            " [0.2864978  0.27784723 0.         0.         0.         0.        ]\n",
            " [0.26713991 0.25388318 0.         0.         0.         0.        ]\n",
            " [0.25824213 0.24203362 0.         0.         0.         0.        ]\n",
            " [0.32567802 0.2390327  0.         0.         0.         0.        ]\n",
            " [0.35056809 0.25247869 0.         0.         0.         0.        ]\n",
            " [0.21439303 0.35256147 0.         0.         0.         0.        ]\n",
            " [0.31200865 0.23178595 0.         0.         0.         0.        ]\n",
            " [0.25148901 0.2295379  0.         0.         0.         0.        ]\n",
            " [0.30748862 0.25875482 0.         0.         0.         0.        ]\n",
            " [0.36547282 0.22246559 0.         0.         0.         0.        ]\n",
            " [0.50939906 0.29415682 1.         0.         0.         0.        ]\n",
            " [0.33621103 0.18236133 0.         0.         0.         0.        ]\n",
            " [0.24180433 0.35080278 0.         0.         0.         0.        ]\n",
            " [0.35077375 0.26796943 0.         0.         0.         0.        ]\n",
            " [0.2810353  0.2497896  0.         0.         0.         0.        ]\n",
            " [0.37979716 0.29824069 0.         0.         0.         0.        ]\n",
            " [0.4084948  0.28126478 0.         0.         0.         0.        ]\n",
            " [0.41586649 0.34354016 0.         0.         0.         0.        ]\n",
            " [0.44602025 0.31593204 0.         0.         0.         0.        ]\n",
            " [0.30718359 0.28312814 0.         0.         0.         0.        ]\n",
            " [0.21127935 0.36157492 0.         0.         0.         0.        ]\n",
            " [0.39502421 0.28212839 0.         0.         0.         1.        ]\n",
            " [0.25605443 0.350959   0.         0.         0.         0.        ]\n",
            " [0.36295936 0.27863702 0.         0.         0.         0.        ]\n",
            " [0.43882093 0.29208171 0.         0.         0.         0.        ]\n",
            " [0.43331116 0.30598509 0.         0.         0.         0.        ]\n",
            " [0.43099898 0.32882822 0.         0.         0.         0.        ]\n",
            " [0.42682663 0.31143302 0.         0.         0.         0.        ]\n",
            " [0.43083894 0.31197315 0.         0.         0.         0.        ]\n",
            " [0.36211678 0.34532639 0.         0.         0.         0.        ]\n",
            " [0.4216564  0.29925725 0.         0.         0.         0.        ]\n",
            " [0.4506959  0.29036602 0.         0.         0.         0.        ]\n",
            " [0.44206724 0.31137094 0.         0.         0.         0.        ]\n",
            " [0.37576964 0.29077742 0.         0.         0.         0.        ]\n",
            " [0.3879618  0.34389964 0.         0.         0.         0.        ]\n",
            " [0.42974004 0.3302609  0.         0.         0.         0.        ]\n",
            " [0.4326345  0.34753361 0.         0.         0.         0.        ]\n",
            " [0.43411845 0.34243396 0.         0.         0.         0.        ]\n",
            " [0.38004628 0.30135271 0.         0.         0.         0.        ]\n",
            " [0.41908586 0.3131015  0.         0.         0.         0.        ]\n",
            " [0.3769055  0.33260036 0.         0.         0.         0.        ]\n",
            " [0.3757326  0.29405242 0.         0.         0.         0.        ]\n",
            " [0.38282827 0.27581745 0.         0.         1.         0.        ]\n",
            " [0.47518209 0.35636511 0.         0.         1.         0.        ]\n",
            " [0.42692202 0.37701121 0.         0.         1.         0.        ]\n",
            " [0.40284193 0.29657209 0.         0.         1.         0.        ]\n",
            " [0.49083123 0.36865437 0.         0.         1.         0.        ]\n",
            " [0.44494432 0.27507311 0.         0.         0.         0.        ]\n",
            " [0.49739167 0.35024777 0.         0.         0.         0.        ]\n",
            " [0.45642799 0.39547625 0.         0.         0.         0.        ]\n",
            " [0.48033896 0.36445114 0.         0.         0.         0.        ]\n",
            " [0.4050675  0.32740116 0.         0.         0.         0.        ]\n",
            " [0.4056139  0.35373104 0.         0.         0.         0.        ]\n",
            " [0.37484795 0.33219567 0.         0.         0.         0.        ]\n",
            " [0.41616634 0.2570079  0.         0.         0.         0.        ]\n",
            " [0.32781351 0.26223198 0.         0.         0.         0.        ]\n",
            " [0.29053447 0.28902116 0.         0.         0.         0.        ]\n",
            " [0.36206296 0.31215405 0.         0.         0.         0.        ]\n",
            " [0.36714876 0.34659007 0.         0.         0.         0.        ]\n",
            " [0.2258441  0.191385   0.         0.         0.         0.        ]\n",
            " [0.40196794 0.32099241 0.         0.         0.         0.        ]\n",
            " [0.43424919 0.24034104 0.         0.         0.         0.        ]\n",
            " [0.36968669 0.34530294 0.         0.         0.         0.        ]\n",
            " [0.38441214 0.33432397 0.         0.         0.         0.        ]\n",
            " [0.39955723 0.33594212 0.         0.         0.         0.        ]\n",
            " [0.42447069 0.33629462 0.         0.         0.         0.        ]\n",
            " [0.40210444 0.2467427  0.         0.         0.         0.        ]\n",
            " [0.39416173 0.25845447 0.         0.         0.         0.        ]\n",
            " [0.37061879 0.20666055 0.         0.         0.         0.        ]\n",
            " [0.32267618 0.3579351  0.         0.         0.         0.        ]\n",
            " [0.38833201 0.35862184 0.         0.         0.         0.        ]\n",
            " [0.38502431 0.36149034 0.         0.         0.         0.        ]\n",
            " [0.4002271  0.36010331 0.         0.         0.         0.        ]\n",
            " [0.44775635 0.38577485 0.         0.         0.         0.        ]\n",
            " [0.38367784 0.23826768 0.         0.         0.         0.        ]\n",
            " [0.36455098 0.30964023 0.         0.         0.         0.        ]\n",
            " [0.41364449 0.20712134 0.         0.         0.         0.        ]\n",
            " [0.45325363 0.25198901 0.         0.         0.         0.        ]\n",
            " [0.48282343 0.35452315 0.         0.         0.         0.        ]\n",
            " [0.46277982 0.32527712 0.         0.         0.         0.        ]\n",
            " [0.48576337 0.36913922 0.         0.         0.         0.        ]\n",
            " [0.45562834 0.2351988  0.         0.         0.         0.        ]\n",
            " [0.3320604  0.2942014  0.         0.         0.         0.        ]\n",
            " [0.34807873 0.24383405 0.         0.         0.         0.        ]\n",
            " [0.33202103 0.34368211 0.         0.         0.         0.        ]\n",
            " [0.33276287 0.31546149 0.         0.         0.         0.        ]\n",
            " [0.35068887 0.32727227 0.         0.         0.         0.        ]\n",
            " [0.28530765 0.28662339 0.         0.         0.         0.        ]\n",
            " [0.38858572 0.33162674 0.         0.         0.         0.        ]\n",
            " [0.35923466 0.27070963 0.         0.         0.         0.        ]\n",
            " [0.33802944 0.28691953 0.         0.         0.         0.        ]\n",
            " [0.40302438 0.33468235 0.         0.         0.         0.        ]\n",
            " [0.42529055 0.34542781 0.         0.         0.         0.        ]\n",
            " [0.44777942 0.3788332  0.         0.         0.         0.        ]\n",
            " [0.44987386 0.37105083 0.         0.         0.         0.        ]\n",
            " [0.4002097  0.26307604 0.         0.         0.         0.        ]\n",
            " [0.45730084 0.38195544 0.         0.         0.         0.        ]\n",
            " [0.43093312 0.33091983 0.         0.         0.         0.        ]\n",
            " [0.46240932 0.36350733 0.         0.         0.         0.        ]\n",
            " [0.42475107 0.20163737 0.         0.         0.         0.        ]\n",
            " [0.40041199 0.30144361 0.         0.         0.         0.        ]\n",
            " [0.44015616 0.35833207 0.         0.         0.         0.        ]\n",
            " [0.43890455 0.37980902 0.         0.         0.         0.        ]\n",
            " [0.4522962  0.38724652 0.         0.         0.         0.        ]\n",
            " [0.43104237 0.3243936  0.         0.         0.         0.        ]\n",
            " [0.43752846 0.37338409 0.         0.         0.         0.        ]\n",
            " [0.42761838 0.36952612 0.         0.         0.         0.        ]\n",
            " [0.43145165 0.35337859 0.         0.         0.         0.        ]\n",
            " [0.47484919 0.25270823 0.         0.         0.         0.        ]\n",
            " [0.48236749 0.35111806 0.         0.         0.         0.        ]\n",
            " [0.48736012 0.36460358 0.         0.         0.         0.        ]\n",
            " [0.47764546 0.37538138 0.         0.         0.         0.        ]\n",
            " [0.47342196 0.363552   0.         0.         0.         0.        ]\n",
            " [0.46945423 0.34269631 0.         0.         0.         0.        ]\n",
            " [0.46868268 0.39845762 0.         0.         0.         0.        ]\n",
            " [0.46930516 0.38427642 0.         0.         0.         0.        ]\n",
            " [0.47658479 0.37172583 0.         0.         0.         0.        ]\n",
            " [0.38022393 0.23419568 0.         0.         0.         0.        ]\n",
            " [0.401793   0.31688884 0.         0.         0.         0.        ]\n",
            " [0.42392492 0.34741017 0.         0.         0.         0.        ]\n",
            " [0.44256431 0.38616756 0.         0.         0.         0.        ]\n",
            " [0.42253825 0.37536535 0.         0.         0.         0.        ]\n",
            " [0.41748276 0.2768943  0.         0.         0.         0.        ]\n",
            " [0.43737668 0.40599987 0.         0.         0.         0.        ]\n",
            " [0.38695371 0.31912765 0.         0.         0.         0.        ]\n",
            " [0.41404909 0.35381839 0.         0.         0.         0.        ]\n",
            " [0.47710592 0.21664946 0.         0.         0.         0.        ]\n",
            " [0.34488168 0.33255106 0.         0.         0.         0.        ]\n",
            " [0.37169746 0.34489739 0.         0.         0.         0.        ]\n",
            " [0.29772055 0.3289786  0.         0.         0.         0.        ]\n",
            " [0.30690786 0.32295367 0.         0.         0.         0.        ]\n",
            " [0.37296519 0.22213881 0.         0.         0.         0.        ]\n",
            " [0.32278189 0.32860303 0.         0.         0.         0.        ]\n",
            " [0.38430011 0.33147806 0.         0.         0.         0.        ]\n",
            " [0.34036636 0.34600386 0.         0.         0.         0.        ]\n",
            " [0.36847225 0.28629652 0.         0.         0.         0.        ]\n",
            " [0.23440556 0.3147122  0.         0.         0.         0.        ]\n",
            " [0.37091935 0.37834135 0.         0.         0.         0.        ]\n",
            " [0.38389969 0.37256894 0.         0.         0.         0.        ]\n",
            " [0.31321099 0.23266879 0.         0.         0.         0.        ]\n",
            " [0.41442493 0.37786734 0.         0.         0.         0.        ]\n",
            " [0.35004929 0.31292689 0.         0.         0.         0.        ]\n",
            " [0.35102662 0.19661863 0.         0.         0.         0.        ]\n",
            " [0.39989311 0.24073009 0.         0.         0.         0.        ]\n",
            " [0.3032068  0.23322506 0.         0.         0.         0.        ]\n",
            " [0.37235028 0.32838488 0.         0.         0.         0.        ]\n",
            " [0.29809675 0.1753311  0.         0.         0.         0.        ]\n",
            " [0.37257329 0.33677104 0.         0.         0.         0.        ]\n",
            " [0.37194216 0.36352214 0.         0.         0.         0.        ]\n",
            " [0.32550696 0.38110331 0.         0.         0.         0.        ]\n",
            " [0.27943486 0.18757771 0.         0.         0.         0.        ]\n",
            " [0.29574463 0.27656922 0.         0.         0.         0.        ]\n",
            " [0.38706553 0.3326484  0.         0.         0.         0.        ]\n",
            " [0.49330291 0.36645949 0.         0.         0.         1.        ]\n",
            " [0.53704315 0.28530982 1.         0.         1.         0.        ]\n",
            " [0.49000034 0.35284597 0.         0.         1.         0.        ]\n",
            " [0.54781473 0.29454899 1.         0.         1.         0.        ]\n",
            " [0.49198917 0.37958387 0.         0.         1.         0.        ]\n",
            " [0.40043741 0.32242629 0.         0.         1.         0.        ]\n",
            " [0.49368158 0.25841582 0.         0.         1.         0.        ]\n",
            " [0.36082602 0.26248622 0.         0.         0.         0.        ]\n",
            " [0.5199613  0.26329565 1.         0.         0.         0.        ]\n",
            " [0.3256948  0.3391552  0.         0.         0.         0.        ]\n",
            " [0.47584119 0.32880363 0.         0.         1.         0.        ]\n",
            " [0.54635847 0.29942974 1.         0.         1.         0.        ]\n",
            " [0.48098305 0.35159007 0.         0.         1.         0.        ]\n",
            " [0.54799843 0.29846275 1.         0.         1.         0.        ]\n",
            " [0.4891724  0.34237546 0.         0.         1.         0.        ]\n",
            " [0.48907292 0.33098516 0.         0.         1.         1.        ]\n",
            " [0.52930176 0.27342299 1.         0.         1.         0.        ]\n",
            " [0.54114062 0.27007946 1.         0.         1.         0.        ]\n",
            " [0.54574907 0.35226607 1.         0.         1.         0.        ]\n",
            " [0.56762475 0.3073757  1.         0.         1.         0.        ]\n",
            " [0.5761022  0.46149299 1.         0.         1.         1.        ]\n",
            " [0.52759868 0.40476841 1.         0.         1.         0.        ]\n",
            " [0.60164607 0.47006705 1.         0.         1.         0.        ]\n",
            " [0.55191517 0.39500764 1.         0.         1.         0.        ]\n",
            " [0.57921034 0.42985982 1.         0.         1.         0.        ]\n",
            " [0.55865133 0.4048799  1.         0.         1.         1.        ]\n",
            " [0.5649631  0.38065982 1.         0.         1.         1.        ]\n",
            " [0.58130723 0.38548613 1.         0.         1.         0.        ]\n",
            " [0.55826455 0.37981248 1.         0.         1.         0.        ]\n",
            " [0.59932017 0.41246706 1.         0.         1.         0.        ]\n",
            " [0.45331013 0.49395356 0.         0.         0.         0.        ]\n",
            " [0.4674502  0.44086966 0.         0.         0.         0.        ]\n",
            " [0.40183589 0.48812321 0.         0.         0.         0.        ]\n",
            " [0.46194109 0.46112859 0.         0.         0.         1.        ]\n",
            " [0.39295557 0.47317478 0.         0.         0.         0.        ]\n",
            " [0.52069879 0.29428309 1.         0.         0.         0.        ]\n",
            " [0.52697599 0.38508594 1.         0.         0.         0.        ]\n",
            " [0.52931809 0.33295196 1.         0.         0.         0.        ]\n",
            " [0.53879273 0.3495177  1.         0.         0.         0.        ]\n",
            " [0.46592513 0.32750952 0.         0.         0.         0.        ]\n",
            " [0.45803156 0.39253914 0.         0.         1.         0.        ]\n",
            " [0.52046067 0.4151386  1.         0.         1.         0.        ]\n",
            " [0.56269151 0.3828918  1.         0.         1.         0.        ]\n",
            " [0.55029982 0.38655341 1.         0.         1.         0.        ]\n",
            " [0.43303555 0.32500774 0.         0.         1.         0.        ]\n",
            " [0.42024213 0.37858036 0.         0.         1.         0.        ]\n",
            " [0.52820867 0.39309555 1.         0.         1.         0.        ]\n",
            " [0.59163034 0.37460616 1.         0.         1.         0.        ]\n",
            " [0.5729363  0.38189015 1.         0.         1.         0.        ]\n",
            " [0.46407312 0.29923379 0.         0.         1.         0.        ]\n",
            " [0.51771313 0.36306965 1.         0.         1.         0.        ]\n",
            " [0.52865875 0.38008517 1.         0.         1.         0.        ]\n",
            " [0.52506143 0.33448115 1.         0.         1.         0.        ]\n",
            " [0.54079807 0.35088071 1.         0.         1.         0.        ]\n",
            " [0.50192833 0.30281886 1.         0.         1.         0.        ]\n",
            " [0.45184374 0.35119125 0.         0.         0.         1.        ]\n",
            " [0.52397543 0.40208152 1.         0.         1.         0.        ]\n",
            " [0.58232367 0.3812255  1.         0.         1.         0.        ]\n",
            " [0.55584258 0.39310774 1.         0.         1.         0.        ]\n",
            " [0.4231025  0.35386723 0.         0.         1.         0.        ]\n",
            " [0.50791115 0.32675225 1.         0.         1.         0.        ]\n",
            " [0.52275258 0.39745477 1.         0.         1.         0.        ]\n",
            " [0.57007182 0.37468067 1.         0.         1.         0.        ]\n",
            " [0.55936193 0.37880924 1.         0.         1.         0.        ]\n",
            " [0.4559876  0.29909489 0.         0.         1.         0.        ]\n",
            " [0.47871625 0.47398701 0.         0.         1.         0.        ]\n",
            " [0.4855229  0.44723299 0.         0.         0.         1.        ]\n",
            " [0.48629308 0.37655312 0.         0.         1.         0.        ]\n",
            " [0.48743182 0.40577266 0.         0.         0.         0.        ]\n",
            " [0.40883061 0.36291578 0.         0.         0.         0.        ]\n",
            " [0.52763373 0.36465201 1.         0.         1.         0.        ]\n",
            " [0.55188209 0.49764845 1.         0.         1.         0.        ]\n",
            " [0.46910557 0.31260651 0.         0.         1.         0.        ]\n",
            " [0.54307312 0.38496241 1.         0.         1.         0.        ]\n",
            " [0.43575406 0.29202145 0.         0.         0.         0.        ]\n",
            " [0.51756859 0.43351969 1.         0.         1.         0.        ]\n",
            " [0.53894114 0.25441158 1.         0.         1.         0.        ]\n",
            " [0.46700338 0.243156   0.         0.         1.         0.        ]\n",
            " [0.55289304 0.30751747 1.         0.         0.         0.        ]\n",
            " [0.44738001 0.29512691 0.         0.         1.         0.        ]\n",
            " [0.56593561 0.3934651  1.         0.         1.         0.        ]\n",
            " [0.62053555 0.35288313 1.         0.         1.         0.        ]\n",
            " [0.53967083 0.2202058  1.         0.         1.         0.        ]\n",
            " [0.61965406 0.30438915 1.         0.         1.         0.        ]\n",
            " [0.50147545 0.3251138  1.         0.         1.         0.        ]\n",
            " [0.49580172 0.42032561 0.         0.         1.         1.        ]\n",
            " [0.50692099 0.35246328 1.         0.         1.         0.        ]\n",
            " [0.46266904 0.34195697 0.         0.         1.         0.        ]\n",
            " [0.48215851 0.3572588  0.         0.         1.         0.        ]\n",
            " [0.42664409 0.27742332 0.         0.         0.         0.        ]\n",
            " [0.52863038 0.29989508 1.         0.         1.         0.        ]\n",
            " [0.53340417 0.29599366 1.         0.         1.         0.        ]\n",
            " [0.47049722 0.24388415 0.         0.         1.         0.        ]\n",
            " [0.52794868 0.28760234 1.         0.         1.         0.        ]\n",
            " [0.40335113 0.29531729 0.         0.         1.         0.        ]\n",
            " [0.4086293  0.36857042 0.         0.         0.         0.        ]\n",
            " [0.33422747 0.31184208 0.         0.         0.         0.        ]\n",
            " [0.36403155 0.30862227 0.         0.         0.         0.        ]\n",
            " [0.32903332 0.31544036 0.         0.         0.         0.        ]\n",
            " [0.41069445 0.35556006 0.         0.         0.         0.        ]\n",
            " [0.44691733 0.37763485 0.         0.         1.         0.        ]\n",
            " [0.48069668 0.29389134 0.         0.         1.         0.        ]\n",
            " [0.49850324 0.30307919 0.         0.         1.         0.        ]\n",
            " [0.4956058  0.30394253 0.         0.         1.         0.        ]\n",
            " [0.55896103 0.40392399 1.         0.         1.         0.        ]\n",
            " [0.51810664 0.32414153 1.         0.         1.         0.        ]\n",
            " [0.44973123 0.30345997 0.         0.         1.         0.        ]\n",
            " [0.49078757 0.36863112 0.         0.         0.         0.        ]\n",
            " [0.45310152 0.3033424  0.         0.         1.         0.        ]\n",
            " [0.39400977 0.36044618 0.         0.         1.         1.        ]\n",
            " [0.41397545 0.32751238 0.         0.         1.         0.        ]\n",
            " [0.49313134 0.37885687 0.         0.         1.         0.        ]\n",
            " [0.49315605 0.31073579 0.         0.         1.         0.        ]\n",
            " [0.46055624 0.44365051 0.         0.         1.         1.        ]\n",
            " [0.45654255 0.33863971 0.         0.         0.         0.        ]\n",
            " [0.47995579 0.36573413 0.         0.         0.         0.        ]\n",
            " [0.50148106 0.36759374 1.         0.         1.         0.        ]\n",
            " [0.49883571 0.36326751 0.         0.         0.         0.        ]\n",
            " [0.54440653 0.3638657  1.         0.         0.         0.        ]\n",
            " [0.48370859 0.28582639 0.         0.         0.         0.        ]\n",
            " [0.55395228 0.45947614 1.         0.         0.         0.        ]\n",
            " [0.3803401  0.38549161 0.         0.         1.         0.        ]\n",
            " [0.42691916 0.32018939 0.         0.         0.         0.        ]\n",
            " [0.46600446 0.31816566 0.         0.         1.         0.        ]\n",
            " [0.4504284  0.31963614 0.         0.         1.         0.        ]\n",
            " [0.54431182 0.37645242 1.         0.         1.         0.        ]\n",
            " [0.46057191 0.18266329 0.         0.         0.         0.        ]\n",
            " [0.4583995  0.36003301 0.         0.         1.         0.        ]\n",
            " [0.49424076 0.46335676 0.         0.         1.         0.        ]\n",
            " [0.46518651 0.3101007  0.         0.         1.         0.        ]\n",
            " [0.50644463 0.31815353 1.         0.         1.         0.        ]\n",
            " [0.4909828  0.32519203 0.         0.         1.         0.        ]\n",
            " [0.54652703 0.31684297 1.         0.         1.         0.        ]\n",
            " [0.52070296 0.36433741 1.         0.         1.         0.        ]\n",
            " [0.50929165 0.41798526 1.         0.         0.         0.        ]\n",
            " [0.45755959 0.3576951  0.         0.         1.         0.        ]\n",
            " [0.47465971 0.31467822 0.         0.         1.         0.        ]\n",
            " [0.49883199 0.36915463 0.         0.         1.         1.        ]\n",
            " [0.47305349 0.3359932  0.         0.         1.         0.        ]\n",
            " [0.5433771  0.32019672 1.         0.         1.         0.        ]\n",
            " [0.48689428 0.30267113 0.         0.         1.         0.        ]\n",
            " [0.53070718 0.48144802 1.         0.         1.         1.        ]\n",
            " [0.3408156  0.38646558 0.         0.         1.         0.        ]\n",
            " [0.3354727  0.37663439 0.         0.         0.         0.        ]\n",
            " [0.37526521 0.30596411 0.         0.         1.         0.        ]\n",
            " [0.30423075 0.30090114 0.         0.         0.         0.        ]\n",
            " [0.49829352 0.28934562 0.         0.         1.         0.        ]\n",
            " [0.4458116  0.28006235 0.         0.         0.         0.        ]\n",
            " [0.49782994 0.3528415  0.         0.         0.         0.        ]\n",
            " [0.48670027 0.24106975 0.         0.         0.         0.        ]\n",
            " [0.47730398 0.31106094 0.         0.         0.         0.        ]\n",
            " [0.42405215 0.36623561 0.         0.         0.         0.        ]\n",
            " [0.40740961 0.34230885 0.         0.         0.         0.        ]\n",
            " [0.47324219 0.37386459 0.         0.         0.         0.        ]\n",
            " [0.41966045 0.34385639 0.         0.         0.         0.        ]\n",
            " [0.48402968 0.32171711 0.         0.         1.         0.        ]\n",
            " [0.39246505 0.29445162 0.         0.         0.         0.        ]\n",
            " [0.5250327  0.34141871 1.         0.         0.         0.        ]\n",
            " [0.34752148 0.2338104  0.         0.         0.         0.        ]\n",
            " [0.33597267 0.15288311 0.         0.         0.         0.        ]\n",
            " [0.40187633 0.20538308 0.         0.         0.         0.        ]\n",
            " [0.51786578 0.31903678 1.         0.         1.         0.        ]\n",
            " [0.44847748 0.25434455 0.         0.         0.         0.        ]\n",
            " [0.4236829  0.23388982 0.         0.         0.         0.        ]\n",
            " [0.31320584 0.18078409 0.         0.         0.         0.        ]\n",
            " [0.37525481 0.23235522 0.         0.         0.         0.        ]\n",
            " [0.39217758 0.2270162  0.         0.         0.         0.        ]\n",
            " [0.45779011 0.30729893 0.         0.         0.         0.        ]\n",
            " [0.51112956 0.28540859 1.         0.         0.         0.        ]\n",
            " [0.38221031 0.21569726 0.         0.         0.         0.        ]\n",
            " [0.39492008 0.30116597 0.         0.         0.         0.        ]\n",
            " [0.36547917 0.29053697 0.         0.         0.         1.        ]\n",
            " [0.43810114 0.28671625 0.         0.         0.         1.        ]\n",
            " [0.41695821 0.3246794  0.         0.         0.         1.        ]\n",
            " [0.53194809 0.44429722 1.         0.         0.         0.        ]\n",
            " [0.38229534 0.29828474 0.         0.         0.         0.        ]\n",
            " [0.38788036 0.2822184  0.         0.         0.         0.        ]\n",
            " [0.38398749 0.28713199 0.         0.         0.         0.        ]\n",
            " [0.53351909 0.3889814  1.         0.         0.         0.        ]\n",
            " [0.45198449 0.37510532 0.         0.         0.         0.        ]\n",
            " [0.4562434  0.40463129 0.         0.         0.         1.        ]\n",
            " [0.48589388 0.39256394 0.         0.         0.         1.        ]\n",
            " [0.46756625 0.35155374 0.         0.         0.         1.        ]\n",
            " [0.4278684  0.30997601 0.         0.         0.         1.        ]\n",
            " [0.4285644  0.35293353 0.         0.         0.         0.        ]\n",
            " [0.45203593 0.32151267 0.         0.         0.         0.        ]\n",
            " [0.4260588  0.36419421 0.         0.         0.         1.        ]\n",
            " [0.48734552 0.34277096 0.         0.         0.         1.        ]\n",
            " [0.3944048  0.24606501 0.         0.         0.         0.        ]\n",
            " [0.41223177 0.54058933 0.         1.         0.         0.        ]\n",
            " [0.4354839  0.52853578 0.         1.         0.         1.        ]\n",
            " [0.42451361 0.51054889 0.         1.         0.         1.        ]\n",
            " [0.46227941 0.49212158 0.         0.         1.         1.        ]\n",
            " [0.37363204 0.54433596 0.         1.         0.         1.        ]\n",
            " [0.45503309 0.28617826 0.         0.         0.         0.        ]\n",
            " [0.4202317  0.41394314 0.         0.         0.         0.        ]\n",
            " [0.54279578 0.37805736 1.         0.         0.         1.        ]\n",
            " [0.43432897 0.44666979 0.         0.         1.         1.        ]\n",
            " [0.48522979 0.48066381 0.         0.         0.         1.        ]\n",
            " [0.39212289 0.23551926 0.         0.         0.         0.        ]\n",
            " [0.51988041 0.42671779 1.         0.         0.         0.        ]\n",
            " [0.47005633 0.4511413  0.         0.         0.         1.        ]\n",
            " [0.47272164 0.4534272  0.         0.         0.         1.        ]\n",
            " [0.54295641 0.5404017  1.         1.         0.         1.        ]\n",
            " [0.50475246 0.46592733 1.         0.         0.         1.        ]\n",
            " [0.49528614 0.31192699 0.         0.         0.         0.        ]\n",
            " [0.53548002 0.5038904  1.         1.         1.         1.        ]\n",
            " [0.51395488 0.63351828 1.         1.         1.         1.        ]\n",
            " [0.52243173 0.60917592 1.         1.         0.         1.        ]\n",
            " [0.52985233 0.59847182 1.         1.         1.         1.        ]\n",
            " [0.48322338 0.57696205 0.         1.         0.         1.        ]\n",
            " [0.48655459 0.43533248 0.         0.         0.         0.        ]\n",
            " [0.49567199 0.42807359 0.         0.         0.         0.        ]\n",
            " [0.47856712 0.39985061 0.         0.         0.         0.        ]\n",
            " [0.47980866 0.43178907 0.         0.         0.         0.        ]\n",
            " [0.43301174 0.33513182 0.         0.         0.         0.        ]\n",
            " [0.38851565 0.28673062 0.         0.         0.         0.        ]\n",
            " [0.41474584 0.40170717 0.         0.         0.         1.        ]\n",
            " [0.47913784 0.32305273 0.         0.         0.         1.        ]\n",
            " [0.38495684 0.39268634 0.         0.         0.         1.        ]\n",
            " [0.33669141 0.28761172 0.         0.         0.         1.        ]\n",
            " [0.4292089  0.3626996  0.         0.         0.         0.        ]\n",
            " [0.46652129 0.46910232 0.         0.         0.         1.        ]\n",
            " [0.44697765 0.43335056 0.         0.         0.         0.        ]\n",
            " [0.48911363 0.47583428 0.         0.         0.         1.        ]\n",
            " [0.44578779 0.35889089 0.         0.         0.         1.        ]\n",
            " [0.38584751 0.49233127 0.         0.         1.         1.        ]\n",
            " [0.51885718 0.6061402  1.         1.         1.         1.        ]\n",
            " [0.54459596 0.54415566 1.         1.         1.         1.        ]\n",
            " [0.50518531 0.65611595 1.         1.         1.         1.        ]\n",
            " [0.51444077 0.5947811  1.         1.         1.         1.        ]\n",
            " [0.44231787 0.53111637 0.         1.         1.         1.        ]\n",
            " [0.46923459 0.26352769 0.         0.         1.         0.        ]\n",
            " [0.51402938 0.36267075 1.         0.         1.         0.        ]\n",
            " [0.53497034 0.38999143 1.         0.         1.         0.        ]\n",
            " [0.47376674 0.34815419 0.         0.         1.         0.        ]\n",
            " [0.35945949 0.32370767 0.         0.         1.         0.        ]\n",
            " [0.49755394 0.36736473 0.         0.         1.         0.        ]\n",
            " [0.51888132 0.36766469 1.         0.         1.         0.        ]\n",
            " [0.48956522 0.34545222 0.         0.         1.         0.        ]\n",
            " [0.54197621 0.43423989 1.         0.         1.         0.        ]\n",
            " [0.53675854 0.21727979 1.         0.         0.         0.        ]\n",
            " [0.33388069 0.29883    0.         0.         0.         0.        ]\n",
            " [0.35205361 0.41584578 0.         0.         0.         0.        ]\n",
            " [0.34438956 0.41698363 0.         0.         0.         0.        ]\n",
            " [0.33177811 0.20118697 0.         0.         0.         0.        ]\n",
            " [0.26892474 0.28656095 0.         0.         0.         0.        ]\n",
            " [0.34985438 0.32692629 0.         0.         0.         0.        ]\n",
            " [0.3021206  0.28752875 0.         0.         0.         0.        ]\n",
            " [0.4174875  0.22742994 0.         0.         0.         0.        ]\n",
            " [0.3468872  0.29358593 0.         0.         0.         0.        ]\n",
            " [0.24324679 0.16818616 0.         0.         0.         0.        ]\n",
            " [0.5002178  0.44791368 1.         0.         0.         0.        ]\n",
            " [0.4123686  0.32448891 0.         0.         0.         0.        ]\n",
            " [0.3777113  0.32668754 0.         0.         0.         0.        ]\n",
            " [0.32563898 0.32400692 0.         0.         0.         0.        ]\n",
            " [0.45472842 0.32342124 0.         0.         0.         0.        ]\n",
            " [0.41785583 0.32303563 0.         0.         0.         0.        ]\n",
            " [0.50876808 0.35244107 1.         0.         0.         0.        ]\n",
            " [0.38877964 0.25786892 0.         0.         0.         0.        ]\n",
            " [0.45728251 0.3314209  0.         0.         0.         0.        ]\n",
            " [0.45037466 0.30698285 0.         0.         0.         0.        ]\n",
            " [0.52804559 0.3920331  1.         0.         0.         0.        ]\n",
            " [0.36748394 0.2830058  0.         0.         0.         0.        ]\n",
            " [0.39177263 0.26396394 0.         0.         0.         0.        ]\n",
            " [0.47546586 0.26604176 0.         0.         0.         0.        ]\n",
            " [0.42479849 0.28372136 0.         0.         0.         0.        ]\n",
            " [0.47678491 0.26494098 0.         0.         0.         0.        ]\n",
            " [0.55192977 0.31270584 1.         0.         1.         0.        ]\n",
            " [0.47014958 0.4361974  0.         0.         1.         0.        ]\n",
            " [0.50203103 0.39921373 1.         0.         1.         0.        ]\n",
            " [0.52321464 0.35754502 1.         0.         1.         0.        ]\n",
            " [0.52923369 0.48164624 1.         0.         0.         0.        ]\n",
            " [0.45818025 0.38142422 0.         0.         0.         0.        ]\n",
            " [0.5115006  0.33043286 1.         0.         1.         0.        ]\n",
            " [0.52383238 0.34652141 1.         0.         1.         0.        ]\n",
            " [0.51871413 0.32531253 1.         0.         0.         0.        ]\n",
            " [0.50536138 0.33814758 1.         0.         1.         0.        ]\n",
            " [0.50405115 0.34581235 1.         0.         1.         0.        ]\n",
            " [0.50820196 0.3498573  1.         0.         1.         0.        ]\n",
            " [0.28880697 0.23710096 0.         0.         0.         0.        ]\n",
            " [0.25429484 0.23601133 0.         0.         0.         0.        ]\n",
            " [0.28299016 0.30265164 0.         0.         0.         0.        ]\n",
            " [0.26710427 0.27534977 0.         0.         0.         0.        ]\n",
            " [0.20814227 0.28606683 0.         0.         0.         0.        ]\n",
            " [0.18263397 0.33717218 0.         0.         1.         0.        ]\n",
            " [0.36057171 0.3196997  0.         0.         0.         0.        ]\n",
            " [0.361581   0.35469326 0.         0.         0.         0.        ]\n",
            " [0.32323909 0.28939879 0.         0.         0.         0.        ]\n",
            " [0.2499781  0.27180246 0.         0.         0.         0.        ]\n",
            " [0.2894952  0.3170301  0.         0.         0.         0.        ]\n",
            " [0.26033744 0.28424552 0.         0.         0.         0.        ]\n",
            " [0.53222728 0.31254226 1.         0.         1.         0.        ]\n",
            " [0.39438781 0.31654531 0.         0.         1.         0.        ]\n",
            " [0.56888133 0.40040696 1.         0.         1.         0.        ]\n",
            " [0.52872217 0.32485321 1.         0.         1.         0.        ]\n",
            " [0.5705632  0.39748833 1.         0.         1.         0.        ]\n",
            " [0.53838575 0.35947594 1.         0.         1.         0.        ]\n",
            " [0.52358538 0.33797303 1.         0.         1.         0.        ]\n",
            " [0.53372782 0.3755827  1.         0.         1.         0.        ]\n",
            " [0.5364449  0.33924285 1.         0.         1.         0.        ]\n",
            " [0.53372502 0.35429129 1.         0.         1.         0.        ]\n",
            " [0.54144514 0.36568353 1.         0.         1.         0.        ]\n",
            " [0.54777175 0.38896406 1.         0.         0.         0.        ]\n",
            " [0.48028445 0.28894591 0.         0.         1.         0.        ]\n",
            " [0.45968536 0.32031018 0.         0.         0.         0.        ]\n",
            " [0.51279193 0.33935437 1.         0.         0.         0.        ]\n",
            " [0.49108046 0.31702793 0.         0.         0.         0.        ]\n",
            " [0.46728235 0.36596587 0.         0.         0.         0.        ]\n",
            " [0.44098374 0.40645105 0.         0.         1.         0.        ]\n",
            " [0.48625427 0.29608628 0.         0.         0.         0.        ]\n",
            " [0.51091486 0.31604272 1.         0.         0.         0.        ]\n",
            " [0.48990867 0.30843291 0.         0.         0.         0.        ]\n",
            " [0.48261943 0.32196128 0.         0.         0.         0.        ]\n",
            " [0.50034738 0.31254956 1.         0.         0.         0.        ]\n",
            " [0.51591885 0.34847102 1.         0.         0.         0.        ]\n",
            " [0.54873782 0.339021   1.         0.         1.         0.        ]\n",
            " [0.49338588 0.29315558 0.         0.         1.         0.        ]\n",
            " [0.57204151 0.40020496 1.         0.         1.         0.        ]\n",
            " [0.54069102 0.37525433 1.         0.         1.         0.        ]\n",
            " [0.59927857 0.33704656 1.         0.         1.         0.        ]\n",
            " [0.54420114 0.31941319 1.         0.         1.         0.        ]\n",
            " [0.5373522  0.34841892 1.         0.         1.         0.        ]\n",
            " [0.5593636  0.39685819 1.         0.         1.         0.        ]\n",
            " [0.53719842 0.3543756  1.         0.         1.         0.        ]\n",
            " [0.52284825 0.38179913 1.         0.         1.         0.        ]\n",
            " [0.56131834 0.39623123 1.         0.         0.         0.        ]\n",
            " [0.56796408 0.39559108 1.         0.         0.         0.        ]\n",
            " [0.49781483 0.29755649 0.         0.         1.         0.        ]\n",
            " [0.50048995 0.3588787  1.         0.         0.         0.        ]\n",
            " [0.53209788 0.3674964  1.         0.         1.         0.        ]\n",
            " [0.51426262 0.32354498 1.         0.         1.         0.        ]\n",
            " [0.46170667 0.39224669 0.         0.         1.         0.        ]\n",
            " [0.47116593 0.41740075 0.         0.         1.         0.        ]\n",
            " [0.51208949 0.31124046 1.         0.         0.         0.        ]\n",
            " [0.53396404 0.33842003 1.         0.         0.         0.        ]\n",
            " [0.51596802 0.31704149 1.         0.         0.         0.        ]\n",
            " [0.50746047 0.32561609 1.         0.         1.         0.        ]\n",
            " [0.53208351 0.34569728 1.         0.         1.         0.        ]\n",
            " [0.53500503 0.34941128 1.         0.         1.         0.        ]\n",
            " [0.40343228 0.18155198 0.         0.         0.         0.        ]\n",
            " [0.46186274 0.32072011 0.         0.         0.         0.        ]\n",
            " [0.51306099 0.30131385 1.         0.         0.         0.        ]\n",
            " [0.47572276 0.29878411 0.         0.         0.         0.        ]\n",
            " [0.4439342  0.3755618  0.         0.         0.         0.        ]\n",
            " [0.46251318 0.36794773 0.         0.         0.         0.        ]\n",
            " [0.39749029 0.20239514 0.         0.         0.         0.        ]\n",
            " [0.51941061 0.2773459  1.         0.         0.         0.        ]\n",
            " [0.43395612 0.25613454 0.         0.         0.         0.        ]\n",
            " [0.4803521  0.30769128 0.         0.         0.         0.        ]\n",
            " [0.50257421 0.29590625 1.         0.         0.         0.        ]\n",
            " [0.5212     0.26944089 1.         0.         0.         0.        ]\n",
            " [0.49587041 0.28382772 0.         0.         0.         0.        ]\n",
            " [0.48791459 0.40166658 0.         0.         0.         0.        ]\n",
            " [0.45673504 0.27996463 0.         0.         1.         0.        ]\n",
            " [0.54930836 0.32859242 1.         0.         1.         0.        ]\n",
            " [0.49586993 0.27627358 0.         0.         1.         0.        ]\n",
            " [0.54810786 0.31808543 1.         0.         1.         0.        ]\n",
            " [0.50476533 0.2874811  1.         0.         1.         0.        ]\n",
            " [0.495873   0.3192212  0.         0.         0.         0.        ]\n",
            " [0.43416455 0.25166652 0.         0.         0.         0.        ]\n",
            " [0.42666614 0.25746545 0.         0.         0.         0.        ]\n",
            " [0.45484155 0.37289742 0.         0.         0.         0.        ]\n",
            " [0.4864085  0.28734979 0.         0.         1.         0.        ]\n",
            " [0.51630098 0.37508842 1.         0.         1.         0.        ]\n",
            " [0.48309058 0.28261456 0.         0.         0.         0.        ]\n",
            " [0.46710947 0.28633392 0.         0.         1.         0.        ]\n",
            " [0.49466959 0.34048113 0.         0.         1.         0.        ]\n",
            " [0.46084416 0.26466307 0.         0.         1.         0.        ]\n",
            " [0.566755   0.2950649  1.         0.         1.         0.        ]\n",
            " [0.48090044 0.26891026 0.         0.         1.         0.        ]\n",
            " [0.54945701 0.32160783 1.         0.         1.         0.        ]\n",
            " [0.49080625 0.31735155 0.         0.         1.         0.        ]\n",
            " [0.5363816  0.29432961 1.         0.         1.         0.        ]\n",
            " [0.47800797 0.33219549 0.         0.         1.         0.        ]\n",
            " [0.49751753 0.30624077 0.         0.         1.         0.        ]\n",
            " [0.5138374  0.41460794 1.         0.         1.         0.        ]\n",
            " [0.53940207 0.287251   1.         0.         1.         0.        ]\n",
            " [0.54858422 0.33919221 1.         0.         1.         0.        ]\n",
            " [0.50991797 0.3019565  1.         0.         1.         0.        ]\n",
            " [0.53224272 0.36333752 1.         0.         1.         0.        ]\n",
            " [0.55423349 0.42635205 1.         0.         1.         0.        ]\n",
            " [0.52761751 0.31343868 1.         0.         1.         0.        ]\n",
            " [0.5451225  0.31372577 1.         0.         1.         0.        ]\n",
            " [0.53039777 0.33618227 1.         0.         1.         0.        ]\n",
            " [0.57336748 0.28757766 1.         0.         1.         0.        ]\n",
            " [0.53959334 0.39033309 1.         0.         1.         0.        ]\n",
            " [0.48082435 0.25122347 0.         0.         0.         0.        ]\n",
            " [0.40204734 0.30080873 0.         0.         0.         0.        ]\n",
            " [0.49090543 0.29155579 0.         0.         1.         0.        ]\n",
            " [0.51613373 0.37589896 1.         0.         0.         0.        ]\n",
            " [0.51518989 0.25142312 1.         0.         0.         0.        ]\n",
            " [0.56721753 0.33866245 1.         0.         1.         0.        ]\n",
            " [0.45665938 0.31450841 0.         0.         0.         0.        ]\n",
            " [0.52743995 0.30197084 1.         0.         0.         0.        ]\n",
            " [0.47050959 0.3294543  0.         0.         0.         0.        ]\n",
            " [0.50307709 0.33107051 1.         0.         0.         0.        ]\n",
            " [0.5037967  0.41091812 1.         0.         0.         0.        ]\n",
            " [0.52557051 0.28911266 1.         0.         0.         0.        ]\n",
            " [0.54481095 0.32512993 1.         0.         0.         0.        ]\n",
            " [0.4816891  0.34156331 0.         0.         0.         0.        ]\n",
            " [0.38024363 0.32237309 0.         0.         0.         0.        ]\n",
            " [0.35520715 0.15156144 0.         0.         0.         0.        ]\n",
            " [0.36762536 0.16647413 0.         0.         1.         0.        ]\n",
            " [0.39132425 0.1609707  0.         0.         0.         0.        ]\n",
            " [0.50543725 0.39735427 1.         0.         1.         0.        ]\n",
            " [0.45748311 0.22777508 0.         0.         0.         0.        ]\n",
            " [0.36011404 0.22788855 0.         0.         1.         0.        ]\n",
            " [0.3734529  0.20460634 0.         0.         1.         0.        ]\n",
            " [0.42060834 0.15468673 0.         0.         1.         0.        ]\n",
            " [0.49320394 0.39830059 0.         0.         1.         0.        ]\n",
            " [0.37661573 0.32319897 0.         0.         1.         0.        ]\n",
            " [0.33982289 0.14283256 0.         0.         1.         0.        ]\n",
            " [0.35524526 0.1449509  0.         0.         1.         0.        ]\n",
            " [0.36415449 0.14635307 0.         0.         1.         0.        ]\n",
            " [0.44798788 0.33043748 0.         0.         0.         0.        ]\n",
            " [0.43667868 0.24183662 0.         0.         1.         0.        ]\n",
            " [0.51352531 0.4050906  1.         0.         1.         1.        ]\n",
            " [0.42967892 0.39463821 0.         0.         1.         0.        ]\n",
            " [0.51834089 0.42755902 1.         0.         1.         0.        ]\n",
            " [0.43840057 0.25116441 0.         0.         1.         0.        ]\n",
            " [0.42178538 0.25714257 0.         0.         1.         0.        ]\n",
            " [0.42586955 0.44155133 0.         0.         0.         0.        ]\n",
            " [0.50885803 0.39982551 1.         0.         1.         0.        ]\n",
            " [0.38442877 0.28493997 0.         0.         1.         0.        ]\n",
            " [0.42040935 0.35938457 0.         0.         0.         0.        ]\n",
            " [0.34201127 0.20467123 0.         0.         1.         0.        ]\n",
            " [0.43136519 0.33729529 0.         0.         1.         0.        ]\n",
            " [0.37746841 0.22819589 0.         0.         1.         0.        ]\n",
            " [0.4510448  0.37399894 0.         0.         1.         0.        ]\n",
            " [0.32548827 0.25630817 0.         0.         0.         0.        ]\n",
            " [0.28005126 0.20580813 0.         0.         1.         0.        ]\n",
            " [0.43529522 0.43465263 0.         0.         1.         0.        ]\n",
            " [0.43265396 0.34314096 0.         0.         0.         0.        ]\n",
            " [0.39944938 0.26029423 0.         0.         1.         0.        ]\n",
            " [0.30983531 0.25315642 0.         0.         0.         0.        ]\n",
            " [0.39999577 0.23706423 0.         0.         0.         0.        ]\n",
            " [0.4630006  0.27518854 0.         0.         0.         0.        ]\n",
            " [0.32211846 0.20244554 0.         0.         0.         0.        ]\n",
            " [0.45075411 0.30947661 0.         0.         0.         0.        ]\n",
            " [0.41613114 0.16398105 0.         0.         0.         0.        ]\n",
            " [0.47513288 0.21411039 0.         0.         0.         0.        ]\n",
            " [0.42195845 0.35147268 0.         0.         0.         0.        ]\n",
            " [0.46003693 0.28115585 0.         0.         0.         0.        ]\n",
            " [0.25367069 0.17689748 0.         0.         0.         0.        ]\n",
            " [0.43646714 0.26943853 0.         0.         0.         0.        ]\n",
            " [0.44531083 0.29989645 0.         0.         1.         0.        ]\n",
            " [0.49341664 0.37791273 0.         0.         1.         0.        ]\n",
            " [0.42586446 0.34859186 0.         0.         1.         0.        ]\n",
            " [0.51230693 0.41315767 1.         0.         1.         0.        ]\n",
            " [0.44155541 0.24828386 0.         0.         1.         0.        ]\n",
            " [0.4396899  0.22414948 0.         0.         1.         0.        ]\n",
            " [0.47115549 0.40686166 0.         0.         1.         0.        ]\n",
            " [0.50262612 0.38534594 1.         0.         1.         0.        ]\n",
            " [0.41484073 0.30551484 0.         0.         1.         0.        ]\n",
            " [0.43691385 0.316901   0.         0.         0.         0.        ]\n",
            " [0.44252545 0.31094125 0.         0.         1.         0.        ]\n",
            " [0.46240258 0.34825531 0.         0.         1.         0.        ]\n",
            " [0.43959585 0.39863297 0.         0.         1.         0.        ]\n",
            " [0.47019684 0.37787545 0.         0.         0.         0.        ]\n",
            " [0.41686609 0.2934925  0.         0.         0.         0.        ]\n",
            " [0.39208719 0.31815222 0.         0.         0.         0.        ]\n",
            " [0.45854598 0.35295004 0.         0.         0.         0.        ]\n",
            " [0.45966426 0.3510364  0.         0.         1.         0.        ]\n",
            " [0.36974838 0.33367631 0.         0.         1.         0.        ]\n",
            " [0.45582354 0.39103827 0.         0.         0.         0.        ]\n",
            " [0.41566935 0.23121276 0.         0.         1.         0.        ]\n",
            " [0.45420983 0.32396138 0.         0.         0.         0.        ]\n",
            " [0.3729057  0.30071989 0.         0.         0.         0.        ]\n",
            " [0.46031997 0.33278891 0.         0.         0.         0.        ]\n",
            " [0.40708426 0.15783346 0.         0.         0.         0.        ]\n",
            " [0.47065386 0.18632217 0.         0.         0.         0.        ]\n",
            " [0.42495739 0.33595684 0.         0.         0.         0.        ]\n",
            " [0.45246339 0.32137328 0.         0.         1.         0.        ]\n",
            " [0.33769765 0.29681119 0.         0.         0.         0.        ]\n",
            " [0.41953143 0.28336993 0.         0.         0.         0.        ]\n",
            " [0.37159124 0.34789586 0.         0.         0.         0.        ]\n",
            " [0.35883808 0.32968697 0.         0.         0.         0.        ]\n",
            " [0.22302735 0.14620191 0.         0.         0.         0.        ]\n",
            " [0.29530835 0.21831957 0.         0.         0.         0.        ]\n",
            " [0.30760705 0.32317683 0.         0.         0.         0.        ]\n",
            " [0.4003045  0.28466004 0.         0.         0.         0.        ]\n",
            " [0.49010193 0.38901091 0.         0.         0.         1.        ]\n",
            " [0.44427738 0.40457904 0.         0.         1.         1.        ]\n",
            " [0.50051743 0.37555882 1.         0.         1.         0.        ]\n",
            " [0.45944387 0.37360039 0.         0.         0.         0.        ]\n",
            " [0.49114171 0.38978913 0.         0.         1.         0.        ]\n",
            " [0.4343932  0.37598968 0.         0.         1.         0.        ]\n",
            " [0.51506507 0.51085132 1.         1.         1.         1.        ]\n",
            " [0.49730569 0.53178144 0.         1.         1.         1.        ]\n",
            " [0.50167662 0.439711   1.         0.         1.         1.        ]\n",
            " [0.46579653 0.47965783 0.         0.         1.         1.        ]\n",
            " [0.49270725 0.4644925  0.         0.         1.         1.        ]\n",
            " [0.43793672 0.45568636 0.         0.         1.         1.        ]\n",
            " [0.50456882 0.46483645 1.         0.         1.         0.        ]\n",
            " [0.50908643 0.47573832 1.         0.         1.         0.        ]\n",
            " [0.50328887 0.4391264  1.         0.         1.         0.        ]\n",
            " [0.47306147 0.43825641 0.         0.         1.         0.        ]\n",
            " [0.4997935  0.42925125 0.         0.         1.         0.        ]\n",
            " [0.43418252 0.39309773 0.         0.         1.         0.        ]\n",
            " [0.49534664 0.44024917 0.         0.         0.         1.        ]\n",
            " [0.50419664 0.51503843 1.         1.         1.         1.        ]\n",
            " [0.50150985 0.48831698 1.         0.         1.         1.        ]\n",
            " [0.5027225  0.43261722 1.         0.         1.         1.        ]\n",
            " [0.51488078 0.47388196 1.         0.         1.         1.        ]\n",
            " [0.48552546 0.52061427 0.         1.         1.         1.        ]\n",
            " [0.49918118 0.48946977 0.         0.         1.         1.        ]\n",
            " [0.50728995 0.51119691 1.         1.         1.         1.        ]\n",
            " [0.45340827 0.40801743 0.         0.         1.         1.        ]\n",
            " [0.47790852 0.44083849 0.         0.         1.         0.        ]\n",
            " [0.50956231 0.50178266 1.         1.         1.         1.        ]\n",
            " [0.50683188 0.47388828 1.         0.         1.         1.        ]\n",
            " [0.4954581  0.44808748 0.         0.         1.         1.        ]\n",
            " [0.51267207 0.46947271 1.         0.         1.         1.        ]\n",
            " [0.51030344 0.47645837 1.         0.         1.         1.        ]\n",
            " [0.4746514  0.45165202 0.         0.         1.         1.        ]\n",
            " [0.51556736 0.48953059 1.         0.         1.         1.        ]\n",
            " [0.49986139 0.47296131 0.         0.         1.         1.        ]\n",
            " [0.5016588  0.52024698 1.         1.         1.         1.        ]\n",
            " [0.49574375 0.53271997 0.         1.         1.         1.        ]\n",
            " [0.48567075 0.52360237 0.         1.         1.         1.        ]\n",
            " [0.506387   0.52676469 1.         1.         1.         1.        ]\n",
            " [0.51513594 0.56431276 1.         1.         1.         1.        ]\n",
            " [0.48272967 0.53969246 0.         1.         1.         1.        ]\n",
            " [0.47222167 0.51743591 0.         1.         1.         1.        ]\n",
            " [0.50163418 0.54393542 1.         1.         1.         1.        ]\n",
            " [0.48336083 0.48734495 0.         0.         1.         1.        ]\n",
            " [0.4267107  0.43787712 0.         0.         1.         0.        ]\n",
            " [0.35532269 0.45804277 0.         0.         0.         1.        ]\n",
            " [0.31726041 0.4395757  0.         0.         0.         1.        ]\n",
            " [0.27930817 0.50274211 0.         1.         0.         1.        ]\n",
            " [0.34074187 0.47326472 0.         0.         0.         1.        ]\n",
            " [0.33593169 0.46742758 0.         0.         0.         0.        ]\n",
            " [0.30387843 0.49244791 0.         0.         0.         1.        ]\n",
            " [0.38146898 0.49105731 0.         0.         0.         1.        ]\n",
            " [0.49564815 0.39026156 0.         0.         1.         0.        ]\n",
            " [0.45612344 0.35057414 0.         0.         1.         1.        ]\n",
            " [0.4898411  0.35707393 0.         0.         1.         1.        ]\n",
            " [0.50012654 0.38824844 1.         0.         1.         1.        ]\n",
            " [0.45522922 0.36707157 0.         0.         1.         1.        ]\n",
            " [0.49648818 0.36249045 0.         0.         1.         1.        ]\n",
            " [0.5000264  0.39056891 1.         0.         1.         1.        ]\n",
            " [0.48057809 0.38332117 0.         0.         1.         1.        ]\n",
            " [0.52923423 0.46175352 1.         0.         1.         0.        ]\n",
            " [0.48938021 0.40934792 0.         0.         0.         1.        ]\n",
            " [0.49381527 0.37052763 0.         0.         1.         1.        ]\n",
            " [0.52119863 0.43380827 1.         0.         1.         1.        ]\n",
            " [0.51693606 0.41953227 1.         0.         1.         1.        ]\n",
            " [0.52306509 0.42451096 1.         0.         1.         0.        ]\n",
            " [0.50210524 0.45286009 1.         0.         1.         1.        ]\n",
            " [0.51521796 0.43362403 1.         0.         1.         1.        ]\n",
            " [0.35387355 0.29490924 0.         0.         0.         0.        ]\n",
            " [0.41385445 0.2731097  0.         0.         0.         0.        ]\n",
            " [0.42771295 0.27889222 0.         0.         0.         0.        ]\n",
            " [0.43579701 0.29494208 0.         0.         0.         0.        ]\n",
            " [0.4463335  0.30277163 0.         0.         0.         0.        ]\n",
            " [0.43034294 0.30889764 0.         0.         0.         0.        ]\n",
            " [0.47234556 0.30379525 0.         0.         0.         0.        ]\n",
            " [0.39101359 0.24744876 0.         0.         1.         0.        ]\n",
            " [0.28827789 0.19677866 0.         0.         0.         0.        ]\n",
            " [0.40847832 0.28126487 0.         0.         0.         0.        ]\n",
            " [0.45364681 0.34438545 0.         0.         0.         0.        ]\n",
            " [0.46177548 0.27337748 0.         0.         1.         0.        ]\n",
            " [0.44636714 0.25721681 0.         0.         0.         0.        ]\n",
            " [0.4623678  0.29360405 0.         0.         0.         0.        ]\n",
            " [0.40709761 0.39236784 0.         0.         0.         0.        ]\n",
            " [0.39761576 0.31325606 0.         0.         0.         0.        ]\n",
            " [0.28074428 0.22245374 0.         0.         0.         0.        ]\n",
            " [0.42265075 0.41581205 0.         0.         0.         0.        ]\n",
            " [0.42875233 0.35421371 0.         0.         0.         0.        ]\n",
            " [0.27873638 0.2216973  0.         0.         0.         0.        ]\n",
            " [0.49601302 0.3340151  0.         0.         0.         0.        ]\n",
            " [0.39111939 0.34292936 0.         0.         0.         0.        ]\n",
            " [0.46517423 0.36448386 0.         0.         0.         0.        ]\n",
            " [0.37856734 0.40342933 0.         0.         0.         0.        ]\n",
            " [0.43490505 0.34182042 0.         0.         0.         0.        ]\n",
            " [0.45285362 0.38610339 0.         0.         0.         0.        ]\n",
            " [0.4506453  0.40274054 0.         0.         0.         0.        ]\n",
            " [0.42460197 0.3565768  0.         0.         1.         0.        ]\n",
            " [0.44118348 0.28666976 0.         0.         1.         0.        ]\n",
            " [0.46015462 0.3192586  0.         0.         0.         0.        ]\n",
            " [0.42976266 0.30122954 0.         0.         1.         0.        ]\n",
            " [0.49822178 0.37007159 0.         0.         1.         0.        ]\n",
            " [0.4744918  0.35477543 0.         0.         1.         0.        ]\n",
            " [0.46801242 0.35397729 0.         0.         1.         0.        ]\n",
            " [0.48299941 0.41097891 0.         0.         1.         0.        ]\n",
            " [0.44829762 0.30202556 0.         0.         0.         0.        ]\n",
            " [0.29460883 0.16668339 0.         0.         0.         0.        ]\n",
            " [0.45300969 0.33107722 0.         0.         0.         0.        ]\n",
            " [0.48577356 0.38948014 0.         0.         0.         0.        ]\n",
            " [0.39320311 0.30631584 0.         0.         0.         0.        ]\n",
            " [0.43678978 0.38193431 0.         0.         0.         0.        ]\n",
            " [0.47234461 0.34417924 0.         0.         0.         0.        ]\n",
            " [0.41799185 0.24933136 0.         0.         1.         0.        ]\n",
            " [0.48064309 0.35908797 0.         0.         1.         0.        ]\n",
            " [0.48923403 0.29756674 0.         0.         0.         0.        ]\n",
            " [0.38377196 0.28778225 0.         0.         0.         0.        ]\n",
            " [0.45682409 0.28314936 0.         0.         1.         0.        ]\n",
            " [0.44937995 0.34918946 0.         0.         1.         0.        ]\n",
            " [0.40994486 0.32246077 0.         0.         0.         0.        ]\n",
            " [0.43410343 0.29147446 0.         0.         1.         0.        ]\n",
            " [0.45393446 0.29355374 0.         0.         1.         0.        ]\n",
            " [0.44904029 0.30459487 0.         0.         1.         0.        ]\n",
            " [0.41518736 0.38006005 0.         0.         1.         0.        ]\n",
            " [0.42496395 0.40140906 0.         0.         1.         0.        ]\n",
            " [0.40406013 0.34918314 0.         0.         0.         0.        ]\n",
            " [0.40080151 0.35883412 0.         0.         1.         0.        ]\n",
            " [0.3780376  0.31551605 0.         0.         0.         0.        ]\n",
            " [0.45390445 0.41134846 0.         0.         0.         0.        ]\n",
            " [0.38147593 0.28242216 0.         0.         0.         0.        ]\n",
            " [0.38954017 0.24367304 0.         0.         0.         0.        ]\n",
            " [0.36696097 0.26267979 0.         0.         1.         0.        ]\n",
            " [0.46020675 0.29326627 0.         0.         1.         0.        ]\n",
            " [0.44323677 0.37544638 0.         0.         1.         0.        ]\n",
            " [0.45909014 0.30779713 0.         0.         1.         0.        ]\n",
            " [0.450167   0.28628039 0.         0.         0.         0.        ]\n",
            " [0.314513   0.18316339 0.         0.         0.         0.        ]\n",
            " [0.31561649 0.25216758 0.         0.         0.         0.        ]\n",
            " [0.46159965 0.29567596 0.         0.         1.         0.        ]\n",
            " [0.32639644 0.24482061 0.         0.         0.         0.        ]\n",
            " [0.29705787 0.29520077 0.         0.         1.         0.        ]\n",
            " [0.48512474 0.30445746 0.         0.         1.         0.        ]\n",
            " [0.37258664 0.19155747 0.         0.         1.         0.        ]\n",
            " [0.4691973  0.28689712 0.         0.         1.         0.        ]\n",
            " [0.47118318 0.33337852 0.         0.         1.         0.        ]\n",
            " [0.39046741 0.23046267 0.         0.         0.         0.        ]\n",
            " [0.5184679  0.43747729 1.         0.         1.         1.        ]\n",
            " [0.44857955 0.38803351 0.         0.         1.         1.        ]\n",
            " [0.51990765 0.36677673 1.         0.         0.         0.        ]\n",
            " [0.48630288 0.42228565 0.         0.         1.         1.        ]\n",
            " [0.44056687 0.38214371 0.         0.         0.         0.        ]\n",
            " [0.31664962 0.273673   0.         0.         0.         0.        ]\n",
            " [0.47832689 0.42963246 0.         0.         0.         0.        ]\n",
            " [0.35865745 0.23988411 0.         0.         0.         0.        ]\n",
            " [0.49189326 0.43981633 0.         0.         1.         1.        ]\n",
            " [0.46209264 0.39822334 0.         0.         1.         1.        ]\n",
            " [0.47771817 0.44220436 0.         0.         0.         0.        ]\n",
            " [0.48727104 0.43219793 0.         0.         1.         1.        ]\n",
            " [0.46579525 0.40187851 0.         0.         0.         0.        ]\n",
            " [0.35983631 0.35393524 0.         0.         0.         0.        ]\n",
            " [0.48675108 0.43742457 0.         0.         0.         0.        ]\n",
            " [0.32722548 0.37103429 0.         0.         0.         0.        ]\n",
            " [0.51821721 0.41991255 1.         0.         1.         0.        ]\n",
            " [0.4699713  0.35608375 0.         0.         1.         0.        ]\n",
            " [0.51556027 0.2912581  1.         0.         1.         0.        ]\n",
            " [0.48789221 0.38468742 0.         0.         1.         1.        ]\n",
            " [0.43936861 0.34032398 0.         0.         1.         0.        ]\n",
            " [0.3484022  0.24125627 0.         0.         1.         0.        ]\n",
            " [0.46029654 0.40844008 0.         0.         0.         0.        ]\n",
            " [0.40386465 0.29544625 0.         0.         0.         0.        ]\n",
            " [0.51503623 0.42330709 1.         0.         1.         1.        ]\n",
            " [0.44425917 0.36602232 0.         0.         1.         1.        ]\n",
            " [0.49158034 0.40694121 0.         0.         1.         1.        ]\n",
            " [0.45131546 0.39963472 0.         0.         1.         1.        ]\n",
            " [0.4143182  0.35121125 0.         0.         0.         0.        ]\n",
            " [0.32401848 0.28210998 0.         0.         0.         0.        ]\n",
            " [0.49433327 0.41939306 0.         0.         0.         0.        ]\n",
            " [0.38648567 0.40043199 0.         0.         0.         1.        ]\n",
            " [0.49656561 0.41697422 0.         0.         1.         1.        ]\n",
            " [0.52490449 0.54020953 1.         1.         1.         1.        ]\n",
            " [0.54339606 0.3147766  1.         0.         1.         0.        ]\n",
            " [0.49919224 0.45894882 0.         0.         1.         1.        ]\n",
            " [0.44605422 0.34830183 0.         0.         0.         1.        ]\n",
            " [0.38873661 0.41036078 0.         0.         0.         1.        ]\n",
            " [0.51181167 0.37049866 1.         0.         0.         0.        ]\n",
            " [0.43848291 0.3266488  0.         0.         0.         0.        ]\n",
            " [0.54595989 0.39744753 1.         0.         1.         0.        ]\n",
            " [0.52285117 0.55839956 1.         1.         1.         1.        ]\n",
            " [0.55544668 0.33220577 1.         0.         1.         1.        ]\n",
            " [0.48964226 0.34663212 0.         0.         1.         1.        ]\n",
            " [0.43876255 0.29738557 0.         0.         1.         1.        ]\n",
            " [0.472853   0.39594918 0.         0.         0.         0.        ]\n",
            " [0.54697353 0.40943238 1.         0.         1.         0.        ]\n",
            " [0.34516519 0.32979637 0.         0.         0.         1.        ]\n",
            " [0.44287276 0.4857406  0.         0.         1.         0.        ]\n",
            " [0.40750992 0.4502618  0.         0.         1.         0.        ]\n",
            " [0.42566374 0.50012177 0.         1.         0.         0.        ]\n",
            " [0.4037495  0.47272888 0.         0.         0.         0.        ]\n",
            " [0.39738199 0.4025346  0.         0.         0.         0.        ]\n",
            " [0.28968382 0.18832794 0.         0.         0.         0.        ]\n",
            " [0.46028674 0.36829144 0.         0.         0.         0.        ]\n",
            " [0.25473285 0.1787473  0.         0.         0.         0.        ]\n",
            " [0.51090872 0.45238024 1.         0.         0.         1.        ]\n",
            " [0.47475761 0.39267373 0.         0.         1.         1.        ]\n",
            " [0.44096705 0.46232408 0.         0.         1.         1.        ]\n",
            " [0.47587639 0.412716   0.         0.         1.         0.        ]\n",
            " [0.54438597 0.46943888 1.         0.         1.         1.        ]\n",
            " [0.54744309 0.43609709 1.         0.         1.         1.        ]\n",
            " [0.54678971 0.45779219 1.         0.         0.         1.        ]\n",
            " [0.54148817 0.45675704 1.         0.         0.         1.        ]\n",
            " [0.30530059 0.21633933 0.         0.         0.         0.        ]\n",
            " [0.53041798 0.44178256 1.         0.         1.         1.        ]\n",
            " [0.45637888 0.38054502 0.         0.         0.         1.        ]\n",
            " [0.43499368 0.49421066 0.         0.         0.         1.        ]\n",
            " [0.45397127 0.45642194 0.         0.         1.         1.        ]\n",
            " [0.55266583 0.47820157 1.         0.         1.         1.        ]\n",
            " [0.54396009 0.46704957 1.         0.         1.         1.        ]\n",
            " [0.55257875 0.46986359 1.         0.         0.         1.        ]\n",
            " [0.54894674 0.46833518 1.         0.         0.         1.        ]\n",
            " [0.50333351 0.43174195 1.         0.         0.         0.        ]\n",
            " [0.5116353  0.47618002 1.         0.         0.         1.        ]\n",
            " [0.51419538 0.5053311  1.         1.         0.         1.        ]\n",
            " [0.434084   0.51225853 0.         1.         0.         1.        ]\n",
            " [0.46695825 0.45830563 0.         0.         1.         0.        ]\n",
            " [0.50708216 0.49572799 1.         0.         0.         1.        ]\n",
            " [0.50003523 0.47794196 1.         0.         1.         1.        ]\n",
            " [0.50893778 0.47082913 1.         0.         1.         1.        ]\n",
            " [0.49786481 0.47529462 0.         0.         0.         1.        ]\n",
            " [0.26488924 0.21608734 0.         0.         0.         0.        ]\n",
            " [0.51540101 0.42795098 1.         0.         1.         1.        ]\n",
            " [0.47474825 0.41069445 0.         0.         0.         1.        ]\n",
            " [0.40910009 0.33326316 0.         0.         0.         1.        ]\n",
            " [0.45770153 0.36572352 0.         0.         0.         1.        ]\n",
            " [0.51170689 0.46163452 1.         0.         1.         1.        ]\n",
            " [0.50244725 0.41802955 1.         0.         1.         1.        ]\n",
            " [0.52123839 0.42628315 1.         0.         1.         1.        ]\n",
            " [0.51371348 0.4217988  1.         0.         0.         1.        ]\n",
            " [0.30965996 0.33229008 0.         0.         0.         1.        ]\n",
            " [0.51808006 0.45229208 1.         0.         0.         1.        ]\n",
            " [0.4347612  0.4092308  0.         0.         0.         1.        ]\n",
            " [0.41563687 0.47723186 0.         0.         0.         1.        ]\n",
            " [0.44308737 0.43321183 0.         0.         0.         1.        ]\n",
            " [0.53427035 0.44569787 1.         0.         1.         1.        ]\n",
            " [0.54868126 0.45790076 1.         0.         1.         1.        ]\n",
            " [0.55015498 0.44353932 1.         0.         1.         1.        ]\n",
            " [0.53692472 0.43169975 1.         0.         0.         1.        ]\n",
            " [0.42376107 0.32086301 0.         0.         0.         0.        ]\n",
            " [0.53654277 0.4270131  1.         0.         0.         1.        ]\n",
            " [0.4856568  0.47320503 0.         0.         0.         1.        ]\n",
            " [0.39243695 0.42830145 0.         0.         0.         1.        ]\n",
            " [0.44721898 0.45933032 0.         0.         1.         1.        ]\n",
            " [0.55662358 0.42882913 1.         0.         0.         1.        ]\n",
            " [0.55464274 0.44696915 1.         0.         1.         1.        ]\n",
            " [0.55505735 0.41816229 1.         0.         0.         1.        ]\n",
            " [0.55293584 0.42200568 1.         0.         1.         1.        ]\n",
            " [0.42381638 0.35210454 0.         0.         0.         1.        ]\n",
            " [0.41279557 0.46597207 0.         0.         0.         1.        ]\n",
            " [0.34887969 0.55558485 0.         1.         0.         1.        ]\n",
            " [0.41489723 0.4280473  0.         0.         0.         1.        ]\n",
            " [0.41877666 0.44786039 0.         0.         0.         0.        ]\n",
            " [0.38821697 0.47060281 0.         0.         0.         1.        ]\n",
            " [0.37179002 0.46382257 0.         0.         0.         1.        ]\n",
            " [0.44108996 0.47305581 0.         0.         0.         1.        ]\n",
            " [0.42894363 0.45535204 0.         0.         0.         1.        ]\n",
            " [0.38709059 0.41627336 0.         0.         0.         0.        ]\n",
            " [0.41468999 0.39303187 0.         0.         1.         1.        ]\n",
            " [0.5387466  0.44974488 1.         0.         1.         1.        ]\n",
            " [0.52791291 0.42950195 1.         0.         1.         0.        ]\n",
            " [0.52458686 0.4120841  1.         0.         0.         0.        ]\n",
            " [0.51698947 0.40625617 1.         0.         1.         0.        ]\n",
            " [0.54773045 0.42260748 1.         0.         1.         0.        ]\n",
            " [0.51501888 0.4053804  1.         0.         0.         0.        ]\n",
            " [0.52533549 0.40223002 1.         0.         1.         1.        ]\n",
            " [0.52705657 0.38377672 1.         0.         0.         0.        ]\n",
            " [0.41077763 0.46171144 0.         0.         1.         1.        ]\n",
            " [0.54283684 0.45956171 1.         0.         1.         0.        ]\n",
            " [0.5477035  0.44050753 1.         0.         1.         0.        ]\n",
            " [0.53681141 0.43356022 1.         0.         0.         0.        ]\n",
            " [0.52618271 0.42749122 1.         0.         1.         0.        ]\n",
            " [0.5466122  0.45747039 1.         0.         1.         0.        ]\n",
            " [0.52500641 0.4297381  1.         0.         0.         0.        ]\n",
            " [0.52078825 0.4330416  1.         0.         1.         0.        ]\n",
            " [0.51778203 0.44818315 1.         0.         1.         0.        ]\n",
            " [0.40622255 0.33161107 0.         0.         1.         1.        ]\n",
            " [0.51164937 0.43945873 1.         0.         1.         1.        ]\n",
            " [0.53391731 0.4781681  1.         0.         1.         1.        ]\n",
            " [0.50744426 0.41657752 1.         0.         0.         1.        ]\n",
            " [0.52178991 0.38952574 1.         0.         0.         1.        ]\n",
            " [0.52090061 0.43832552 1.         0.         0.         1.        ]\n",
            " [0.53183931 0.38151971 1.         0.         0.         1.        ]\n",
            " [0.53829718 0.37401903 1.         0.         1.         1.        ]\n",
            " [0.53831422 0.37565324 1.         0.         1.         1.        ]\n",
            " [0.43992189 0.50114882 0.         1.         0.         1.        ]\n",
            " [0.5442968  0.46321025 1.         0.         1.         1.        ]\n",
            " [0.54461086 0.44925138 1.         0.         1.         0.        ]\n",
            " [0.53116888 0.43353027 1.         0.         0.         0.        ]\n",
            " [0.51577741 0.43320838 1.         0.         1.         0.        ]\n",
            " [0.55695754 0.4451201  1.         0.         1.         0.        ]\n",
            " [0.51229572 0.45371157 1.         0.         0.         0.        ]\n",
            " [0.51267987 0.45697969 1.         0.         1.         1.        ]\n",
            " [0.51014811 0.47439471 1.         0.         1.         1.        ]\n",
            " [0.43158966 0.39198261 0.         0.         0.         1.        ]\n",
            " [0.55191207 0.45115614 1.         0.         1.         1.        ]\n",
            " [0.54861116 0.43582293 1.         0.         1.         1.        ]\n",
            " [0.53167212 0.43681052 1.         0.         1.         1.        ]\n",
            " [0.45918044 0.44355115 0.         0.         1.         1.        ]\n",
            " [0.47104141 0.3962633  0.         0.         1.         1.        ]\n",
            " [0.44495866 0.43345734 0.         0.         0.         1.        ]\n",
            " [0.46532306 0.4452967  0.         0.         1.         1.        ]\n",
            " [0.46238586 0.41281018 0.         0.         1.         1.        ]\n",
            " [0.49359632 0.41281804 0.         0.         1.         0.        ]\n",
            " [0.39781654 0.46277329 0.         0.         1.         0.        ]\n",
            " [0.43913841 0.49052778 0.         0.         0.         0.        ]\n",
            " [0.42548746 0.49181637 0.         0.         0.         0.        ]\n",
            " [0.47363809 0.49817219 0.         0.         1.         0.        ]\n",
            " [0.41298088 0.47330555 0.         0.         0.         0.        ]\n",
            " [0.4962644  0.49573994 0.         0.         0.         0.        ]\n",
            " [0.48089641 0.5080896  0.         1.         1.         0.        ]\n",
            " [0.46374688 0.47721744 0.         0.         0.         0.        ]\n",
            " [0.60667676 0.33017492 1.         0.         1.         0.        ]\n",
            " [0.59836954 0.33558881 1.         0.         1.         1.        ]\n",
            " [0.25224185 0.5159741  0.         1.         0.         1.        ]\n",
            " [0.4867397  0.28536776 0.         0.         0.         0.        ]\n",
            " [0.58942896 0.45714185 1.         0.         1.         1.        ]\n",
            " [0.55460465 0.31805125 1.         0.         1.         0.        ]\n",
            " [0.57177812 0.46007943 1.         0.         1.         0.        ]\n",
            " [0.56695747 0.38434777 1.         0.         1.         0.        ]\n",
            " [0.57226872 0.39883026 1.         0.         1.         0.        ]\n",
            " [0.47517195 0.34296343 0.         0.         1.         0.        ]\n",
            " [0.58100247 0.37669152 1.         0.         1.         0.        ]\n",
            " [0.5590179  0.36708966 1.         0.         1.         1.        ]\n",
            " [0.61653709 0.45224541 1.         0.         1.         0.        ]\n",
            " [0.38487247 0.33876562 0.         0.         1.         0.        ]\n",
            " [0.58114994 0.43901953 1.         0.         1.         0.        ]\n",
            " [0.37032953 0.34722319 0.         0.         1.         0.        ]\n",
            " [0.56732398 0.4735024  1.         0.         1.         0.        ]\n",
            " [0.56841636 0.49349466 1.         0.         1.         1.        ]\n",
            " [0.50752854 0.44058469 1.         0.         1.         1.        ]\n",
            " [0.50758195 0.34769696 1.         0.         1.         1.        ]\n",
            " [0.48981345 0.39329368 0.         0.         1.         1.        ]\n",
            " [0.44605678 0.41570377 0.         0.         0.         1.        ]\n",
            " [0.59258747 0.45724851 1.         0.         1.         1.        ]\n",
            " [0.40285447 0.40945405 0.         0.         0.         1.        ]\n",
            " [0.54324043 0.45089841 1.         0.         0.         1.        ]\n",
            " [0.41117245 0.47885391 0.         0.         0.         1.        ]\n",
            " [0.48161399 0.48886633 0.         0.         1.         1.        ]\n",
            " [0.40209737 0.46612638 0.         0.         0.         1.        ]\n",
            " [0.45222661 0.45657536 0.         0.         0.         1.        ]\n",
            " [0.44392642 0.40072832 0.         0.         0.         1.        ]\n",
            " [0.50242096 0.50002891 1.         1.         0.         1.        ]\n",
            " [0.3451668  0.40041041 0.         0.         0.         1.        ]\n",
            " [0.3555412  0.40077436 0.         0.         0.         1.        ]\n",
            " [0.48794967 0.38672686 0.         0.         0.         0.        ]\n",
            " [0.3997066  0.28186792 0.         0.         0.         0.        ]\n",
            " [0.40201718 0.35332432 0.         0.         0.         1.        ]\n",
            " [0.43650612 0.37617293 0.         0.         0.         0.        ]\n",
            " [0.48738787 0.40337867 0.         0.         0.         0.        ]\n",
            " [0.37895641 0.28389388 0.         0.         0.         0.        ]\n",
            " [0.42764616 0.3579905  0.         0.         0.         0.        ]\n",
            " [0.52559173 0.38776469 1.         0.         0.         0.        ]\n",
            " [0.52510959 0.3772319  1.         0.         0.         0.        ]\n",
            " [0.43404657 0.43629423 0.         0.         0.         0.        ]\n",
            " [0.42676756 0.43279207 0.         0.         0.         0.        ]\n",
            " [0.48250279 0.39016023 0.         0.         0.         0.        ]\n",
            " [0.48266092 0.36606884 0.         0.         0.         0.        ]\n",
            " [0.40325588 0.30476648 0.         0.         0.         0.        ]\n",
            " [0.51794857 0.30558601 1.         0.         0.         0.        ]\n",
            " [0.43534189 0.39295623 0.         0.         0.         0.        ]\n",
            " [0.41543466 0.33814523 0.         0.         0.         0.        ]\n",
            " [0.38868666 0.2786884  0.         0.         0.         0.        ]\n",
            " [0.44202587 0.41092178 0.         0.         0.         0.        ]\n",
            " [0.37945551 0.41961583 0.         0.         0.         0.        ]\n",
            " [0.38923076 0.30109835 0.         0.         0.         0.        ]\n",
            " [0.3476688  0.20405205 0.         0.         0.         0.        ]\n",
            " [0.45841813 0.34812704 0.         0.         0.         0.        ]\n",
            " [0.39747837 0.32485244 0.         0.         0.         0.        ]\n",
            " [0.34626254 0.31225145 0.         0.         0.         0.        ]\n",
            " [0.33685964 0.28071615 0.         0.         0.         0.        ]\n",
            " [0.36405855 0.24609394 0.         0.         0.         0.        ]\n",
            " [0.44779643 0.35275543 0.         0.         0.         0.        ]\n",
            " [0.40111661 0.29349393 0.         0.         0.         0.        ]\n",
            " [0.33120781 0.30339971 0.         0.         0.         0.        ]\n",
            " [0.3481684  0.3622131  0.         0.         0.         0.        ]\n",
            " [0.28212535 0.22641654 0.         0.         0.         0.        ]\n",
            " [0.30510491 0.24051596 0.         0.         0.         0.        ]\n",
            " [0.50275147 0.34941334 1.         0.         0.         0.        ]\n",
            " [0.43343213 0.3153941  0.         0.         0.         0.        ]\n",
            " [0.44298095 0.37646839 0.         0.         0.         0.        ]\n",
            " [0.35414019 0.39079899 0.         0.         0.         0.        ]\n",
            " [0.32449469 0.23083255 0.         0.         0.         0.        ]\n",
            " [0.36808479 0.25876546 0.         0.         0.         0.        ]\n",
            " [0.29076082 0.26666003 0.         0.         0.         0.        ]\n",
            " [0.34158936 0.29262948 0.         0.         0.         0.        ]\n",
            " [0.4790245  0.31165558 0.         0.         0.         0.        ]\n",
            " [0.44395506 0.48646793 0.         0.         1.         1.        ]\n",
            " [0.46664035 0.4360024  0.         0.         1.         1.        ]\n",
            " [0.46064454 0.52501327 0.         1.         0.         1.        ]\n",
            " [0.44919521 0.40564528 0.         0.         0.         1.        ]\n",
            " [0.42948675 0.41077343 0.         0.         0.         0.        ]\n",
            " [0.56367546 0.36192816 1.         0.         1.         0.        ]\n",
            " [0.550574   0.40338671 1.         0.         0.         0.        ]\n",
            " [0.4960874  0.39884388 0.         0.         1.         0.        ]\n",
            " [0.43403184 0.35099167 0.         0.         0.         0.        ]\n",
            " [0.38818145 0.36259001 0.         0.         0.         0.        ]\n",
            " [0.40470904 0.376358   0.         0.         0.         0.        ]\n",
            " [0.40266159 0.37036934 0.         0.         0.         0.        ]\n",
            " [0.37820554 0.33369213 0.         0.         0.         1.        ]\n",
            " [0.41848814 0.50323015 0.         1.         0.         1.        ]\n",
            " [0.46765992 0.35584104 0.         0.         0.         1.        ]\n",
            " [0.37498555 0.36166537 0.         0.         0.         1.        ]\n",
            " [0.40007311 0.53303844 0.         1.         0.         1.        ]\n",
            " [0.39405972 0.50867832 0.         1.         0.         1.        ]\n",
            " [0.35343915 0.40349847 0.         0.         0.         1.        ]\n",
            " [0.52718467 0.43430546 1.         0.         0.         0.        ]\n",
            " [0.5599395  0.30855906 1.         0.         0.         0.        ]\n",
            " [0.45136935 0.38973182 0.         0.         0.         0.        ]\n",
            " [0.51363993 0.44051403 1.         0.         0.         0.        ]\n",
            " [0.577281   0.29907927 1.         0.         1.         1.        ]\n",
            " [0.45595455 0.41770399 0.         0.         0.         0.        ]\n",
            " [0.50948644 0.41407827 1.         0.         0.         0.        ]\n",
            " [0.57499838 0.27476415 1.         0.         0.         0.        ]\n",
            " [0.46514025 0.29225501 0.         0.         0.         0.        ]\n",
            " [0.4256272  0.31301042 0.         0.         0.         0.        ]\n",
            " [0.50220841 0.27536556 1.         0.         0.         0.        ]\n",
            " [0.37910143 0.3144809  0.         0.         0.         0.        ]\n",
            " [0.51440507 0.3911525  1.         0.         0.         0.        ]\n",
            " [0.57299918 0.25948969 1.         0.         0.         0.        ]\n",
            " [0.46895918 0.37033084 0.         0.         0.         0.        ]\n",
            " [0.49850899 0.39261147 0.         0.         0.         0.        ]\n",
            " [0.58921713 0.25434035 1.         0.         0.         0.        ]\n",
            " [0.47067252 0.36560804 0.         0.         0.         0.        ]\n",
            " [0.44945374 0.53838408 0.         1.         1.         0.        ]\n",
            " [0.39414239 0.40482739 0.         0.         1.         0.        ]\n",
            " [0.39431643 0.17554222 0.         0.         1.         0.        ]\n",
            " [0.4788653  0.28582484 0.         0.         0.         0.        ]\n",
            " [0.51532888 0.34946701 1.         0.         0.         0.        ]\n",
            " [0.48966593 0.39046746 0.         0.         0.         0.        ]\n",
            " [0.46062756 0.36238804 0.         0.         0.         0.        ]\n",
            " [0.46441287 0.37060055 0.         0.         0.         0.        ]\n",
            " [0.52723527 0.42177305 1.         0.         0.         0.        ]\n",
            " [0.47879329 0.46507901 0.         0.         0.         0.        ]\n",
            " [0.50474119 0.43567666 1.         0.         0.         0.        ]\n",
            " [0.48709354 0.39954191 0.         0.         0.         0.        ]\n",
            " [0.52990067 0.40540105 1.         0.         0.         0.        ]\n",
            " [0.48405498 0.41585612 0.         0.         0.         0.        ]\n",
            " [0.50639588 0.45466331 1.         0.         0.         0.        ]\n",
            " [0.42518821 0.23828962 0.         0.         0.         0.        ]\n",
            " [0.51192576 0.3511636  1.         0.         0.         0.        ]\n",
            " [0.51194364 0.37221983 1.         0.         0.         0.        ]\n",
            " [0.50010496 0.404149   1.         0.         0.         0.        ]\n",
            " [0.40825975 0.30760169 0.         0.         0.         0.        ]\n",
            " [0.44292831 0.41990557 0.         0.         0.         0.        ]\n",
            " [0.42084751 0.52817267 0.         1.         0.         0.        ]\n",
            " [0.44059399 0.43806088 0.         0.         0.         0.        ]\n",
            " [0.46322018 0.20387757 0.         0.         0.         0.        ]\n",
            " [0.48571619 0.41404369 0.         0.         0.         0.        ]\n",
            " [0.50666058 0.40335807 1.         0.         0.         0.        ]\n",
            " [0.44560543 0.36816001 0.         0.         0.         0.        ]\n",
            " [0.4104872  0.24332985 0.         0.         0.         0.        ]\n",
            " [0.47653177 0.49752152 0.         0.         0.         0.        ]\n",
            " [0.50596297 0.49788898 1.         0.         0.         0.        ]\n",
            " [0.45335168 0.45368999 0.         0.         0.         0.        ]\n",
            " [0.45039448 0.14707428 0.         0.         0.         0.        ]\n",
            " [0.47404504 0.35033485 0.         0.         0.         0.        ]\n",
            " [0.5060696  0.34141117 1.         0.         0.         0.        ]\n",
            " [0.52272075 0.41440311 1.         0.         0.         0.        ]\n",
            " [0.41465169 0.29658592 0.         0.         0.         0.        ]\n",
            " [0.50434494 0.42217916 1.         0.         0.         0.        ]\n",
            " [0.52021879 0.41542414 1.         0.         0.         0.        ]\n",
            " [0.46232918 0.43031403 0.         0.         0.         0.        ]\n",
            " [0.44104654 0.28932145 0.         0.         0.         0.        ]\n",
            " [0.52190083 0.39673397 1.         0.         0.         0.        ]\n",
            " [0.52301055 0.40174955 1.         0.         0.         0.        ]\n",
            " [0.47488979 0.42455426 0.         0.         0.         0.        ]\n",
            " [0.28983173 0.11822291 0.         0.         0.         0.        ]\n",
            " [0.43503109 0.3842226  0.         0.         0.         0.        ]\n",
            " [0.44819388 0.37306684 0.         0.         0.         0.        ]\n",
            " [0.33384216 0.21279028 0.         0.         0.         0.        ]\n",
            " [0.41039419 0.29114243 0.         0.         0.         0.        ]\n",
            " [0.43595529 0.34655666 0.         0.         0.         0.        ]\n",
            " [0.4846431  0.41268465 0.         0.         0.         0.        ]\n",
            " [0.48795    0.53599977 0.         1.         0.         0.        ]\n",
            " [0.40383276 0.37773278 0.         0.         0.         0.        ]\n",
            " [0.44891948 0.37090623 0.         0.         0.         0.        ]\n",
            " [0.4946987  0.43096089 0.         0.         0.         0.        ]\n",
            " [0.48796976 0.50654882 0.         1.         0.         0.        ]\n",
            " [0.46839401 0.32818827 0.         0.         0.         0.        ]\n",
            " [0.39375401 0.40850413 0.         0.         0.         0.        ]\n",
            " [0.48111287 0.4165526  0.         0.         0.         0.        ]\n",
            " [0.46679735 0.41100848 0.         0.         0.         0.        ]\n",
            " [0.42382222 0.42646638 0.         0.         0.         0.        ]\n",
            " [0.44574955 0.3703959  0.         0.         0.         0.        ]\n",
            " [0.47867778 0.41351607 0.         0.         0.         0.        ]\n",
            " [0.50313991 0.47935539 1.         0.         0.         0.        ]\n",
            " [0.45581353 0.42654565 0.         0.         0.         1.        ]\n",
            " [0.43777445 0.35669714 0.         0.         0.         0.        ]\n",
            " [0.47648576 0.39578152 0.         0.         0.         0.        ]\n",
            " [0.50520331 0.43949908 1.         0.         0.         0.        ]\n",
            " [0.36814702 0.24099478 0.         0.         1.         0.        ]\n",
            " [0.50335979 0.19688928 1.         0.         1.         0.        ]\n",
            " [0.48769626 0.32712433 0.         0.         1.         0.        ]\n",
            " [0.38265654 0.4390685  0.         0.         0.         0.        ]\n",
            " [0.49262246 0.39318693 0.         0.         0.         0.        ]\n",
            " [0.39812809 0.47006601 0.         0.         0.         0.        ]\n",
            " [0.40242025 0.46702376 0.         0.         0.         0.        ]\n",
            " [0.3438485  0.38768074 0.         0.         0.         0.        ]\n",
            " [0.45521227 0.21532893 0.         0.         0.         0.        ]\n",
            " [0.49566472 0.40326265 0.         0.         0.         0.        ]\n",
            " [0.47372892 0.41160429 0.         0.         0.         0.        ]\n",
            " [0.46178067 0.39535651 0.         0.         0.         0.        ]\n",
            " [0.43323651 0.35704547 0.         0.         0.         0.        ]\n",
            " [0.45226014 0.24211152 0.         0.         0.         0.        ]\n",
            " [0.43884325 0.25346479 0.         0.         0.         0.        ]\n",
            " [0.44211516 0.34834683 0.         0.         1.         0.        ]\n",
            " [0.44124767 0.34373584 0.         0.         1.         0.        ]\n",
            " [0.40927914 0.31238699 0.         0.         0.         0.        ]\n",
            " [0.45999336 0.17211144 0.         0.         0.         0.        ]\n",
            " [0.43744126 0.28275454 0.         0.         1.         0.        ]\n",
            " [0.44298002 0.3495869  0.         0.         0.         0.        ]\n",
            " [0.4416306  0.35135859 0.         0.         1.         0.        ]\n",
            " [0.41193897 0.3162446  0.         0.         1.         0.        ]\n",
            " [0.47031829 0.1718159  0.         0.         0.         0.        ]\n",
            " [0.47471827 0.33818346 0.         0.         1.         0.        ]\n",
            " [0.47254592 0.42099291 0.         0.         1.         0.        ]\n",
            " [0.46206918 0.41604826 0.         0.         0.         0.        ]\n",
            " [0.41673052 0.37178633 0.         0.         0.         0.        ]\n",
            " [0.47233185 0.34744465 0.         0.         0.         0.        ]\n",
            " [0.44827315 0.36510152 0.         0.         0.         0.        ]\n",
            " [0.46160078 0.34549049 0.         0.         0.         0.        ]\n",
            " [0.4514862  0.34509915 0.         0.         0.         0.        ]\n",
            " [0.39040539 0.32380494 0.         0.         0.         0.        ]\n",
            " [0.49838802 0.35271814 0.         0.         0.         0.        ]\n",
            " [0.37405851 0.38425043 0.         0.         0.         0.        ]\n",
            " [0.48548231 0.40320086 0.         0.         0.         0.        ]\n",
            " [0.49279913 0.38216433 0.         0.         0.         0.        ]\n",
            " [0.3859635  0.38571298 0.         0.         0.         0.        ]\n",
            " [0.3315486  0.41032439 0.         0.         0.         0.        ]\n",
            " [0.44672257 0.39036435 0.         0.         0.         0.        ]\n",
            " [0.5123449  0.38614923 1.         0.         0.         0.        ]\n",
            " [0.4108209  0.37465841 0.         0.         0.         0.        ]\n",
            " [0.43334243 0.37759432 0.         0.         0.         0.        ]\n",
            " [0.50258499 0.39601985 1.         0.         0.         0.        ]\n",
            " [0.40616691 0.35033    0.         0.         0.         0.        ]\n",
            " [0.47963226 0.4089421  0.         0.         0.         0.        ]\n",
            " [0.48731256 0.34311643 0.         0.         0.         0.        ]\n",
            " [0.44734728 0.305282   0.         0.         0.         0.        ]\n",
            " [0.48604685 0.32527769 0.         0.         0.         0.        ]\n",
            " [0.47224528 0.34057486 0.         0.         0.         0.        ]\n",
            " [0.41799724 0.2769677  0.         0.         0.         0.        ]\n",
            " [0.46658975 0.4503102  0.         0.         0.         0.        ]\n",
            " [0.53782856 0.41364133 1.         0.         0.         0.        ]\n",
            " [0.44957715 0.39610234 0.         0.         0.         0.        ]\n",
            " [0.45477885 0.416298   0.         0.         0.         0.        ]\n",
            " [0.50792944 0.41533428 1.         0.         0.         0.        ]\n",
            " [0.49181852 0.44069749 0.         0.         0.         0.        ]\n",
            " [0.36103496 0.43493509 0.         0.         0.         0.        ]\n",
            " [0.42342481 0.35751271 0.         0.         0.         0.        ]\n",
            " [0.35796973 0.42888168 0.         0.         0.         0.        ]\n",
            " [0.38634127 0.43953684 0.         0.         0.         0.        ]\n",
            " [0.43432158 0.35056067 0.         0.         0.         0.        ]\n",
            " [0.29411435 0.32777637 0.         0.         0.         0.        ]\n",
            " [0.32911834 0.42874715 0.         0.         0.         0.        ]\n",
            " [0.41142288 0.27977315 0.         0.         0.         0.        ]\n",
            " [0.3788946  0.4379693  0.         0.         0.         0.        ]\n",
            " [0.39171001 0.43204409 0.         0.         0.         0.        ]\n",
            " [0.34920979 0.18051    0.         0.         0.         0.        ]\n",
            " [0.40596408 0.37964574 0.         0.         0.         0.        ]\n",
            " [0.46565485 0.39188167 0.         0.         0.         0.        ]\n",
            " [0.4973675  0.37796229 0.         0.         0.         0.        ]\n",
            " [0.47039813 0.3829397  0.         0.         0.         0.        ]\n",
            " [0.50384367 0.36385459 1.         0.         0.         0.        ]\n",
            " [0.51490843 0.31815389 1.         0.         0.         0.        ]\n",
            " [0.50417298 0.39259174 1.         0.         0.         0.        ]\n",
            " [0.44015551 0.4345479  0.         0.         0.         1.        ]\n",
            " [0.42968553 0.42028245 0.         0.         0.         1.        ]\n",
            " [0.32437855 0.44119164 0.         0.         1.         0.        ]\n",
            " [0.30433187 0.33751312 0.         0.         0.         0.        ]\n",
            " [0.29261714 0.38773817 0.         0.         0.         0.        ]\n",
            " [0.36738592 0.29531449 0.         0.         0.         1.        ]\n",
            " [0.32479477 0.35316393 0.         0.         0.         0.        ]\n",
            " [0.42982918 0.39119518 0.         0.         0.         0.        ]\n",
            " [0.30323303 0.34536365 0.         0.         0.         0.        ]\n",
            " [0.33936739 0.26509258 0.         0.         0.         0.        ]\n",
            " [0.36667016 0.35539529 0.         0.         0.         0.        ]\n",
            " [0.39453739 0.36996827 0.         0.         0.         0.        ]\n",
            " [0.26260886 0.2626074  0.         0.         0.         0.        ]\n",
            " [0.4506132  0.33777648 0.         0.         0.         0.        ]\n",
            " [0.36572456 0.26077253 0.         0.         0.         0.        ]\n",
            " [0.4406909  0.31536695 0.         0.         0.         0.        ]\n",
            " [0.28362975 0.28509891 0.         0.         0.         0.        ]\n",
            " [0.44291189 0.36549273 0.         0.         0.         0.        ]\n",
            " [0.32126758 0.1472638  0.         0.         0.         0.        ]\n",
            " [0.44173217 0.36905181 0.         0.         0.         0.        ]\n",
            " [0.41322419 0.28877392 0.         0.         1.         0.        ]\n",
            " [0.44515333 0.32354578 0.         0.         1.         0.        ]\n",
            " [0.40880305 0.24715862 0.         0.         0.         0.        ]\n",
            " [0.4627009  0.31396815 0.         0.         1.         0.        ]\n",
            " [0.47170576 0.30830622 0.         0.         1.         0.        ]\n",
            " [0.4455263  0.28925717 0.         0.         1.         0.        ]\n",
            " [0.42738089 0.32177907 0.         0.         0.         0.        ]\n",
            " [0.43431461 0.32929429 0.         0.         0.         0.        ]\n",
            " [0.41775402 0.36652699 0.         0.         0.         0.        ]\n",
            " [0.37766162 0.36734045 0.         0.         0.         0.        ]\n",
            " [0.22736418 0.26368511 0.         0.         0.         0.        ]\n",
            " [0.42123866 0.33266631 0.         0.         0.         0.        ]\n",
            " [0.44679621 0.31945172 0.         0.         0.         0.        ]\n",
            " [0.44087788 0.35869053 0.         0.         0.         0.        ]\n",
            " [0.45006242 0.34758428 0.         0.         0.         0.        ]\n",
            " [0.43121624 0.35994688 0.         0.         0.         0.        ]\n",
            " [0.42128438 0.29464635 0.         0.         0.         0.        ]\n",
            " [0.30608055 0.36113784 0.         0.         0.         0.        ]\n",
            " [0.41629389 0.2567966  0.         0.         0.         0.        ]\n",
            " [0.43832546 0.29860887 0.         0.         0.         0.        ]\n",
            " [0.39783391 0.31326982 0.         0.         0.         0.        ]\n",
            " [0.39581412 0.32545725 0.         0.         0.         0.        ]\n",
            " [0.44058749 0.35801318 0.         0.         0.         0.        ]\n",
            " [0.45379797 0.34336978 0.         0.         0.         0.        ]\n",
            " [0.4440757  0.39739591 0.         0.         0.         0.        ]\n",
            " [0.42911607 0.27327198 0.         0.         0.         0.        ]\n",
            " [0.43259683 0.37961859 0.         0.         0.         0.        ]\n",
            " [0.43784356 0.37505046 0.         0.         0.         0.        ]\n",
            " [0.40548313 0.37607619 0.         0.         0.         0.        ]\n",
            " [0.43695092 0.34667063 0.         0.         0.         0.        ]\n",
            " [0.43940505 0.37794667 0.         0.         0.         0.        ]\n",
            " [0.43193856 0.33868292 0.         0.         0.         0.        ]\n",
            " [0.42116886 0.28360558 0.         0.         1.         0.        ]\n",
            " [0.37215114 0.29000667 0.         0.         1.         0.        ]\n",
            " [0.43777582 0.28788963 0.         0.         1.         0.        ]\n",
            " [0.44024971 0.29390925 0.         0.         1.         0.        ]\n",
            " [0.37540466 0.34572223 0.         0.         1.         0.        ]\n",
            " [0.41293305 0.35177916 0.         0.         1.         0.        ]\n",
            " [0.41489422 0.33957708 0.         0.         1.         0.        ]\n",
            " [0.339221   0.44307196 0.         0.         1.         0.        ]\n",
            " [0.39966336 0.3200089  0.         0.         1.         0.        ]\n",
            " [0.42090467 0.29879093 0.         0.         1.         0.        ]\n",
            " [0.39777228 0.29777399 0.         0.         1.         0.        ]\n",
            " [0.36661169 0.37708455 0.         0.         1.         0.        ]\n",
            " [0.42885613 0.29839173 0.         0.         1.         0.        ]\n",
            " [0.3115533  0.44479549 0.         0.         1.         0.        ]\n",
            " [0.34648159 0.41524354 0.         0.         1.         0.        ]\n",
            " [0.36602303 0.35012963 0.         0.         0.         0.        ]\n",
            " [0.36101368 0.43645284 0.         0.         0.         0.        ]\n",
            " [0.3606509  0.29224777 0.         0.         1.         0.        ]\n",
            " [0.37042528 0.24526568 0.         0.         0.         0.        ]\n",
            " [0.46325815 0.33309999 0.         0.         0.         0.        ]\n",
            " [0.291417   0.46635821 0.         0.         0.         0.        ]\n",
            " [0.27109379 0.46694577 0.         0.         0.         0.        ]\n",
            " [0.33493608 0.48743364 0.         0.         0.         0.        ]\n",
            " [0.33702323 0.43305039 0.         0.         0.         0.        ]\n",
            " [0.45273948 0.31446376 0.         0.         0.         0.        ]\n",
            " [0.39653832 0.30929008 0.         0.         0.         0.        ]\n",
            " [0.37904656 0.27791592 0.         0.         0.         0.        ]\n",
            " [0.33841094 0.32669789 0.         0.         0.         0.        ]\n",
            " [0.37664211 0.26312646 0.         0.         0.         0.        ]\n",
            " [0.42906794 0.33772695 0.         0.         0.         0.        ]\n",
            " [0.35891774 0.34838739 0.         0.         0.         0.        ]\n",
            " [0.41352639 0.34691778 0.         0.         0.         0.        ]\n",
            " [0.43583691 0.3182216  0.         0.         0.         0.        ]\n",
            " [0.43536502 0.34267157 0.         0.         0.         0.        ]\n",
            " [0.44550794 0.3110128  0.         0.         0.         0.        ]\n",
            " [0.42982173 0.29127729 0.         0.         0.         0.        ]\n",
            " [0.35758775 0.23573682 0.         0.         0.         0.        ]\n",
            " [0.40620393 0.29128352 0.         0.         0.         0.        ]\n",
            " [0.43202582 0.31618887 0.         0.         0.         0.        ]\n",
            " [0.3860462  0.29595512 0.         0.         0.         0.        ]\n",
            " [0.45429599 0.28876698 0.         0.         0.         0.        ]\n",
            " [0.44582289 0.24621651 0.         0.         1.         0.        ]\n",
            " [0.46359095 0.26220241 0.         0.         1.         0.        ]\n",
            " [0.46920893 0.28441331 0.         0.         1.         0.        ]\n",
            " [0.45433885 0.26311287 0.         0.         1.         0.        ]\n",
            " [0.4659147  0.25859159 0.         0.         1.         0.        ]\n",
            " [0.46412241 0.25186571 0.         0.         1.         0.        ]\n",
            " [0.44685626 0.20872796 0.         0.         0.         0.        ]\n",
            " [0.43018821 0.23439071 0.         0.         1.         0.        ]\n",
            " [0.33440062 0.25586659 0.         0.         0.         0.        ]\n",
            " [0.24250515 0.22773461 0.         0.         0.         0.        ]\n",
            " [0.35425255 0.33555922 0.         0.         0.         0.        ]\n",
            " [0.41802001 0.29499167 0.         0.         0.         1.        ]\n",
            " [0.33487833 0.3225939  0.         0.         0.         1.        ]\n",
            " [0.34045103 0.19821963 0.         0.         0.         0.        ]\n",
            " [0.37447006 0.34255576 0.         0.         0.         0.        ]\n",
            " [0.43068135 0.30808586 0.         0.         0.         0.        ]\n",
            " [0.35363683 0.28335005 0.         0.         0.         0.        ]\n",
            " [0.38583508 0.34284264 0.         0.         0.         0.        ]\n",
            " [0.34416372 0.25691009 0.         0.         0.         0.        ]\n",
            " [0.39475185 0.33028197 0.         0.         0.         0.        ]\n",
            " [0.43792111 0.29151824 0.         0.         0.         0.        ]\n",
            " [0.42668295 0.31039613 0.         0.         0.         0.        ]\n",
            " [0.38214192 0.27713659 0.         0.         0.         0.        ]\n",
            " [0.36922666 0.23928434 0.         0.         0.         1.        ]\n",
            " [0.33151746 0.18823612 0.         0.         0.         0.        ]\n",
            " [0.33901852 0.18207569 0.         0.         0.         0.        ]\n",
            " [0.37106577 0.30612651 0.         0.         0.         0.        ]\n",
            " [0.36294481 0.20612025 0.         0.         0.         0.        ]\n",
            " [0.36293253 0.28772923 0.         0.         0.         0.        ]\n",
            " [0.3785775  0.28269076 0.         0.         0.         0.        ]\n",
            " [0.33831865 0.18413293 0.         0.         0.         0.        ]\n",
            " [0.38476309 0.29087928 0.         0.         0.         0.        ]\n",
            " [0.44446093 0.37279806 0.         0.         0.         0.        ]\n",
            " [0.36442325 0.34544754 0.         0.         0.         0.        ]\n",
            " [0.33817065 0.31554392 0.         0.         0.         0.        ]\n",
            " [0.34015101 0.32308164 0.         0.         0.         0.        ]\n",
            " [0.36078236 0.39047083 0.         0.         0.         0.        ]\n",
            " [0.2669282  0.44726086 0.         0.         0.         0.        ]\n",
            " [0.33902204 0.32865945 0.         0.         0.         0.        ]\n",
            " [0.36032346 0.37736666 0.         0.         0.         0.        ]\n",
            " [0.36186394 0.43734908 0.         0.         0.         0.        ]\n",
            " [0.38134554 0.41723034 0.         0.         0.         0.        ]\n",
            " [0.39701545 0.37545514 0.         0.         0.         0.        ]\n",
            " [0.36739787 0.3437261  0.         0.         0.         0.        ]\n",
            " [0.43738842 0.44810989 0.         0.         0.         0.        ]\n",
            " [0.54120362 0.49271378 1.         0.         0.         0.        ]\n",
            " [0.38263422 0.44666067 0.         0.         0.         1.        ]\n",
            " [0.399661   0.44524822 0.         0.         0.         1.        ]\n",
            " [0.37886748 0.36121672 0.         0.         0.         0.        ]\n",
            " [0.37026021 0.36776423 0.         0.         0.         1.        ]\n",
            " [0.46995497 0.47458217 0.         0.         0.         1.        ]\n",
            " [0.36474371 0.50283754 0.         1.         0.         1.        ]\n",
            " [0.4168689  0.43976241 0.         0.         0.         0.        ]\n",
            " [0.4267363  0.35284227 0.         0.         0.         0.        ]\n",
            " [0.34377941 0.37633669 0.         0.         0.         1.        ]\n",
            " [0.37887761 0.48989883 0.         0.         0.         1.        ]\n",
            " [0.41716468 0.36923659 0.         0.         0.         0.        ]\n",
            " [0.4515698  0.40334213 0.         0.         0.         0.        ]\n",
            " [0.3836883  0.34088919 0.         0.         0.         0.        ]\n",
            " [0.38840744 0.46926835 0.         0.         0.         1.        ]\n",
            " [0.48072252 0.38099512 0.         0.         0.         0.        ]\n",
            " [0.43519011 0.52773273 0.         1.         0.         0.        ]\n",
            " [0.43136126 0.44227162 0.         0.         0.         0.        ]\n",
            " [0.44415942 0.51656127 0.         1.         0.         0.        ]\n",
            " [0.45658112 0.25826147 0.         0.         0.         0.        ]\n",
            " [0.47410408 0.38712096 0.         0.         0.         0.        ]\n",
            " [0.4598414  0.55184019 0.         1.         0.         0.        ]\n",
            " [0.46715131 0.33582476 0.         0.         0.         0.        ]\n",
            " [0.51838583 0.43510261 1.         0.         0.         0.        ]\n",
            " [0.53056586 0.26256105 1.         0.         0.         0.        ]\n",
            " [0.46385428 0.33897692 0.         0.         0.         0.        ]\n",
            " [0.49665838 0.34285694 0.         0.         0.         0.        ]\n",
            " [0.52341551 0.39247623 1.         0.         0.         0.        ]\n",
            " [0.56323642 0.25766033 1.         0.         1.         0.        ]\n",
            " [0.42383438 0.36987302 0.         0.         0.         0.        ]\n",
            " [0.42070994 0.46952885 0.         0.         0.         0.        ]\n",
            " [0.52392352 0.3381035  1.         0.         0.         0.        ]\n",
            " [0.44951162 0.39500007 0.         0.         0.         0.        ]\n",
            " [0.47232291 0.41342995 0.         0.         0.         0.        ]\n",
            " [0.47902909 0.43273404 0.         0.         0.         0.        ]\n",
            " [0.55889457 0.30509871 1.         0.         0.         0.        ]\n",
            " [0.4660545  0.32750958 0.         0.         1.         0.        ]\n",
            " [0.50482088 0.40178117 1.         0.         0.         0.        ]\n",
            " [0.54877257 0.25896686 1.         0.         1.         0.        ]\n",
            " [0.47555512 0.33617342 0.         0.         1.         0.        ]\n",
            " [0.49434707 0.34504449 0.         0.         1.         0.        ]\n",
            " [0.50725681 0.37976378 1.         0.         1.         0.        ]\n",
            " [0.56819361 0.24724096 1.         0.         1.         0.        ]\n",
            " [0.38467523 0.34748662 0.         0.         0.         0.        ]\n",
            " [0.41959384 0.45075276 0.         0.         0.         0.        ]\n",
            " [0.4764851  0.30555913 0.         0.         0.         0.        ]\n",
            " [0.3941575  0.34552309 0.         0.         0.         0.        ]\n",
            " [0.42938009 0.38861385 0.         0.         0.         0.        ]\n",
            " [0.44681221 0.40663937 0.         0.         0.         0.        ]\n",
            " [0.43143055 0.37996039 0.         0.         0.         0.        ]\n",
            " [0.43172994 0.33680376 0.         0.         1.         0.        ]\n",
            " [0.50656623 0.43574893 1.         0.         0.         0.        ]\n",
            " [0.53341532 0.29400668 1.         0.         0.         0.        ]\n",
            " [0.45519483 0.35489368 0.         0.         1.         0.        ]\n",
            " [0.48056456 0.37888008 0.         0.         0.         0.        ]\n",
            " [0.51526254 0.42709723 1.         0.         1.         0.        ]\n",
            " [0.6106053  0.34824529 1.         0.         0.         0.        ]\n",
            " [0.47208416 0.34551334 0.         0.         1.         0.        ]\n",
            " [0.5184564  0.44478163 1.         0.         1.         0.        ]\n",
            " [0.5629949  0.30940884 1.         0.         1.         0.        ]\n",
            " [0.46959278 0.34126255 0.         0.         1.         0.        ]\n",
            " [0.50171703 0.38582933 1.         0.         1.         0.        ]\n",
            " [0.51677185 0.42230725 1.         0.         1.         0.        ]\n",
            " [0.62512076 0.34218493 1.         0.         1.         0.        ]\n",
            " [0.40997052 0.29788089 0.         0.         0.         0.        ]\n",
            " [0.46184739 0.36703452 0.         0.         0.         0.        ]\n",
            " [0.53618497 0.37404251 1.         0.         0.         0.        ]\n",
            " [0.46449238 0.31699845 0.         0.         0.         0.        ]\n",
            " [0.48473737 0.32949978 0.         0.         0.         0.        ]\n",
            " [0.42278579 0.33899888 0.         0.         0.         0.        ]\n",
            " [0.63448858 0.48450935 1.         0.         1.         0.        ]\n",
            " [0.5749191  0.23754887 1.         0.         1.         0.        ]\n",
            " [0.5200299  0.53537852 1.         1.         0.         1.        ]\n",
            " [0.43454185 0.48789522 0.         0.         0.         1.        ]\n",
            " [0.52737325 0.43342194 1.         0.         0.         1.        ]\n",
            " [0.4815698  0.35939893 0.         0.         0.         0.        ]\n",
            " [0.48377788 0.37212169 0.         0.         1.         0.        ]\n",
            " [0.54897547 0.3789354  1.         0.         0.         0.        ]\n",
            " [0.56297904 0.42137766 1.         0.         1.         1.        ]\n",
            " [0.47210228 0.55114669 0.         1.         0.         1.        ]\n",
            " [0.41831827 0.45792195 0.         0.         0.         1.        ]\n",
            " [0.41578066 0.42923304 0.         0.         0.         1.        ]\n",
            " [0.44195351 0.38723698 0.         0.         0.         0.        ]\n",
            " [0.59050894 0.32548174 1.         0.         0.         0.        ]\n",
            " [0.44869298 0.51565051 0.         1.         1.         1.        ]\n",
            " [0.43959427 0.56149018 0.         1.         1.         1.        ]\n",
            " [0.51757836 0.42451397 1.         0.         0.         1.        ]\n",
            " [0.47814456 0.36809659 0.         0.         1.         0.        ]\n",
            " [0.47718093 0.37137303 0.         0.         0.         0.        ]\n",
            " [0.43920848 0.34656012 0.         0.         0.         0.        ]\n",
            " [0.41276354 0.34634122 0.         0.         0.         1.        ]\n",
            " [0.47189337 0.46885261 0.         0.         0.         1.        ]\n",
            " [0.25811875 0.44100517 0.         0.         0.         1.        ]\n",
            " [0.36285651 0.39698938 0.         0.         0.         1.        ]\n",
            " [0.41673753 0.3838945  0.         0.         0.         0.        ]\n",
            " [0.5789935  0.34714651 1.         0.         1.         0.        ]\n",
            " [0.44803563 0.60649925 0.         1.         0.         1.        ]\n",
            " [0.47273031 0.64785391 0.         1.         0.         1.        ]\n",
            " [0.48970246 0.4254224  0.         0.         0.         1.        ]\n",
            " [0.44275701 0.42199615 0.         0.         0.         0.        ]\n",
            " [0.47607744 0.38647008 0.         0.         1.         1.        ]\n",
            " [0.62383139 0.38123256 1.         0.         0.         0.        ]\n",
            " [0.50596768 0.60763276 1.         1.         0.         1.        ]\n",
            " [0.468512   0.68586928 0.         1.         0.         1.        ]\n",
            " [0.50885713 0.44502729 1.         0.         0.         1.        ]\n",
            " [0.47494802 0.46415991 0.         0.         0.         0.        ]\n",
            " [0.45561028 0.3210544  0.         0.         0.         0.        ]\n",
            " [0.48078904 0.43764529 0.         0.         0.         0.        ]\n",
            " [0.33670458 0.34640309 0.         0.         1.         1.        ]\n",
            " [0.44925895 0.451803   0.         0.         0.         1.        ]\n",
            " [0.45012468 0.31810266 0.         0.         1.         1.        ]\n",
            " [0.34924662 0.58744776 0.         1.         0.         0.        ]\n",
            " [0.4917838  0.33442768 0.         0.         0.         0.        ]\n",
            " [0.5063144  0.13504444 1.         0.         0.         0.        ]\n",
            " [0.37852591 0.34091839 0.         0.         0.         1.        ]\n",
            " [0.46981296 0.37893972 0.         0.         1.         0.        ]\n",
            " [0.55719107 0.35865796 1.         0.         0.         0.        ]\n",
            " [0.44317624 0.25250366 0.         0.         0.         0.        ]\n",
            " [0.43667367 0.22052753 0.         0.         0.         0.        ]\n",
            " [0.48644546 0.29757991 0.         0.         0.         0.        ]\n",
            " [0.50133461 0.34255049 1.         0.         0.         0.        ]\n",
            " [0.46207976 0.45034391 0.         0.         0.         1.        ]\n",
            " [0.42190465 0.36033255 0.         0.         0.         0.        ]\n",
            " [0.43991035 0.27050006 0.         0.         0.         0.        ]\n",
            " [0.53851938 0.38316149 1.         0.         0.         0.        ]\n",
            " [0.44113904 0.36344358 0.         0.         0.         0.        ]\n",
            " [0.46854371 0.37802514 0.         0.         0.         0.        ]\n",
            " [0.54712135 0.25247234 1.         0.         1.         0.        ]\n",
            " [0.41428769 0.46383038 0.         0.         0.         1.        ]\n",
            " [0.50618577 0.34315071 1.         0.         1.         0.        ]\n",
            " [0.41416201 0.46446061 0.         0.         0.         0.        ]\n",
            " [0.5072906  0.34066558 1.         0.         1.         0.        ]\n",
            " [0.50460166 0.36777422 1.         0.         0.         0.        ]\n",
            " [0.50321484 0.37386194 1.         0.         0.         0.        ]\n",
            " [0.43339792 0.13790682 0.         0.         0.         0.        ]\n",
            " [0.48763832 0.42715451 0.         0.         0.         1.        ]\n",
            " [0.28621915 0.44533709 0.         0.         0.         0.        ]\n",
            " [0.43581024 0.18755756 0.         0.         1.         0.        ]\n",
            " [0.56934518 0.34876221 1.         0.         1.         0.        ]\n",
            " [0.43103588 0.28626779 0.         0.         0.         0.        ]\n",
            " [0.4261063  0.32564056 0.         0.         0.         0.        ]\n",
            " [0.5202902  0.32830971 1.         0.         1.         0.        ]\n",
            " [0.48342949 0.52720273 0.         1.         0.         1.        ]\n",
            " [0.48925102 0.32328087 0.         0.         1.         0.        ]\n",
            " [0.39090377 0.32687256 0.         0.         0.         0.        ]\n",
            " [0.61939609 0.43097368 1.         0.         1.         1.        ]\n",
            " [0.49106672 0.39636296 0.         0.         1.         0.        ]\n",
            " [0.49148518 0.40253696 0.         0.         0.         0.        ]\n",
            " [0.51037478 0.3163625  1.         0.         0.         0.        ]\n",
            " [0.50255215 0.56130868 1.         1.         0.         1.        ]\n",
            " [0.5267086  0.31902465 1.         0.         1.         0.        ]\n",
            " [0.40779978 0.30530939 0.         0.         0.         0.        ]\n",
            " [0.63121212 0.52118403 1.         1.         0.         1.        ]\n",
            " [0.51547194 0.39357463 1.         0.         0.         0.        ]\n",
            " [0.52181667 0.38560092 1.         0.         0.         0.        ]\n",
            " [0.5495249  0.52222955 1.         1.         0.         0.        ]\n",
            " [0.36914456 0.51798373 0.         1.         1.         1.        ]\n",
            " [0.49663252 0.32273602 0.         0.         0.         0.        ]\n",
            " [0.29231057 0.19713469 0.         0.         0.         0.        ]\n",
            " [0.39642143 0.39864445 0.         0.         0.         0.        ]\n",
            " [0.45672143 0.37570745 0.         0.         0.         0.        ]\n",
            " [0.49866235 0.40995061 0.         0.         0.         0.        ]\n",
            " [0.44202429 0.37646213 0.         0.         1.         0.        ]\n",
            " [0.42250097 0.41060591 0.         0.         1.         0.        ]\n",
            " [0.42587444 0.37019321 0.         0.         1.         0.        ]\n",
            " [0.38457265 0.35091195 0.         0.         1.         0.        ]\n",
            " [0.43045169 0.36460474 0.         0.         1.         0.        ]\n",
            " [0.42329773 0.48562267 0.         0.         1.         1.        ]\n",
            " [0.39907151 0.38430563 0.         0.         0.         0.        ]\n",
            " [0.39302349 0.35039026 0.         0.         0.         0.        ]\n",
            " [0.43574536 0.36811835 0.         0.         0.         0.        ]\n",
            " [0.39508504 0.34182492 0.         0.         0.         0.        ]\n",
            " [0.42569745 0.35078877 0.         0.         0.         1.        ]\n",
            " [0.40077564 0.35870698 0.         0.         0.         1.        ]\n",
            " [0.40121511 0.35645494 0.         0.         0.         0.        ]\n",
            " [0.4913083  0.45372993 0.         0.         1.         0.        ]\n",
            " [0.38310653 0.36016223 0.         0.         0.         0.        ]\n",
            " [0.34764764 0.38039398 0.         0.         0.         0.        ]\n",
            " [0.36535463 0.3707611  0.         0.         0.         1.        ]\n",
            " [0.46656764 0.43835959 0.         0.         0.         0.        ]\n",
            " [0.46214834 0.36024836 0.         0.         1.         0.        ]\n",
            " [0.46732688 0.48869193 0.         0.         1.         0.        ]\n",
            " [0.42964795 0.38176382 0.         0.         1.         0.        ]\n",
            " [0.41861945 0.33657962 0.         0.         0.         0.        ]\n",
            " [0.41496465 0.36191395 0.         0.         0.         0.        ]\n",
            " [0.43362543 0.49131423 0.         0.         0.         1.        ]\n",
            " [0.51393509 0.33159986 1.         0.         1.         0.        ]\n",
            " [0.47641984 0.51021522 0.         1.         0.         0.        ]\n",
            " [0.48332301 0.3251425  0.         0.         0.         0.        ]\n",
            " [0.43549141 0.30615249 0.         0.         0.         0.        ]\n",
            " [0.44541645 0.32074645 0.         0.         1.         1.        ]\n",
            " [0.4616636  0.50192547 0.         1.         0.         0.        ]\n",
            " [0.4739067  0.31008109 0.         0.         0.         0.        ]\n",
            " [0.38000765 0.43307155 0.         0.         0.         0.        ]\n",
            " [0.50718129 0.31729552 1.         0.         0.         0.        ]\n",
            " [0.48464569 0.33168849 0.         0.         0.         0.        ]\n",
            " [0.51653665 0.32474208 1.         0.         0.         0.        ]\n",
            " [0.34437799 0.48422107 0.         0.         0.         1.        ]\n",
            " [0.3878732  0.43510294 0.         0.         1.         0.        ]\n",
            " [0.44768816 0.31033739 0.         0.         1.         1.        ]\n",
            " [0.4759604  0.39657462 0.         0.         1.         0.        ]\n",
            " [0.40476441 0.22529522 0.         0.         0.         0.        ]\n",
            " [0.48738644 0.42125952 0.         0.         0.         0.        ]\n",
            " [0.44479135 0.26019076 0.         0.         0.         0.        ]\n",
            " [0.45219082 0.41676876 0.         0.         0.         0.        ]\n",
            " [0.44655553 0.27605438 0.         0.         0.         0.        ]\n",
            " [0.30980599 0.19395353 0.         0.         0.         0.        ]\n",
            " [0.35827199 0.2767702  0.         0.         0.         0.        ]\n",
            " [0.42536312 0.29187107 0.         0.         1.         0.        ]\n",
            " [0.31402072 0.21681032 0.         0.         0.         0.        ]\n",
            " [0.33552688 0.31059149 0.         0.         0.         1.        ]\n",
            " [0.31935042 0.22497341 0.         0.         1.         0.        ]\n",
            " [0.29265726 0.18180345 0.         0.         0.         0.        ]\n",
            " [0.54142618 0.46750095 1.         0.         1.         1.        ]\n",
            " [0.53891301 0.48618349 1.         0.         1.         1.        ]\n",
            " [0.51293236 0.52988195 1.         1.         1.         1.        ]\n",
            " [0.55075759 0.5394603  1.         1.         1.         1.        ]\n",
            " [0.5781799  0.51043218 1.         1.         1.         1.        ]\n",
            " [0.5694356  0.38915789 1.         0.         0.         1.        ]\n",
            " [0.41365072 0.42363593 0.         0.         1.         1.        ]\n",
            " [0.44507265 0.4316147  0.         0.         1.         1.        ]\n",
            " [0.4820956  0.51849437 0.         1.         1.         1.        ]\n",
            " [0.46359813 0.50951886 0.         1.         1.         1.        ]\n",
            " [0.51364315 0.50808942 1.         1.         1.         1.        ]\n",
            " [0.4320823  0.43878055 0.         0.         1.         0.        ]\n",
            " [0.51325595 0.42676651 1.         0.         1.         1.        ]\n",
            " [0.50905645 0.47253576 1.         0.         1.         1.        ]\n",
            " [0.56887138 0.53560102 1.         1.         1.         1.        ]\n",
            " [0.58685321 0.51052678 1.         1.         1.         1.        ]\n",
            " [0.60168463 0.51825649 1.         1.         1.         1.        ]\n",
            " [0.53474396 0.33248904 1.         0.         1.         0.        ]\n",
            " [0.48688129 0.44473702 0.         0.         1.         1.        ]\n",
            " [0.51059383 0.48386151 1.         0.         1.         1.        ]\n",
            " [0.61665028 0.54109353 1.         1.         1.         1.        ]\n",
            " [0.59069747 0.55066216 1.         1.         1.         1.        ]\n",
            " [0.60211247 0.52408415 1.         1.         1.         1.        ]\n",
            " [0.60904473 0.5075081  1.         1.         1.         0.        ]\n",
            " [0.58551431 0.47881359 1.         0.         1.         1.        ]\n",
            " [0.5302043  0.56260043 1.         1.         1.         1.        ]\n",
            " [0.54106605 0.53222603 1.         1.         1.         1.        ]\n",
            " [0.61467952 0.56583011 1.         1.         1.         1.        ]\n",
            " [0.60648876 0.51163048 1.         1.         1.         1.        ]\n",
            " [0.53963053 0.39162859 1.         0.         1.         0.        ]\n",
            " [0.4886671  0.216657   0.         0.         0.         0.        ]\n",
            " [0.47296929 0.23558082 0.         0.         0.         0.        ]\n",
            " [0.45275789 0.24582399 0.         0.         0.         0.        ]\n",
            " [0.41543204 0.32226795 0.         0.         0.         0.        ]\n",
            " [0.28619152 0.44440216 0.         0.         0.         0.        ]\n",
            " [0.30556044 0.41048986 0.         0.         0.         0.        ]\n",
            " [0.31722033 0.38469544 0.         0.         0.         0.        ]\n",
            " [0.34038195 0.34091079 0.         0.         0.         0.        ]\n",
            " [0.46837211 0.22992679 0.         0.         1.         0.        ]\n",
            " [0.47184095 0.23752148 0.         0.         1.         0.        ]\n",
            " [0.41209155 0.24534647 0.         0.         0.         0.        ]\n",
            " [0.39989883 0.2718569  0.         0.         0.         0.        ]\n",
            " [0.507649   0.50865322 1.         1.         0.         0.        ]\n",
            " [0.32787943 0.4717477  0.         0.         0.         0.        ]\n",
            " [0.30093116 0.5563826  0.         1.         0.         0.        ]\n",
            " [0.3142761  0.56853747 0.         1.         0.         0.        ]\n",
            " [0.31683078 0.37919366 0.         0.         0.         0.        ]\n",
            " [0.3250277  0.25080392 0.         0.         1.         0.        ]\n",
            " [0.46575969 0.24735604 0.         0.         0.         0.        ]\n",
            " [0.45268041 0.24147373 0.         0.         1.         0.        ]\n",
            " [0.51812267 0.40607399 1.         0.         0.         0.        ]\n",
            " [0.36016095 0.37122723 0.         0.         0.         0.        ]\n",
            " [0.36099434 0.31200835 0.         0.         0.         0.        ]\n",
            " [0.43766865 0.2401749  0.         0.         0.         0.        ]\n",
            " [0.37636581 0.35681739 0.         0.         0.         0.        ]\n",
            " [0.41069138 0.35696456 0.         0.         0.         0.        ]\n",
            " [0.3484489  0.32581124 0.         0.         0.         0.        ]\n",
            " [0.46692863 0.30158347 0.         0.         0.         0.        ]\n",
            " [0.44304085 0.31366393 0.         0.         0.         0.        ]\n",
            " [0.31506142 0.40902114 0.         0.         0.         0.        ]\n",
            " [0.50361317 0.32147977 1.         0.         0.         0.        ]\n",
            " [0.44770896 0.33095476 0.         0.         0.         0.        ]\n",
            " [0.3853859  0.31991461 0.         0.         0.         0.        ]\n",
            " [0.40437493 0.34225962 0.         0.         0.         1.        ]\n",
            " [0.52042508 0.38027865 1.         0.         0.         0.        ]\n",
            " [0.53229696 0.23833567 1.         0.         0.         0.        ]\n",
            " [0.51969683 0.38450179 1.         0.         0.         0.        ]\n",
            " [0.49823943 0.29997629 0.         0.         0.         0.        ]\n",
            " [0.51018506 0.26692718 1.         0.         1.         0.        ]\n",
            " [0.53661805 0.40180707 1.         0.         1.         0.        ]\n",
            " [0.49443698 0.25614122 0.         0.         1.         0.        ]\n",
            " [0.54908401 0.41311309 1.         0.         1.         0.        ]\n",
            " [0.50099385 0.30823198 1.         0.         1.         0.        ]\n",
            " [0.49402282 0.33471921 0.         0.         1.         0.        ]\n",
            " [0.5286423  0.40131903 1.         0.         1.         0.        ]\n",
            " [0.5600487  0.31807476 1.         0.         1.         0.        ]\n",
            " [0.52649003 0.41219175 1.         0.         1.         0.        ]\n",
            " [0.48553655 0.38641712 0.         0.         1.         0.        ]\n",
            " [0.48421809 0.42723209 0.         0.         1.         0.        ]\n",
            " [0.50286621 0.37692574 1.         0.         1.         0.        ]\n",
            " [0.54587036 0.37374282 1.         0.         1.         0.        ]\n",
            " [0.49610654 0.38751048 0.         0.         1.         0.        ]\n",
            " [0.52597016 0.38962597 1.         0.         1.         0.        ]\n",
            " [0.46347031 0.34711662 0.         0.         1.         0.        ]\n",
            " [0.50305903 0.36246684 1.         0.         1.         0.        ]\n",
            " [0.54362696 0.3159152  1.         0.         1.         0.        ]\n",
            " [0.49928558 0.36932802 0.         0.         1.         0.        ]\n",
            " [0.51377308 0.3461943  1.         0.         1.         0.        ]\n",
            " [0.40818891 0.3574867  0.         0.         0.         0.        ]\n",
            " [0.47814262 0.42241007 0.         0.         0.         0.        ]\n",
            " [0.39830777 0.27476063 0.         0.         0.         0.        ]\n",
            " [0.49452972 0.42126146 0.         0.         0.         0.        ]\n",
            " [0.4447138  0.4222751  0.         0.         0.         0.        ]\n",
            " [0.44405991 0.22230481 0.         0.         0.         0.        ]\n",
            " [0.51515281 0.26314044 1.         0.         0.         0.        ]\n",
            " [0.52590102 0.38064566 1.         0.         0.         0.        ]\n",
            " [0.52799082 0.38268828 1.         0.         0.         0.        ]\n",
            " [0.385975   0.32989445 0.         0.         1.         0.        ]\n",
            " [0.35441267 0.30892283 0.         0.         0.         0.        ]\n",
            " [0.50693029 0.31203446 1.         0.         1.         0.        ]\n",
            " [0.55493945 0.40631598 1.         0.         1.         0.        ]\n",
            " [0.56540489 0.41139963 1.         0.         1.         0.        ]\n",
            " [0.37138879 0.31444064 0.         0.         1.         0.        ]\n",
            " [0.41381812 0.31640175 0.         0.         1.         0.        ]\n",
            " [0.50258291 0.34521416 1.         0.         1.         0.        ]\n",
            " [0.53877413 0.39829972 1.         0.         1.         0.        ]\n",
            " [0.5389322  0.39713436 1.         0.         1.         0.        ]\n",
            " [0.51952112 0.4544147  1.         0.         1.         0.        ]\n",
            " [0.43382767 0.30490202 0.         0.         1.         0.        ]\n",
            " [0.51477903 0.34278446 1.         0.         1.         0.        ]\n",
            " [0.50095117 0.37393314 1.         0.         1.         0.        ]\n",
            " [0.50447315 0.37466508 1.         0.         1.         0.        ]\n",
            " [0.46447203 0.36893657 0.         0.         1.         0.        ]\n",
            " [0.42072839 0.25927466 0.         0.         1.         0.        ]\n",
            " [0.49183202 0.27464461 0.         0.         1.         0.        ]\n",
            " [0.50469112 0.36117652 1.         0.         1.         0.        ]\n",
            " [0.50107837 0.3575975  1.         0.         1.         0.        ]\n",
            " [0.48429024 0.42197517 0.         0.         1.         0.        ]\n",
            " [0.39445668 0.26748875 0.         0.         0.         0.        ]\n",
            " [0.43284649 0.3757762  0.         0.         0.         0.        ]\n",
            " [0.51171929 0.41043964 1.         0.         0.         0.        ]\n",
            " [0.52665532 0.40579873 1.         0.         0.         0.        ]\n",
            " [0.45106697 0.39339823 0.         0.         0.         1.        ]\n",
            " [0.50768894 0.35988802 1.         0.         1.         0.        ]\n",
            " [0.51228285 0.36822757 1.         0.         0.         0.        ]\n",
            " [0.50913274 0.35943657 1.         0.         1.         0.        ]\n",
            " [0.47053131 0.32287204 0.         0.         1.         0.        ]\n",
            " [0.58704823 0.39932868 1.         0.         1.         0.        ]\n",
            " [0.55570108 0.40875685 1.         0.         1.         0.        ]\n",
            " [0.58113158 0.41131371 1.         0.         1.         0.        ]\n",
            " [0.54140121 0.40234286 1.         0.         1.         0.        ]\n",
            " [0.46126127 0.35664827 0.         0.         1.         0.        ]\n",
            " [0.50163502 0.25684687 1.         0.         1.         0.        ]\n",
            " [0.53916472 0.40271485 1.         0.         1.         0.        ]\n",
            " [0.56197107 0.40276024 1.         0.         1.         0.        ]\n",
            " [0.52812743 0.39946976 1.         0.         1.         0.        ]\n",
            " [0.46705824 0.36405328 0.         0.         1.         0.        ]\n",
            " [0.51881629 0.29639924 1.         0.         1.         0.        ]\n",
            " [0.50339991 0.37917301 1.         0.         1.         0.        ]\n",
            " [0.50903398 0.38233718 1.         0.         0.         0.        ]\n",
            " [0.50598079 0.37255427 1.         0.         1.         0.        ]\n",
            " [0.46142283 0.34127432 0.         0.         1.         0.        ]\n",
            " [0.54889548 0.41609639 1.         0.         1.         0.        ]\n",
            " [0.50460422 0.3622407  1.         0.         1.         0.        ]\n",
            " [0.506567   0.36514056 1.         0.         1.         0.        ]\n",
            " [0.50368947 0.35883316 1.         0.         1.         0.        ]\n",
            " [0.46265173 0.32410923 0.         0.         1.         0.        ]\n",
            " [0.56259787 0.4212994  1.         0.         1.         0.        ]\n",
            " [0.50724471 0.40851134 1.         0.         0.         0.        ]\n",
            " [0.47533858 0.32177341 0.         0.         0.         0.        ]\n",
            " [0.47588983 0.29987037 0.         0.         0.         0.        ]\n",
            " [0.38478982 0.17319101 0.         0.         0.         0.        ]\n",
            " [0.41858703 0.31497833 0.         0.         0.         0.        ]\n",
            " [0.29442891 0.14480914 0.         0.         0.         0.        ]\n",
            " [0.47562641 0.28165188 0.         0.         0.         0.        ]\n",
            " [0.46752134 0.3338725  0.         0.         1.         0.        ]\n",
            " [0.41642216 0.30301023 0.         0.         0.         0.        ]\n",
            " [0.44693515 0.32175228 0.         0.         0.         0.        ]\n",
            " [0.5047307  0.31264693 1.         0.         0.         0.        ]\n",
            " [0.33310929 0.19977891 0.         0.         0.         0.        ]\n",
            " [0.40396595 0.28280225 0.         0.         0.         0.        ]\n",
            " [0.42529625 0.31045544 0.         0.         1.         0.        ]\n",
            " [0.41232091 0.30194893 0.         0.         0.         0.        ]\n",
            " [0.43267411 0.31387824 0.         0.         1.         0.        ]\n",
            " [0.48105273 0.33279961 0.         0.         1.         0.        ]\n",
            " [0.34358498 0.19512337 0.         0.         0.         0.        ]\n",
            " [0.45269585 0.29226181 0.         0.         0.         0.        ]\n",
            " [0.45123789 0.30244881 0.         0.         0.         0.        ]\n",
            " [0.45320526 0.32513669 0.         0.         0.         0.        ]\n",
            " [0.46200377 0.33625147 0.         0.         1.         0.        ]\n",
            " [0.49680722 0.33303538 0.         0.         0.         0.        ]\n",
            " [0.40915242 0.20472296 0.         0.         1.         0.        ]\n",
            " [0.52144575 0.38773695 1.         0.         1.         0.        ]\n",
            " [0.52378523 0.38509923 1.         0.         1.         0.        ]\n",
            " [0.50419044 0.41173312 1.         0.         1.         0.        ]\n",
            " [0.5145207  0.3980062  1.         0.         1.         0.        ]\n",
            " [0.51582193 0.43948755 1.         0.         1.         0.        ]\n",
            " [0.39593431 0.17602588 0.         0.         0.         0.        ]\n",
            " [0.50399941 0.37953922 1.         0.         0.         0.        ]\n",
            " [0.47178441 0.37481254 0.         0.         0.         0.        ]\n",
            " [0.47881851 0.41373655 0.         0.         0.         0.        ]\n",
            " [0.47221559 0.40279505 0.         0.         0.         0.        ]\n",
            " [0.50891781 0.41338107 1.         0.         0.         0.        ]\n",
            " [0.45119935 0.2870118  0.         0.         0.         0.        ]\n",
            " [0.48173785 0.39236057 0.         0.         0.         0.        ]\n",
            " [0.41893363 0.32833326 0.         0.         0.         0.        ]\n",
            " [0.42690179 0.36069703 0.         0.         0.         0.        ]\n",
            " [0.4984107  0.3479169  0.         0.         0.         0.        ]\n",
            " [0.4746269  0.37268245 0.         0.         0.         0.        ]\n",
            " [0.39189646 0.30259338 0.         0.         0.         0.        ]\n",
            " [0.4525978  0.3580282  0.         0.         0.         0.        ]\n",
            " [0.44727316 0.36643919 0.         0.         0.         0.        ]\n",
            " [0.43465677 0.31314006 0.         0.         0.         0.        ]\n",
            " [0.43928483 0.39375454 0.         0.         0.         0.        ]\n",
            " [0.34968162 0.30689496 0.         0.         0.         0.        ]\n",
            " [0.43939891 0.4133229  0.         0.         0.         0.        ]\n",
            " [0.43988648 0.35445905 0.         0.         0.         0.        ]\n",
            " [0.38421768 0.38341191 0.         0.         0.         0.        ]\n",
            " [0.35333779 0.29231477 0.         0.         0.         0.        ]\n",
            " [0.42101365 0.30147889 0.         0.         0.         0.        ]\n",
            " [0.36342922 0.30484247 0.         0.         0.         0.        ]\n",
            " [0.44062111 0.37365633 0.         0.         0.         0.        ]\n",
            " [0.40867138 0.29275855 0.         0.         0.         0.        ]\n",
            " [0.36355603 0.31793144 0.         0.         0.         0.        ]\n",
            " [0.44188446 0.32366115 0.         0.         0.         0.        ]\n",
            " [0.41245511 0.34836209 0.         0.         0.         0.        ]\n",
            " [0.42581335 0.32472059 0.         0.         0.         0.        ]\n",
            " [0.38208488 0.31815851 0.         0.         0.         0.        ]\n",
            " [0.40061185 0.30748498 0.         0.         0.         0.        ]\n",
            " [0.44374055 0.35800698 0.         0.         0.         0.        ]\n",
            " [0.40114331 0.31344685 0.         0.         0.         0.        ]\n",
            " [0.41792819 0.34520543 0.         0.         0.         0.        ]\n",
            " [0.38874713 0.31836531 0.         0.         0.         0.        ]\n",
            " [0.43316832 0.34373507 0.         0.         0.         0.        ]\n",
            " [0.41632742 0.33249146 0.         0.         0.         0.        ]\n",
            " [0.43031594 0.3655439  0.         0.         0.         0.        ]\n",
            " [0.35697493 0.36868626 0.         0.         0.         0.        ]\n",
            " [0.41881198 0.28673387 0.         0.         0.         0.        ]\n",
            " [0.43141448 0.34437039 0.         0.         0.         0.        ]\n",
            " [0.40774253 0.37612489 0.         0.         0.         0.        ]\n",
            " [0.40853694 0.3148858  0.         0.         0.         0.        ]\n",
            " [0.45878884 0.30952591 0.         0.         0.         0.        ]\n",
            " [0.41402221 0.38924962 0.         0.         0.         0.        ]\n",
            " [0.43482637 0.339881   0.         0.         0.         0.        ]\n",
            " [0.39207554 0.33804968 0.         0.         0.         0.        ]\n",
            " [0.42653194 0.31579444 0.         0.         0.         0.        ]\n",
            " [0.42671663 0.37835431 0.         0.         0.         0.        ]\n",
            " [0.40003642 0.34179249 0.         0.         0.         0.        ]\n",
            " [0.38487074 0.29675534 0.         0.         0.         0.        ]\n",
            " [0.35341966 0.30767065 0.         0.         0.         0.        ]\n",
            " [0.37513068 0.30893329 0.         0.         0.         0.        ]\n",
            " [0.44174075 0.34849679 0.         0.         0.         0.        ]\n",
            " [0.39631921 0.31435576 0.         0.         0.         0.        ]\n",
            " [0.27187505 0.27521005 0.         0.         0.         0.        ]\n",
            " [0.44003034 0.3563365  0.         0.         0.         0.        ]\n",
            " [0.35308883 0.22917718 0.         0.         0.         0.        ]\n",
            " [0.42973915 0.26151171 0.         0.         0.         0.        ]\n",
            " [0.41660428 0.32977429 0.         0.         0.         0.        ]\n",
            " [0.28302342 0.26897258 0.         0.         0.         0.        ]\n",
            " [0.43487242 0.26447141 0.         0.         0.         0.        ]\n",
            " [0.21888499 0.19805802 0.         0.         0.         0.        ]\n",
            " [0.34626344 0.2029265  0.         0.         0.         0.        ]\n",
            " [0.39665779 0.26670986 0.         0.         0.         0.        ]\n",
            " [0.36214834 0.32524246 0.         0.         0.         0.        ]\n",
            " [0.38842127 0.23735188 0.         0.         0.         0.        ]\n",
            " [0.40798244 0.1777264  0.         0.         0.         0.        ]\n",
            " [0.40927443 0.29887033 0.         0.         0.         0.        ]\n",
            " [0.34345135 0.20590809 0.         0.         0.         0.        ]\n",
            " [0.43954033 0.29583108 0.         0.         0.         0.        ]\n",
            " [0.34540659 0.27770501 0.         0.         0.         0.        ]\n",
            " [0.40548182 0.25638551 0.         0.         0.         0.        ]\n",
            " [0.38834909 0.15863596 0.         0.         1.         0.        ]\n",
            " [0.34179163 0.15328962 0.         0.         1.         0.        ]\n",
            " [0.33543301 0.23082274 0.         0.         0.         0.        ]\n",
            " [0.44123334 0.2714527  0.         0.         0.         0.        ]\n",
            " [0.39705697 0.23576327 0.         0.         0.         0.        ]\n",
            " [0.3352648  0.36915722 0.         0.         0.         0.        ]\n",
            " [0.31962478 0.26232249 0.         0.         0.         0.        ]\n",
            " [0.26332551 0.26351956 0.         0.         0.         0.        ]\n",
            " [0.42020294 0.38353449 0.         0.         0.         0.        ]\n",
            " [0.39547417 0.3595283  0.         0.         0.         0.        ]\n",
            " [0.34656522 0.3576932  0.         0.         0.         0.        ]\n",
            " [0.30226853 0.29798609 0.         0.         0.         0.        ]\n",
            " [0.32209238 0.32748321 0.         0.         0.         0.        ]\n",
            " [0.29690325 0.2944656  0.         0.         0.         0.        ]\n",
            " [0.42040008 0.28598788 0.         0.         0.         0.        ]\n",
            " [0.32191199 0.32052156 0.         0.         0.         0.        ]\n",
            " [0.40957633 0.30493864 0.         0.         0.         0.        ]\n",
            " [0.28957182 0.31197223 0.         0.         0.         0.        ]\n",
            " [0.33354953 0.37247959 0.         0.         0.         0.        ]\n",
            " [0.26483169 0.30943894 0.         0.         0.         0.        ]\n",
            " [0.30661586 0.34533697 0.         0.         0.         0.        ]\n",
            " [0.29298633 0.31160557 0.         0.         0.         0.        ]\n",
            " [0.28907567 0.31218407 0.         0.         0.         0.        ]\n",
            " [0.31897163 0.33875304 0.         0.         0.         0.        ]\n",
            " [0.42306742 0.32353956 0.         0.         0.         0.        ]\n",
            " [0.4110119  0.31779212 0.         0.         0.         0.        ]\n",
            " [0.3328661  0.14805061 0.         0.         0.         0.        ]\n",
            " [0.47387007 0.43539906 0.         0.         0.         0.        ]\n",
            " [0.41875875 0.39606047 0.         0.         0.         0.        ]\n",
            " [0.4597111  0.44006598 0.         0.         0.         0.        ]\n",
            " [0.41587707 0.445023   0.         0.         0.         0.        ]\n",
            " [0.49118963 0.44091672 0.         0.         0.         0.        ]\n",
            " [0.25843409 0.16830486 0.         0.         0.         0.        ]\n",
            " [0.41875494 0.20840654 0.         0.         0.         0.        ]\n",
            " [0.53405124 0.4325839  1.         0.         0.         1.        ]\n",
            " [0.4564434  0.43666533 0.         0.         0.         1.        ]\n",
            " [0.4835985  0.42584664 0.         0.         0.         1.        ]\n",
            " [0.42778155 0.44563547 0.         0.         0.         1.        ]\n",
            " [0.43073323 0.43557873 0.         0.         1.         1.        ]\n",
            " [0.41902319 0.44105858 0.         0.         0.         1.        ]\n",
            " [0.56009978 0.43529391 1.         0.         0.         1.        ]\n",
            " [0.45662606 0.38658708 0.         0.         0.         0.        ]\n",
            " [0.3883307  0.34366158 0.         0.         0.         1.        ]\n",
            " [0.46146831 0.47816145 0.         0.         0.         1.        ]\n",
            " [0.47416434 0.48874    0.         0.         0.         1.        ]\n",
            " [0.46846783 0.4630273  0.         0.         0.         1.        ]\n",
            " [0.46938235 0.48415571 0.         0.         0.         1.        ]\n",
            " [0.47147554 0.47174826 0.         0.         0.         1.        ]\n",
            " [0.44660118 0.47220072 0.         0.         0.         1.        ]\n",
            " [0.4144192  0.2826319  0.         0.         0.         1.        ]\n",
            " [0.61565077 0.44600171 1.         0.         1.         1.        ]\n",
            " [0.43144095 0.42708895 0.         0.         0.         1.        ]\n",
            " [0.42014295 0.43311706 0.         0.         1.         1.        ]\n",
            " [0.43246365 0.43344104 0.         0.         0.         1.        ]\n",
            " [0.4168734  0.43645602 0.         0.         0.         1.        ]\n",
            " [0.44811592 0.44843942 0.         0.         0.         1.        ]\n",
            " [0.41954914 0.50977772 0.         1.         0.         1.        ]\n",
            " [0.41589344 0.28964862 0.         0.         0.         0.        ]\n",
            " [0.44257626 0.46547553 0.         0.         0.         1.        ]\n",
            " [0.47118446 0.46692565 0.         0.         0.         1.        ]\n",
            " [0.44733855 0.45916036 0.         0.         0.         1.        ]\n",
            " [0.46907368 0.47393459 0.         0.         0.         1.        ]\n",
            " [0.45028773 0.47073326 0.         0.         0.         1.        ]\n",
            " [0.44699067 0.4532648  0.         0.         0.         1.        ]\n",
            " [0.37409168 0.44097066 0.         0.         0.         1.        ]\n",
            " [0.41109148 0.22943136 0.         0.         1.         0.        ]\n",
            " [0.43046767 0.42499039 0.         0.         0.         1.        ]\n",
            " [0.43525603 0.39017224 0.         0.         0.         1.        ]\n",
            " [0.41351712 0.4336729  0.         0.         0.         1.        ]\n",
            " [0.41985098 0.39975724 0.         0.         0.         1.        ]\n",
            " [0.4303599  0.44384733 0.         0.         0.         1.        ]\n",
            " [0.46142679 0.41354907 0.         0.         0.         1.        ]\n",
            " [0.44524434 0.24289072 0.         0.         0.         0.        ]\n",
            " [0.45619413 0.44890544 0.         0.         0.         1.        ]\n",
            " [0.43125352 0.40914053 0.         0.         0.         1.        ]\n",
            " [0.40288374 0.43896118 0.         0.         0.         1.        ]\n",
            " [0.43593872 0.45431557 0.         0.         0.         1.        ]\n",
            " [0.45313445 0.46613705 0.         0.         0.         1.        ]\n",
            " [0.44799909 0.44034511 0.         0.         0.         1.        ]\n",
            " [0.38951346 0.4155677  0.         0.         0.         0.        ]\n",
            " [0.47590253 0.52298009 0.         1.         0.         1.        ]\n",
            " [0.47969857 0.53812528 0.         1.         0.         1.        ]\n",
            " [0.49787995 0.5192222  0.         1.         0.         1.        ]\n",
            " [0.49118543 0.53134722 0.         1.         0.         1.        ]\n",
            " [0.46275213 0.50171179 0.         1.         0.         1.        ]\n",
            " [0.49380296 0.53358161 0.         1.         0.         1.        ]\n",
            " [0.44103938 0.47329795 0.         0.         0.         1.        ]\n",
            " [0.48601267 0.50471479 0.         1.         0.         1.        ]\n",
            " [0.43682635 0.52888674 0.         1.         0.         1.        ]\n",
            " [0.47221884 0.53419703 0.         1.         0.         1.        ]\n",
            " [0.40494934 0.45372808 0.         0.         0.         1.        ]\n",
            " [0.28349048 0.22705775 0.         0.         0.         0.        ]\n",
            " [0.47166482 0.53526074 0.         1.         0.         1.        ]\n",
            " [0.47337091 0.54432213 0.         1.         0.         1.        ]\n",
            " [0.48586339 0.5211857  0.         1.         0.         1.        ]\n",
            " [0.47748253 0.52780855 0.         1.         0.         1.        ]\n",
            " [0.44563839 0.51888317 0.         1.         0.         1.        ]\n",
            " [0.48342806 0.53624529 0.         1.         0.         1.        ]\n",
            " [0.45759481 0.51678568 0.         1.         0.         1.        ]\n",
            " [0.48613891 0.52818662 0.         1.         0.         1.        ]\n",
            " [0.43859434 0.51724857 0.         1.         0.         1.        ]\n",
            " [0.46867701 0.53844911 0.         1.         0.         1.        ]\n",
            " [0.41458479 0.47635782 0.         0.         0.         1.        ]\n",
            " [0.29593667 0.18857718 0.         0.         0.         0.        ]\n",
            " [0.42334333 0.24657463 0.         0.         0.         0.        ]\n",
            " [0.43354964 0.24959807 0.         0.         0.         0.        ]\n",
            " [0.36912832 0.22454962 0.         0.         0.         0.        ]\n",
            " [0.42000875 0.23772581 0.         0.         0.         0.        ]\n",
            " [0.44828191 0.26379111 0.         0.         0.         0.        ]\n",
            " [0.42904237 0.24078754 0.         0.         0.         0.        ]\n",
            " [0.32685226 0.23821165 0.         0.         0.         0.        ]\n",
            " [0.34021616 0.21382123 0.         0.         0.         0.        ]\n",
            " [0.29858917 0.19046769 0.         0.         0.         0.        ]\n",
            " [0.41747826 0.23379269 0.         0.         0.         0.        ]\n",
            " [0.29688185 0.1981898  0.         0.         0.         0.        ]\n",
            " [0.49370798 0.52211183 0.         1.         0.         1.        ]\n",
            " [0.52319127 0.49821392 1.         0.         0.         1.        ]\n",
            " [0.51665074 0.49955693 1.         0.         0.         1.        ]\n",
            " [0.50306875 0.47947484 1.         0.         0.         1.        ]\n",
            " [0.51787966 0.50004154 1.         1.         0.         1.        ]\n",
            " [0.50551939 0.48519745 1.         0.         0.         1.        ]\n",
            " [0.50421768 0.47628903 1.         0.         0.         1.        ]\n",
            " [0.47981542 0.49106166 0.         0.         0.         1.        ]\n",
            " [0.50343567 0.46712926 1.         0.         0.         1.        ]\n",
            " [0.48043025 0.53742504 0.         1.         0.         1.        ]\n",
            " [0.51448226 0.5046885  1.         1.         0.         1.        ]\n",
            " [0.44178918 0.51102263 0.         1.         0.         1.        ]\n",
            " [0.42563912 0.44565159 0.         0.         0.         1.        ]\n",
            " [0.52045947 0.51131439 1.         1.         0.         1.        ]\n",
            " [0.5023492  0.51289451 1.         1.         0.         1.        ]\n",
            " [0.52209198 0.50797039 1.         1.         0.         1.        ]\n",
            " [0.51212257 0.50005496 1.         1.         0.         1.        ]\n",
            " [0.49726194 0.49767119 0.         0.         0.         1.        ]\n",
            " [0.51477951 0.50939673 1.         1.         0.         1.        ]\n",
            " [0.45796055 0.49528497 0.         0.         0.         1.        ]\n",
            " [0.51296622 0.49394497 1.         0.         0.         1.        ]\n",
            " [0.46697012 0.55252957 0.         1.         0.         1.        ]\n",
            " [0.50009257 0.52564639 1.         1.         0.         1.        ]\n",
            " [0.42597595 0.50970447 0.         1.         0.         1.        ]\n",
            " [0.41846117 0.44964299 0.         0.         0.         0.        ]\n",
            " [0.45974174 0.44279733 0.         0.         0.         1.        ]\n",
            " [0.44965765 0.44629067 0.         0.         0.         1.        ]\n",
            " [0.43179077 0.50591803 0.         1.         0.         0.        ]\n",
            " [0.46574134 0.46423393 0.         0.         0.         0.        ]\n",
            " [0.4596414  0.41085774 0.         0.         0.         1.        ]\n",
            " [0.46031573 0.46466991 0.         0.         0.         1.        ]\n",
            " [0.37908423 0.48501265 0.         0.         0.         1.        ]\n",
            " [0.40620318 0.51587242 0.         1.         0.         1.        ]\n",
            " [0.43984106 0.49758664 0.         0.         0.         1.        ]\n",
            " [0.41789737 0.49974015 0.         0.         0.         1.        ]\n",
            " [0.39450577 0.45642507 0.         0.         0.         1.        ]\n",
            " [0.44138053 0.4244118  0.         0.         0.         1.        ]\n",
            " [0.44333783 0.5193696  0.         1.         0.         1.        ]\n",
            " [0.52408928 0.48585543 1.         0.         0.         1.        ]\n",
            " [0.48907486 0.36390519 0.         0.         0.         1.        ]\n",
            " [0.48785725 0.43318722 0.         0.         0.         1.        ]\n",
            " [0.48664933 0.38023695 0.         0.         0.         1.        ]\n",
            " [0.40744144 0.33775514 0.         0.         0.         1.        ]\n",
            " [0.53479415 0.36124048 1.         0.         0.         1.        ]\n",
            " [0.39393684 0.37597021 0.         0.         0.         1.        ]\n",
            " [0.39201352 0.36496004 0.         0.         0.         1.        ]\n",
            " [0.44576088 0.27771801 0.         0.         0.         0.        ]\n",
            " [0.43197674 0.33596849 0.         0.         0.         0.        ]\n",
            " [0.44120073 0.27845663 0.         0.         0.         0.        ]\n",
            " [0.44174561 0.24068034 0.         0.         0.         0.        ]\n",
            " [0.47925782 0.26248708 0.         0.         0.         0.        ]\n",
            " [0.42330569 0.31719911 0.         0.         0.         0.        ]\n",
            " [0.43958211 0.32678047 0.         0.         0.         0.        ]\n",
            " [0.48800257 0.33767855 0.         0.         0.         0.        ]\n",
            " [0.49068433 0.3163034  0.         0.         0.         0.        ]\n",
            " [0.46762782 0.33425304 0.         0.         1.         0.        ]\n",
            " [0.50755489 0.30709988 1.         0.         1.         0.        ]\n",
            " [0.46527931 0.26564801 0.         0.         1.         0.        ]\n",
            " [0.51106215 0.35504961 1.         0.         1.         0.        ]\n",
            " [0.48363563 0.31403297 0.         0.         0.         0.        ]\n",
            " [0.49494904 0.28064662 0.         0.         1.         0.        ]\n",
            " [0.50679272 0.30949032 1.         0.         1.         0.        ]\n",
            " [0.48758447 0.29277077 0.         0.         0.         0.        ]\n",
            " [0.42046216 0.35003814 0.         0.         0.         0.        ]\n",
            " [0.49661866 0.36126998 0.         0.         0.         0.        ]\n",
            " [0.46162972 0.25218654 0.         0.         1.         0.        ]\n",
            " [0.53518409 0.33423749 1.         0.         0.         0.        ]\n",
            " [0.5317111  0.40995935 1.         0.         0.         0.        ]\n",
            " [0.50856918 0.3949292  1.         0.         0.         0.        ]\n",
            " [0.4893105  0.38954166 0.         0.         0.         0.        ]\n",
            " [0.54161566 0.28503394 1.         0.         1.         0.        ]\n",
            " [0.5370819  0.33656955 1.         0.         1.         0.        ]\n",
            " [0.56063515 0.33351955 1.         0.         1.         0.        ]\n",
            " [0.48259544 0.26632652 0.         0.         1.         0.        ]\n",
            " [0.5134539  0.32850304 1.         0.         1.         0.        ]\n",
            " [0.48669788 0.32249433 0.         0.         1.         0.        ]\n",
            " [0.46316797 0.27284056 0.         0.         1.         0.        ]\n",
            " [0.56432551 0.32707554 1.         0.         1.         0.        ]\n",
            " [0.51818711 0.26881075 1.         0.         1.         0.        ]\n",
            " [0.51210964 0.39628688 1.         0.         1.         0.        ]\n",
            " [0.51934683 0.34361893 1.         0.         1.         0.        ]\n",
            " [0.45291221 0.25752607 0.         0.         1.         0.        ]\n",
            " [0.5574407  0.37344024 1.         0.         1.         0.        ]\n",
            " [0.57508534 0.37503177 1.         0.         1.         0.        ]\n",
            " [0.5224902  0.36826628 1.         0.         1.         0.        ]\n",
            " [0.53643322 0.37907907 1.         0.         1.         0.        ]\n",
            " [0.44862288 0.29475242 0.         0.         0.         0.        ]\n",
            " [0.41071546 0.34065396 0.         0.         0.         0.        ]\n",
            " [0.3280547  0.30600506 0.         0.         0.         0.        ]\n",
            " [0.38810325 0.30447763 0.         0.         0.         0.        ]\n",
            " [0.3877736  0.31340727 0.         0.         0.         0.        ]\n",
            " [0.26959309 0.25020963 0.         0.         0.         0.        ]\n",
            " [0.3885262  0.28717914 0.         0.         0.         0.        ]\n",
            " [0.40013364 0.33060721 0.         0.         0.         0.        ]\n",
            " [0.39623913 0.2866981  0.         0.         0.         0.        ]\n",
            " [0.4193587  0.41346592 0.         0.         1.         0.        ]\n",
            " [0.36173582 0.32436928 0.         0.         1.         0.        ]\n",
            " [0.41577879 0.32551154 0.         0.         1.         0.        ]\n",
            " [0.45027786 0.32638147 0.         0.         0.         0.        ]\n",
            " [0.37650639 0.30553225 0.         0.         0.         0.        ]\n",
            " [0.43086135 0.35866439 0.         0.         1.         0.        ]\n",
            " [0.3373808  0.31777668 0.         0.         1.         0.        ]\n",
            " [0.43906778 0.27971372 0.         0.         0.         0.        ]\n",
            " [0.4143073  0.26453686 0.         0.         0.         0.        ]\n",
            " [0.35483667 0.3324711  0.         0.         0.         0.        ]\n",
            " [0.35582316 0.33007586 0.         0.         0.         0.        ]\n",
            " [0.3465372  0.32166356 0.         0.         0.         0.        ]\n",
            " [0.41054401 0.24399695 0.         0.         0.         0.        ]\n",
            " [0.34228978 0.26740256 0.         0.         0.         0.        ]\n",
            " [0.25560328 0.25386694 0.         0.         0.         0.        ]\n",
            " [0.29072538 0.22106005 0.         0.         0.         0.        ]\n",
            " [0.2760224  0.20369899 0.         0.         0.         0.        ]\n",
            " [0.51939189 0.41311824 1.         0.         1.         0.        ]\n",
            " [0.38897958 0.32136056 0.         0.         0.         0.        ]\n",
            " [0.40467507 0.30446982 0.         0.         0.         0.        ]\n",
            " [0.39093718 0.2743524  0.         0.         0.         1.        ]\n",
            " [0.33654648 0.28822768 0.         0.         0.         0.        ]\n",
            " [0.37121239 0.24863268 0.         0.         1.         0.        ]\n",
            " [0.30353418 0.36260277 0.         0.         1.         0.        ]\n",
            " [0.42013723 0.28648281 0.         0.         1.         0.        ]\n",
            " [0.42576343 0.26623771 0.         0.         1.         0.        ]\n",
            " [0.32981861 0.25736046 0.         0.         0.         0.        ]\n",
            " [0.43587348 0.20029534 0.         0.         0.         0.        ]\n",
            " [0.30406946 0.2308448  0.         0.         0.         0.        ]\n",
            " [0.30079567 0.23540182 0.         0.         0.         0.        ]\n",
            " [0.33422625 0.23674606 0.         0.         1.         0.        ]\n",
            " [0.32316703 0.21705802 0.         0.         1.         0.        ]\n",
            " [0.44929692 0.20475654 0.         0.         1.         0.        ]\n",
            " [0.39598686 0.21445765 0.         0.         1.         0.        ]\n",
            " [0.48635319 0.26713431 0.         0.         1.         0.        ]\n",
            " [0.48807135 0.27494544 0.         0.         1.         0.        ]\n",
            " [0.47915977 0.25713012 0.         0.         1.         0.        ]\n",
            " [0.40402797 0.19011998 0.         0.         1.         0.        ]\n",
            " [0.35783675 0.20787334 0.         0.         0.         0.        ]\n",
            " [0.4774321  0.31713411 0.         0.         0.         0.        ]\n",
            " [0.43570721 0.09401745 0.         0.         0.         0.        ]\n",
            " [0.56104624 0.2260299  1.         0.         0.         0.        ]\n",
            " [0.4895387  0.26404426 0.         0.         0.         0.        ]\n",
            " [0.46578667 0.28551951 0.         0.         0.         0.        ]\n",
            " [0.53381103 0.37948248 1.         0.         0.         0.        ]\n",
            " [0.49455026 0.2712608  0.         0.         0.         0.        ]\n",
            " [0.50117981 0.29223692 1.         0.         0.         0.        ]\n",
            " [0.42843673 0.35610485 0.         0.         0.         0.        ]\n",
            " [0.47525188 0.32878166 0.         0.         0.         0.        ]\n",
            " [0.45629343 0.32286993 0.         0.         0.         0.        ]\n",
            " [0.43293664 0.16387777 0.         0.         0.         0.        ]\n",
            " [0.54530811 0.2637707  1.         0.         0.         0.        ]\n",
            " [0.47854486 0.30101854 0.         0.         0.         0.        ]\n",
            " [0.46051124 0.29986587 0.         0.         0.         0.        ]\n",
            " [0.47189981 0.33626673 0.         0.         0.         0.        ]\n",
            " [0.50111306 0.25494599 1.         0.         0.         0.        ]\n",
            " [0.49602723 0.28597662 0.         0.         0.         0.        ]\n",
            " [0.45112848 0.34419027 0.         0.         0.         0.        ]\n",
            " [0.48349515 0.35546282 0.         0.         0.         0.        ]\n",
            " [0.3682529  0.27996159 0.         0.         0.         0.        ]\n",
            " [0.437581   0.21568236 0.         0.         0.         0.        ]\n",
            " [0.49919486 0.24243456 0.         0.         0.         0.        ]\n",
            " [0.42875752 0.29629308 0.         0.         1.         0.        ]\n",
            " [0.46942237 0.33157414 0.         0.         0.         0.        ]\n",
            " [0.438447   0.33349502 0.         0.         1.         0.        ]\n",
            " [0.44045174 0.26434141 0.         0.         1.         0.        ]\n",
            " [0.48469675 0.29803941 0.         0.         1.         0.        ]\n",
            " [0.48159829 0.31501991 0.         0.         1.         0.        ]\n",
            " [0.45332345 0.30536908 0.         0.         0.         0.        ]\n",
            " [0.33296534 0.17980196 0.         0.         0.         0.        ]\n",
            " [0.39551756 0.25816798 0.         0.         0.         0.        ]\n",
            " [0.38182566 0.24396496 0.         0.         0.         0.        ]\n",
            " [0.49382457 0.41037017 0.         0.         0.         0.        ]\n",
            " [0.52246517 0.38958946 1.         0.         0.         0.        ]\n",
            " [0.50509727 0.37637767 1.         0.         0.         0.        ]\n",
            " [0.47750178 0.29042515 0.         0.         0.         0.        ]\n",
            " [0.47954467 0.25335184 0.         0.         0.         0.        ]\n",
            " [0.48450437 0.2519955  0.         0.         0.         0.        ]\n",
            " [0.45153072 0.35986325 0.         0.         1.         0.        ]\n",
            " [0.51260239 0.39068848 1.         0.         0.         0.        ]\n",
            " [0.49952093 0.36861873 0.         0.         0.         0.        ]\n",
            " [0.47217351 0.32298982 0.         0.         0.         0.        ]\n",
            " [0.48060948 0.29175428 0.         0.         0.         0.        ]\n",
            " [0.479877   0.28077325 0.         0.         0.         0.        ]\n",
            " [0.49099463 0.37153429 0.         0.         1.         0.        ]\n",
            " [0.52926695 0.36192238 1.         0.         0.         0.        ]\n",
            " [0.53203094 0.3695927  1.         0.         1.         0.        ]\n",
            " [0.51289064 0.25910372 1.         0.         0.         0.        ]\n",
            " [0.44584352 0.17261569 0.         0.         0.         0.        ]\n",
            " [0.36364752 0.1783894  0.         0.         0.         0.        ]\n",
            " [0.37342817 0.18199323 0.         0.         0.         0.        ]\n",
            " [0.30639642 0.15558711 0.         0.         0.         0.        ]\n",
            " [0.49265465 0.29220486 0.         0.         0.         0.        ]\n",
            " [0.43213597 0.21428828 0.         0.         0.         0.        ]\n",
            " [0.53771216 0.33276004 1.         0.         0.         0.        ]\n",
            " [0.38178608 0.21404631 0.         0.         0.         0.        ]\n",
            " [0.3661027  0.32574499 0.         0.         0.         0.        ]\n",
            " [0.48048395 0.33175308 0.         0.         0.         0.        ]\n",
            " [0.43537459 0.22350611 0.         0.         0.         0.        ]\n",
            " [0.51893497 0.3643353  1.         0.         0.         0.        ]\n",
            " [0.39696011 0.22031789 0.         0.         0.         0.        ]\n",
            " [0.3661885  0.31273797 0.         0.         0.         0.        ]\n",
            " [0.51870203 0.39456055 1.         0.         0.         0.        ]\n",
            " [0.39698637 0.25785071 0.         0.         0.         0.        ]\n",
            " [0.35776222 0.35438591 0.         0.         0.         0.        ]\n",
            " [0.38349542 0.23988023 0.         0.         1.         0.        ]\n",
            " [0.39931148 0.38608849 0.         0.         0.         0.        ]\n",
            " [0.48731786 0.29999381 0.         0.         1.         0.        ]\n",
            " [0.39841232 0.25593069 0.         0.         0.         0.        ]\n",
            " [0.36517808 0.33807436 0.         0.         0.         0.        ]\n",
            " [0.3653729  0.22725157 0.         0.         0.         0.        ]\n",
            " [0.42023814 0.37292838 0.         0.         0.         0.        ]\n",
            " [0.53700787 0.49829134 1.         0.         0.         0.        ]\n",
            " [0.44576547 0.28766584 0.         0.         0.         0.        ]\n",
            " [0.3691487  0.30123141 0.         0.         0.         0.        ]\n",
            " [0.38713887 0.25090119 0.         0.         0.         0.        ]\n",
            " [0.32692051 0.24120511 0.         0.         0.         0.        ]\n",
            " [0.49685478 0.24354321 0.         0.         0.         0.        ]\n",
            " [0.45567656 0.21604635 0.         0.         0.         0.        ]\n",
            " [0.30001953 0.14574021 0.         0.         0.         0.        ]\n",
            " [0.38236347 0.1619672  0.         0.         0.         0.        ]\n",
            " [0.49642903 0.32123563 0.         0.         0.         0.        ]\n",
            " [0.38484091 0.28482458 0.         0.         0.         0.        ]\n",
            " [0.3648839  0.20999716 0.         0.         0.         0.        ]\n",
            " [0.395399   0.22850734 0.         0.         0.         0.        ]\n",
            " [0.47985196 0.31667155 0.         0.         0.         0.        ]\n",
            " [0.4130621  0.27732036 0.         0.         0.         0.        ]\n",
            " [0.3880845  0.34848377 0.         0.         0.         0.        ]\n",
            " [0.38915706 0.22175719 0.         0.         0.         0.        ]\n",
            " [0.50860643 0.36143395 1.         0.         0.         0.        ]\n",
            " [0.43600705 0.2882432  0.         0.         0.         0.        ]\n",
            " [0.4223609  0.41528162 0.         0.         0.         0.        ]\n",
            " [0.38563862 0.22659369 0.         0.         0.         0.        ]\n",
            " [0.5393908  0.40805084 1.         0.         1.         0.        ]\n",
            " [0.45255351 0.30818221 0.         0.         0.         0.        ]\n",
            " [0.38279301 0.29095736 0.         0.         0.         0.        ]\n",
            " [0.44515607 0.29686716 0.         0.         0.         0.        ]\n",
            " [0.47390065 0.4778623  0.         0.         0.         0.        ]\n",
            " [0.47546774 0.62518775 0.         1.         1.         0.        ]\n",
            " [0.48562929 0.62793684 0.         1.         0.         1.        ]\n",
            " [0.49134877 0.59994906 0.         1.         1.         1.        ]\n",
            " [0.47219115 0.60614598 0.         1.         1.         1.        ]\n",
            " [0.46600327 0.62376457 0.         1.         0.         1.        ]\n",
            " [0.46924245 0.57778323 0.         1.         0.         0.        ]\n",
            " [0.41453522 0.34590697 0.         0.         0.         0.        ]\n",
            " [0.4674648  0.65167588 0.         1.         0.         1.        ]\n",
            " [0.41355038 0.61010718 0.         1.         0.         1.        ]\n",
            " [0.47544774 0.66324556 0.         1.         0.         1.        ]\n",
            " [0.45221695 0.61042613 0.         1.         0.         1.        ]\n",
            " [0.47993526 0.61469668 0.         1.         0.         1.        ]\n",
            " [0.45973933 0.65629494 0.         1.         0.         1.        ]\n",
            " [0.43278512 0.43759114 0.         0.         0.         1.        ]\n",
            " [0.4690333  0.63970149 0.         1.         1.         1.        ]\n",
            " [0.45675355 0.63684618 0.         1.         1.         1.        ]\n",
            " [0.4567838  0.61518526 0.         1.         1.         1.        ]\n",
            " [0.46513504 0.61296397 0.         1.         1.         1.        ]\n",
            " [0.43449908 0.5403235  0.         1.         1.         1.        ]\n",
            " [0.43756866 0.42669037 0.         0.         0.         0.        ]\n",
            " [0.39726767 0.40799457 0.         0.         0.         0.        ]\n",
            " [0.44979942 0.59004754 0.         1.         0.         1.        ]\n",
            " [0.47409239 0.62387776 0.         1.         1.         1.        ]\n",
            " [0.47244263 0.64158797 0.         1.         0.         1.        ]\n",
            " [0.47745818 0.62573731 0.         1.         0.         1.        ]\n",
            " [0.45962149 0.65817267 0.         1.         0.         1.        ]\n",
            " [0.3359659  0.36838078 0.         0.         0.         1.        ]\n",
            " [0.47390449 0.58960551 0.         1.         0.         1.        ]\n",
            " [0.476574   0.61649734 0.         1.         0.         1.        ]\n",
            " [0.48828936 0.6149835  0.         1.         1.         1.        ]\n",
            " [0.48628545 0.58218771 0.         1.         1.         1.        ]\n",
            " [0.36478704 0.40657499 0.         0.         0.         1.        ]\n",
            " [0.46084946 0.60378778 0.         1.         0.         1.        ]\n",
            " [0.32783833 0.34611112 0.         0.         0.         1.        ]\n",
            " [0.46228841 0.60424894 0.         1.         0.         1.        ]\n",
            " [0.48246631 0.63679999 0.         1.         0.         1.        ]\n",
            " [0.46676555 0.60400671 0.         1.         0.         1.        ]\n",
            " [0.39044303 0.47764415 0.         0.         0.         1.        ]\n",
            " [0.44537386 0.66315353 0.         1.         0.         1.        ]\n",
            " [0.43331879 0.66594821 0.         1.         0.         1.        ]\n",
            " [0.55725616 0.35084063 1.         0.         1.         0.        ]\n",
            " [0.61334574 0.21560226 1.         0.         1.         0.        ]\n",
            " [0.53176075 0.37503108 1.         0.         1.         0.        ]\n",
            " [0.58798659 0.23433654 1.         0.         1.         0.        ]\n",
            " [0.51593983 0.41496325 1.         0.         1.         0.        ]\n",
            " [0.53451735 0.25738043 1.         0.         1.         1.        ]\n",
            " [0.52129453 0.36056101 1.         0.         1.         0.        ]\n",
            " [0.52321732 0.37820944 1.         0.         1.         0.        ]\n",
            " [0.64275301 0.20969628 1.         0.         1.         0.        ]\n",
            " [0.50976622 0.45309931 1.         0.         0.         0.        ]\n",
            " [0.53561616 0.350407   1.         0.         1.         0.        ]\n",
            " [0.65067798 0.19016913 1.         0.         1.         0.        ]\n",
            " [0.51703387 0.37424436 1.         0.         1.         0.        ]\n",
            " [0.60795844 0.17161493 1.         0.         1.         0.        ]\n",
            " [0.54866481 0.4566201  1.         0.         1.         0.        ]\n",
            " [0.58372903 0.20492168 1.         0.         1.         0.        ]\n",
            " [0.50901735 0.35413176 1.         0.         1.         0.        ]\n",
            " [0.52760237 0.37211132 1.         0.         1.         0.        ]\n",
            " [0.62841523 0.21546386 1.         0.         1.         0.        ]\n",
            " [0.61027431 0.22267048 1.         0.         1.         0.        ]\n",
            " [0.549537   0.31328997 1.         0.         1.         1.        ]\n",
            " [0.63572752 0.27071014 1.         0.         1.         1.        ]\n",
            " [0.66969252 0.38924176 1.         0.         1.         0.        ]\n",
            " [0.51451313 0.36784771 1.         0.         1.         1.        ]\n",
            " [0.62968951 0.60077536 1.         1.         1.         0.        ]\n",
            " [0.43669879 0.34078988 0.         0.         1.         0.        ]\n",
            " [0.65058935 0.42582053 1.         0.         1.         1.        ]\n",
            " [0.66797483 0.49811918 1.         0.         1.         1.        ]\n",
            " [0.4207097  0.36782593 0.         0.         0.         0.        ]\n",
            " [0.50303227 0.40049523 1.         0.         1.         0.        ]\n",
            " [0.601933   0.25506443 1.         0.         1.         0.        ]\n",
            " [0.52833599 0.3895703  1.         0.         1.         0.        ]\n",
            " [0.58437043 0.44582418 1.         0.         1.         0.        ]\n",
            " [0.53156894 0.38115865 1.         0.         0.         0.        ]\n",
            " [0.58303422 0.43655419 1.         0.         1.         0.        ]\n",
            " [0.5011462  0.37768561 1.         0.         1.         0.        ]\n",
            " [0.58379167 0.42917332 1.         0.         1.         0.        ]\n",
            " [0.62009758 0.45070562 1.         0.         1.         0.        ]\n",
            " [0.52192098 0.39572752 1.         0.         1.         0.        ]\n",
            " [0.53865218 0.48088843 1.         0.         0.         0.        ]\n",
            " [0.55359703 0.30240697 1.         0.         0.         0.        ]\n",
            " [0.50697136 0.34766003 1.         0.         1.         0.        ]\n",
            " [0.54104167 0.45227137 1.         0.         0.         0.        ]\n",
            " [0.53055006 0.33051652 1.         0.         0.         0.        ]\n",
            " [0.62122428 0.40295649 1.         0.         0.         0.        ]\n",
            " [0.49493945 0.36240634 0.         0.         0.         0.        ]\n",
            " [0.52731407 0.42949232 1.         0.         0.         0.        ]\n",
            " [0.58287627 0.43891409 1.         0.         1.         0.        ]\n",
            " [0.48701629 0.34983709 0.         0.         0.         0.        ]\n",
            " [0.51902258 0.38886008 1.         0.         0.         0.        ]\n",
            " [0.47555485 0.29819024 0.         0.         0.         0.        ]\n",
            " [0.3468025  0.32683143 0.         0.         0.         0.        ]\n",
            " [0.3861824  0.43102357 0.         0.         0.         0.        ]\n",
            " [0.33658418 0.30590314 0.         0.         0.         0.        ]\n",
            " [0.48562282 0.45397675 0.         0.         0.         1.        ]\n",
            " [0.3313584  0.30367047 0.         0.         0.         1.        ]\n",
            " [0.36954084 0.38236013 0.         0.         0.         0.        ]\n",
            " [0.31381983 0.40150663 0.         0.         0.         0.        ]\n",
            " [0.35317418 0.32375288 0.         0.         0.         0.        ]\n",
            " [0.3582001  0.35803872 0.         0.         0.         0.        ]\n",
            " [0.42500857 0.27040899 0.         0.         1.         0.        ]\n",
            " [0.56526005 0.45867682 1.         0.         1.         0.        ]\n",
            " [0.45277637 0.29057267 0.         0.         1.         0.        ]\n",
            " [0.41107997 0.33558765 0.         0.         0.         0.        ]\n",
            " [0.4883669  0.34088951 0.         0.         1.         0.        ]\n",
            " [0.54063308 0.43314821 1.         0.         1.         0.        ]\n",
            " [0.53033537 0.36229137 1.         0.         1.         0.        ]\n",
            " [0.53518653 0.40038317 1.         0.         1.         0.        ]\n",
            " [0.47867975 0.46138871 0.         0.         1.         0.        ]\n",
            " [0.54855216 0.47980502 1.         0.         0.         0.        ]\n",
            " [0.43615356 0.22524828 0.         0.         1.         0.        ]\n",
            " [0.40493456 0.40491483 0.         0.         1.         0.        ]\n",
            " [0.40727037 0.19755092 0.         0.         1.         0.        ]\n",
            " [0.52560335 0.35776684 1.         0.         1.         1.        ]\n",
            " [0.52252924 0.35034397 1.         0.         1.         0.        ]\n",
            " [0.40823227 0.40116182 0.         0.         1.         0.        ]\n",
            " [0.5242582  0.36955369 1.         0.         1.         0.        ]\n",
            " [0.43894079 0.41269827 0.         0.         1.         0.        ]\n",
            " [0.47817883 0.36924875 0.         0.         1.         0.        ]\n",
            " [0.5303973  0.26394144 1.         0.         1.         0.        ]\n",
            " [0.49968418 0.36286327 0.         0.         0.         0.        ]\n",
            " [0.51234698 0.43971673 1.         0.         1.         0.        ]\n",
            " [0.43846193 0.30129954 0.         0.         1.         0.        ]\n",
            " [0.48003808 0.3856357  0.         0.         1.         0.        ]\n",
            " [0.47113216 0.40629143 0.         0.         1.         0.        ]\n",
            " [0.57364249 0.44283596 1.         0.         1.         0.        ]\n",
            " [0.46135873 0.42420959 0.         0.         1.         0.        ]\n",
            " [0.58886451 0.41940993 1.         0.         1.         0.        ]\n",
            " [0.5198518  0.44426993 1.         0.         1.         0.        ]\n",
            " [0.55201024 0.42478868 1.         0.         1.         0.        ]\n",
            " [0.49148414 0.28150907 0.         0.         1.         0.        ]\n",
            " [0.56652588 0.44699726 1.         0.         1.         0.        ]\n",
            " [0.45978752 0.26688257 0.         0.         1.         0.        ]\n",
            " [0.51208371 0.34681505 1.         0.         0.         0.        ]\n",
            " [0.50058824 0.34802708 1.         0.         0.         0.        ]\n",
            " [0.5631417  0.44841841 1.         0.         1.         1.        ]\n",
            " [0.52261674 0.36064357 1.         0.         1.         0.        ]\n",
            " [0.54108953 0.39876837 1.         0.         0.         0.        ]\n",
            " [0.49256718 0.4229247  0.         0.         1.         0.        ]\n",
            " [0.56644857 0.36333659 1.         0.         1.         0.        ]\n",
            " [0.27452925 0.25728747 0.         0.         0.         0.        ]\n",
            " [0.21525708 0.38016918 0.         0.         0.         1.        ]\n",
            " [0.50571764 0.39839661 1.         0.         0.         0.        ]\n",
            " [0.30917406 0.29802838 0.         0.         0.         0.        ]\n",
            " [0.35996208 0.28771222 0.         0.         0.         0.        ]\n",
            " [0.20400292 0.37835374 0.         0.         0.         0.        ]\n",
            " [0.35989395 0.29976439 0.         0.         0.         0.        ]\n",
            " [0.21648428 0.36412707 0.         0.         0.         0.        ]\n",
            " [0.26504371 0.38600242 0.         0.         0.         0.        ]\n",
            " [0.38162249 0.44396853 0.         0.         0.         0.        ]\n",
            " [0.45891729 0.23687348 0.         0.         0.         0.        ]\n",
            " [0.55720001 0.24210659 1.         0.         1.         0.        ]\n",
            " [0.53159654 0.20297924 1.         0.         1.         0.        ]\n",
            " [0.49058414 0.20463035 0.         0.         1.         0.        ]\n",
            " [0.43540478 0.14093176 0.         0.         0.         0.        ]\n",
            " [0.55389959 0.15532021 1.         0.         0.         0.        ]\n",
            " [0.45997137 0.2067592  0.         0.         0.         0.        ]\n",
            " [0.54220712 0.15534049 1.         0.         0.         0.        ]\n",
            " [0.47066218 0.24443272 0.         0.         0.         0.        ]\n",
            " [0.4058466  0.20324647 0.         0.         0.         0.        ]\n",
            " [0.51747352 0.18897468 1.         0.         1.         0.        ]\n",
            " [0.49716994 0.18129316 0.         0.         1.         0.        ]\n",
            " [0.45730755 0.18037452 0.         0.         1.         0.        ]\n",
            " [0.4425365  0.15848799 0.         0.         1.         0.        ]\n",
            " [0.50437057 0.17359713 1.         0.         1.         0.        ]\n",
            " [0.44184595 0.19104335 0.         0.         1.         0.        ]\n",
            " [0.49165559 0.16945091 0.         0.         0.         0.        ]\n",
            " [0.40808681 0.23199916 0.         0.         1.         0.        ]\n",
            " [0.50972545 0.32877332 1.         0.         1.         0.        ]\n",
            " [0.64920074 0.45255518 1.         0.         1.         0.        ]\n",
            " [0.63910538 0.38261336 1.         0.         1.         0.        ]\n",
            " [0.6305995  0.35978785 1.         0.         1.         0.        ]\n",
            " [0.45716599 0.32702261 0.         0.         1.         0.        ]\n",
            " [0.6732018  0.38544062 1.         0.         1.         0.        ]\n",
            " [0.47500795 0.35518125 0.         0.         1.         1.        ]\n",
            " [0.6506843  0.37764585 1.         0.         1.         0.        ]\n",
            " [0.42717957 0.36853021 0.         0.         0.         0.        ]\n",
            " [0.43803853 0.20806037 0.         0.         0.         0.        ]\n",
            " [0.60378408 0.25619581 1.         0.         1.         0.        ]\n",
            " [0.5734781  0.21445066 1.         0.         0.         0.        ]\n",
            " [0.58223969 0.21575589 1.         0.         1.         0.        ]\n",
            " [0.4556419  0.17169559 0.         0.         0.         0.        ]\n",
            " [0.60428244 0.20825173 1.         0.         0.         0.        ]\n",
            " [0.46891564 0.19090682 0.         0.         0.         0.        ]\n",
            " [0.58436602 0.20492543 1.         0.         0.         0.        ]\n",
            " [0.45668563 0.30448875 0.         0.         0.         0.        ]\n",
            " [0.5000788  0.42913035 1.         0.         0.         0.        ]\n",
            " [0.45378894 0.35602304 0.         0.         1.         0.        ]\n",
            " [0.46349373 0.32874423 0.         0.         1.         0.        ]\n",
            " [0.47384709 0.33582965 0.         0.         0.         0.        ]\n",
            " [0.42905346 0.3411153  0.         0.         0.         0.        ]\n",
            " [0.46041325 0.37822443 0.         0.         0.         0.        ]\n",
            " [0.38688648 0.32744506 0.         0.         1.         0.        ]\n",
            " [0.45541245 0.37828729 0.         0.         1.         1.        ]\n",
            " [0.36820841 0.27606168 0.         0.         0.         0.        ]\n",
            " [0.45398241 0.38097447 0.         0.         0.         0.        ]\n",
            " [0.41625756 0.36070532 0.         0.         0.         0.        ]\n",
            " [0.44257197 0.32122985 0.         0.         0.         0.        ]\n",
            " [0.42695701 0.30388144 0.         0.         0.         0.        ]\n",
            " [0.42346835 0.29958716 0.         0.         0.         0.        ]\n",
            " [0.34074202 0.26997995 0.         0.         0.         0.        ]\n",
            " [0.44005683 0.36737722 0.         0.         0.         0.        ]\n",
            " [0.36771131 0.36322179 0.         0.         1.         0.        ]\n",
            " [0.38906908 0.30409941 0.         0.         1.         0.        ]\n",
            " [0.3895818  0.28648818 0.         0.         1.         0.        ]\n",
            " [0.38558343 0.26489863 0.         0.         1.         0.        ]\n",
            " [0.34197009 0.2686739  0.         0.         1.         0.        ]\n",
            " [0.46056393 0.36018136 0.         0.         0.         0.        ]\n",
            " [0.4287259  0.36774707 0.         0.         0.         0.        ]\n",
            " [0.47269601 0.36613047 0.         0.         1.         0.        ]\n",
            " [0.44220436 0.33433452 0.         0.         0.         0.        ]\n",
            " [0.42916358 0.31798437 0.         0.         0.         0.        ]\n",
            " [0.39304692 0.28829965 0.         0.         0.         0.        ]\n",
            " [0.45077911 0.32796583 0.         0.         0.         0.        ]\n",
            " [0.42401859 0.31674123 0.         0.         0.         0.        ]\n",
            " [0.46361941 0.33677179 0.         0.         0.         0.        ]\n",
            " [0.42237103 0.29772565 0.         0.         1.         0.        ]\n",
            " [0.39794523 0.28600174 0.         0.         0.         0.        ]\n",
            " [0.39198041 0.28760555 0.         0.         1.         0.        ]\n",
            " [0.40952331 0.3819688  0.         0.         0.         0.        ]\n",
            " [0.41056594 0.37384087 0.         0.         0.         0.        ]\n",
            " [0.45531338 0.36671659 0.         0.         0.         0.        ]\n",
            " [0.43101779 0.33038399 0.         0.         0.         0.        ]\n",
            " [0.41830242 0.34004629 0.         0.         0.         0.        ]\n",
            " [0.39730701 0.30838993 0.         0.         0.         0.        ]\n",
            " [0.40659013 0.29486936 0.         0.         0.         0.        ]\n",
            " [0.45982346 0.37015101 0.         0.         0.         1.        ]\n",
            " [0.44425154 0.42977649 0.         0.         0.         1.        ]\n",
            " [0.44118962 0.33563399 0.         0.         0.         1.        ]\n",
            " [0.19310306 0.40161362 0.         0.         0.         0.        ]\n",
            " [0.34826779 0.44598031 0.         0.         0.         1.        ]\n",
            " [0.40297562 0.31749943 0.         0.         0.         0.        ]\n",
            " [0.1903256  0.06485464 0.         0.         0.         0.        ]\n",
            " [0.44676176 0.31616506 0.         0.         0.         1.        ]\n",
            " [0.4047246  0.28899592 0.         0.         0.         1.        ]\n",
            " [0.38314909 0.27902275 0.         0.         0.         0.        ]\n",
            " [0.31031594 0.26928383 0.         0.         0.         0.        ]\n",
            " [0.4446266  0.35297775 0.         0.         0.         0.        ]\n",
            " [0.35660428 0.28246588 0.         0.         0.         0.        ]\n",
            " [0.32998687 0.2973102  0.         0.         0.         0.        ]\n",
            " [0.36833587 0.32313633 0.         0.         0.         0.        ]\n",
            " [0.38248044 0.36434758 0.         0.         0.         0.        ]\n",
            " [0.41295558 0.35546583 0.         0.         0.         0.        ]\n",
            " [0.42299703 0.36177808 0.         0.         0.         0.        ]\n",
            " [0.2976163  0.44044286 0.         0.         0.         0.        ]\n",
            " [0.31864411 0.21613742 0.         0.         0.         0.        ]\n",
            " [0.46130297 0.30539343 0.         0.         0.         0.        ]\n",
            " [0.49424151 0.29397577 0.         0.         0.         0.        ]\n",
            " [0.49405247 0.33370435 0.         0.         0.         0.        ]\n",
            " [0.48226327 0.31543154 0.         0.         0.         0.        ]\n",
            " [0.49070811 0.3393445  0.         0.         0.         0.        ]\n",
            " [0.49475956 0.34118178 0.         0.         0.         0.        ]\n",
            " [0.38367805 0.33713919 0.         0.         0.         0.        ]\n",
            " [0.42743272 0.28453222 0.         0.         0.         0.        ]\n",
            " [0.50974816 0.29422626 1.         0.         0.         0.        ]\n",
            " [0.50506008 0.31669593 1.         0.         0.         0.        ]\n",
            " [0.49644595 0.29830492 0.         0.         0.         0.        ]\n",
            " [0.49892715 0.33745104 0.         0.         0.         0.        ]\n",
            " [0.51397681 0.30829111 1.         0.         0.         0.        ]\n",
            " [0.49458694 0.28486449 0.         0.         0.         0.        ]\n",
            " [0.45605439 0.31614697 0.         0.         0.         0.        ]\n",
            " [0.46102762 0.33148381 0.         0.         0.         0.        ]\n",
            " [0.47532076 0.34361142 0.         0.         0.         0.        ]\n",
            " [0.49073556 0.36980468 0.         0.         0.         0.        ]\n",
            " [0.47688791 0.3541854  0.         0.         0.         0.        ]\n",
            " [0.48049259 0.34471902 0.         0.         0.         0.        ]\n",
            " [0.4655216  0.39987019 0.         0.         0.         0.        ]\n",
            " [0.45514733 0.27650088 0.         0.         0.         0.        ]\n",
            " [0.51663637 0.33172777 1.         0.         0.         0.        ]\n",
            " [0.50980502 0.33266407 1.         0.         0.         0.        ]\n",
            " [0.51292729 0.33803737 1.         0.         0.         0.        ]\n",
            " [0.50757921 0.33713615 1.         0.         0.         0.        ]\n",
            " [0.51545572 0.3408584  1.         0.         0.         0.        ]\n",
            " [0.43587038 0.39231497 0.         0.         0.         0.        ]\n",
            " [0.4509944  0.35233316 0.         0.         0.         0.        ]\n",
            " [0.46120152 0.34353426 0.         0.         0.         0.        ]\n",
            " [0.48883057 0.39832309 0.         0.         0.         0.        ]\n",
            " [0.47692093 0.38712785 0.         0.         0.         0.        ]\n",
            " [0.44253778 0.35712239 0.         0.         0.         0.        ]\n",
            " [0.4852865  0.39477831 0.         0.         0.         0.        ]\n",
            " [0.48960134 0.3939074  0.         0.         0.         0.        ]\n",
            " [0.47498402 0.31070518 0.         0.         0.         0.        ]\n",
            " [0.43876266 0.30759212 0.         0.         0.         0.        ]\n",
            " [0.47340021 0.34856835 0.         0.         0.         0.        ]\n",
            " [0.4870863  0.32634267 0.         0.         0.         0.        ]\n",
            " [0.48443779 0.32910693 0.         0.         0.         0.        ]\n",
            " [0.46682355 0.35808024 0.         0.         0.         0.        ]\n",
            " [0.36752808 0.36069819 0.         0.         0.         0.        ]\n",
            " [0.31985298 0.24497212 0.         0.         0.         0.        ]\n",
            " [0.37936744 0.32139072 0.         0.         0.         0.        ]\n",
            " [0.33066434 0.5168308  0.         1.         0.         1.        ]\n",
            " [0.37384754 0.44759277 0.         0.         0.         1.        ]\n",
            " [0.41047081 0.5457955  0.         1.         0.         1.        ]\n",
            " [0.3881444  0.29790875 0.         0.         0.         1.        ]\n",
            " [0.40436357 0.30713972 0.         0.         1.         1.        ]\n",
            " [0.31258816 0.29108101 0.         0.         0.         1.        ]\n",
            " [0.34940153 0.26257533 0.         0.         0.         0.        ]\n",
            " [0.43195623 0.52663219 0.         1.         0.         1.        ]\n",
            " [0.4041492  0.47262755 0.         0.         0.         0.        ]\n",
            " [0.31934628 0.20031148 0.         0.         0.         0.        ]\n",
            " [0.39858288 0.40050209 0.         0.         0.         1.        ]\n",
            " [0.23247461 0.48357341 0.         0.         0.         1.        ]\n",
            " [0.3566474  0.38707745 0.         0.         0.         1.        ]\n",
            " [0.42722076 0.31066567 0.         0.         0.         1.        ]\n",
            " [0.2329236  0.49801108 0.         0.         0.         1.        ]\n",
            " [0.24052623 0.49411535 0.         0.         0.         1.        ]\n",
            " [0.41749004 0.32450664 0.         0.         0.         1.        ]\n",
            " [0.31398404 0.48298639 0.         0.         0.         1.        ]\n",
            " [0.41576391 0.5034765  0.         1.         0.         1.        ]\n",
            " [0.42350358 0.32253778 0.         0.         0.         1.        ]\n",
            " [0.28407517 0.52212775 0.         1.         0.         1.        ]\n",
            " [0.44875082 0.52994072 0.         1.         0.         1.        ]\n",
            " [0.28882742 0.47924715 0.         0.         0.         1.        ]\n",
            " [0.41306344 0.47929841 0.         0.         0.         1.        ]\n",
            " [0.30370671 0.4175466  0.         0.         0.         1.        ]\n",
            " [0.31122148 0.19351412 0.         0.         0.         0.        ]\n",
            " [0.35968876 0.23469558 0.         0.         0.         0.        ]\n",
            " [0.38188964 0.29778656 0.         0.         0.         0.        ]\n",
            " [0.42072242 0.37040237 0.         0.         0.         0.        ]\n",
            " [0.46342745 0.2067924  0.         0.         0.         0.        ]\n",
            " [0.38886839 0.22251205 0.         0.         0.         0.        ]\n",
            " [0.30951163 0.13511498 0.         0.         0.         0.        ]\n",
            " [0.28654882 0.12817417 0.         0.         0.         0.        ]\n",
            " [0.43635377 0.30908883 0.         0.         0.         0.        ]\n",
            " [0.32608542 0.17127867 0.         0.         0.         0.        ]\n",
            " [0.41228983 0.34165373 0.         0.         0.         0.        ]\n",
            " [0.35907927 0.27812532 0.         0.         0.         0.        ]\n",
            " [0.41892433 0.24951869 0.         0.         0.         0.        ]\n",
            " [0.21811029 0.17494002 0.         0.         0.         0.        ]\n",
            " [0.29777226 0.19331998 0.         0.         0.         0.        ]\n",
            " [0.32670164 0.24959648 0.         0.         0.         0.        ]\n",
            " [0.36900744 0.25946474 0.         0.         0.         0.        ]\n",
            " [0.41328323 0.2631107  0.         0.         0.         0.        ]\n",
            " [0.42506024 0.32890347 0.         0.         0.         0.        ]\n",
            " [0.27148178 0.33966079 0.         0.         0.         0.        ]\n",
            " [0.32198003 0.24736774 0.         0.         0.         0.        ]\n",
            " [0.43271625 0.33986208 0.         0.         0.         0.        ]\n",
            " [0.36762372 0.39354005 0.         0.         0.         0.        ]\n",
            " [0.39631656 0.30409288 0.         0.         0.         0.        ]\n",
            " [0.41178438 0.29332548 0.         0.         0.         0.        ]\n",
            " [0.37676907 0.31311521 0.         0.         1.         0.        ]\n",
            " [0.42471766 0.33925992 0.         0.         0.         0.        ]\n",
            " [0.38434118 0.25199968 0.         0.         0.         0.        ]\n",
            " [0.36145872 0.28789228 0.         0.         0.         0.        ]\n",
            " [0.37757805 0.24273166 0.         0.         0.         0.        ]\n",
            " [0.32795638 0.22473313 0.         0.         0.         0.        ]\n",
            " [0.40617031 0.25886253 0.         0.         0.         0.        ]\n",
            " [0.36145759 0.39811099 0.         0.         0.         0.        ]\n",
            " [0.37932581 0.25886303 0.         0.         0.         0.        ]\n",
            " [0.39117968 0.36070552 0.         0.         0.         0.        ]\n",
            " [0.43657324 0.33979192 0.         0.         0.         0.        ]\n",
            " [0.27430063 0.33326837 0.         0.         0.         0.        ]\n",
            " [0.37579611 0.30056864 0.         0.         0.         0.        ]\n",
            " [0.35588983 0.26745608 0.         0.         0.         0.        ]\n",
            " [0.31889662 0.22841519 0.         0.         0.         0.        ]\n",
            " [0.38720384 0.31047362 0.         0.         1.         0.        ]\n",
            " [0.38651067 0.40253329 0.         0.         0.         0.        ]\n",
            " [0.35018116 0.33132604 0.         0.         0.         0.        ]\n",
            " [0.32981738 0.24804917 0.         0.         0.         0.        ]\n",
            " [0.3782194  0.32557681 0.         0.         0.         0.        ]\n",
            " [0.37640664 0.31272727 0.         0.         0.         0.        ]\n",
            " [0.36912727 0.26858163 0.         0.         0.         0.        ]\n",
            " [0.34674123 0.35915107 0.         0.         0.         0.        ]\n",
            " [0.34213671 0.35193989 0.         0.         0.         0.        ]\n",
            " [0.40903041 0.35327256 0.         0.         1.         0.        ]\n",
            " [0.37979329 0.39096326 0.         0.         0.         0.        ]\n",
            " [0.43503737 0.28229767 0.         0.         1.         0.        ]\n",
            " [0.26329419 0.43799224 0.         0.         0.         0.        ]\n",
            " [0.38101321 0.38003099 0.         0.         0.         0.        ]\n",
            " [0.31157082 0.29137033 0.         0.         0.         0.        ]\n",
            " [0.47661537 0.41837254 0.         0.         0.         0.        ]\n",
            " [0.48517954 0.40413362 0.         0.         0.         0.        ]\n",
            " [0.47355872 0.39117795 0.         0.         0.         0.        ]\n",
            " [0.45283055 0.36286041 0.         0.         0.         0.        ]\n",
            " [0.47999305 0.35609716 0.         0.         0.         0.        ]\n",
            " [0.46032816 0.39353094 0.         0.         0.         0.        ]\n",
            " [0.48337698 0.41103438 0.         0.         0.         0.        ]\n",
            " [0.48605096 0.39878619 0.         0.         0.         0.        ]\n",
            " [0.47881353 0.36198303 0.         0.         0.         0.        ]\n",
            " [0.44632828 0.37080526 0.         0.         0.         0.        ]\n",
            " [0.47936115 0.3282381  0.         0.         0.         0.        ]\n",
            " [0.47145519 0.39154124 0.         0.         0.         0.        ]\n",
            " [0.46717972 0.41222197 0.         0.         0.         0.        ]\n",
            " [0.44705003 0.33410153 0.         0.         0.         0.        ]\n",
            " [0.46192771 0.36031497 0.         0.         0.         0.        ]\n",
            " [0.52972996 0.31191316 1.         0.         0.         0.        ]\n",
            " [0.47087985 0.26141804 0.         0.         0.         0.        ]\n",
            " [0.42793745 0.37576619 0.         0.         0.         0.        ]\n",
            " [0.45100829 0.38999891 0.         0.         0.         0.        ]\n",
            " [0.45898941 0.37626928 0.         0.         0.         0.        ]\n",
            " [0.42504123 0.37946472 0.         0.         1.         0.        ]\n",
            " [0.43360531 0.35601762 0.         0.         0.         0.        ]\n",
            " [0.36386022 0.37702191 0.         0.         1.         0.        ]\n",
            " [0.40823483 0.35684088 0.         0.         1.         0.        ]\n",
            " [0.47375792 0.41334799 0.         0.         0.         0.        ]\n",
            " [0.46766672 0.41052258 0.         0.         1.         0.        ]\n",
            " [0.43752655 0.38040227 0.         0.         1.         0.        ]\n",
            " [0.41858378 0.36748776 0.         0.         1.         0.        ]\n",
            " [0.43289456 0.37374374 0.         0.         1.         0.        ]\n",
            " [0.46220759 0.37506118 0.         0.         0.         0.        ]\n",
            " [0.29637805 0.36375615 0.         0.         0.         0.        ]\n",
            " [0.28266811 0.32689446 0.         0.         0.         0.        ]\n",
            " [0.26790392 0.31776094 0.         0.         0.         0.        ]\n",
            " [0.24657361 0.21942961 0.         0.         0.         0.        ]\n",
            " [0.24903214 0.21726644 0.         0.         0.         0.        ]\n",
            " [0.27319968 0.28791326 0.         0.         0.         0.        ]\n",
            " [0.44231316 0.35854337 0.         0.         0.         0.        ]\n",
            " [0.45332536 0.24247845 0.         0.         0.         0.        ]\n",
            " [0.40511712 0.27936149 0.         0.         0.         0.        ]\n",
            " [0.41990793 0.2198012  0.         0.         0.         0.        ]\n",
            " [0.28335401 0.37792298 0.         0.         0.         0.        ]\n",
            " [0.38361314 0.28272954 0.         0.         0.         0.        ]\n",
            " [0.43696475 0.2809779  0.         0.         0.         0.        ]\n",
            " [0.41682419 0.37228096 0.         0.         0.         0.        ]\n",
            " [0.41373554 0.2253364  0.         0.         0.         0.        ]\n",
            " [0.39169231 0.33050266 0.         0.         0.         0.        ]\n",
            " [0.43187639 0.2662726  0.         0.         0.         0.        ]\n",
            " [0.39108342 0.4170697  0.         0.         0.         0.        ]\n",
            " [0.37400255 0.33173895 0.         0.         0.         0.        ]\n",
            " [0.44724274 0.28969416 0.         0.         0.         0.        ]\n",
            " [0.45222726 0.36628482 0.         0.         0.         0.        ]\n",
            " [0.38306519 0.20050642 0.         0.         0.         0.        ]\n",
            " [0.39107633 0.26580799 0.         0.         0.         0.        ]\n",
            " [0.44068128 0.22789076 0.         0.         0.         0.        ]\n",
            " [0.28897628 0.18177453 0.         0.         0.         0.        ]\n",
            " [0.39211956 0.25263199 0.         0.         0.         0.        ]\n",
            " [0.30674842 0.38853833 0.         0.         0.         0.        ]\n",
            " [0.44835734 0.36208886 0.         0.         0.         0.        ]\n",
            " [0.45180985 0.31167182 0.         0.         0.         0.        ]\n",
            " [0.4100005  0.28541315 0.         0.         0.         0.        ]\n",
            " [0.45391864 0.28047779 0.         0.         0.         0.        ]\n",
            " [0.44545382 0.39235225 0.         0.         0.         0.        ]\n",
            " [0.39745557 0.25501499 0.         0.         0.         0.        ]\n",
            " [0.31544471 0.40756798 0.         0.         0.         0.        ]\n",
            " [0.49748948 0.34458911 0.         0.         0.         0.        ]\n",
            " [0.48957032 0.39597178 0.         0.         0.         0.        ]\n",
            " [0.40559819 0.31883761 0.         0.         0.         0.        ]\n",
            " [0.48208517 0.37784645 0.         0.         0.         0.        ]\n",
            " [0.44693923 0.37316662 0.         0.         0.         0.        ]\n",
            " [0.4876284  0.39138424 0.         0.         0.         0.        ]\n",
            " [0.42163885 0.38154536 0.         0.         0.         0.        ]\n",
            " [0.46014071 0.41280505 0.         0.         0.         0.        ]\n",
            " [0.41165042 0.34335649 0.         0.         0.         0.        ]\n",
            " [0.45752078 0.40641245 0.         0.         0.         0.        ]\n",
            " [0.43025467 0.38070557 0.         0.         0.         0.        ]\n",
            " [0.46990168 0.42269731 0.         0.         0.         0.        ]\n",
            " [0.46487263 0.29125226 0.         0.         0.         0.        ]\n",
            " [0.45541769 0.34594232 0.         0.         1.         0.        ]\n",
            " [0.52066797 0.29321948 1.         0.         0.         0.        ]\n",
            " [0.48990351 0.34563884 0.         0.         0.         0.        ]\n",
            " [0.48841956 0.32332847 0.         0.         0.         0.        ]\n",
            " [0.52359015 0.40218252 1.         0.         0.         0.        ]\n",
            " [0.48527247 0.3708792  0.         0.         0.         0.        ]\n",
            " [0.48061454 0.36572546 0.         0.         1.         0.        ]\n",
            " [0.47623679 0.36384279 0.         0.         0.         0.        ]\n",
            " [0.49755985 0.3722184  0.         0.         0.         0.        ]\n",
            " [0.5172959  0.37690157 1.         0.         0.         0.        ]\n",
            " [0.49541491 0.39331669 0.         0.         1.         0.        ]\n",
            " [0.41075274 0.38057166 0.         0.         0.         0.        ]\n",
            " [0.37891629 0.40214062 0.         0.         0.         0.        ]\n",
            " [0.40134799 0.34619176 0.         0.         0.         0.        ]\n",
            " [0.34777129 0.3709805  0.         0.         0.         0.        ]\n",
            " [0.40062511 0.36795798 0.         0.         0.         0.        ]\n",
            " [0.37995154 0.40714228 0.         0.         0.         0.        ]\n",
            " [0.43680161 0.30808941 0.         0.         0.         0.        ]\n",
            " [0.4444972  0.28961977 0.         0.         0.         0.        ]\n",
            " [0.4615128  0.31858206 0.         0.         0.         0.        ]\n",
            " [0.4394508  0.28898868 0.         0.         0.         0.        ]\n",
            " [0.41202143 0.20588468 0.         0.         0.         0.        ]\n",
            " [0.27797332 0.12145518 0.         0.         0.         0.        ]\n",
            " [0.37273008 0.23762232 0.         0.         0.         0.        ]\n",
            " [0.46435019 0.37467092 0.         0.         1.         0.        ]\n",
            " [0.46849048 0.35958415 0.         0.         0.         0.        ]\n",
            " [0.45240423 0.37082967 0.         0.         0.         0.        ]\n",
            " [0.47158968 0.36646518 0.         0.         0.         0.        ]\n",
            " [0.42442244 0.32625362 0.         0.         0.         0.        ]\n",
            " [0.42866644 0.33922279 0.         0.         0.         0.        ]\n",
            " [0.42893851 0.36708385 0.         0.         0.         0.        ]\n",
            " [0.43370116 0.37385598 0.         0.         1.         0.        ]\n",
            " [0.44156352 0.36996812 0.         0.         1.         0.        ]\n",
            " [0.43877438 0.38939521 0.         0.         1.         0.        ]\n",
            " [0.44309598 0.36504516 0.         0.         0.         0.        ]\n",
            " [0.47014198 0.38308722 0.         0.         1.         0.        ]\n",
            " [0.4712162  0.39134201 0.         0.         0.         0.        ]\n",
            " [0.43126401 0.40752441 0.         0.         1.         0.        ]\n",
            " [0.48164818 0.34851098 0.         0.         0.         0.        ]\n",
            " [0.49150488 0.34858277 0.         0.         0.         0.        ]\n",
            " [0.47872531 0.35733646 0.         0.         0.         0.        ]\n",
            " [0.4971787  0.3592276  0.         0.         0.         0.        ]\n",
            " [0.42431366 0.32585689 0.         0.         0.         0.        ]\n",
            " [0.45153445 0.31154236 0.         0.         1.         0.        ]\n",
            " [0.42395329 0.37770656 0.         0.         1.         0.        ]\n",
            " [0.40871608 0.36425087 0.         0.         0.         0.        ]\n",
            " [0.39701846 0.36820424 0.         0.         0.         0.        ]\n",
            " [0.43400544 0.37460908 0.         0.         0.         0.        ]\n",
            " [0.36943844 0.35493413 0.         0.         0.         0.        ]\n",
            " [0.33294055 0.2426201  0.         0.         0.         0.        ]\n",
            " [0.37170491 0.29848599 0.         0.         0.         0.        ]\n",
            " [0.27731279 0.26115003 0.         0.         0.         0.        ]\n",
            " [0.41280642 0.3399024  0.         0.         0.         0.        ]\n",
            " [0.44111475 0.4485428  0.         0.         0.         1.        ]\n",
            " [0.4328047  0.43464556 0.         0.         0.         1.        ]\n",
            " [0.56098521 0.43371707 1.         0.         0.         1.        ]\n",
            " [0.4388786  0.4556388  0.         0.         0.         1.        ]\n",
            " [0.25647429 0.27498209 0.         0.         0.         0.        ]\n",
            " [0.39426345 0.35023925 0.         0.         0.         0.        ]\n",
            " [0.42070952 0.36237034 0.         0.         0.         0.        ]\n",
            " [0.3977592  0.3564828  0.         0.         0.         0.        ]\n",
            " [0.39147121 0.3629899  0.         0.         0.         0.        ]\n",
            " [0.32849407 0.31977728 0.         0.         0.         0.        ]\n",
            " [0.42806306 0.29043308 0.         0.         0.         0.        ]\n",
            " [0.45113665 0.35183543 0.         0.         0.         0.        ]\n",
            " [0.41458392 0.37646282 0.         0.         0.         0.        ]\n",
            " [0.41204587 0.3552016  0.         0.         0.         0.        ]\n",
            " [0.42798889 0.31126302 0.         0.         0.         0.        ]\n",
            " [0.42459813 0.29803503 0.         0.         0.         0.        ]\n",
            " [0.42464778 0.35583675 0.         0.         0.         0.        ]\n",
            " [0.43117785 0.35439616 0.         0.         0.         0.        ]\n",
            " [0.4190999  0.33654231 0.         0.         0.         0.        ]\n",
            " [0.37081218 0.3031671  0.         0.         0.         0.        ]\n",
            " [0.35805607 0.27765411 0.         0.         0.         0.        ]\n",
            " [0.44741571 0.32932919 0.         0.         1.         1.        ]\n",
            " [0.40143886 0.28407887 0.         0.         1.         1.        ]\n",
            " [0.45741931 0.35900876 0.         0.         1.         1.        ]\n",
            " [0.4405168  0.33510798 0.         0.         0.         0.        ]\n",
            " [0.44114479 0.33269405 0.         0.         0.         1.        ]\n",
            " [0.42989895 0.33124191 0.         0.         1.         1.        ]\n",
            " [0.45786306 0.35343885 0.         0.         1.         1.        ]\n",
            " [0.42993668 0.32096225 0.         0.         1.         1.        ]\n",
            " [0.49490008 0.31802207 0.         0.         1.         0.        ]\n",
            " [0.44410241 0.31740713 0.         0.         1.         0.        ]\n",
            " [0.44159177 0.3949517  0.         0.         1.         1.        ]\n",
            " [0.43806922 0.40789053 0.         0.         1.         1.        ]\n",
            " [0.45840284 0.39154899 0.         0.         1.         1.        ]\n",
            " [0.5303182  0.37369946 1.         0.         1.         1.        ]\n",
            " [0.46844983 0.37345764 0.         0.         1.         1.        ]\n",
            " [0.46328571 0.35941604 0.         0.         0.         0.        ]\n",
            " [0.47493726 0.2910493  0.         0.         1.         0.        ]\n",
            " [0.44688773 0.29520923 0.         0.         1.         0.        ]\n",
            " [0.44848576 0.28679872 0.         0.         1.         0.        ]\n",
            " [0.46790215 0.30526185 0.         0.         1.         0.        ]\n",
            " [0.46688485 0.27489123 0.         0.         1.         0.        ]\n",
            " [0.48100841 0.277033   0.         0.         1.         0.        ]\n",
            " [0.47709474 0.29234907 0.         0.         1.         0.        ]\n",
            " [0.52278137 0.31352317 1.         0.         1.         0.        ]\n",
            " [0.3941766  0.33282793 0.         0.         1.         0.        ]\n",
            " [0.36534807 0.25287157 0.         0.         0.         0.        ]\n",
            " [0.46324831 0.21391295 0.         0.         1.         0.        ]\n",
            " [0.44658786 0.35693505 0.         0.         1.         0.        ]\n",
            " [0.59392732 0.35090616 1.         0.         1.         1.        ]\n",
            " [0.43366683 0.36180013 0.         0.         1.         1.        ]\n",
            " [0.4155477  0.37136468 0.         0.         1.         1.        ]\n",
            " [0.47956607 0.40875486 0.         0.         0.         1.        ]\n",
            " [0.39548826 0.36650553 0.         0.         0.         1.        ]\n",
            " [0.41168067 0.37272358 0.         0.         1.         1.        ]\n",
            " [0.37146741 0.24552655 0.         0.         0.         0.        ]\n",
            " [0.44186449 0.36380586 0.         0.         0.         0.        ]\n",
            " [0.45392627 0.40303323 0.         0.         0.         0.        ]\n",
            " [0.46981296 0.40614703 0.         0.         0.         0.        ]\n",
            " [0.53558177 0.6075809  1.         1.         0.         1.        ]\n",
            " [0.49793693 0.5499301  0.         1.         0.         1.        ]\n",
            " [0.52631426 0.57455897 1.         1.         0.         1.        ]\n",
            " [0.41996497 0.42942756 0.         0.         1.         0.        ]\n",
            " [0.42864403 0.35914096 0.         0.         1.         0.        ]\n",
            " [0.31984431 0.2527701  0.         0.         0.         0.        ]\n",
            " [0.53482527 0.5478757  1.         1.         1.         1.        ]\n",
            " [0.52264166 0.5885576  1.         1.         1.         1.        ]\n",
            " [0.5040763  0.58726108 1.         1.         1.         1.        ]\n",
            " [0.45364699 0.40738919 0.         0.         1.         1.        ]\n",
            " [0.30740878 0.31514466 0.         0.         0.         0.        ]\n",
            " [0.28996226 0.42147073 0.         0.         0.         0.        ]\n",
            " [0.32337999 0.40188745 0.         0.         0.         0.        ]\n",
            " [0.32171416 0.34744152 0.         0.         0.         0.        ]\n",
            " [0.3631317  0.2929211  0.         0.         0.         0.        ]\n",
            " [0.46245152 0.31614515 0.         0.         0.         0.        ]\n",
            " [0.46166193 0.33121109 0.         0.         0.         0.        ]\n",
            " [0.45824373 0.34737799 0.         0.         0.         0.        ]\n",
            " [0.4594498  0.34157613 0.         0.         0.         0.        ]\n",
            " [0.38246417 0.23023461 0.         0.         0.         0.        ]\n",
            " [0.33610353 0.20065644 0.         0.         0.         0.        ]\n",
            " [0.43421602 0.44272816 0.         0.         0.         0.        ]\n",
            " [0.36915204 0.2657735  0.         0.         1.         0.        ]\n",
            " [0.43882102 0.23657326 0.         0.         0.         0.        ]\n",
            " [0.39504841 0.3126502  0.         0.         0.         0.        ]\n",
            " [0.36877906 0.1947915  0.         0.         0.         0.        ]\n",
            " [0.45088166 0.30823696 0.         0.         0.         0.        ]\n",
            " [0.4669778  0.35488746 0.         0.         0.         0.        ]\n",
            " [0.45530784 0.33984706 0.         0.         0.         0.        ]\n",
            " [0.48212197 0.31048813 0.         0.         0.         0.        ]\n",
            " [0.50855333 0.49189591 1.         0.         0.         0.        ]\n",
            " [0.45816433 0.31397036 0.         0.         0.         0.        ]\n",
            " [0.46777755 0.34015834 0.         0.         0.         0.        ]\n",
            " [0.45585182 0.34087214 0.         0.         0.         0.        ]\n",
            " [0.46094322 0.32443213 0.         0.         0.         0.        ]\n",
            " [0.43917409 0.28086868 0.         0.         0.         0.        ]\n",
            " [0.42320427 0.52317548 0.         1.         0.         0.        ]\n",
            " [0.43923083 0.36064139 0.         0.         0.         0.        ]\n",
            " [0.37933871 0.39481521 0.         0.         0.         0.        ]\n",
            " [0.41517535 0.40562549 0.         0.         0.         0.        ]\n",
            " [0.36859497 0.38925481 0.         0.         0.         0.        ]\n",
            " [0.42949879 0.43260753 0.         0.         1.         0.        ]\n",
            " [0.43592775 0.43997043 0.         0.         1.         0.        ]\n",
            " [0.47151688 0.37238324 0.         0.         0.         0.        ]\n",
            " [0.46261775 0.42067418 0.         0.         0.         0.        ]\n",
            " [0.48060805 0.38398436 0.         0.         0.         0.        ]\n",
            " [0.4777036  0.41532961 0.         0.         0.         0.        ]\n",
            " [0.475508   0.40222329 0.         0.         0.         0.        ]\n",
            " [0.49389932 0.4212293  0.         0.         0.         0.        ]\n",
            " [0.47834411 0.38963342 0.         0.         0.         0.        ]\n",
            " [0.49865755 0.50431454 0.         1.         0.         1.        ]\n",
            " [0.4988617  0.44767088 0.         0.         1.         1.        ]\n",
            " [0.51127255 0.48992372 1.         0.         1.         1.        ]\n",
            " [0.50556964 0.46158832 1.         0.         1.         1.        ]\n",
            " [0.51419657 0.51635402 1.         1.         1.         1.        ]\n",
            " [0.42109212 0.34021947 0.         0.         0.         1.        ]\n",
            " [0.49824995 0.44598222 0.         0.         1.         1.        ]\n",
            " [0.51009852 0.44792143 1.         0.         0.         1.        ]\n",
            " [0.51097542 0.45287263 1.         0.         1.         1.        ]\n",
            " [0.50917327 0.50213277 1.         1.         1.         1.        ]\n",
            " [0.47488397 0.57188743 0.         1.         1.         1.        ]\n",
            " [0.49604088 0.43624657 0.         0.         1.         1.        ]\n",
            " [0.51138359 0.44449022 1.         0.         0.         1.        ]\n",
            " [0.51232296 0.4678438  1.         0.         1.         1.        ]\n",
            " [0.51311648 0.57991904 1.         1.         1.         1.        ]\n",
            " [0.51792175 0.51894391 1.         1.         0.         1.        ]\n",
            " [0.5066331  0.4581171  1.         0.         0.         1.        ]\n",
            " [0.51381212 0.46951997 1.         0.         0.         1.        ]\n",
            " [0.50287944 0.45382419 1.         0.         0.         1.        ]\n",
            " [0.50598234 0.56511903 1.         1.         0.         1.        ]\n",
            " [0.38713869 0.23006766 0.         0.         0.         1.        ]\n",
            " [0.51368684 0.47330374 1.         0.         0.         1.        ]\n",
            " [0.52206421 0.42975709 1.         0.         0.         1.        ]\n",
            " [0.50971729 0.4531033  1.         0.         0.         1.        ]\n",
            " [0.50416291 0.4676702  1.         0.         0.         1.        ]\n",
            " [0.42195556 0.36825725 0.         0.         0.         0.        ]\n",
            " [0.41935667 0.20098896 0.         0.         0.         0.        ]\n",
            " [0.52475995 0.46854538 1.         0.         1.         1.        ]\n",
            " [0.52698147 0.47251022 1.         0.         1.         1.        ]\n",
            " [0.49555275 0.4612498  0.         0.         1.         1.        ]\n",
            " [0.50166327 0.44514185 1.         0.         1.         1.        ]\n",
            " [0.404347   0.42777425 0.         0.         0.         1.        ]\n",
            " [0.28450328 0.32601923 0.         0.         0.         0.        ]\n",
            " [0.51686442 0.49106839 1.         0.         1.         1.        ]\n",
            " [0.52060121 0.46564481 1.         0.         1.         1.        ]\n",
            " [0.51205134 0.45244437 1.         0.         1.         1.        ]\n",
            " [0.52050072 0.49059218 1.         0.         1.         1.        ]\n",
            " [0.46530011 0.45962825 0.         0.         0.         1.        ]\n",
            " [0.51151657 0.46022916 1.         0.         0.         1.        ]\n",
            " [0.47380963 0.40995398 0.         0.         0.         1.        ]\n",
            " [0.47165215 0.39722964 0.         0.         0.         1.        ]\n",
            " [0.50855494 0.48387232 1.         0.         0.         1.        ]\n",
            " [0.49207795 0.57082111 0.         1.         0.         0.        ]\n",
            " [0.53551102 0.65077859 1.         1.         0.         1.        ]\n",
            " [0.50357729 0.42346415 1.         0.         0.         1.        ]\n",
            " [0.51384449 0.47675288 1.         0.         0.         1.        ]\n",
            " [0.51236087 0.50327492 1.         1.         0.         1.        ]\n",
            " [0.50701213 0.55213624 1.         1.         0.         1.        ]\n",
            " [0.55402768 0.58651268 1.         1.         0.         1.        ]\n",
            " [0.49822858 0.46930346 0.         0.         1.         1.        ]\n",
            " [0.5003258  0.4618369  1.         0.         1.         1.        ]\n",
            " [0.49535295 0.44134021 0.         0.         1.         1.        ]\n",
            " [0.41176701 0.40948874 0.         0.         1.         1.        ]\n",
            " [0.4426097  0.51100367 0.         1.         0.         1.        ]\n",
            " [0.5326584  0.43165389 1.         0.         1.         1.        ]\n",
            " [0.50835657 0.44889641 1.         0.         1.         1.        ]\n",
            " [0.50606281 0.47972798 1.         0.         1.         1.        ]\n",
            " [0.49118394 0.54152268 0.         1.         1.         1.        ]\n",
            " [0.51589644 0.60610521 1.         1.         0.         1.        ]\n",
            " [0.50053954 0.44964269 1.         0.         0.         1.        ]\n",
            " [0.51847082 0.50300413 1.         1.         1.         1.        ]\n",
            " [0.54245293 0.54736722 1.         1.         1.         1.        ]\n",
            " [0.52865672 0.62411553 1.         1.         1.         1.        ]\n",
            " [0.33869427 0.3909758  0.         0.         0.         0.        ]\n",
            " [0.50030702 0.31835735 1.         0.         0.         0.        ]\n",
            " [0.41429496 0.37825358 0.         0.         0.         0.        ]\n",
            " [0.43696335 0.43195227 0.         0.         0.         0.        ]\n",
            " [0.51371706 0.28549248 1.         0.         0.         0.        ]\n",
            " [0.51960242 0.26556224 1.         0.         0.         0.        ]\n",
            " [0.49545851 0.30230212 0.         0.         0.         0.        ]\n",
            " [0.5075379  0.31347588 1.         0.         0.         0.        ]\n",
            " [0.49728516 0.346766   0.         0.         0.         0.        ]\n",
            " [0.37620944 0.14976592 0.         0.         0.         0.        ]\n",
            " [0.43183091 0.27320376 0.         0.         1.         0.        ]\n",
            " [0.43833646 0.33287618 0.         0.         0.         0.        ]\n",
            " [0.47467625 0.30227849 0.         0.         1.         0.        ]\n",
            " [0.31955561 0.30319661 0.         0.         0.         0.        ]\n",
            " [0.41503435 0.26556018 0.         0.         0.         0.        ]\n",
            " [0.43744275 0.23371883 0.         0.         1.         0.        ]\n",
            " [0.40605578 0.19141288 0.         0.         0.         0.        ]\n",
            " [0.46381986 0.32952857 0.         0.         1.         0.        ]\n",
            " [0.46504799 0.25238913 0.         0.         0.         0.        ]\n",
            " [0.45908532 0.23483825 0.         0.         1.         0.        ]\n",
            " [0.48587096 0.27930927 0.         0.         1.         0.        ]\n",
            " [0.49902213 0.46091381 0.         0.         1.         0.        ]\n",
            " [0.50630099 0.43154746 1.         0.         1.         0.        ]\n",
            " [0.43698376 0.38632169 0.         0.         1.         0.        ]\n",
            " [0.44301099 0.27950922 0.         0.         1.         0.        ]\n",
            " [0.46504447 0.31291759 0.         0.         1.         0.        ]\n",
            " [0.47211036 0.33502731 0.         0.         1.         0.        ]\n",
            " [0.47595024 0.27476594 0.         0.         0.         0.        ]\n",
            " [0.46998805 0.34702817 0.         0.         1.         0.        ]\n",
            " [0.41970623 0.24918999 0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(threshold=10000000)\n",
        "print(np.concatenate([sigmoid(all_output), all_preds, all_labels], axis=1)[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pIwj_6k_iutp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIwj_6k_iutp",
        "outputId": "738fb012-8d71-4fbf-e81b-3895059a6be4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.86672515, -0.6288399 ],\n",
              "       [-0.7458726 , -1.636513  ],\n",
              "       [-1.8829846 , -0.3979123 ],\n",
              "       [-0.77564996, -1.1631111 ],\n",
              "       [-0.81919086, -0.4535097 ],\n",
              "       [-0.7337581 , -0.9586285 ],\n",
              "       [-1.5288213 , -1.2345314 ],\n",
              "       [-2.044149  , -1.569083  ],\n",
              "       [-1.8092502 , -1.19278   ],\n",
              "       [-0.59921384, -1.0845551 ],\n",
              "       [-0.6409741 , -0.73405147],\n",
              "       [-0.28068855, -0.94793004],\n",
              "       [-0.6066643 , -1.0891669 ],\n",
              "       [-0.3000644 , -0.29803196],\n",
              "       [-0.06913435, -1.0665059 ],\n",
              "       [-0.10274158, -0.6871642 ],\n",
              "       [-0.4060951 , -1.2572975 ],\n",
              "       [-0.07292394, -0.65511864],\n",
              "       [-0.04572494, -0.7020534 ],\n",
              "       [-0.00493805, -0.66906536],\n",
              "       [-0.03605343, -0.71217704],\n",
              "       [ 0.03058596, -0.5650396 ],\n",
              "       [-0.00318052, -0.6497315 ],\n",
              "       [-1.004205  , -0.7709531 ],\n",
              "       [-0.26960325, -0.9847997 ],\n",
              "       [-0.28092158, -0.8904669 ],\n",
              "       [-0.13617802, -0.8292655 ],\n",
              "       [-0.49842778, -0.87798995],\n",
              "       [-0.38527226, -0.53398573],\n",
              "       [-0.38915825, -0.92751515],\n",
              "       [-0.7155458 , -0.7542336 ],\n",
              "       [-0.15597191, -0.7525901 ],\n",
              "       [-0.48643547, -1.2355595 ],\n",
              "       [-0.13732466, -0.94947684],\n",
              "       [-0.26715803, -0.43531922],\n",
              "       [-0.2487655 , -0.4263461 ],\n",
              "       [-0.20855981, -0.5899361 ],\n",
              "       [-0.24537098, -0.7020765 ],\n",
              "       [-0.24841936, -0.8059778 ],\n",
              "       [-0.21819742, -0.6107075 ],\n",
              "       [-0.36568493, -0.86302257],\n",
              "       [ 0.08125332, -0.90232354],\n",
              "       [-0.26463404, -0.33569142],\n",
              "       [-0.41502228, -0.45446342],\n",
              "       [-0.27942836, -0.58210915],\n",
              "       [-0.12111387, -0.5972538 ],\n",
              "       [-0.27767375, -0.8183095 ],\n",
              "       [-0.24763587, -0.6668886 ],\n",
              "       [-0.0588472 , -0.8795053 ],\n",
              "       [ 0.26601097, -1.1682959 ],\n",
              "       [-0.11471587, -0.5968677 ],\n",
              "       [-0.08441606, -0.74587137],\n",
              "       [-0.14429885, -0.52944326],\n",
              "       [-0.02660029, -0.59456563],\n",
              "       [-0.02643465, -0.81990564],\n",
              "       [-0.01091452, -0.73167765],\n",
              "       [-0.37190852, -1.4185084 ],\n",
              "       [ 0.1947909 , -1.1452177 ],\n",
              "       [-0.13204972, -0.6860839 ],\n",
              "       [-0.30892792, -0.8959192 ],\n",
              "       [ 0.08350515, -0.79606354],\n",
              "       [-0.14940768, -0.9735823 ],\n",
              "       [-0.05742443, -1.1980141 ],\n",
              "       [ 0.04555691, -0.9104481 ],\n",
              "       [-0.67626655, -0.8779251 ],\n",
              "       [ 0.27590558, -0.78241926],\n",
              "       [-0.3289953 , -0.1411925 ],\n",
              "       [-0.47609362, -0.28628337],\n",
              "       [-0.49060866, -0.6338296 ],\n",
              "       [-0.71868795, -0.57743794],\n",
              "       [-0.29005975, -0.63890064],\n",
              "       [-0.6853306 , -0.66991997],\n",
              "       [-0.39382568, -0.8272826 ],\n",
              "       [ 0.2578552 , -1.0281839 ],\n",
              "       [-0.22118725, -0.3308909 ],\n",
              "       [-0.4991723 , -0.4751939 ],\n",
              "       [-0.53491974, -0.618009  ],\n",
              "       [-0.28234673, -0.6129183 ],\n",
              "       [-0.2895488 , -0.66109496],\n",
              "       [-0.49088442, -0.5665543 ],\n",
              "       [-0.719192  , -0.9346097 ],\n",
              "       [-0.11879079, -0.91569495],\n",
              "       [-0.4506595 , -0.4456378 ],\n",
              "       [-0.725885  , -0.59034777],\n",
              "       [-0.72005785, -0.7993895 ],\n",
              "       [-0.5975613 , -0.7510836 ],\n",
              "       [-0.31862873, -0.73363966],\n",
              "       [-0.25523087, -0.6187687 ],\n",
              "       [-0.20623296, -0.71356016],\n",
              "       [-0.22110283, -0.69295096],\n",
              "       [-0.25205204, -0.87696964],\n",
              "       [-0.07160546, -0.9221358 ],\n",
              "       [-0.22132552, -0.68893784],\n",
              "       [-0.13698775, -0.947983  ],\n",
              "       [-0.22922221, -0.77066004],\n",
              "       [-0.16993374, -0.65672445],\n",
              "       [-0.22723423, -0.70743835],\n",
              "       [-0.2129083 , -0.691389  ],\n",
              "       [-0.29027247, -0.93655616],\n",
              "       [-0.0695998 , -0.8973918 ],\n",
              "       [-0.25734705, -0.70944977],\n",
              "       [ 0.03959154, -0.9216212 ],\n",
              "       [-0.24285881, -0.77198386],\n",
              "       [-0.4583335 , -0.9456257 ],\n",
              "       [-0.10199954, -0.8106215 ],\n",
              "       [ 0.00989911, -0.79554725],\n",
              "       [-0.19585244, -1.0184984 ],\n",
              "       [-0.38354576, -0.95232517],\n",
              "       [-0.11335872, -0.7363411 ],\n",
              "       [ 0.26002142, -1.1606171 ],\n",
              "       [ 0.01402148, -0.85930717],\n",
              "       [-0.01944128, -0.8288075 ],\n",
              "       [-0.03066058, -1.0045218 ],\n",
              "       [-0.00746903, -1.0983803 ],\n",
              "       [-0.32099345, -1.2500188 ],\n",
              "       [-0.44958085, -1.104345  ],\n",
              "       [-0.09334898, -0.96451634],\n",
              "       [ 0.20282853, -1.1382256 ],\n",
              "       [-0.05170345, -1.291575  ],\n",
              "       [ 0.03644134, -1.0209153 ],\n",
              "       [-0.14927842, -0.63361514],\n",
              "       [-0.26077256, -0.59446436],\n",
              "       [-0.2354956 , -0.66978353],\n",
              "       [-0.15874043, -1.0163602 ],\n",
              "       [-0.27276137, -0.6595496 ],\n",
              "       [ 0.14735731, -0.7342557 ],\n",
              "       [-0.20114705, -0.5706983 ],\n",
              "       [-0.27167824, -0.63142264]], dtype=float32)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_output[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7BB5kyP1cPDR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BB5kyP1cPDR",
        "outputId": "4695bf6d-1e51-4b2d-c17c-a8d8640d17f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_outputs[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
