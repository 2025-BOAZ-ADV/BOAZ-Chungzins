{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef6b52e2",
      "metadata": {
        "id": "ef6b52e2"
      },
      "source": [
        "#### 환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc03a42",
      "metadata": {
        "id": "9dc03a42"
      },
      "source": [
        "##### 1. Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f04d7d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04d7d6f",
        "outputId": "3c57e712-a314-411b-d4cf-1a953a648946"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ressera3/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboaz_woony\u001b[0m (\u001b[33mboaz_woony-boaz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "\n",
        "# wandb 로그인\n",
        "wandb.login(key=\"37e029d940c3722b338d8079392931beecdbef3b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992382bf",
      "metadata": {
        "id": "992382bf"
      },
      "source": [
        "##### 2. 라이브러리 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5MISAwpScmYt",
      "metadata": {
        "id": "5MISAwpScmYt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ebed6c5",
      "metadata": {
        "id": "8ebed6c5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch import Tensor\n",
        "from torchsummary import summary\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d453e5f",
      "metadata": {
        "id": "2d453e5f"
      },
      "source": [
        "##### 3. 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "mSXgKx8GoItj",
      "metadata": {
        "id": "mSXgKx8GoItj"
      },
      "outputs": [],
      "source": [
        "\n",
        "ROOT = \"/home/ressera3/BOAZ-Chungzins/data/raw\"\n",
        "CHECKPOINT_PATH = \"/home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp\"\n",
        "PICKLE_PATH = \"/home/ressera3/BOAZ-Chungzins/notebook/pickle\"\n",
        "text = \"/home/ressera3/BOAZ-Chungzins/data/metadata/train_test_split.txt\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecaaf5a1",
      "metadata": {
        "id": "ecaaf5a1"
      },
      "source": [
        "##### 4. Seed 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c9f4e372",
      "metadata": {
        "id": "c9f4e372"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nydfgBckyPt3",
      "metadata": {
        "id": "nydfgBckyPt3"
      },
      "source": [
        "## 1. Data Load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3fdcf1",
      "metadata": {
        "id": "ce3fdcf1"
      },
      "source": [
        "#### 1.1 Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "OhJa9jivcg1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJa9jivcg1k",
        "outputId": "a78dee02-13e0-4e6f-cce1-455b6e9da489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train :539, Test: 381, Total: 920\n"
          ]
        }
      ],
      "source": [
        "# WAV 파일이 있는 디렉토리 경로\n",
        "data_dir = ROOT\n",
        "txt_dir = ROOT\n",
        "\n",
        "df = pd.read_csv(text, sep='\\t', header=None)\n",
        "\n",
        "# 컬럼 이름 변경\n",
        "df.columns = ['filename', 'set']\n",
        "\n",
        "# train, test split\n",
        "train_df = df[df['set'] == 'train']\n",
        "test_df = df[df['set'] == 'test']\n",
        "\n",
        "# filename list\n",
        "train_list = sorted(train_df['filename'].tolist())\n",
        "test_list = sorted(test_df['filename'].tolist())\n",
        "\n",
        "print(f'Train :{len(train_list)}, Test: {len(test_list)}, Total: {len(train_list) + len(test_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04291977",
      "metadata": {
        "id": "04291977"
      },
      "source": [
        "#### 1.2 Pretext-Finetune Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ESBIVnKej0G9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBIVnKej0G9",
        "outputId": "849f490c-dd11-4b23-f1da-0fe6482fb71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pretrain] 환자 수: 79, 샘플 수: 539\n",
            "[Finetune] 환자 수: 79, 샘플 수: 539\n"
          ]
        }
      ],
      "source": [
        "# shuffle train data\n",
        "df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# split ratio\n",
        "train_size = int(len(df_shuffled))\n",
        "\n",
        "# pretrain, finetune split\n",
        "pretrain_df = df_shuffled[:train_size]\n",
        "finetune_df = pretrain_df\n",
        "\n",
        "# filename list (pretext_list -> pretrain list)\n",
        "pretrain_list = sorted(pretrain_df['filename'].tolist())\n",
        "finetune_list = sorted(finetune_df['filename'].tolist())\n",
        "\n",
        "# patient id list\n",
        "pretrain_patient_list = []\n",
        "for filename in pretrain_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    pretrain_patient_list.append(number)\n",
        "\n",
        "finetune_patient_list = []\n",
        "for filename in finetune_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    finetune_patient_list.append(number)\n",
        "\n",
        "pretrain_patient_counts = pd.Series(pretrain_patient_list).value_counts()\n",
        "finetune_patient_counts = pd.Series(finetune_patient_list).value_counts()\n",
        "\n",
        "print(f\"[Pretrain] 환자 수: {len(pretrain_patient_counts.index)}, 샘플 수: {pretrain_patient_counts.sum()}\")\n",
        "print(f\"[Finetune] 환자 수: {len(finetune_patient_counts.index)}, 샘플 수: {finetune_patient_counts.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oVi6lzuPpSbk",
      "metadata": {
        "id": "oVi6lzuPpSbk"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8c7719",
      "metadata": {
        "id": "5e8c7719"
      },
      "source": [
        "#### 2.1 Args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634b232e",
      "metadata": {
        "id": "634b232e"
      },
      "source": [
        "        K: queue size; number of negative keys (default: 65536)\n",
        "        m: moco momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "add5c69b",
      "metadata": {
        "id": "add5c69b"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    # Audio & Spectrogram\n",
        "    target_sr = 4000    # 4KHz\n",
        "    frame_size = 1024\n",
        "    hop_length = 512    # frame_size 절반\n",
        "    n_mels = 128\n",
        "    target_sec = 8\n",
        "\n",
        "    # Augmentation\n",
        "    time_mask_param = 0.5\n",
        "    freq_mask_param = 0.5\n",
        "\n",
        "    # Train\n",
        "    lr = 0.03\n",
        "    warm = True                     # warm-up 사용 여부\n",
        "    warm_epochs = 10                # warm-up 적용할 초기 epoch 수\n",
        "    warmup_from = lr * 0.1          # warm-up 시작 learning rate (보통 lr의 10%)\n",
        "    warmup_to = lr\n",
        "\n",
        "    batch_size = 128\n",
        "    workers = 2\n",
        "    epochs = 300\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    resume = None\n",
        "    schedule=[120, 160] # schedule\n",
        "\n",
        "    # MLS\n",
        "    K = 512\n",
        "    momentum = 0.999\n",
        "    T = 0.07\n",
        "    dim_prj = 128\n",
        "    top_k = 20\n",
        "    lambda_bce = 0.3\n",
        "    out_dim = 2048\n",
        "\n",
        "    # Linear Evaluation\n",
        "    ft_epochs = 100\n",
        "\n",
        "    # etc\n",
        "    gpu = 0\n",
        "    data = \"./data_path\"\n",
        "    seed=42\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e1f949",
      "metadata": {
        "id": "58e1f949"
      },
      "source": [
        "#### 2.2 Utils (func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d2d1329",
      "metadata": {
        "id": "8d2d1329"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# cycle의 클래스를 추출\n",
        "def get_class(cr, wh):\n",
        "    if cr == 1 and wh == 1:\n",
        "        return 3\n",
        "    elif cr == 0 and wh == 1:\n",
        "        return 2\n",
        "    elif cr == 1 and wh == 0:\n",
        "        return 1\n",
        "    elif cr == 0 and wh == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Mel Spectrogram 생성 ( sr=4KHz, frame_size=1024, hop_length=512, n_mels=128 )\n",
        "def generate_mel_spectrogram(waveform, sample_rate, frame_size, hop_length, n_mels):\n",
        "    if hop_length is None:\n",
        "        hop_length = frame_size // 2\n",
        "    mel_spec_transform = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=frame_size,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "    mel_spectrogram = mel_spec_transform(waveform)\n",
        "    mel_db = T.AmplitudeToDB()(mel_spectrogram)\n",
        "    \n",
        "    return mel_db\n",
        "\n",
        "# Cycle Repeat 또는 Crop\n",
        "def repeat_or_truncate_segment(mel_segment, target_frames):\n",
        "    current_frames = mel_segment.shape[-1]\n",
        "    if current_frames >= target_frames:\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "    else:\n",
        "        repeat_ratio = math.ceil(target_frames / current_frames)\n",
        "        mel_segment = mel_segment.repeat(1, 1, repeat_ratio)\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "\n",
        "def preprocess_waveform_segment(waveform, unit_length):\n",
        "\n",
        "    \"\"\"unit_length 기준으로 waveform을 repeat + padding 또는 crop하여 길이 정규화\"\"\"\n",
        "    waveform = waveform.squeeze(0)  # (1, L) → (L,) 로 바꿔도 무방\n",
        "    length_adj = unit_length - len(waveform)\n",
        "\n",
        "    if length_adj > 0:\n",
        "        # waveform이 너무 짧은 경우 → repeat + zero-padding\n",
        "        half_unit = unit_length // 2\n",
        "\n",
        "        if length_adj < half_unit:\n",
        "            # 길이 차이가 작으면 단순 padding\n",
        "            half_adj = length_adj // 2\n",
        "            waveform = F.pad(waveform, (half_adj, length_adj - half_adj))\n",
        "        else:\n",
        "            # 반복 후 부족한 부분 padding\n",
        "            repeat_factor = unit_length // len(waveform)\n",
        "            waveform = waveform.repeat(repeat_factor)[:unit_length]\n",
        "            remaining = unit_length - len(waveform)\n",
        "            half_pad = remaining // 2\n",
        "            waveform = F.pad(waveform, (half_pad, remaining - half_pad))\n",
        "    else:\n",
        "        # waveform이 너무 길면 앞쪽 1/4 내에서 랜덤 crop\n",
        "        length_adj = len(waveform) - unit_length\n",
        "        start = random.randint(0, length_adj // 4)\n",
        "        waveform = waveform[start:start + unit_length]\n",
        "\n",
        "    return waveform.unsqueeze(0)  # 다시 (1, L)로\n",
        "\n",
        "# 데이터 Spec Augmentation ( 0~80% Random Masking )\n",
        "def apply_spec_augment(mel_segment):\n",
        "\n",
        "    M = mel_segment.shape[-1]\n",
        "    F = mel_segment.shape[-2]\n",
        "\n",
        "    # torchaudio의 마스킹은 0부터 mask_param까지 균등분포에서 랜덤하게 길이를 선택\n",
        "    time_masking = T.TimeMasking(time_mask_param=int(M * 0.8))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=int(F * 0.8) )\n",
        "\n",
        "    aug1 = freq_masking(mel_segment.clone())\n",
        "    aug2 = time_masking(mel_segment.clone())\n",
        "    aug3 = freq_masking(time_masking(mel_segment.clone()))\n",
        "\n",
        "    return aug1, aug2, aug3\n",
        "\n",
        "# Waveform resample\n",
        "def resample_waveform(waveform, orig_sr, target_sr=args.target_sr):\n",
        "    if orig_sr != target_sr:\n",
        "        resampler = torchaudio.transforms.Resample(\n",
        "            orig_freq=orig_sr,\n",
        "            new_freq=target_sr\n",
        "        )\n",
        "        return resampler(waveform), target_sr\n",
        "    return waveform, orig_sr\n",
        "\n",
        "# Normalize - Mean/Std\n",
        "# def get_mean_and_std(dataset):\n",
        "#     \"\"\" 전체 mel-spectrogram에서 mean과 std 계산 \"\"\"\n",
        "#     dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "#     cnt = 0\n",
        "#     fst_moment = torch.zeros(1)\n",
        "#     snd_moment = torch.zeros(1)\n",
        "#     for inputs, _, _ in tqdm(dataloader, desc=\"[Calculating Mean/Std]\"):\n",
        "#         b, c, h, w = inputs.shape  # inputs: [1, 1, n_mels, time]\n",
        "#         nb_pixels = b * h * w\n",
        "\n",
        "#         fst_moment += torch.sum(inputs, dim=[0, 2, 3])\n",
        "#         snd_moment += torch.sum(inputs**2, dim=[0, 2, 3])\n",
        "#         cnt += nb_pixels\n",
        "\n",
        "#     mean = fst_moment / cnt\n",
        "#     std = torch.sqrt(snd_moment / cnt - mean**2)\n",
        "#     return mean.item(), std.item()\n",
        "\n",
        "def get_mean_and_std(dataset, mask_threshold=-99.0):\n",
        "    \"\"\" 마스킹(-100 등)을 제외하고 mean/std 계산 \"\"\"\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    cnt = 0\n",
        "    fst_moment = 0.0\n",
        "    snd_moment = 0.0\n",
        "\n",
        "    for inputs, _, _ in tqdm(dataloader, desc=\"[Calculating Mean/Std]\"):\n",
        "        # mask: 유효한 mel 값만 추출 (e.g. > -99.0)\n",
        "        valid = inputs[inputs > mask_threshold]  # 1D tensor\n",
        "\n",
        "        fst_moment += valid.sum().item()\n",
        "        snd_moment += (valid ** 2).sum().item()\n",
        "        cnt += valid.numel()\n",
        "\n",
        "    mean = fst_moment / cnt\n",
        "    std = np.sqrt(snd_moment / cnt - mean**2)\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "70af5e6b",
      "metadata": {
        "id": "70af5e6b"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import torchaudio.transforms as T\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import math\n",
        "\n",
        "# # -------------------- Augmentation functions (Torch 기반) --------------------\n",
        "\n",
        "# def spec_augment(mel, time_mask_ratio, freq_mask_ratio): # default: 0.8\n",
        "#     M = mel.shape[-1]  # 시간 축\n",
        "#     F = mel.shape[-2]  # 주파수 축\n",
        "\n",
        "#     time_masking = T.TimeMasking(time_mask_param=int(M * time_mask_ratio))\n",
        "#     freq_masking = T.FrequencyMasking(freq_mask_param=int(F * freq_mask_ratio))\n",
        "\n",
        "#     mel = freq_masking(mel.clone())\n",
        "#     mel = time_masking(mel)\n",
        "#     return mel\n",
        "\n",
        "# # def random_crop(mel, crop_size):\n",
        "# #     if mel.shape[-1] <= crop_size:\n",
        "# #         return mel\n",
        "# #     start = torch.randint(0, mel.shape[-1] - crop_size + 1, (1,)).item()\n",
        "# #     return mel[:, :, start:start + crop_size]\n",
        "\n",
        "# def add_noise(mel, noise_level=0.005):\n",
        "#     noise = torch.randn_like(mel) * noise_level\n",
        "#     return mel + noise\n",
        "\n",
        "# def pitch_shift(mel, n_steps=2):\n",
        "#     shift = random.randint(-n_steps, n_steps)\n",
        "#     if shift == 0:\n",
        "#         return mel\n",
        "#     if shift > 0:\n",
        "#         mel = torch.cat([mel[:, shift:, :], mel[:, :shift, :]], dim=1)\n",
        "#     else:\n",
        "#         shift = abs(shift)\n",
        "#         mel = torch.cat([mel[:, -shift:, :], mel[:, :-shift, :]], dim=1)\n",
        "#     return mel\n",
        "\n",
        "# def time_stretch(mel, min_rate=0.8, max_rate=1.2):\n",
        "#     rate = random.uniform(min_rate, max_rate)\n",
        "#     if rate == 1.0:\n",
        "#         return mel\n",
        "\n",
        "#     orig_size = mel.shape[-1]\n",
        "#     target_size = int(orig_size * rate)\n",
        "#     mel_stretched = F.interpolate(\n",
        "#         mel, size=(mel.shape[1], target_size),\n",
        "#         mode='bilinear', align_corners=False\n",
        "#     )\n",
        "\n",
        "#     if target_size > orig_size:\n",
        "#         return mel_stretched[:, :, :orig_size]\n",
        "#     else:\n",
        "#         padding = orig_size - target_size\n",
        "#         return F.pad(mel_stretched, (0, padding))\n",
        "\n",
        "# # -------------------- Dispatcher --------------------\n",
        "\n",
        "# AUGMENTATION_FUNCTIONS_TORCH = {\n",
        "#     \"spec_augment\": spec_augment,\n",
        "#     # \"random_crop\": random_crop,\n",
        "#     \"add_noise\": add_noise,\n",
        "#     \"pitch_shift\": pitch_shift,\n",
        "#     \"time_stretch\": time_stretch\n",
        "# }\n",
        "\n",
        "# def apply_augmentations_torch(x, methods=[], **kwargs):\n",
        "#     for method in methods:\n",
        "#         func = AUGMENTATION_FUNCTIONS_TORCH.get(method)\n",
        "#         if func is None:\n",
        "#             raise ValueError(f\"Unknown augmentation: {method}\")\n",
        "#         x = func(x, **kwargs.get(method, {}))\n",
        "#     return x\n",
        "\n",
        "\n",
        "##############################################\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# -------------------- Augmentation functions (ICBHI 멜스펙트로그램에 최적화) --------------------\n",
        "\n",
        "def spec_augment(mel, time_mask_ratio=0.15, freq_mask_ratio=0.15):\n",
        "    \"\"\"\n",
        "    SpecAugment: 시간/주파수 영역 마스킹\n",
        "    - 시간축 마스킹: 63 * 0.15 ≈ 9 프레임\n",
        "    - 주파수 마스킹: 128 * 0.1 ≈ 12 채널\n",
        "    \"\"\"\n",
        "    M = mel.shape[-1]  # 시간 축\n",
        "    F = mel.shape[-2]  # 주파수 축\n",
        "\n",
        "    time_masking = T.TimeMasking(time_mask_param=max(1, int(M * time_mask_ratio)))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=max(1, int(F * freq_mask_ratio)))\n",
        "\n",
        "    mel = freq_masking(mel.clone())\n",
        "    mel = time_masking(mel)\n",
        "    return mel\n",
        "\n",
        "def add_noise(mel, noise_level=0.001):\n",
        "    \"\"\"\n",
        "    노이즈 추가: 적당한 수준의 표준 정규분포 노이즈 (너무 높으면 손실 커짐)\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(mel) * noise_level\n",
        "    return mel + noise\n",
        "\n",
        "def pitch_shift(mel, n_steps=2):\n",
        "    \"\"\"\n",
        "    주파수 축 순환 이동 (mel axis). shape은 그대로 유지됨.\n",
        "    n_steps=2면 ±2 멜 채널만 이동.\n",
        "    \"\"\"\n",
        "    shift = random.randint(-n_steps, n_steps)\n",
        "    if shift == 0:\n",
        "        return mel\n",
        "    if shift > 0:\n",
        "        mel = torch.cat([mel[:, :, shift:, :], mel[:, :, :shift, :]], dim=2)\n",
        "    else:\n",
        "        shift = abs(shift)\n",
        "        mel = torch.cat([mel[:, :, -shift:, :], mel[:, :, :-shift, :]], dim=2)\n",
        "    return mel\n",
        "\n",
        "def time_stretch(mel, min_rate=0.95, max_rate=1.05):\n",
        "    \"\"\"\n",
        "    시간 축 길이 조절. 너무 심하지 않게 ±5% 범위로만 조정.\n",
        "    - shape 유지 위해 interpolation 후 crop/pad\n",
        "    \"\"\"\n",
        "    rate = random.uniform(min_rate, max_rate)\n",
        "    if rate == 1.0:\n",
        "        return mel\n",
        "\n",
        "    orig_size = mel.shape[-1]\n",
        "    target_size = int(orig_size * rate)\n",
        "\n",
        "    mel_stretched = F.interpolate(\n",
        "        mel, size=(mel.shape[-2], target_size),  # (mel_bins, time)\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    if target_size > orig_size:\n",
        "        return mel_stretched[..., :orig_size]\n",
        "    else:\n",
        "        pad = orig_size - target_size\n",
        "        return F.pad(mel_stretched, (0, pad))\n",
        "\n",
        "# -------------------- Dispatcher --------------------\n",
        "\n",
        "AUGMENTATION_FUNCTIONS_TORCH = {\n",
        "    \"spec_augment\": spec_augment,\n",
        "    \"add_noise\": add_noise,\n",
        "    \"pitch_shift\": pitch_shift,\n",
        "    \"time_stretch\": time_stretch\n",
        "}\n",
        "\n",
        "def apply_augmentations_torch(x, methods=[], **kwargs):\n",
        "    for method in methods:\n",
        "        func = AUGMENTATION_FUNCTIONS_TORCH.get(method)\n",
        "        if func is None:\n",
        "            raise ValueError(f\"Unknown augmentation: {method}\")\n",
        "        x = func(x, **kwargs.get(method, {}))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4a62aa74",
      "metadata": {
        "id": "4a62aa74"
      },
      "outputs": [],
      "source": [
        "def aug(repeat_mel):\n",
        "    # 먼저 복사본 준비\n",
        "    mel1 = repeat_mel.clone()\n",
        "    mel2 = repeat_mel.clone()\n",
        "\n",
        "    # 각각 다른 증강 A, B 적용\n",
        "    aug1 = apply_augmentations_torch(mel1, methods=[\"add_noise\"], add_noise={\"noise_level\": 0.005})\n",
        "    # aug2 = apply_augmentations_torch(mel2, methods=[\"time_stretch\"], time_stretch={\"min_rate\": 0.8, \"max_rate\": 1.2})\n",
        "    aug3 = apply_augmentations_torch(mel2, methods=[\"pitch_shift\"], pitch_shift={\"n_steps\": 2})\n",
        "\n",
        "    # # 각 결과에 spec_augment 추가 적용\n",
        "    aug1_spec = spec_augment(aug1, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "    aug2_spec = spec_augment(aug3, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "    # aug3_spec = spec_augment(aug3, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "\n",
        "    return aug1, aug3, None\n",
        "\n",
        "\n",
        "def get_timestamp():\n",
        "    \"\"\"Outputs current time in KST like 2404070830\"\"\"\n",
        "    kst_time = datetime.now(ZoneInfo(\"Asia/Seoul\"))\n",
        "    return kst_time.strftime('%y%m%d%H%M')\n",
        "\n",
        "# Origin\n",
        "# def aug(repeat_mel):\n",
        "#     aug1, aug2, aug3 = apply_spec_augment(repeat_mel)\n",
        "#     return aug1, aug2, aug3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e684cb",
      "metadata": {
        "id": "39e684cb"
      },
      "source": [
        "#### 2.3 CycleDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1642a79a",
      "metadata": {
        "id": "1642a79a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CycleDataset(Dataset):\n",
        "    def __init__(self, filename_list, wav_dir, txt_dir, target_sec=args.target_sec, target_sr=args.target_sr, frame_size=args.frame_size, hop_length=args.hop_length, n_mels=args.n_mels, mean=None, std=None):\n",
        "        self.filename_list = filename_list\n",
        "        self.wav_dir = wav_dir\n",
        "        self.txt_dir = txt_dir\n",
        "        self.target_sec = target_sec\n",
        "        self.target_sr = target_sr\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.cycle_list = []\n",
        "\n",
        "        print(\"[INFO] Preprocessing cycles...\")\n",
        "        for filename in tqdm(self.filename_list):\n",
        "            txt_path = os.path.join(self.txt_dir, filename + '.txt')\n",
        "            wav_path = os.path.join(self.wav_dir, filename + '.wav')\n",
        "\n",
        "            if not os.path.exists(txt_path):\n",
        "                print(f\"[WARNING] Missing file: {txt_path}\")\n",
        "            if not os.path.exists(wav_path):\n",
        "                print(f\"[WARNING] Missing file: {wav_path}\")\n",
        "\n",
        "            # Load annotation\n",
        "            cycle_data = np.loadtxt(txt_path, usecols=(0, 1))\n",
        "            lung_label = np.loadtxt(txt_path, usecols=(2, 3))\n",
        "\n",
        "            # Load waveform\n",
        "            waveform, orig_sr = torchaudio.load(wav_path)\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)  # Stereo to mono\n",
        "\n",
        "            # Resample to target sample rate (4kHz)\n",
        "            waveform, sample_rate = resample_waveform(waveform, orig_sr, self.target_sr)\n",
        "\n",
        "            for idx in range(len(cycle_data)):\n",
        "                # 호흡 주기 start, end\n",
        "                start_sample = int(cycle_data[idx, 0] * sample_rate)\n",
        "                end_sample = int(cycle_data[idx, 1] * sample_rate)\n",
        "                lung_duration = cycle_data[idx, 1] - cycle_data[idx, 0]\n",
        "\n",
        "                if end_sample <= start_sample:\n",
        "                    continue  # 잘못된 구간 스킵\n",
        "\n",
        "                # Waveform repeat + padding 후 Mel_db\n",
        "                cycle_wave = waveform[:, start_sample:end_sample]\n",
        "                # seg_wave = preprocess_waveform_segment(cycle_wave, unit_length=int(self.target_sec * self.target_sr))\n",
        "                mel = generate_mel_spectrogram(cycle_wave, sample_rate, frame_size=self.frame_size, hop_length=self.hop_length, n_mels=self.n_mels)\n",
        "\n",
        "                # 정규화\n",
        "                if self.mean is not None and self.std is not None:\n",
        "                    mask_value = -100.0 # mel db 에서 마스킹된 값\n",
        "                    mask = (mel == mask_value)\n",
        "                    mel = (mel - mean) / std\n",
        "                    mel[mask] = 0.0\n",
        "                    \n",
        "                # crackle, wheeze -> class\n",
        "                cr = int(lung_label[idx, 0])\n",
        "                wh = int(lung_label[idx, 1])\n",
        "                label = get_class(cr, wh)\n",
        "\n",
        "                multi_label = torch.tensor([\n",
        "                    float(label in [1, 3]),\n",
        "                    float(label in [2, 3])\n",
        "                ])  # 변환된 multi-label 반환\n",
        "\n",
        "                # meta_data\n",
        "                meta_data = (filename, lung_duration)\n",
        "\n",
        "                self.cycle_list.append((mel, multi_label, meta_data))\n",
        "\n",
        "        print(f\"[INFO] Total cycles collected: {len(self.cycle_list)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cycle_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel, label, meta_data = self.cycle_list[idx]\n",
        "        return mel, label, meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d5a070",
      "metadata": {
        "id": "55d5a070"
      },
      "source": [
        "##### Pickle.dump"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752088df",
      "metadata": {
        "id": "752088df"
      },
      "source": [
        "CycleDataset 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "67673cde",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "539"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d386e82",
      "metadata": {
        "id": "9d386e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Preprocessing cycles...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 539/539 [00:16<00:00, 32.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Total cycles collected: 4142\n",
            "[INFO] Preprocessing cycles...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 381/381 [00:10<00:00, 36.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Total cycles collected: 2756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# # # import random\n",
        "# # # import matplotlib.pyplot as plt\n",
        "# # # import librosa.display\n",
        "\n",
        "# # # wav_dir = ROOT\n",
        "# # # txt_dir = ROOT\n",
        "\n",
        "# # # # 1. Dataset 로드\n",
        "# # # train_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# # # test_dataset = CycleDataset(test_list, wav_dir, txt_dir)\n",
        "\n",
        "# # ################################################################\n",
        "\n",
        "# import random\n",
        "# import matplotlib.pyplot as plt\n",
        "# import librosa.display\n",
        "\n",
        "# wav_dir = ROOT\n",
        "# txt_dir = ROOT\n",
        "\n",
        "# # # mean, std 먼저 계산\n",
        "# # normless_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# # mean, std = get_mean_and_std(normless_dataset)\n",
        "\n",
        "# # 정규화 적용된 데이터셋 생성\n",
        "# train_dataset = CycleDataset(train_list, wav_dir, txt_dir) # , mean=mean, std=std\n",
        "# test_dataset = CycleDataset(test_list, wav_dir, txt_dir) # , mean=mean, std=std\n",
        "\n",
        "# # pickle_dict = {\n",
        "# #     'train_dataset': train_dataset,\n",
        "# #     'test_dataset': test_dataset,\n",
        "# #     'mean': mean,\n",
        "# #     'std': std\n",
        "# # }\n",
        "# # with open(os.path.join(PICKLE_PATH, '3_norm_saved_datasets_multilabel.pkl'), 'wb') as f:\n",
        "# #     pickle.dump(pickle_dict, f)\n",
        "\n",
        "# # print(f'mean: {mean}, std: {std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "86298ba9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-100., -100., -100.,  ..., -100., -100., -100.],\n",
              "         [-100., -100., -100.,  ..., -100., -100., -100.],\n",
              "         [-100., -100., -100.,  ..., -100., -100., -100.],\n",
              "         ...,\n",
              "         [-100., -100., -100.,  ..., -100., -100., -100.],\n",
              "         [-100., -100., -100.,  ..., -100., -100., -100.],\n",
              "         [-100., -100., -100.,  ..., -100., -100., -100.]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normless_dataset[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BQgVyGnrDbN",
      "metadata": {
        "id": "4BQgVyGnrDbN"
      },
      "source": [
        "pickle로 train_dataset, test_dataset 외부 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a273735",
      "metadata": {
        "id": "7a273735"
      },
      "outputs": [],
      "source": [
        "# pickle_name = f'Aug_Moco_MLS_MelSpec_{args.target_sr//1000}kHz_{args.frame_size}win_{args.hop_length}hop_{args.n_mels}mel_{args.target_sec}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd34caa0",
      "metadata": {
        "id": "cd34caa0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pickle_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_dataset\u001b[49m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: test_dataset\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      6\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PICKLE_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaw_datasets_multilabel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset\n",
        "# }\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, 'Raw_datasets_multilabel.pkl')\n",
        "# with open(save_path, 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)\n",
        "\n",
        "# #####\n",
        "\n",
        "# # 🔹 mean, std 함께 저장\n",
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset,\n",
        "#     'mean': mean,\n",
        "#     'std': std\n",
        "# }\n",
        "# with open(os.path.join(PICKLE_PATH, 'pad0_norm_saved_datasets_multilabel.pkl'), 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)\n",
        "\n",
        "# print(f'mean: {mean}, std: {std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zRqSwthYTtxq",
      "metadata": {
        "id": "zRqSwthYTtxq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total cycles: 4142\n",
            "Class 0: 2063 cycles\n",
            "Class 1: 1215 cycles\n",
            "Class 2: 501 cycles\n",
            "Class 3: 363 cycles\n"
          ]
        }
      ],
      "source": [
        "# # 2. 간단 통계\n",
        "# print(f\"Total cycles: {len(train_dataset)}\")\n",
        "\n",
        "# label_counter = [0] * 4  # normal, crackle, wheeze, both\n",
        "# for _, multi_label,_ in train_dataset:\n",
        "#     if torch.equal(multi_label, torch.tensor([0., 0.])):\n",
        "#         label_counter[0] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 0.])):\n",
        "#         label_counter[1] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([0., 1.])):\n",
        "#         label_counter[2] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 1.])):\n",
        "#         label_counter[3] += 1\n",
        "\n",
        "# for idx, count in enumerate(label_counter):\n",
        "#     print(f\"Class {idx}: {count} cycles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yJPtbC3BrqAE",
      "metadata": {
        "id": "yJPtbC3BrqAE"
      },
      "source": [
        "##### Pickle.load\n",
        "저장된 train_dataset, test_dataset을 로드  \n",
        "(> Aug 는 Moco 모델에서 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "EWrjdCFSrmER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWrjdCFSrmER",
        "outputId": "ad9770b7-e29b-4c41-e83e-2d35bb552c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Train] Cycles: 4142\n",
            "[Test] Cycles: 2756\n"
          ]
        }
      ],
      "source": [
        "save_path = os.path.join(PICKLE_PATH, 'Raw_datasets_multilabel.pkl')\n",
        "with open(save_path, 'rb') as f:\n",
        "    pickle_dict = pickle.load(f)\n",
        "\n",
        "train_dataset = pickle_dict['train_dataset']\n",
        "test_dataset = pickle_dict['test_dataset']\n",
        "\n",
        "print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "print(f\"[Test] Cycles: {len(test_dataset)}\")\n",
        "\n",
        "###################\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, 'pad0_norm_saved_datasets_multilabel.pkl')\n",
        "# # 🔹 load with normalization values\n",
        "# with open(save_path, 'rb') as f:\n",
        "#     pickle_dict = pickle.load(f)\n",
        "\n",
        "# train_dataset = pickle_dict['train_dataset']\n",
        "# test_dataset = pickle_dict['test_dataset']\n",
        "# mean = pickle_dict['mean']\n",
        "# std = pickle_dict['std']\n",
        "\n",
        "# print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "# print(f\"[Test] Cycles: {len(test_dataset)}\")\n",
        "# print(f\"[INFO] Loaded mean={mean:.4f}, std={std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc6a84a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c366b896",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'normless_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnormless_dataset\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
            "\u001b[0;31mNameError\u001b[0m: name 'normless_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "normless_dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bb3c24b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 36])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[2][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "938e67be",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# 1. 데이터 가져오기\n",
        "spec = train_dataset[0][0]  # shape: (1, 128, 63)\n",
        "\n",
        "# 2. 채널 차원 제거\n",
        "spec = spec.squeeze(0)  # shape: (128, 63)\n",
        "\n",
        "# 3. 시각화\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.imshow(spec, origin='lower', aspect='auto', cmap='magma')  # 또는 cmap='inferno', 'viridis' 등\n",
        "plt.colorbar(label='Amplitude')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Mel Frequency')\n",
        "plt.title('Mel-Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cebfa6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "# 🔹 각 파일별로 cycle segments 시각화\n",
        "for i, cycle_data in enumerate(raw_cycle_list):\n",
        "    filename = cycle_data['file']\n",
        "    sample_rate = cycle_data['sr']\n",
        "    segments = cycle_data['seg']\n",
        "\n",
        "    print(f\"파일: {filename}, 세그먼트 개수: {len(segments)}\")\n",
        "\n",
        "    # 🔹 전체 원본 db 스펙트로그램 (크게 출력)\n",
        "    origin_db = segments[0]['db']  # 첫 번째 세그먼트에서 전체 db 스펙트로그램 사용\n",
        "\n",
        "    print(f\"Original dB Spectrogram shape: {origin_db.shape}\")  # 🔹 데이터 shape 확인\n",
        "\n",
        "    # 🔹 원본 dB Spectrogram을 크게 시각화\n",
        "    fig, main_ax = plt.subplots(figsize=(15, 5))\n",
        "    main_ax.imshow(origin_db.squeeze(0).numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "    main_ax.set_title(f\"Original dB Spectrogram - {filename}\")\n",
        "    main_ax.set_xlabel(\"Time Frames\")\n",
        "    main_ax.set_ylabel(\"Frequency Bins\")\n",
        "    plt.show()\n",
        "\n",
        "    # 세그먼트 개수에 맞게 서브플롯 생성 (원본 + 두 가지 Augment 버전)\n",
        "    fig, axes = plt.subplots(len(segments), 3, figsize=(15, 5 * len(segments))) # plt.subplots(행, 열, figsize)\n",
        "\n",
        "    # 세그먼트별로 반복하여 스펙트로그램 시각화\n",
        "    for j, segment in enumerate(segments):\n",
        "        mel_spectrogram = segment['mel']  # 원본 Mel Spectrogram\n",
        "        augmented_spec1 = segment['aug'][0]  # 주파수 마스킹\n",
        "        augmented_spec2 = segment['aug'][1]  # 시간 마스킹\n",
        "        start_time, end_time = segment['period']\n",
        "\n",
        "        # 한 개의 세그먼트만 있을 경우, `axes[j]` 대신 `axes`를 직접 사용\n",
        "        if len(segments) > 1:\n",
        "            ax1, ax2, ax3 = axes[j]\n",
        "        else:\n",
        "            ax1, ax2, ax3 = axes\n",
        "\n",
        "        # 🔹 원본 Mel Spectrogram 시각화\n",
        "        ax1.imshow(mel_spectrogram.squeeze(0).numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "        ax1.set_title(f\"Original Mel Spectrogram (Cycle {j+1}: {start_time:.2f}s - {end_time:.2f}s)\")\n",
        "        ax1.set_xlabel(\"Time Frames\")\n",
        "        ax1.set_ylabel(\"Mel Bins\")\n",
        "\n",
        "        # 🔹 주파수 마스킹이 적용된 Mel Spectrogram 시각화\n",
        "        ax2.imshow(augmented_spec1.squeeze(0).numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "        ax2.set_title(f\"Augmented Mel (Freq Masking) (Cycle {j+1})\")\n",
        "        ax2.set_xlabel(\"Time Frames\")\n",
        "        ax2.set_ylabel(\"Mel Bins\")\n",
        "\n",
        "        # 🔹 시간 마스킹이 적용된 Mel Spectrogram 시각화\n",
        "        ax3.imshow(augmented_spec2.squeeze(0).numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "        ax3.set_title(f\"Augmented Mel (Time Masking) (Cycle {j+1})\")\n",
        "        ax3.set_xlabel(\"Time Frames\")\n",
        "        ax3.set_ylabel(\"Mel Bins\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcca3481",
      "metadata": {
        "id": "bcca3481"
      },
      "source": [
        "#### 2.4 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "44c9b5b9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 18.2739,  41.0651,  39.4717,  ...,  39.0717,  35.6136,  34.7371],\n",
              "          [ 26.7610,  38.4059,  39.4080,  ...,  36.3724,  38.7695,  34.5259],\n",
              "          [ 18.6967,  26.5022,  26.2651,  ...,  28.4122,  29.0566,  24.7872],\n",
              "          ...,\n",
              "          [-42.1164, -40.1613, -38.2948,  ..., -39.9382, -33.8735, -42.9880],\n",
              "          [-43.9740, -43.6206, -37.8362,  ..., -41.0909, -32.5942, -41.4029],\n",
              "          [-41.8878, -42.3428, -39.6249,  ..., -39.0022, -32.5291, -40.6569]]]),\n",
              " tensor([0., 1.]),\n",
              " ('103_2b2_Ar_mc_LittC2SE', np.float64(2.886)))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "01e91c50",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 24])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[10][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5f19b4a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f19b4a7",
        "outputId": "c2ac9fb5-3049-4aaa-f5bb-c28a747088d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrain set size: 4142, Finetune set size: 4142\n"
          ]
        }
      ],
      "source": [
        "# ---------------- 학습 데이터 구성(seed) ----------------\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# train_dataset 내에서 각 파일의 인덱스를 추출\n",
        "pretrain_idx = []\n",
        "finetune_idx = []\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "    filename = train_dataset[i][2][0]\n",
        "\n",
        "    if filename in pretrain_list:\n",
        "        pretrain_idx.append(i)\n",
        "    # elif filename in finetune_list:\n",
        "    #     finetune_idx.append(i)\n",
        "\n",
        "    # pretrain = finetune\n",
        "    if filename in finetune_list:\n",
        "        finetune_idx.append(i)\n",
        "\n",
        "# 인덱스 순서 셔플\n",
        "random.shuffle(pretrain_idx)\n",
        "random.shuffle(finetune_idx)\n",
        "\n",
        "print(f\"Pretrain set size: {len(pretrain_idx)}, Finetune set size: {len(finetune_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce2c3c8",
      "metadata": {
        "id": "cce2c3c8"
      },
      "source": [
        "코드 실행 환경에 따라 num_workers를 적절한 값으로 지정해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e3ccb9ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_with_mask(batch):\n",
        "    # batch: [(mel, label, extra), ...]\n",
        "    mels, labels, extras = zip(*batch)  # 길이 B 튜플\n",
        "\n",
        "    # 가장 긴 time length 찾기\n",
        "    max_T = max([mel.shape[-1] for mel in mels])  # ex) 22, 26 → 26\n",
        "    PAD_DB = -100.0  # dB 스케일 기준 최소값으로 padding\n",
        "\n",
        "    padded_mels = []\n",
        "    masks = []\n",
        "\n",
        "    for mel in mels:\n",
        "        # mel: (1, F, T)  e.g., (1, 128, 24)\n",
        "        _, F, T = mel.shape\n",
        "        mel = mel.squeeze(0)  # → (F, T)\n",
        "\n",
        "        pad_len = max_T - T\n",
        "        if pad_len > 0:\n",
        "            # Pad 생성 및 mel concat\n",
        "            pad = mel.new_full((F, pad_len), fill_value=PAD_DB)  # (F, pad_len)\n",
        "            mel_padded = torch.cat([mel, pad], dim=-1)  # (F, max_T)\n",
        "\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_len)])  # (max_T,)\n",
        "        else:\n",
        "            mel_padded = mel  # (F, max_T)\n",
        "            mask = torch.ones(T)  # (max_T)\n",
        "\n",
        "        # 다시 (1, F, T)로 복원\n",
        "        padded_mels.append(mel_padded.unsqueeze(0))  # (1, F, T)\n",
        "        masks.append(mask)\n",
        "\n",
        "    # 최종 batch 텐서화\n",
        "    padded_mels = torch.stack(padded_mels, dim=0)  # (B, 1, F, T)\n",
        "    masks = torch.stack(masks).bool()              # (B, T)\n",
        "\n",
        "    return padded_mels, torch.stack(labels), masks, extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "432ae0cd",
      "metadata": {
        "id": "432ae0cd"
      },
      "outputs": [],
      "source": [
        "# # Dataset 생성 (Subset)\n",
        "# pretrain_dataset = Subset(train_dataset, pretrain_idx)\n",
        "# finetune_dataset = Subset(train_dataset, finetune_idx)\n",
        "\n",
        "# # DataLoader 생성\n",
        "# # DataLoader에서 shuffle=True로 지정하면 매 epoch마다 셔플 순서가 달라짐 => 재현성 문제 발생\n",
        "# # pretrain_dataset, finetune_dataset은 이미 셔플이 완료된 것으로, 이것을 DataLoader에 입력함\n",
        "# pretrain_loader = DataLoader(\n",
        "#     pretrain_dataset,\n",
        "#     batch_size=args.batch_size,\n",
        "#     num_workers=0,\n",
        "#     drop_last=True,\n",
        "#     pin_memory=True,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# finetune_loader = DataLoader(\n",
        "#     finetune_dataset,\n",
        "#     batch_size=args.batch_size,\n",
        "#     num_workers=0,\n",
        "#     drop_last=True,\n",
        "#     pin_memory=True,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=args.batch_size,\n",
        "#     num_workers=0,\n",
        "#     pin_memory=True,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "#########################\n",
        "# Dataset 생성 (Subset)\n",
        "pretrain_dataset = Subset(train_dataset, pretrain_idx)\n",
        "finetune_dataset = Subset(train_dataset, finetune_idx)\n",
        "\n",
        "# DataLoader 생성\n",
        "# DataLoader에서 shuffle=True로 지정하면 매 epoch마다 셔플 순서가 달라짐 => 재현성 문제 발생\n",
        "# pretrain_dataset, finetune_dataset은 이미 셔플이 완료된 것으로, 이것을 DataLoader에 입력함\n",
        "pretrain_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_with_mask\n",
        ")\n",
        "\n",
        "finetune_loader = DataLoader(\n",
        "    finetune_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_with_mask\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_with_mask\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b492ad67",
      "metadata": {
        "id": "b492ad67"
      },
      "source": [
        "label 분포 확인 (단순 참고용, 실제 환경에서는 pretrain set의 label 분포가 어떤지 알 수 없음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fea9d290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea9d290",
        "outputId": "2066f8d9-fbc5-44a6-b3b3-0bc214f136ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrain sample: 4142\n",
            "Pretrain label distribution: Counter({0: 2063, 1: 1215, 2: 501, 3: 363})\n",
            "\n",
            "Finetune sample: 4142\n",
            "Finetune label distribution: Counter({0: 2063, 1: 1215, 2: 501, 3: 363})\n",
            "Test sample: 2756\n",
            "Test label distribution: Counter({0: 1579, 1: 649, 2: 385, 3: 143})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# label\n",
        "labels = torch.stack([multi_label for _, multi_label, _ in train_dataset])\n",
        "\n",
        "# pretext와 finetune 데이터셋의 라벨 분포 출력\n",
        "pretrain_labels = labels[pretrain_idx]\n",
        "pretrain_labels_class = (\n",
        "    pretrain_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    pretrain_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "finetune_labels = labels[finetune_idx]\n",
        "finetune_labels_class = (\n",
        "    finetune_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    finetune_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "# test 데이터셋의 라벨 분포 출력\n",
        "test_labels = torch.stack([multi_label for _, multi_label, _ in test_dataset])\n",
        "test_labels_class = (\n",
        "    test_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    test_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "print(f\"Pretrain sample: {len(pretrain_labels_class)}\")\n",
        "print(\"Pretrain label distribution:\", Counter(pretrain_labels_class.tolist()))\n",
        "print(f\"\\nFinetune sample: {len(finetune_labels_class)}\")\n",
        "print(\"Finetune label distribution:\", Counter(finetune_labels_class.tolist()))\n",
        "print(f\"Test sample: {len(test_labels_class)}\")\n",
        "print(\"Test label distribution:\", Counter(test_labels_class.tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed559ff1",
      "metadata": {
        "id": "ed559ff1"
      },
      "source": [
        "## 3. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca710799",
      "metadata": {
        "id": "ca710799"
      },
      "source": [
        "#### 3.1 Pre-trained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2caf4a6c",
      "metadata": {
        "id": "2caf4a6c"
      },
      "outputs": [],
      "source": [
        "# def backbone_resnet():\n",
        "#     # 1. 기본 ResNet50 생성 (pretrained=False로 시작)\n",
        "#     resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "#     # 2. 첫 번째 conv 레이어를 1채널용으로 수정\n",
        "#     resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "#     # 먼저 fc 제거\n",
        "#     resnet.fc = nn.Identity()\n",
        "\n",
        "#     # 3. ImageNet 가중치 로드 (conv1 제외)\n",
        "#     state_dict = load_state_dict_from_url(\n",
        "#         'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "#         progress=True\n",
        "#     )\n",
        "#     if 'conv1.weight' in state_dict:\n",
        "#         del state_dict['conv1.weight']\n",
        "#     resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "#     return resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ad728509",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "class ResNet50(torchvision.models.resnet.ResNet):\n",
        "    def __init__(self, track_bn=True):\n",
        "        def norm_layer(*args, **kwargs):\n",
        "            return nn.BatchNorm2d(*args, **kwargs, track_running_stats=track_bn)\n",
        "        super().__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], norm_layer=norm_layer)\n",
        "        del self.fc\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.final_feat_dim = 2048\n",
        "\n",
        "    def load_sl_official_weights(self, progress=True):\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "        state_dict = weights.get_state_dict(progress=progress)\n",
        "\n",
        "        del state_dict['conv1.weight']\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "        # if len(missing) > 0:\n",
        "            # raise AssertionError('Model code may be incorrect')\n",
        "\n",
        "    def load_ssl_official_weights(self, progress=True):\n",
        "        # only SimCLR is available\n",
        "        from pl_bolts.models.self_supervised import SimCLR\n",
        "        \n",
        "        weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
        "        simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
        "\n",
        "        state_dict = {}\n",
        "        for k, v in simclr.state_dict().items():\n",
        "            if 'encoder.' in k:\n",
        "                k = k.replace('encoder.', '')\n",
        "            if 'fc' not in k or 'project' not in k:\n",
        "                state_dict[k] = v\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "        # non_linear_evaluator.block_forward is a pretrained MLP classifier for SimCLR\n",
        "        # refer to https://github.com/Lightning-AI/lightning-bolts/blob/bcbbf6ab6c36430946dd8a416ddc7e697e8507fc/pl_bolts/models/self_supervised/evaluator.py#L7\n",
        "        if len(missing) > 0:\n",
        "            raise AssertionError('Model code may be incorrect')\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f76dbd0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_resnet50_patch():\n",
        "    \"\"\"\n",
        "    MoCo 구조에 사용할 CNN6 백본 정의 함수.\n",
        "    \n",
        "    주요 변경 사항:\n",
        "    - ResNet50 대신 CNN6 클래스 사용\n",
        "    - 출력 feature dim은 512로 고정됨 (MoCo에서는 dim_enc=2048 → 이 부분만 맞춰서 사용하면 문제 없음)\n",
        "    - ImageNet pretrained 사용 대신 공식 CNN6 pretrained 로딩 함수 포함 (옵션 사용 가능)\n",
        "    \"\"\"\n",
        "    model = ResNet50()\n",
        "\n",
        "    # 공식 SL pretrained weight를 사용하고자 할 경우 아래 줄을 주석 해제\n",
        "    model.load_sl_official_weights()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d7776d9",
      "metadata": {},
      "source": [
        "#### 3.2 Pre-trained CNN6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d0de338c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def init_layer(layer):\n",
        "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "    if hasattr(layer, 'bias'):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "            \n",
        "\n",
        "def init_bn(bn):\n",
        "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.)\n",
        "\n",
        "\n",
        "class ConvBlock5x5(nn.Module): #for CNN6\n",
        "    def __init__(self, in_channels, out_channels, stride=(1,1)):\n",
        "        \n",
        "        super(ConvBlock5x5, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=(5, 5), stride=stride,\n",
        "                              padding=(2, 2), bias=False)\n",
        "                              \n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.init_weight()\n",
        "        \n",
        "    def init_weight(self):\n",
        "        init_layer(self.conv1)\n",
        "        init_bn(self.bn1)\n",
        "        \n",
        "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):        \n",
        "        x = input\n",
        "        x = F.relu_(self.bn1(self.conv1(x)))\n",
        "        if pool_type == 'max':\n",
        "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg':\n",
        "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg+max':\n",
        "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            x = x1 + x2\n",
        "        else:\n",
        "            raise Exception('Incorrect argument!')\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN6, self).__init__()\n",
        "        self.final_feat_dim = 512\n",
        "\n",
        "        self.do_dropout = False\n",
        "        self.conv_block1 = ConvBlock5x5(in_channels=1, out_channels=64, stride=(1,1))\n",
        "        self.conv_block2 = ConvBlock5x5(in_channels=64, out_channels=128, stride=(1,1))\n",
        "        self.conv_block3 = ConvBlock5x5(in_channels=128, out_channels=256, stride=(1,1))\n",
        "        self.conv_block4 = ConvBlock5x5(in_channels=256, out_channels=512, stride=(1,1))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # self.linear = nn.Linear(512, num_classes, bias=True)\n",
        "\n",
        "    def load_sl_official_weights(self):\n",
        "        \"\"\" download AudioSet pretrained CNN6 in https://zenodo.org/record/3960586#.Y8dz8y_kEiY\n",
        "        \"\"\"\n",
        "        weights = torch.load('/home/ressera3/boaz/pretrained_pth/Cnn6_mAP=0.343.pth')['model']\n",
        "        state_dict = {k: v for k, v in weights.items() if k in self.state_dict().keys()}\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = torch.mean(x, dim=3) #mean over time dim\n",
        "        (x1, _) = torch.max(x, dim=2) #max over freq dim\n",
        "        x2 = torch.mean(x, dim=2) #mean over freq dim (after mean over time)\n",
        "        x = x1 + x2\n",
        "\n",
        "        # if self.embed_only:\n",
        "        #     return x\n",
        "        # return self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f839c412",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_cnn6():\n",
        "    \"\"\"\n",
        "    MoCo 구조에 사용할 CNN6 백본 정의 함수.\n",
        "    \n",
        "    주요 변경 사항:\n",
        "    - ResNet50 대신 CNN6 클래스 사용\n",
        "    - 출력 feature dim은 512로 고정됨 (MoCo에서는 dim_enc=2048 → 이 부분만 맞춰서 사용하면 문제 없음)\n",
        "    - ImageNet pretrained 사용 대신 공식 CNN6 pretrained 로딩 함수 포함 (옵션 사용 가능)\n",
        "    \"\"\"\n",
        "    model = CNN6()\n",
        "\n",
        "    # 공식 SL pretrained weight를 사용하고자 할 경우 아래 줄을 주석 해제\n",
        "    model.load_sl_official_weights()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb5d4c8",
      "metadata": {},
      "source": [
        "##### 3-3. GRU+ATT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "84f83f9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class HAN_GRU(nn.Module):\n",
        "    def __init__(self, freq_dim=128, hidden_freq=100, hidden_time=250, output_dim=512):\n",
        "        super(HAN_GRU, self).__init__()\n",
        "        self.hidden_freq = hidden_freq\n",
        "        self.hidden_time = hidden_time\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # Bidirectional GRU (주파수 영역)\n",
        "        self.freq_gru = nn.GRU(input_size=freq_dim, hidden_size=hidden_freq,\n",
        "                               batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Attention for frequency\n",
        "        self.freq_attn_fc = nn.Linear(hidden_freq * 2, hidden_freq * 2)\n",
        "        self.freq_context_vector = nn.Parameter(torch.randn(hidden_freq * 2))\n",
        "\n",
        "        # Bidirectional GRU (시간 영역)\n",
        "        self.time_gru = nn.GRU(input_size=hidden_freq * 2, hidden_size=hidden_time,\n",
        "                               batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Attention for time\n",
        "        self.time_attn_fc = nn.Linear(hidden_time * 2, hidden_time * 2)\n",
        "        self.time_context_vector = nn.Parameter(torch.randn(hidden_time * 2))\n",
        "\n",
        "        # 마지막 출력 벡터 차원 맞추기\n",
        "        self.fc_out = nn.Linear(hidden_time * 2, output_dim)\n",
        "\n",
        "    def attention(self, rnn_output, attn_fc, context_vector, mask=None):\n",
        "        u = torch.tanh(attn_fc(rnn_output))  # [B, T, D]\n",
        "        attn_scores = torch.matmul(u, context_vector)  # [B, T]\n",
        "\n",
        "        if mask is not None:\n",
        "            # mask가 0인 (padding) 위치의 attention score를 -1e9로 설정 → softmax 이후 거의 0이 됨\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)  # [B, T]\n",
        "        attn_output = torch.sum(rnn_output * attn_weights.unsqueeze(-1), dim=1)  # [B, D]\n",
        "        return attn_output\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # x: (B, C=1, F, T) → squeeze channel\n",
        "        x = x.squeeze(1)   # (B, F, T)\n",
        "        x = x.permute(0, 2, 1)  # (B, T, F)\n",
        "\n",
        "        # Frequency GRU\n",
        "        freq_output, _ = self.freq_gru(x)  # (B, T, 2*hidden_freq)\n",
        "        freq_attn_output = self.attention(freq_output, self.freq_attn_fc, self.freq_context_vector, mask)  # (B, 2*hidden_freq)\n",
        "\n",
        "        # 시간 축을 따라 Attention-GRU\n",
        "        time_input = freq_output  # (B, T, 2*hidden_freq)\n",
        "        time_output, _ = self.time_gru(time_input)  # (B, T, 2*hidden_time)\n",
        "        time_attn_output = self.attention(time_output, self.time_attn_fc, self.time_context_vector, mask)  # (B, 2*hidden_time)\n",
        "\n",
        "        # 최종 임베딩 차원으로 투사\n",
        "        # out = self.fc_out(time_attn_output)  # (B, output_dim)\n",
        "        return time_attn_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "93ad3cc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_han_gru():\n",
        "    \"\"\"\n",
        "    MoCo에 사용 가능한 GRU + 계층적 Attention 기반 백본 모델 정의.\n",
        "    - 입력: log-mel spectrogram 형태 (B, 1, F, T)\n",
        "    - 출력: 512차원 feature vector\n",
        "    \"\"\"\n",
        "    return HAN_GRU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "09f21daa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f21daa",
        "outputId": "0c812f61-67a5-474c-a91e-2ed67a2c0c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "               GRU-1  [[-1, 63, 200], [-1, 2, 100]]               0\n",
            "            Linear-2              [-1, 63, 200]          40,200\n",
            "               GRU-3  [[-1, 63, 500], [-1, 2, 250]]               0\n",
            "            Linear-4              [-1, 63, 500]         250,500\n",
            "================================================================\n",
            "Total params: 290,700\n",
            "Trainable params: 290,700\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 139.05\n",
            "Params size (MB): 1.11\n",
            "Estimated Total Size (MB): 140.19\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# summary 함수 사용: (채널, 높이, 너비) 크기를 지정\n",
        "summary(backbone_han_gru().to(device), input_size=(1, 128, 63))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0305c74",
      "metadata": {
        "id": "e0305c74"
      },
      "source": [
        "#### 3.2 MoCo (MLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ska5GunlcKzI",
      "metadata": {
        "id": "ska5GunlcKzI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# K: queue_g의 크기\n",
        "# dim_enc: projector 통과 전, g1,g2 벡터의 차원\n",
        "# dim_prj: projector 통과 후, z1,z2 벡터의 차원\n",
        "class MoCo(nn.Module):\n",
        "    def __init__(self, base_encoder, dim_enc=512, dim_prj=128, K=512, m=0.999, T=0.07, top_k=10, lambda_bce=0.5):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "        self.top_k = top_k\n",
        "        self.lambda_bce = lambda_bce\n",
        "\n",
        "        self.encoder_q = base_encoder()\n",
        "        self.encoder_k = base_encoder()\n",
        "\n",
        "        # dim_enc = 2048\n",
        "        if dim_enc == 2048:\n",
        "            self.proj_head_q = nn.Sequential(\n",
        "                nn.Linear(dim_enc, dim_enc),\n",
        "                nn.BatchNorm1d(dim_enc),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(dim_enc, dim_prj)\n",
        "            )\n",
        "            self.proj_head_k = nn.Sequential(\n",
        "                nn.Linear(dim_enc, dim_enc),\n",
        "                nn.BatchNorm1d(dim_enc),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(dim_enc, dim_prj)\n",
        "            )\n",
        "\n",
        "        elif dim_enc == 500:\n",
        "            self.proj_head_q = nn.Sequential(\n",
        "                nn.Linear(dim_enc, dim_enc),\n",
        "                nn.BatchNorm1d(dim_enc),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(dim_enc, dim_prj)\n",
        "            )\n",
        "            self.proj_head_k = nn.Sequential(\n",
        "                nn.Linear(dim_enc, dim_enc),\n",
        "                nn.BatchNorm1d(dim_enc),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(dim_enc, dim_prj)\n",
        "            )\n",
        "            print(f\"[INFO] Using CNN6 backbone with dim_enc={dim_enc} and dim_prj={dim_prj}\")\n",
        "\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False\n",
        "\n",
        "        self.register_buffer(\"queue_g\", F.normalize(torch.randn(dim_enc, K), dim=0))      # g2를 정규화한 후 열 단위로 Qg에 저장\n",
        "        self.register_buffer(\"queue_z\", F.normalize(torch.randn(dim_prj, K), dim=0))      # z2를 정규화한 후 열 단위로 Qz에 저장\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))      \n",
        "        \n",
        "        # Top-k 확인용 버퍼\n",
        "        self.register_buffer(\"queue_label\", torch.zeros(K, 2))  # or float for multi-label\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, g2, z2, labels=None):\n",
        "        batch_size = g2.shape[0]\n",
        "        ptr = int(self.queue_ptr)\n",
        "        assert self.K % batch_size == 0\n",
        "        # self.queue_g[:, ptr:ptr + batch_size] = g2.T.detach()[:, :self.queue_g.shape[1] - ptr]  # Update only available space\n",
        "        # self.queue_z[:, ptr:ptr + batch_size] = z2.T.detach()[:, :self.queue_z.shape[1] - ptr]  # Update only available space\n",
        "        self.queue_g[:, ptr:ptr+batch_size] = g2.T.detach()\n",
        "        self.queue_z[:, ptr:ptr+batch_size] = z2.T.detach()\n",
        "\n",
        "        # label 확인용\n",
        "        if labels is not None:\n",
        "            self.queue_label[ptr:ptr+batch_size] = labels.detach()\n",
        "            \n",
        "        self.queue_ptr[0] = (ptr + batch_size) % self.K\n",
        "\n",
        "    def forward(self, im_q, im_k, epoch=None, warmup_epochs=10, labels_k=None, mask=None):\n",
        "        # encoder_q → g1 (feature)\n",
        "        g1 = F.normalize(self.encoder_q(im_q, mask=mask), dim=1)  # shape: [B, 2048]\n",
        "\n",
        "        # projection head → z1\n",
        "        z1 = F.normalize(self.proj_head_q(g1), dim=1)  # shape: [B, 128]\n",
        "\n",
        "        # encoder k\n",
        "        with torch.no_grad():\n",
        "            self._momentum_update_key_encoder()\n",
        "            g2 = F.normalize(self.encoder_k(im_k, mask=mask), dim=1)\n",
        "            z2 = F.normalize(self.proj_head_k(g2), dim=1)\n",
        "\n",
        "        # top-k mining\n",
        "        sim_g = torch.matmul(g1, self.queue_g.clone().detach())  # [N, K]\n",
        "        # Ablation(1-1) Hard top-k\n",
        "        topk_idx = torch.topk(sim_g, self.top_k, dim=1).indices\n",
        "        y = torch.zeros_like(sim_g)\n",
        "        y.scatter_(1, topk_idx, 1.0)\n",
        "        # # Ablation(1-2) Soft top-k\n",
        "        # topk_sim, topk_idx = torch.topk(sim_g, self.top_k, dim=1)\n",
        "        # y = torch.zeros_like(sim_g)\n",
        "        # y.scatter_(1, topk_idx, F.softmax(topk_sim / self.T, dim=1))\n",
        "\n",
        "        ##################################################################\n",
        "        # logits from z1 · Qz\n",
        "        sim_z = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        # Ablation(2-1) BCE Loss\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y) # 개선-> sigmoid(sim_z), 1/D\n",
        "\n",
        "        # # Ablation(2-2) Weighted BCE Loss\n",
        "        # pos_weight = torch.ones_like(sim_z) * (self.K / self.top_k)\n",
        "        # bce_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y, pos_weight=pos_weight)\n",
        "        # # Ablation(2-3) another Weighted BCE Loss (비추, top-k만 보는 느낌)\n",
        "        # raw_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y, reduction='none')  # shape: [B, K]\n",
        "        # bce_loss = raw_loss.sum() / (y.sum() + 1e-6)\n",
        "\n",
        "        ###################################################################\n",
        "        # InfoNCE loss\n",
        "        l_pos = torch.sum(z1 * z2, dim=1, keepdim=True)\n",
        "        l_neg = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1) / self.T\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(logits.device)\n",
        "        info_nce_loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        # Total loss (with optional warmup) # MLS 논문에서는 warmup 아예 안쓴다고 함\n",
        "        if epoch is not None and epoch < warmup_epochs:\n",
        "            loss = info_nce_loss\n",
        "        else:\n",
        "            loss = info_nce_loss + self.lambda_bce * bce_loss\n",
        "\n",
        "        self._dequeue_and_enqueue(g2, z2, labels=labels_k)\n",
        "\n",
        "        return loss, logits, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc1bf21",
      "metadata": {
        "id": "1cc1bf21"
      },
      "source": [
        "## 4. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1d0015cd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(next(iter(pretrain_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "-BkAfkqhyHrY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkAfkqhyHrY",
        "outputId": "70fa83d7-4e71-4275-eb00-1531ed151726"
      },
      "outputs": [],
      "source": [
        "loader_iter = iter(pretrain_loader)\n",
        "batch1 = next(loader_iter)\n",
        "batch2 = next(loader_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d646dec5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 128, 62])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(pretrain_loader))[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "115b9965",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 128, 127])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch2[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e745fdd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "e745fdd5",
        "outputId": "3c8db9e4-49ad-4846-b176-598cb7bd18ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ressera3/boaz/wandb/run-20250718_152055-k3fjim4u</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/k3fjim4u' target=\"_blank\">shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/k3fjim4u' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/k3fjim4u</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using CNN6 backbone with dim_enc=500 and dim_prj=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1392: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /opt/conda/conda-bld/pytorch_1729647382455/work/aten/src/ATen/native/cudnn/RNN.cpp:1410.)\n",
            "  result = _VF.gru(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Top-k Label Logging] Epoch 0\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     104     0.1689    0.0     [0. 0.]\n",
            "2     442     0.1267    0.0     [0. 0.]\n",
            "3     353     0.1262    0.0     [0. 0.]\n",
            "4     417     0.1113    0.0     [0. 0.]\n",
            "5     60      0.1088    2.0     [0. 1.]\n",
            "6     174     0.1086    0.0     [0. 0.]\n",
            "7     127     0.1084    1.0     [1. 0.]\n",
            "8     109     0.1064    1.0     [1. 0.]\n",
            "9     9       0.1062    0.0     [0. 0.]\n",
            "10    18      0.1049    0.0     [0. 0.]\n",
            "[Epoch 0 | Step 31] im_q: torch.Size([128, 1, 128, 54]), im_k: torch.Size([128, 1, 128, 54])\n",
            "=> Saved best checkpoint (epoch: 0, loss: 15.0364)\n",
            "\n",
            "[Top-k Label Logging] Epoch 1\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     9       0.3667    1.0     [1. 0.]\n",
            "2     14      0.3603    0.0     [0. 0.]\n",
            "3     57      0.3568    0.0     [0. 0.]\n",
            "4     75      0.3560    0.0     [0. 0.]\n",
            "5     125     0.3517    0.0     [0. 0.]\n",
            "6     66      0.3501    1.0     [1. 0.]\n",
            "7     32      0.3458    2.0     [0. 1.]\n",
            "8     426     0.3433    0.0     [0. 0.]\n",
            "9     117     0.3425    0.0     [0. 0.]\n",
            "10    65      0.3420    0.0     [0. 0.]\n",
            "[Epoch 1 | Step 31] im_q: torch.Size([128, 1, 128, 59]), im_k: torch.Size([128, 1, 128, 59])\n",
            "=> Saved best checkpoint (epoch: 1, loss: 13.4788)\n",
            "\n",
            "[Top-k Label Logging] Epoch 2\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     118     0.6572    2.0     [0. 1.]\n",
            "2     403     0.6546    0.0     [0. 0.]\n",
            "3     56      0.6537    0.0     [0. 0.]\n",
            "4     31      0.6505    1.0     [1. 0.]\n",
            "5     495     0.6504    2.0     [0. 1.]\n",
            "6     115     0.6498    0.0     [0. 0.]\n",
            "7     8       0.6498    0.0     [0. 0.]\n",
            "8     63      0.6488    0.0     [0. 0.]\n",
            "9     422     0.6483    0.0     [0. 0.]\n",
            "10    2       0.6483    3.0     [1. 1.]\n",
            "[Epoch 2 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "=> Saved best checkpoint (epoch: 2, loss: 11.5117)\n",
            "\n",
            "[Top-k Label Logging] Epoch 3\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     72      0.8026    1.0     [1. 0.]\n",
            "2     77      0.8016    0.0     [0. 0.]\n",
            "3     441     0.8013    0.0     [0. 0.]\n",
            "4     16      0.8011    0.0     [0. 0.]\n",
            "5     413     0.8007    1.0     [1. 0.]\n",
            "6     90      0.8005    1.0     [1. 0.]\n",
            "7     4       0.8004    1.0     [1. 0.]\n",
            "8     446     0.8004    0.0     [0. 0.]\n",
            "9     435     0.8000    0.0     [0. 0.]\n",
            "10    15      0.7997    0.0     [0. 0.]\n",
            "[Epoch 3 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "=> Saved best checkpoint (epoch: 3, loss: 10.9225)\n",
            "\n",
            "[Top-k Label Logging] Epoch 4\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     95      0.8589    1.0     [1. 0.]\n",
            "2     406     0.8586    1.0     [1. 0.]\n",
            "3     419     0.8583    1.0     [1. 0.]\n",
            "4     466     0.8581    1.0     [1. 0.]\n",
            "5     12      0.8580    0.0     [0. 0.]\n",
            "6     508     0.8579    0.0     [0. 0.]\n",
            "7     461     0.8579    1.0     [1. 0.]\n",
            "8     86      0.8576    0.0     [0. 0.]\n",
            "9     400     0.8576    0.0     [0. 0.]\n",
            "10    417     0.8575    0.0     [0. 0.]\n",
            "[Epoch 4 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "=> Saved best checkpoint (epoch: 4, loss: 10.3227)\n",
            "\n",
            "[Top-k Label Logging] Epoch 5\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     298     0.9165    1.0     [1. 0.]\n",
            "2     351     0.9155    0.0     [0. 0.]\n",
            "3     325     0.9152    1.0     [1. 0.]\n",
            "4     348     0.9149    3.0     [1. 1.]\n",
            "5     299     0.9139    1.0     [1. 0.]\n",
            "6     282     0.9139    1.0     [1. 0.]\n",
            "7     294     0.9137    3.0     [1. 1.]\n",
            "8     289     0.9136    0.0     [0. 0.]\n",
            "9     378     0.9136    0.0     [0. 0.]\n",
            "10    318     0.9136    1.0     [1. 0.]\n",
            "[Epoch 5 | Step 31] im_q: torch.Size([128, 1, 128, 43]), im_k: torch.Size([128, 1, 128, 43])\n",
            "=> Saved best checkpoint (epoch: 5, loss: 9.8343)\n",
            "\n",
            "[Top-k Label Logging] Epoch 6\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     467     0.9529    0.0     [0. 0.]\n",
            "2     399     0.9528    2.0     [0. 1.]\n",
            "3     413     0.9528    1.0     [1. 0.]\n",
            "4     426     0.9527    1.0     [1. 0.]\n",
            "5     455     0.9524    0.0     [0. 0.]\n",
            "6     415     0.9524    1.0     [1. 0.]\n",
            "7     481     0.9523    2.0     [0. 1.]\n",
            "8     435     0.9520    0.0     [0. 0.]\n",
            "9     503     0.9520    0.0     [0. 0.]\n",
            "10    422     0.9519    0.0     [0. 0.]\n",
            "[Epoch 6 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "=> Saved best checkpoint (epoch: 6, loss: 9.5170)\n",
            "\n",
            "[Top-k Label Logging] Epoch 7\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     113     0.9540    1.0     [1. 0.]\n",
            "2     38      0.9539    0.0     [0. 0.]\n",
            "3     30      0.9538    0.0     [0. 0.]\n",
            "4     44      0.9538    0.0     [0. 0.]\n",
            "5     39      0.9538    1.0     [1. 0.]\n",
            "6     97      0.9538    0.0     [0. 0.]\n",
            "7     25      0.9537    0.0     [0. 0.]\n",
            "8     1       0.9537    0.0     [0. 0.]\n",
            "9     59      0.9537    1.0     [1. 0.]\n",
            "10    119     0.9536    0.0     [0. 0.]\n",
            "[Epoch 7 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "=> Saved best checkpoint (epoch: 7, loss: 9.4281)\n",
            "\n",
            "[Top-k Label Logging] Epoch 8\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     292     0.9642    0.0     [0. 0.]\n",
            "2     258     0.9641    0.0     [0. 0.]\n",
            "3     293     0.9641    3.0     [1. 1.]\n",
            "4     128     0.9640    0.0     [0. 0.]\n",
            "5     138     0.9639    0.0     [0. 0.]\n",
            "6     276     0.9639    0.0     [0. 0.]\n",
            "7     318     0.9639    0.0     [0. 0.]\n",
            "8     283     0.9638    0.0     [0. 0.]\n",
            "9     341     0.9638    0.0     [0. 0.]\n",
            "10    298     0.9638    1.0     [1. 0.]\n",
            "[Epoch 8 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 9\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     46      0.9762    0.0     [0. 0.]\n",
            "2     105     0.9752    0.0     [0. 0.]\n",
            "3     110     0.9751    0.0     [0. 0.]\n",
            "4     64      0.9750    3.0     [1. 1.]\n",
            "5     95      0.9750    0.0     [0. 0.]\n",
            "6     24      0.9749    0.0     [0. 0.]\n",
            "7     56      0.9749    2.0     [0. 1.]\n",
            "8     79      0.9749    3.0     [1. 1.]\n",
            "9     37      0.9747    0.0     [0. 0.]\n",
            "10    80      0.9747    2.0     [0. 1.]\n",
            "[Epoch 9 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "=> Saved best checkpoint (epoch: 9, loss: 9.0813)\n",
            "\n",
            "[Top-k Label Logging] Epoch 10\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     317     0.9730    0.0     [0. 0.]\n",
            "2     3       0.9729    0.0     [0. 0.]\n",
            "3     368     0.9727    0.0     [0. 0.]\n",
            "4     71      0.9726    0.0     [0. 0.]\n",
            "5     10      0.9725    1.0     [1. 0.]\n",
            "6     79      0.9725    1.0     [1. 0.]\n",
            "7     20      0.9724    0.0     [0. 0.]\n",
            "8     35      0.9724    1.0     [1. 0.]\n",
            "9     115     0.9724    0.0     [0. 0.]\n",
            "10    112     0.9724    2.0     [0. 1.]\n",
            "[Epoch 10 | Step 31] im_q: torch.Size([128, 1, 128, 42]), im_k: torch.Size([128, 1, 128, 42])\n",
            "=> Saved best checkpoint (epoch: 10, loss: 8.7629)\n",
            "\n",
            "[Top-k Label Logging] Epoch 11\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     113     0.9757    0.0     [0. 0.]\n",
            "2     508     0.9744    2.0     [0. 1.]\n",
            "3     57      0.9743    0.0     [0. 0.]\n",
            "4     91      0.9741    1.0     [1. 0.]\n",
            "5     437     0.9740    0.0     [0. 0.]\n",
            "6     313     0.9740    1.0     [1. 0.]\n",
            "7     0       0.9739    2.0     [0. 1.]\n",
            "8     11      0.9739    0.0     [0. 0.]\n",
            "9     403     0.9738    1.0     [1. 0.]\n",
            "10    61      0.9738    1.0     [1. 0.]\n",
            "[Epoch 11 | Step 31] im_q: torch.Size([128, 1, 128, 54]), im_k: torch.Size([128, 1, 128, 54])\n",
            "=> Saved best checkpoint (epoch: 11, loss: 8.5028)\n",
            "\n",
            "[Top-k Label Logging] Epoch 12\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     332     0.9688    0.0     [0. 0.]\n",
            "2     142     0.9683    0.0     [0. 0.]\n",
            "3     9       0.9671    2.0     [0. 1.]\n",
            "4     72      0.9670    0.0     [0. 0.]\n",
            "5     73      0.9670    3.0     [1. 1.]\n",
            "6     102     0.9670    1.0     [1. 0.]\n",
            "7     10      0.9668    0.0     [0. 0.]\n",
            "8     471     0.9667    2.0     [0. 1.]\n",
            "9     0       0.9666    2.0     [0. 1.]\n",
            "10    89      0.9664    1.0     [1. 0.]\n",
            "[Epoch 12 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 12, loss: 8.4831)\n",
            "\n",
            "[Top-k Label Logging] Epoch 13\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     6       0.9814    0.0     [0. 0.]\n",
            "2     450     0.9804    0.0     [0. 0.]\n",
            "3     63      0.9800    2.0     [0. 1.]\n",
            "4     96      0.9797    0.0     [0. 0.]\n",
            "5     59      0.9797    2.0     [0. 1.]\n",
            "6     49      0.9797    0.0     [0. 0.]\n",
            "7     0       0.9797    0.0     [0. 0.]\n",
            "8     98      0.9797    1.0     [1. 0.]\n",
            "9     53      0.9797    0.0     [0. 0.]\n",
            "10    36      0.9797    0.0     [0. 0.]\n",
            "[Epoch 13 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 14\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     503     0.9702    0.0     [0. 0.]\n",
            "2     69      0.9700    0.0     [0. 0.]\n",
            "3     56      0.9699    1.0     [1. 0.]\n",
            "4     89      0.9697    0.0     [0. 0.]\n",
            "5     53      0.9697    2.0     [0. 1.]\n",
            "6     70      0.9697    0.0     [0. 0.]\n",
            "7     412     0.9697    0.0     [0. 0.]\n",
            "8     449     0.9697    0.0     [0. 0.]\n",
            "9     13      0.9697    0.0     [0. 0.]\n",
            "10    425     0.9696    0.0     [0. 0.]\n",
            "[Epoch 14 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 15\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     454     0.9631    3.0     [1. 1.]\n",
            "2     490     0.9631    1.0     [1. 0.]\n",
            "3     67      0.9629    0.0     [0. 0.]\n",
            "4     259     0.9628    1.0     [1. 0.]\n",
            "5     9       0.9628    0.0     [0. 0.]\n",
            "6     118     0.9627    1.0     [1. 0.]\n",
            "7     424     0.9627    1.0     [1. 0.]\n",
            "8     319     0.9625    0.0     [0. 0.]\n",
            "9     480     0.9624    0.0     [0. 0.]\n",
            "10    7       0.9624    1.0     [1. 0.]\n",
            "[Epoch 15 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 15, loss: 8.1490)\n",
            "\n",
            "[Top-k Label Logging] Epoch 16\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     22      0.9823    2.0     [0. 1.]\n",
            "2     419     0.9815    0.0     [0. 0.]\n",
            "3     415     0.9814    0.0     [0. 0.]\n",
            "4     78      0.9812    1.0     [1. 0.]\n",
            "5     147     0.9799    0.0     [0. 0.]\n",
            "6     85      0.9798    1.0     [1. 0.]\n",
            "7     116     0.9795    0.0     [0. 0.]\n",
            "8     266     0.9795    0.0     [0. 0.]\n",
            "9     243     0.9795    2.0     [0. 1.]\n",
            "10    33      0.9795    1.0     [1. 0.]\n",
            "[Epoch 16 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "=> Saved best checkpoint (epoch: 16, loss: 8.0488)\n",
            "\n",
            "[Top-k Label Logging] Epoch 17\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     79      0.9774    0.0     [0. 0.]\n",
            "2     101     0.9773    0.0     [0. 0.]\n",
            "3     70      0.9772    0.0     [0. 0.]\n",
            "4     115     0.9772    2.0     [0. 1.]\n",
            "5     22      0.9772    0.0     [0. 0.]\n",
            "6     110     0.9771    0.0     [0. 0.]\n",
            "7     2       0.9771    1.0     [1. 0.]\n",
            "8     54      0.9771    1.0     [1. 0.]\n",
            "9     111     0.9771    0.0     [0. 0.]\n",
            "10    32      0.9771    0.0     [0. 0.]\n",
            "[Epoch 17 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "=> Saved best checkpoint (epoch: 17, loss: 7.7622)\n",
            "\n",
            "[Top-k Label Logging] Epoch 18\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     437     0.9742    1.0     [1. 0.]\n",
            "2     130     0.9742    0.0     [0. 0.]\n",
            "3     393     0.9736    0.0     [0. 0.]\n",
            "4     55      0.9735    3.0     [1. 1.]\n",
            "5     66      0.9734    2.0     [0. 1.]\n",
            "6     434     0.9733    0.0     [0. 0.]\n",
            "7     9       0.9733    0.0     [0. 0.]\n",
            "8     186     0.9732    0.0     [0. 0.]\n",
            "9     0       0.9732    3.0     [1. 1.]\n",
            "10    189     0.9732    0.0     [0. 0.]\n",
            "[Epoch 18 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 19\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     65      0.9761    0.0     [0. 0.]\n",
            "2     501     0.9745    0.0     [0. 0.]\n",
            "3     25      0.9740    2.0     [0. 1.]\n",
            "4     408     0.9738    2.0     [0. 1.]\n",
            "5     34      0.9736    0.0     [0. 0.]\n",
            "6     84      0.9736    0.0     [0. 0.]\n",
            "7     32      0.9736    1.0     [1. 0.]\n",
            "8     92      0.9736    2.0     [0. 1.]\n",
            "9     87      0.9735    1.0     [1. 0.]\n",
            "10    478     0.9735    1.0     [1. 0.]\n",
            "[Epoch 19 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 20\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     317     0.9789    1.0     [1. 0.]\n",
            "2     152     0.9759    3.0     [1. 1.]\n",
            "3     272     0.9757    1.0     [1. 0.]\n",
            "4     0       0.9756    0.0     [0. 0.]\n",
            "5     266     0.9730    2.0     [0. 1.]\n",
            "6     361     0.9728    0.0     [0. 0.]\n",
            "7     488     0.9724    0.0     [0. 0.]\n",
            "8     86      0.9724    1.0     [1. 0.]\n",
            "9     1       0.9724    0.0     [0. 0.]\n",
            "10    73      0.9723    0.0     [0. 0.]\n",
            "[Epoch 20 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "=> Saved best checkpoint (epoch: 20, loss: 7.6769)\n",
            "\n",
            "[Top-k Label Logging] Epoch 21\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     494     0.9855    3.0     [1. 1.]\n",
            "2     88      0.9853    0.0     [0. 0.]\n",
            "3     30      0.9852    1.0     [1. 0.]\n",
            "4     46      0.9850    0.0     [0. 0.]\n",
            "5     31      0.9850    3.0     [1. 1.]\n",
            "6     84      0.9849    3.0     [1. 1.]\n",
            "7     422     0.9849    2.0     [0. 1.]\n",
            "8     81      0.9849    0.0     [0. 0.]\n",
            "9     82      0.9849    3.0     [1. 1.]\n",
            "10    317     0.9848    2.0     [0. 1.]\n",
            "[Epoch 21 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 22\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     159     0.9845    3.0     [1. 1.]\n",
            "2     10      0.9841    1.0     [1. 0.]\n",
            "3     118     0.9840    0.0     [0. 0.]\n",
            "4     95      0.9839    0.0     [0. 0.]\n",
            "5     341     0.9838    1.0     [1. 0.]\n",
            "6     314     0.9838    0.0     [0. 0.]\n",
            "7     20      0.9837    1.0     [1. 0.]\n",
            "8     22      0.9837    0.0     [0. 0.]\n",
            "9     14      0.9837    2.0     [0. 1.]\n",
            "10    470     0.9835    2.0     [0. 1.]\n",
            "[Epoch 22 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 23\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     176     0.9837    0.0     [0. 0.]\n",
            "2     443     0.9825    1.0     [1. 0.]\n",
            "3     370     0.9825    1.0     [1. 0.]\n",
            "4     150     0.9824    2.0     [0. 1.]\n",
            "5     248     0.9824    0.0     [0. 0.]\n",
            "6     191     0.9823    1.0     [1. 0.]\n",
            "7     34      0.9823    0.0     [0. 0.]\n",
            "8     424     0.9822    0.0     [0. 0.]\n",
            "9     25      0.9822    1.0     [1. 0.]\n",
            "10    319     0.9821    0.0     [0. 0.]\n",
            "[Epoch 23 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 24\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     61      0.9540    0.0     [0. 0.]\n",
            "2     70      0.9537    2.0     [0. 1.]\n",
            "3     264     0.9535    0.0     [0. 0.]\n",
            "4     83      0.9535    0.0     [0. 0.]\n",
            "5     481     0.9534    0.0     [0. 0.]\n",
            "6     8       0.9533    0.0     [0. 0.]\n",
            "7     406     0.9533    2.0     [0. 1.]\n",
            "8     463     0.9533    0.0     [0. 0.]\n",
            "9     84      0.9533    0.0     [0. 0.]\n",
            "10    14      0.9532    0.0     [0. 0.]\n",
            "[Epoch 24 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 25\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     46      0.9560    0.0     [0. 0.]\n",
            "2     126     0.9559    0.0     [0. 0.]\n",
            "3     23      0.9552    0.0     [0. 0.]\n",
            "4     118     0.9552    1.0     [1. 0.]\n",
            "5     30      0.9551    0.0     [0. 0.]\n",
            "6     41      0.9551    0.0     [0. 0.]\n",
            "7     25      0.9550    0.0     [0. 0.]\n",
            "8     76      0.9549    0.0     [0. 0.]\n",
            "9     64      0.9548    0.0     [0. 0.]\n",
            "10    32      0.9548    1.0     [1. 0.]\n",
            "[Epoch 25 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 26\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     262     0.9748    0.0     [0. 0.]\n",
            "2     50      0.9745    0.0     [0. 0.]\n",
            "3     90      0.9733    1.0     [1. 0.]\n",
            "4     479     0.9725    3.0     [1. 1.]\n",
            "5     96      0.9723    1.0     [1. 0.]\n",
            "6     32      0.9722    2.0     [0. 1.]\n",
            "7     433     0.9719    1.0     [1. 0.]\n",
            "8     191     0.9718    1.0     [1. 0.]\n",
            "9     140     0.9712    3.0     [1. 1.]\n",
            "10    312     0.9711    2.0     [0. 1.]\n",
            "[Epoch 26 | Step 31] im_q: torch.Size([128, 1, 128, 59]), im_k: torch.Size([128, 1, 128, 59])\n",
            "\n",
            "[Top-k Label Logging] Epoch 27\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     40      0.9750    1.0     [1. 0.]\n",
            "2     53      0.9745    0.0     [0. 0.]\n",
            "3     34      0.9741    2.0     [0. 1.]\n",
            "4     118     0.9740    1.0     [1. 0.]\n",
            "5     110     0.9738    1.0     [1. 0.]\n",
            "6     379     0.9738    1.0     [1. 0.]\n",
            "7     291     0.9738    0.0     [0. 0.]\n",
            "8     85      0.9738    1.0     [1. 0.]\n",
            "9     456     0.9737    1.0     [1. 0.]\n",
            "10    82      0.9737    1.0     [1. 0.]\n",
            "[Epoch 27 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 28\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     490     0.9624    3.0     [1. 1.]\n",
            "2     217     0.9621    0.0     [0. 0.]\n",
            "3     453     0.9616    0.0     [0. 0.]\n",
            "4     37      0.9616    0.0     [0. 0.]\n",
            "5     67      0.9614    1.0     [1. 0.]\n",
            "6     0       0.9613    0.0     [0. 0.]\n",
            "7     370     0.9612    0.0     [0. 0.]\n",
            "8     65      0.9611    0.0     [0. 0.]\n",
            "9     24      0.9609    1.0     [1. 0.]\n",
            "10    43      0.9607    2.0     [0. 1.]\n",
            "[Epoch 28 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 29\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     55      0.9687    1.0     [1. 0.]\n",
            "2     91      0.9683    2.0     [0. 1.]\n",
            "3     493     0.9682    0.0     [0. 0.]\n",
            "4     107     0.9682    2.0     [0. 1.]\n",
            "5     326     0.9678    2.0     [0. 1.]\n",
            "6     385     0.9677    0.0     [0. 0.]\n",
            "7     41      0.9677    3.0     [1. 1.]\n",
            "8     71      0.9676    1.0     [1. 0.]\n",
            "9     86      0.9673    0.0     [0. 0.]\n",
            "10    476     0.9673    0.0     [0. 0.]\n",
            "[Epoch 29 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 30\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     391     0.9744    0.0     [0. 0.]\n",
            "2     27      0.9736    0.0     [0. 0.]\n",
            "3     8       0.9732    3.0     [1. 1.]\n",
            "4     243     0.9731    0.0     [0. 0.]\n",
            "5     371     0.9730    0.0     [0. 0.]\n",
            "6     239     0.9728    0.0     [0. 0.]\n",
            "7     91      0.9726    1.0     [1. 0.]\n",
            "8     90      0.9725    0.0     [0. 0.]\n",
            "9     11      0.9723    1.0     [1. 0.]\n",
            "10    463     0.9723    0.0     [0. 0.]\n",
            "[Epoch 30 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 31\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     20      0.9664    0.0     [0. 0.]\n",
            "2     406     0.9663    0.0     [0. 0.]\n",
            "3     500     0.9660    1.0     [1. 0.]\n",
            "4     426     0.9659    0.0     [0. 0.]\n",
            "5     388     0.9657    0.0     [0. 0.]\n",
            "6     189     0.9657    2.0     [0. 1.]\n",
            "7     322     0.9655    0.0     [0. 0.]\n",
            "8     123     0.9654    3.0     [1. 1.]\n",
            "9     429     0.9653    0.0     [0. 0.]\n",
            "10    391     0.9653    0.0     [0. 0.]\n",
            "[Epoch 31 | Step 31] im_q: torch.Size([128, 1, 128, 45]), im_k: torch.Size([128, 1, 128, 45])\n",
            "\n",
            "[Top-k Label Logging] Epoch 32\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     142     0.9444    1.0     [1. 0.]\n",
            "2     71      0.9439    0.0     [0. 0.]\n",
            "3     7       0.9438    1.0     [1. 0.]\n",
            "4     50      0.9435    0.0     [0. 0.]\n",
            "5     251     0.9434    0.0     [0. 0.]\n",
            "6     65      0.9434    0.0     [0. 0.]\n",
            "7     91      0.9434    1.0     [1. 0.]\n",
            "8     410     0.9434    0.0     [0. 0.]\n",
            "9     79      0.9433    1.0     [1. 0.]\n",
            "10    414     0.9432    0.0     [0. 0.]\n",
            "[Epoch 32 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 33\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     10      0.9338    0.0     [0. 0.]\n",
            "2     395     0.9335    0.0     [0. 0.]\n",
            "3     97      0.9312    0.0     [0. 0.]\n",
            "4     367     0.9305    0.0     [0. 0.]\n",
            "5     155     0.9301    0.0     [0. 0.]\n",
            "6     109     0.9299    0.0     [0. 0.]\n",
            "7     505     0.9297    1.0     [1. 0.]\n",
            "8     383     0.9290    0.0     [0. 0.]\n",
            "9     504     0.9287    3.0     [1. 1.]\n",
            "10    76      0.9283    0.0     [0. 0.]\n",
            "[Epoch 33 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 34\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     36      0.9242    1.0     [1. 0.]\n",
            "2     63      0.9236    0.0     [0. 0.]\n",
            "3     478     0.9234    0.0     [0. 0.]\n",
            "4     96      0.9234    2.0     [0. 1.]\n",
            "5     29      0.9230    1.0     [1. 0.]\n",
            "6     3       0.9228    0.0     [0. 0.]\n",
            "7     12      0.9226    1.0     [1. 0.]\n",
            "8     8       0.9226    0.0     [0. 0.]\n",
            "9     2       0.9225    1.0     [1. 0.]\n",
            "10    112     0.9225    0.0     [0. 0.]\n",
            "[Epoch 34 | Step 31] im_q: torch.Size([128, 1, 128, 48]), im_k: torch.Size([128, 1, 128, 48])\n",
            "\n",
            "[Top-k Label Logging] Epoch 35\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     41      0.9294    0.0     [0. 0.]\n",
            "2     406     0.9288    1.0     [1. 0.]\n",
            "3     426     0.9287    2.0     [0. 1.]\n",
            "4     12      0.9284    1.0     [1. 0.]\n",
            "5     418     0.9282    2.0     [0. 1.]\n",
            "6     110     0.9281    0.0     [0. 0.]\n",
            "7     66      0.9281    0.0     [0. 0.]\n",
            "8     509     0.9281    1.0     [1. 0.]\n",
            "9     39      0.9280    3.0     [1. 1.]\n",
            "10    98      0.9280    1.0     [1. 0.]\n",
            "[Epoch 35 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 36\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     22      0.9215    1.0     [1. 0.]\n",
            "2     92      0.9211    0.0     [0. 0.]\n",
            "3     285     0.9210    0.0     [0. 0.]\n",
            "4     421     0.9208    0.0     [0. 0.]\n",
            "5     103     0.9208    0.0     [0. 0.]\n",
            "6     109     0.9199    0.0     [0. 0.]\n",
            "7     40      0.9199    1.0     [1. 0.]\n",
            "8     74      0.9199    2.0     [0. 1.]\n",
            "9     52      0.9199    0.0     [0. 0.]\n",
            "10    15      0.9197    1.0     [1. 0.]\n",
            "[Epoch 36 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 37\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     58      0.9033    0.0     [0. 0.]\n",
            "2     405     0.9028    2.0     [0. 1.]\n",
            "3     106     0.9027    0.0     [0. 0.]\n",
            "4     91      0.9026    1.0     [1. 0.]\n",
            "5     495     0.9023    0.0     [0. 0.]\n",
            "6     81      0.9019    1.0     [1. 0.]\n",
            "7     76      0.9018    0.0     [0. 0.]\n",
            "8     109     0.9016    1.0     [1. 0.]\n",
            "9     59      0.9016    0.0     [0. 0.]\n",
            "10    477     0.9015    1.0     [1. 0.]\n",
            "[Epoch 37 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 38\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     340     0.9330    0.0     [0. 0.]\n",
            "2     44      0.9299    0.0     [0. 0.]\n",
            "3     115     0.9299    0.0     [0. 0.]\n",
            "4     126     0.9286    0.0     [0. 0.]\n",
            "5     67      0.9283    3.0     [1. 1.]\n",
            "6     125     0.9282    1.0     [1. 0.]\n",
            "7     9       0.9278    2.0     [0. 1.]\n",
            "8     120     0.9276    0.0     [0. 0.]\n",
            "9     11      0.9276    0.0     [0. 0.]\n",
            "10    57      0.9275    0.0     [0. 0.]\n",
            "[Epoch 38 | Step 31] im_q: torch.Size([128, 1, 128, 51]), im_k: torch.Size([128, 1, 128, 51])\n",
            "\n",
            "[Top-k Label Logging] Epoch 39\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     154     0.9473    0.0     [0. 0.]\n",
            "2     141     0.9472    2.0     [0. 1.]\n",
            "3     122     0.9465    1.0     [1. 0.]\n",
            "4     75      0.9464    1.0     [1. 0.]\n",
            "5     463     0.9464    0.0     [0. 0.]\n",
            "6     53      0.9462    1.0     [1. 0.]\n",
            "7     35      0.9462    2.0     [0. 1.]\n",
            "8     65      0.9461    0.0     [0. 0.]\n",
            "9     364     0.9460    0.0     [0. 0.]\n",
            "10    82      0.9460    0.0     [0. 0.]\n",
            "[Epoch 39 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 40\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     94      0.9629    0.0     [0. 0.]\n",
            "2     154     0.9570    0.0     [0. 0.]\n",
            "3     488     0.9545    0.0     [0. 0.]\n",
            "4     195     0.9544    0.0     [0. 0.]\n",
            "5     393     0.9542    0.0     [0. 0.]\n",
            "6     494     0.9541    3.0     [1. 1.]\n",
            "7     442     0.9539    2.0     [0. 1.]\n",
            "8     120     0.9532    1.0     [1. 0.]\n",
            "9     74      0.9527    1.0     [1. 0.]\n",
            "10    407     0.9526    1.0     [1. 0.]\n",
            "[Epoch 40 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 41\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     461     0.9748    0.0     [0. 0.]\n",
            "2     449     0.9724    0.0     [0. 0.]\n",
            "3     502     0.9715    0.0     [0. 0.]\n",
            "4     261     0.9697    0.0     [0. 0.]\n",
            "5     472     0.9687    0.0     [0. 0.]\n",
            "6     358     0.9681    0.0     [0. 0.]\n",
            "7     0       0.9680    0.0     [0. 0.]\n",
            "8     135     0.9678    0.0     [0. 0.]\n",
            "9     89      0.9676    0.0     [0. 0.]\n",
            "10    505     0.9673    3.0     [1. 1.]\n",
            "[Epoch 41 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 42\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     364     0.9806    0.0     [0. 0.]\n",
            "2     67      0.9790    1.0     [1. 0.]\n",
            "3     9       0.9789    0.0     [0. 0.]\n",
            "4     83      0.9787    3.0     [1. 1.]\n",
            "5     202     0.9784    1.0     [1. 0.]\n",
            "6     0       0.9780    1.0     [1. 0.]\n",
            "7     452     0.9776    0.0     [0. 0.]\n",
            "8     37      0.9776    0.0     [0. 0.]\n",
            "9     281     0.9774    1.0     [1. 0.]\n",
            "10    78      0.9772    1.0     [1. 0.]\n",
            "[Epoch 42 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 43\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     261     0.9915    3.0     [1. 1.]\n",
            "2     144     0.9913    1.0     [1. 0.]\n",
            "3     453     0.9895    1.0     [1. 0.]\n",
            "4     308     0.9894    0.0     [0. 0.]\n",
            "5     26      0.9892    0.0     [0. 0.]\n",
            "6     240     0.9890    3.0     [1. 1.]\n",
            "7     254     0.9888    2.0     [0. 1.]\n",
            "8     388     0.9888    0.0     [0. 0.]\n",
            "9     147     0.9887    0.0     [0. 0.]\n",
            "10    503     0.9885    1.0     [1. 0.]\n",
            "[Epoch 43 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 44\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     181     0.9801    3.0     [1. 1.]\n",
            "2     120     0.9796    0.0     [0. 0.]\n",
            "3     384     0.9795    1.0     [1. 0.]\n",
            "4     278     0.9794    2.0     [0. 1.]\n",
            "5     14      0.9793    1.0     [1. 0.]\n",
            "6     79      0.9793    1.0     [1. 0.]\n",
            "7     303     0.9786    1.0     [1. 0.]\n",
            "8     190     0.9781    1.0     [1. 0.]\n",
            "9     6       0.9780    1.0     [1. 0.]\n",
            "10    274     0.9776    0.0     [0. 0.]\n",
            "[Epoch 44 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 45\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     359     0.9845    0.0     [0. 0.]\n",
            "2     468     0.9843    3.0     [1. 1.]\n",
            "3     248     0.9832    1.0     [1. 0.]\n",
            "4     370     0.9825    1.0     [1. 0.]\n",
            "5     209     0.9823    0.0     [0. 0.]\n",
            "6     99      0.9821    0.0     [0. 0.]\n",
            "7     24      0.9820    0.0     [0. 0.]\n",
            "8     17      0.9818    0.0     [0. 0.]\n",
            "9     6       0.9817    2.0     [0. 1.]\n",
            "10    499     0.9816    0.0     [0. 0.]\n",
            "[Epoch 45 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 46\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     106     0.9842    0.0     [0. 0.]\n",
            "2     436     0.9833    1.0     [1. 0.]\n",
            "3     404     0.9832    1.0     [1. 0.]\n",
            "4     424     0.9828    0.0     [0. 0.]\n",
            "5     179     0.9827    1.0     [1. 0.]\n",
            "6     16      0.9823    0.0     [0. 0.]\n",
            "7     374     0.9823    1.0     [1. 0.]\n",
            "8     68      0.9820    0.0     [0. 0.]\n",
            "9     247     0.9819    1.0     [1. 0.]\n",
            "10    79      0.9817    2.0     [0. 1.]\n",
            "[Epoch 46 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 47\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     279     0.9862    0.0     [0. 0.]\n",
            "2     493     0.9861    0.0     [0. 0.]\n",
            "3     349     0.9857    0.0     [0. 0.]\n",
            "4     330     0.9856    1.0     [1. 0.]\n",
            "5     212     0.9856    0.0     [0. 0.]\n",
            "6     443     0.9855    0.0     [0. 0.]\n",
            "7     73      0.9854    1.0     [1. 0.]\n",
            "8     238     0.9854    0.0     [0. 0.]\n",
            "9     29      0.9854    0.0     [0. 0.]\n",
            "10    1       0.9854    1.0     [1. 0.]\n",
            "[Epoch 47 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 48\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     390     0.9899    1.0     [1. 0.]\n",
            "2     268     0.9898    0.0     [0. 0.]\n",
            "3     53      0.9898    1.0     [1. 0.]\n",
            "4     213     0.9897    3.0     [1. 1.]\n",
            "5     3       0.9896    0.0     [0. 0.]\n",
            "6     460     0.9896    1.0     [1. 0.]\n",
            "7     33      0.9894    3.0     [1. 1.]\n",
            "8     295     0.9894    0.0     [0. 0.]\n",
            "9     28      0.9892    1.0     [1. 0.]\n",
            "10    119     0.9892    0.0     [0. 0.]\n",
            "[Epoch 48 | Step 31] im_q: torch.Size([128, 1, 128, 51]), im_k: torch.Size([128, 1, 128, 51])\n",
            "\n",
            "[Top-k Label Logging] Epoch 49\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     66      0.9808    1.0     [1. 0.]\n",
            "2     169     0.9806    1.0     [1. 0.]\n",
            "3     385     0.9805    1.0     [1. 0.]\n",
            "4     26      0.9804    0.0     [0. 0.]\n",
            "5     175     0.9803    0.0     [0. 0.]\n",
            "6     196     0.9803    2.0     [0. 1.]\n",
            "7     171     0.9803    2.0     [0. 1.]\n",
            "8     22      0.9803    1.0     [1. 0.]\n",
            "9     18      0.9801    1.0     [1. 0.]\n",
            "10    359     0.9801    1.0     [1. 0.]\n",
            "[Epoch 49 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 50\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     404     0.9813    1.0     [1. 0.]\n",
            "2     331     0.9810    1.0     [1. 0.]\n",
            "3     441     0.9809    0.0     [0. 0.]\n",
            "4     111     0.9809    2.0     [0. 1.]\n",
            "5     398     0.9808    1.0     [1. 0.]\n",
            "6     361     0.9808    1.0     [1. 0.]\n",
            "7     257     0.9806    0.0     [0. 0.]\n",
            "8     308     0.9806    0.0     [0. 0.]\n",
            "9     277     0.9805    0.0     [0. 0.]\n",
            "10    75      0.9804    0.0     [0. 0.]\n",
            "[Epoch 50 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 51\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     27      0.9906    0.0     [0. 0.]\n",
            "2     0       0.9905    2.0     [0. 1.]\n",
            "3     295     0.9905    0.0     [0. 0.]\n",
            "4     43      0.9905    1.0     [1. 0.]\n",
            "5     378     0.9904    3.0     [1. 1.]\n",
            "6     89      0.9903    0.0     [0. 0.]\n",
            "7     275     0.9903    2.0     [0. 1.]\n",
            "8     455     0.9902    2.0     [0. 1.]\n",
            "9     76      0.9901    0.0     [0. 0.]\n",
            "10    90      0.9900    2.0     [0. 1.]\n",
            "[Epoch 51 | Step 31] im_q: torch.Size([128, 1, 128, 59]), im_k: torch.Size([128, 1, 128, 59])\n",
            "\n",
            "[Top-k Label Logging] Epoch 52\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     20      0.9885    0.0     [0. 0.]\n",
            "2     493     0.9880    0.0     [0. 0.]\n",
            "3     2       0.9878    0.0     [0. 0.]\n",
            "4     253     0.9874    0.0     [0. 0.]\n",
            "5     453     0.9874    3.0     [1. 1.]\n",
            "6     86      0.9871    0.0     [0. 0.]\n",
            "7     358     0.9869    0.0     [0. 0.]\n",
            "8     364     0.9867    0.0     [0. 0.]\n",
            "9     303     0.9866    1.0     [1. 0.]\n",
            "10    507     0.9866    1.0     [1. 0.]\n",
            "[Epoch 52 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 53\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     206     0.9912    1.0     [1. 0.]\n",
            "2     390     0.9910    0.0     [0. 0.]\n",
            "3     306     0.9901    3.0     [1. 1.]\n",
            "4     462     0.9901    0.0     [0. 0.]\n",
            "5     293     0.9898    3.0     [1. 1.]\n",
            "6     443     0.9897    1.0     [1. 0.]\n",
            "7     316     0.9896    3.0     [1. 1.]\n",
            "8     311     0.9894    0.0     [0. 0.]\n",
            "9     290     0.9894    0.0     [0. 0.]\n",
            "10    249     0.9893    0.0     [0. 0.]\n",
            "[Epoch 53 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 54\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     81      0.9965    0.0     [0. 0.]\n",
            "2     278     0.9965    1.0     [1. 0.]\n",
            "3     50      0.9964    1.0     [1. 0.]\n",
            "4     25      0.9964    3.0     [1. 1.]\n",
            "5     19      0.9964    0.0     [0. 0.]\n",
            "6     110     0.9964    0.0     [0. 0.]\n",
            "7     219     0.9962    1.0     [1. 0.]\n",
            "8     118     0.9961    0.0     [0. 0.]\n",
            "9     492     0.9960    0.0     [0. 0.]\n",
            "10    27      0.9960    0.0     [0. 0.]\n",
            "[Epoch 54 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 55\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     80      0.9968    2.0     [0. 1.]\n",
            "2     398     0.9968    0.0     [0. 0.]\n",
            "3     16      0.9968    1.0     [1. 0.]\n",
            "4     15      0.9968    2.0     [0. 1.]\n",
            "5     343     0.9967    1.0     [1. 0.]\n",
            "6     43      0.9967    0.0     [0. 0.]\n",
            "7     0       0.9967    3.0     [1. 1.]\n",
            "8     466     0.9967    0.0     [0. 0.]\n",
            "9     62      0.9967    3.0     [1. 1.]\n",
            "10    413     0.9967    3.0     [1. 1.]\n",
            "[Epoch 55 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "=> Saved best checkpoint (epoch: 55, loss: 7.5595)\n",
            "\n",
            "[Top-k Label Logging] Epoch 56\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     427     0.9955    0.0     [0. 0.]\n",
            "2     493     0.9955    1.0     [1. 0.]\n",
            "3     437     0.9955    0.0     [0. 0.]\n",
            "4     32      0.9954    3.0     [1. 1.]\n",
            "5     481     0.9954    0.0     [0. 0.]\n",
            "6     496     0.9954    1.0     [1. 0.]\n",
            "7     434     0.9954    1.0     [1. 0.]\n",
            "8     80      0.9954    0.0     [0. 0.]\n",
            "9     510     0.9954    0.0     [0. 0.]\n",
            "10    35      0.9954    1.0     [1. 0.]\n",
            "[Epoch 56 | Step 31] im_q: torch.Size([128, 1, 128, 61]), im_k: torch.Size([128, 1, 128, 61])\n",
            "=> Saved best checkpoint (epoch: 56, loss: 7.5561)\n",
            "\n",
            "[Top-k Label Logging] Epoch 57\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     50      0.9889    2.0     [0. 1.]\n",
            "2     292     0.9888    3.0     [1. 1.]\n",
            "3     388     0.9888    1.0     [1. 0.]\n",
            "4     508     0.9887    2.0     [0. 1.]\n",
            "5     442     0.9887    1.0     [1. 0.]\n",
            "6     464     0.9887    1.0     [1. 0.]\n",
            "7     12      0.9887    0.0     [0. 0.]\n",
            "8     58      0.9887    0.0     [0. 0.]\n",
            "9     391     0.9887    1.0     [1. 0.]\n",
            "10    249     0.9887    1.0     [1. 0.]\n",
            "[Epoch 57 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "=> Saved best checkpoint (epoch: 57, loss: 7.5011)\n",
            "\n",
            "[Top-k Label Logging] Epoch 58\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     19      0.9911    0.0     [0. 0.]\n",
            "2     92      0.9911    0.0     [0. 0.]\n",
            "3     68      0.9910    0.0     [0. 0.]\n",
            "4     110     0.9910    1.0     [1. 0.]\n",
            "5     396     0.9910    1.0     [1. 0.]\n",
            "6     466     0.9909    3.0     [1. 1.]\n",
            "7     487     0.9909    2.0     [0. 1.]\n",
            "8     288     0.9909    0.0     [0. 0.]\n",
            "9     129     0.9908    0.0     [0. 0.]\n",
            "10    477     0.9908    0.0     [0. 0.]\n",
            "[Epoch 58 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 59\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     467     0.9953    0.0     [0. 0.]\n",
            "2     50      0.9951    0.0     [0. 0.]\n",
            "3     16      0.9949    1.0     [1. 0.]\n",
            "4     2       0.9949    0.0     [0. 0.]\n",
            "5     457     0.9948    0.0     [0. 0.]\n",
            "6     394     0.9947    0.0     [0. 0.]\n",
            "7     14      0.9947    1.0     [1. 0.]\n",
            "8     131     0.9947    1.0     [1. 0.]\n",
            "9     91      0.9946    1.0     [1. 0.]\n",
            "10    62      0.9945    1.0     [1. 0.]\n",
            "[Epoch 59 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 60\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     462     0.9963    0.0     [0. 0.]\n",
            "2     52      0.9963    2.0     [0. 1.]\n",
            "3     433     0.9962    0.0     [0. 0.]\n",
            "4     141     0.9961    0.0     [0. 0.]\n",
            "5     15      0.9961    1.0     [1. 0.]\n",
            "6     282     0.9961    1.0     [1. 0.]\n",
            "7     427     0.9961    1.0     [1. 0.]\n",
            "8     163     0.9961    1.0     [1. 0.]\n",
            "9     455     0.9961    1.0     [1. 0.]\n",
            "10    129     0.9960    0.0     [0. 0.]\n",
            "[Epoch 60 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "=> Saved best checkpoint (epoch: 60, loss: 7.4494)\n",
            "\n",
            "[Top-k Label Logging] Epoch 61\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     34      0.9970    0.0     [0. 0.]\n",
            "2     473     0.9970    0.0     [0. 0.]\n",
            "3     36      0.9969    0.0     [0. 0.]\n",
            "4     108     0.9969    0.0     [0. 0.]\n",
            "5     109     0.9969    0.0     [0. 0.]\n",
            "6     10      0.9969    0.0     [0. 0.]\n",
            "7     324     0.9969    2.0     [0. 1.]\n",
            "8     276     0.9969    0.0     [0. 0.]\n",
            "9     413     0.9969    0.0     [0. 0.]\n",
            "10    347     0.9969    0.0     [0. 0.]\n",
            "[Epoch 61 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 61, loss: 7.3550)\n",
            "\n",
            "[Top-k Label Logging] Epoch 62\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     437     0.9971    0.0     [0. 0.]\n",
            "2     493     0.9971    0.0     [0. 0.]\n",
            "3     385     0.9971    2.0     [0. 1.]\n",
            "4     176     0.9971    0.0     [0. 0.]\n",
            "5     459     0.9971    0.0     [0. 0.]\n",
            "6     105     0.9971    3.0     [1. 1.]\n",
            "7     232     0.9971    2.0     [0. 1.]\n",
            "8     461     0.9971    3.0     [1. 1.]\n",
            "9     29      0.9970    2.0     [0. 1.]\n",
            "10    30      0.9970    2.0     [0. 1.]\n",
            "[Epoch 62 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 63\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     222     0.9886    0.0     [0. 0.]\n",
            "2     5       0.9880    1.0     [1. 0.]\n",
            "3     145     0.9878    2.0     [0. 1.]\n",
            "4     183     0.9878    1.0     [1. 0.]\n",
            "5     8       0.9878    0.0     [0. 0.]\n",
            "6     16      0.9877    3.0     [1. 1.]\n",
            "7     118     0.9877    0.0     [0. 0.]\n",
            "8     42      0.9877    2.0     [0. 1.]\n",
            "9     196     0.9877    1.0     [1. 0.]\n",
            "10    282     0.9877    0.0     [0. 0.]\n",
            "[Epoch 63 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 64\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     418     0.9872    0.0     [0. 0.]\n",
            "2     384     0.9872    0.0     [0. 0.]\n",
            "3     476     0.9872    3.0     [1. 1.]\n",
            "4     431     0.9871    1.0     [1. 0.]\n",
            "5     509     0.9871    0.0     [0. 0.]\n",
            "6     423     0.9871    0.0     [0. 0.]\n",
            "7     447     0.9870    0.0     [0. 0.]\n",
            "8     70      0.9866    1.0     [1. 0.]\n",
            "9     441     0.9863    0.0     [0. 0.]\n",
            "10    470     0.9863    2.0     [0. 1.]\n",
            "[Epoch 64 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 64, loss: 7.2771)\n",
            "\n",
            "[Top-k Label Logging] Epoch 65\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     294     0.9882    0.0     [0. 0.]\n",
            "2     95      0.9882    0.0     [0. 0.]\n",
            "3     6       0.9880    1.0     [1. 0.]\n",
            "4     454     0.9876    3.0     [1. 1.]\n",
            "5     178     0.9876    0.0     [0. 0.]\n",
            "6     354     0.9875    3.0     [1. 1.]\n",
            "7     99      0.9874    2.0     [0. 1.]\n",
            "8     119     0.9874    0.0     [0. 0.]\n",
            "9     2       0.9874    0.0     [0. 0.]\n",
            "10    96      0.9873    2.0     [0. 1.]\n",
            "[Epoch 65 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 66\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     362     0.9934    1.0     [1. 0.]\n",
            "2     39      0.9929    1.0     [1. 0.]\n",
            "3     395     0.9926    1.0     [1. 0.]\n",
            "4     310     0.9925    3.0     [1. 1.]\n",
            "5     116     0.9923    1.0     [1. 0.]\n",
            "6     426     0.9921    1.0     [1. 0.]\n",
            "7     237     0.9918    1.0     [1. 0.]\n",
            "8     150     0.9913    1.0     [1. 0.]\n",
            "9     451     0.9911    0.0     [0. 0.]\n",
            "10    292     0.9911    1.0     [1. 0.]\n",
            "[Epoch 66 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 67\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     11      0.9968    2.0     [0. 1.]\n",
            "2     433     0.9968    0.0     [0. 0.]\n",
            "3     135     0.9968    2.0     [0. 1.]\n",
            "4     474     0.9968    1.0     [1. 0.]\n",
            "5     422     0.9968    0.0     [0. 0.]\n",
            "6     326     0.9968    0.0     [0. 0.]\n",
            "7     432     0.9968    0.0     [0. 0.]\n",
            "8     404     0.9968    0.0     [0. 0.]\n",
            "9     1       0.9968    0.0     [0. 0.]\n",
            "10    511     0.9968    0.0     [0. 0.]\n",
            "[Epoch 67 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "=> Saved best checkpoint (epoch: 67, loss: 7.2597)\n",
            "\n",
            "[Top-k Label Logging] Epoch 68\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     510     0.9969    2.0     [0. 1.]\n",
            "2     156     0.9968    0.0     [0. 0.]\n",
            "3     42      0.9968    0.0     [0. 0.]\n",
            "4     114     0.9968    3.0     [1. 1.]\n",
            "5     379     0.9968    0.0     [0. 0.]\n",
            "6     348     0.9968    1.0     [1. 0.]\n",
            "7     345     0.9968    0.0     [0. 0.]\n",
            "8     434     0.9968    1.0     [1. 0.]\n",
            "9     173     0.9968    2.0     [0. 1.]\n",
            "10    123     0.9968    0.0     [0. 0.]\n",
            "[Epoch 68 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "=> Saved best checkpoint (epoch: 68, loss: 7.1376)\n",
            "\n",
            "[Top-k Label Logging] Epoch 69\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     250     0.9967    2.0     [0. 1.]\n",
            "2     260     0.9967    0.0     [0. 0.]\n",
            "3     160     0.9967    1.0     [1. 0.]\n",
            "4     317     0.9966    0.0     [0. 0.]\n",
            "5     140     0.9966    2.0     [0. 1.]\n",
            "6     301     0.9966    1.0     [1. 0.]\n",
            "7     242     0.9966    2.0     [0. 1.]\n",
            "8     457     0.9965    1.0     [1. 0.]\n",
            "9     138     0.9965    0.0     [0. 0.]\n",
            "10    452     0.9965    1.0     [1. 0.]\n",
            "[Epoch 69 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 70\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     84      0.9963    1.0     [1. 0.]\n",
            "2     470     0.9962    0.0     [0. 0.]\n",
            "3     429     0.9962    0.0     [0. 0.]\n",
            "4     130     0.9962    1.0     [1. 0.]\n",
            "5     202     0.9962    0.0     [0. 0.]\n",
            "6     46      0.9961    1.0     [1. 0.]\n",
            "7     500     0.9961    0.0     [0. 0.]\n",
            "8     243     0.9960    2.0     [0. 1.]\n",
            "9     138     0.9960    0.0     [0. 0.]\n",
            "10    305     0.9960    1.0     [1. 0.]\n",
            "[Epoch 70 | Step 31] im_q: torch.Size([128, 1, 128, 47]), im_k: torch.Size([128, 1, 128, 47])\n",
            "\n",
            "[Top-k Label Logging] Epoch 71\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     466     0.9973    0.0     [0. 0.]\n",
            "2     132     0.9972    1.0     [1. 0.]\n",
            "3     219     0.9971    2.0     [0. 1.]\n",
            "4     289     0.9970    1.0     [1. 0.]\n",
            "5     70      0.9970    0.0     [0. 0.]\n",
            "6     385     0.9970    1.0     [1. 0.]\n",
            "7     440     0.9970    1.0     [1. 0.]\n",
            "8     333     0.9969    0.0     [0. 0.]\n",
            "9     441     0.9969    0.0     [0. 0.]\n",
            "10    334     0.9969    0.0     [0. 0.]\n",
            "[Epoch 71 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 72\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     397     0.9880    3.0     [1. 1.]\n",
            "2     278     0.9880    3.0     [1. 1.]\n",
            "3     47      0.9878    1.0     [1. 0.]\n",
            "4     259     0.9876    1.0     [1. 0.]\n",
            "5     150     0.9871    0.0     [0. 0.]\n",
            "6     396     0.9870    1.0     [1. 0.]\n",
            "7     125     0.9870    0.0     [0. 0.]\n",
            "8     455     0.9870    0.0     [0. 0.]\n",
            "9     88      0.9869    0.0     [0. 0.]\n",
            "10    379     0.9868    0.0     [0. 0.]\n",
            "[Epoch 72 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 73\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     91      0.9797    0.0     [0. 0.]\n",
            "2     86      0.9797    0.0     [0. 0.]\n",
            "3     16      0.9797    0.0     [0. 0.]\n",
            "4     426     0.9797    0.0     [0. 0.]\n",
            "5     424     0.9797    3.0     [1. 1.]\n",
            "6     403     0.9797    3.0     [1. 1.]\n",
            "7     422     0.9797    0.0     [0. 0.]\n",
            "8     301     0.9796    0.0     [0. 0.]\n",
            "9     350     0.9796    3.0     [1. 1.]\n",
            "10    271     0.9796    0.0     [0. 0.]\n",
            "[Epoch 73 | Step 31] im_q: torch.Size([128, 1, 128, 45]), im_k: torch.Size([128, 1, 128, 45])\n",
            "\n",
            "[Top-k Label Logging] Epoch 74\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     299     0.9664    0.0     [0. 0.]\n",
            "2     351     0.9662    0.0     [0. 0.]\n",
            "3     295     0.9662    1.0     [1. 0.]\n",
            "4     153     0.9660    3.0     [1. 1.]\n",
            "5     225     0.9659    1.0     [1. 0.]\n",
            "6     120     0.9653    0.0     [0. 0.]\n",
            "7     127     0.9652    0.0     [0. 0.]\n",
            "8     119     0.9652    2.0     [0. 1.]\n",
            "9     69      0.9651    0.0     [0. 0.]\n",
            "10    49      0.9651    0.0     [0. 0.]\n",
            "[Epoch 74 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 75\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     427     0.9697    1.0     [1. 0.]\n",
            "2     127     0.9694    0.0     [0. 0.]\n",
            "3     247     0.9693    2.0     [0. 1.]\n",
            "4     129     0.9690    0.0     [0. 0.]\n",
            "5     268     0.9689    3.0     [1. 1.]\n",
            "6     63      0.9688    1.0     [1. 0.]\n",
            "7     239     0.9687    2.0     [0. 1.]\n",
            "8     0       0.9686    1.0     [1. 0.]\n",
            "9     59      0.9686    0.0     [0. 0.]\n",
            "10    139     0.9685    0.0     [0. 0.]\n",
            "[Epoch 75 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 76\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     88      0.9638    2.0     [0. 1.]\n",
            "2     96      0.9636    3.0     [1. 1.]\n",
            "3     48      0.9635    3.0     [1. 1.]\n",
            "4     8       0.9635    3.0     [1. 1.]\n",
            "5     481     0.9634    0.0     [0. 0.]\n",
            "6     350     0.9634    2.0     [0. 1.]\n",
            "7     122     0.9634    1.0     [1. 0.]\n",
            "8     288     0.9634    3.0     [1. 1.]\n",
            "9     317     0.9634    0.0     [0. 0.]\n",
            "10    349     0.9633    2.0     [0. 1.]\n",
            "[Epoch 76 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 77\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     393     0.9645    1.0     [1. 0.]\n",
            "2     404     0.9644    1.0     [1. 0.]\n",
            "3     272     0.9644    0.0     [0. 0.]\n",
            "4     457     0.9643    0.0     [0. 0.]\n",
            "5     282     0.9641    1.0     [1. 0.]\n",
            "6     399     0.9640    1.0     [1. 0.]\n",
            "7     126     0.9640    1.0     [1. 0.]\n",
            "8     309     0.9638    1.0     [1. 0.]\n",
            "9     136     0.9638    3.0     [1. 1.]\n",
            "10    350     0.9637    0.0     [0. 0.]\n",
            "[Epoch 77 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 78\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     42      0.9783    1.0     [1. 0.]\n",
            "2     54      0.9774    2.0     [0. 1.]\n",
            "3     55      0.9770    1.0     [1. 0.]\n",
            "4     347     0.9770    1.0     [1. 0.]\n",
            "5     12      0.9761    1.0     [1. 0.]\n",
            "6     447     0.9760    1.0     [1. 0.]\n",
            "7     262     0.9760    1.0     [1. 0.]\n",
            "8     112     0.9759    3.0     [1. 1.]\n",
            "9     155     0.9758    1.0     [1. 0.]\n",
            "10    33      0.9758    1.0     [1. 0.]\n",
            "[Epoch 78 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 79\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     241     0.9768    0.0     [0. 0.]\n",
            "2     224     0.9768    2.0     [0. 1.]\n",
            "3     200     0.9767    1.0     [1. 0.]\n",
            "4     108     0.9763    3.0     [1. 1.]\n",
            "5     270     0.9763    1.0     [1. 0.]\n",
            "6     197     0.9762    2.0     [0. 1.]\n",
            "7     436     0.9761    1.0     [1. 0.]\n",
            "8     476     0.9760    0.0     [0. 0.]\n",
            "9     20      0.9759    3.0     [1. 1.]\n",
            "10    87      0.9758    1.0     [1. 0.]\n",
            "[Epoch 79 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "=> Saved best checkpoint (epoch: 79, loss: 7.1356)\n",
            "\n",
            "[Top-k Label Logging] Epoch 80\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     310     0.9847    0.0     [0. 0.]\n",
            "2     102     0.9831    0.0     [0. 0.]\n",
            "3     314     0.9831    0.0     [0. 0.]\n",
            "4     218     0.9826    0.0     [0. 0.]\n",
            "5     356     0.9825    3.0     [1. 1.]\n",
            "6     78      0.9823    0.0     [0. 0.]\n",
            "7     117     0.9822    0.0     [0. 0.]\n",
            "8     373     0.9821    2.0     [0. 1.]\n",
            "9     17      0.9819    1.0     [1. 0.]\n",
            "10    51      0.9818    0.0     [0. 0.]\n",
            "[Epoch 80 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "=> Saved best checkpoint (epoch: 80, loss: 7.0195)\n",
            "\n",
            "[Top-k Label Logging] Epoch 81\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     273     0.9849    0.0     [0. 0.]\n",
            "2     102     0.9845    0.0     [0. 0.]\n",
            "3     127     0.9845    0.0     [0. 0.]\n",
            "4     104     0.9844    0.0     [0. 0.]\n",
            "5     235     0.9844    3.0     [1. 1.]\n",
            "6     87      0.9844    0.0     [0. 0.]\n",
            "7     187     0.9844    3.0     [1. 1.]\n",
            "8     118     0.9844    2.0     [0. 1.]\n",
            "9     109     0.9844    2.0     [0. 1.]\n",
            "10    179     0.9844    0.0     [0. 0.]\n",
            "[Epoch 81 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 82\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     186     0.9846    0.0     [0. 0.]\n",
            "2     376     0.9845    2.0     [0. 1.]\n",
            "3     221     0.9844    3.0     [1. 1.]\n",
            "4     418     0.9844    0.0     [0. 0.]\n",
            "5     90      0.9841    0.0     [0. 0.]\n",
            "6     276     0.9835    3.0     [1. 1.]\n",
            "7     74      0.9832    0.0     [0. 0.]\n",
            "8     312     0.9831    0.0     [0. 0.]\n",
            "9     395     0.9831    3.0     [1. 1.]\n",
            "10    344     0.9830    1.0     [1. 0.]\n",
            "[Epoch 82 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 83\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     19      0.9846    0.0     [0. 0.]\n",
            "2     105     0.9844    3.0     [1. 1.]\n",
            "3     511     0.9843    0.0     [0. 0.]\n",
            "4     71      0.9843    0.0     [0. 0.]\n",
            "5     420     0.9842    0.0     [0. 0.]\n",
            "6     302     0.9842    0.0     [0. 0.]\n",
            "7     127     0.9841    0.0     [0. 0.]\n",
            "8     85      0.9841    0.0     [0. 0.]\n",
            "9     54      0.9840    0.0     [0. 0.]\n",
            "10    20      0.9840    0.0     [0. 0.]\n",
            "[Epoch 83 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 84\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     335     0.9862    0.0     [0. 0.]\n",
            "2     130     0.9852    0.0     [0. 0.]\n",
            "3     398     0.9846    0.0     [0. 0.]\n",
            "4     2       0.9846    0.0     [0. 0.]\n",
            "5     31      0.9845    0.0     [0. 0.]\n",
            "6     356     0.9845    0.0     [0. 0.]\n",
            "7     101     0.9845    2.0     [0. 1.]\n",
            "8     71      0.9845    0.0     [0. 0.]\n",
            "9     291     0.9845    0.0     [0. 0.]\n",
            "10    55      0.9845    3.0     [1. 1.]\n",
            "[Epoch 84 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 85\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     29      0.9872    0.0     [0. 0.]\n",
            "2     26      0.9853    0.0     [0. 0.]\n",
            "3     269     0.9853    0.0     [0. 0.]\n",
            "4     11      0.9849    0.0     [0. 0.]\n",
            "5     0       0.9849    3.0     [1. 1.]\n",
            "6     102     0.9849    0.0     [0. 0.]\n",
            "7     394     0.9849    2.0     [0. 1.]\n",
            "8     414     0.9849    1.0     [1. 0.]\n",
            "9     301     0.9848    1.0     [1. 0.]\n",
            "10    473     0.9848    0.0     [0. 0.]\n",
            "[Epoch 85 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 86\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       0.9901    0.0     [0. 0.]\n",
            "2     181     0.9901    0.0     [0. 0.]\n",
            "3     308     0.9893    0.0     [0. 0.]\n",
            "4     460     0.9887    0.0     [0. 0.]\n",
            "5     36      0.9885    2.0     [0. 1.]\n",
            "6     480     0.9883    0.0     [0. 0.]\n",
            "7     233     0.9879    0.0     [0. 0.]\n",
            "8     386     0.9877    0.0     [0. 0.]\n",
            "9     258     0.9876    2.0     [0. 1.]\n",
            "10    494     0.9874    0.0     [0. 0.]\n",
            "[Epoch 86 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 87\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     115     0.9926    1.0     [1. 0.]\n",
            "2     76      0.9921    1.0     [1. 0.]\n",
            "3     344     0.9921    1.0     [1. 0.]\n",
            "4     69      0.9914    1.0     [1. 0.]\n",
            "5     63      0.9914    3.0     [1. 1.]\n",
            "6     97      0.9913    2.0     [0. 1.]\n",
            "7     26      0.9910    1.0     [1. 0.]\n",
            "8     426     0.9909    2.0     [0. 1.]\n",
            "9     65      0.9909    0.0     [0. 0.]\n",
            "10    126     0.9907    0.0     [0. 0.]\n",
            "[Epoch 87 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 88\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     7       0.9956    0.0     [0. 0.]\n",
            "2     452     0.9942    0.0     [0. 0.]\n",
            "3     88      0.9936    0.0     [0. 0.]\n",
            "4     184     0.9936    0.0     [0. 0.]\n",
            "5     11      0.9933    1.0     [1. 0.]\n",
            "6     117     0.9933    0.0     [0. 0.]\n",
            "7     503     0.9932    0.0     [0. 0.]\n",
            "8     172     0.9932    0.0     [0. 0.]\n",
            "9     472     0.9931    1.0     [1. 0.]\n",
            "10    42      0.9931    1.0     [1. 0.]\n",
            "[Epoch 88 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 89\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     445     0.9979    0.0     [0. 0.]\n",
            "2     26      0.9967    1.0     [1. 0.]\n",
            "3     505     0.9966    0.0     [0. 0.]\n",
            "4     157     0.9964    1.0     [1. 0.]\n",
            "5     400     0.9962    0.0     [0. 0.]\n",
            "6     405     0.9961    3.0     [1. 1.]\n",
            "7     0       0.9960    0.0     [0. 0.]\n",
            "8     373     0.9960    0.0     [0. 0.]\n",
            "9     84      0.9959    3.0     [1. 1.]\n",
            "10    143     0.9958    0.0     [0. 0.]\n",
            "[Epoch 89 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 90\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     15      0.9983    2.0     [0. 1.]\n",
            "2     59      0.9983    1.0     [1. 0.]\n",
            "3     33      0.9983    0.0     [0. 0.]\n",
            "4     41      0.9983    2.0     [0. 1.]\n",
            "5     114     0.9983    0.0     [0. 0.]\n",
            "6     101     0.9983    0.0     [0. 0.]\n",
            "7     10      0.9982    3.0     [1. 1.]\n",
            "8     74      0.9982    2.0     [0. 1.]\n",
            "9     483     0.9982    2.0     [0. 1.]\n",
            "10    368     0.9982    0.0     [0. 0.]\n",
            "[Epoch 90 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 91\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     263     0.9983    0.0     [0. 0.]\n",
            "2     196     0.9983    3.0     [1. 1.]\n",
            "3     200     0.9983    1.0     [1. 0.]\n",
            "4     475     0.9982    1.0     [1. 0.]\n",
            "5     480     0.9982    0.0     [0. 0.]\n",
            "6     245     0.9981    2.0     [0. 1.]\n",
            "7     206     0.9981    0.0     [0. 0.]\n",
            "8     297     0.9981    0.0     [0. 0.]\n",
            "9     242     0.9980    0.0     [0. 0.]\n",
            "10    503     0.9980    1.0     [1. 0.]\n",
            "[Epoch 91 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 92\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     161     0.9978    1.0     [1. 0.]\n",
            "2     379     0.9976    1.0     [1. 0.]\n",
            "3     395     0.9976    0.0     [0. 0.]\n",
            "4     427     0.9971    0.0     [0. 0.]\n",
            "5     308     0.9970    3.0     [1. 1.]\n",
            "6     107     0.9970    0.0     [0. 0.]\n",
            "7     366     0.9969    0.0     [0. 0.]\n",
            "8     409     0.9969    0.0     [0. 0.]\n",
            "9     75      0.9969    1.0     [1. 0.]\n",
            "10    327     0.9968    0.0     [0. 0.]\n",
            "[Epoch 92 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 93\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     379     0.9984    1.0     [1. 0.]\n",
            "2     43      0.9984    2.0     [0. 1.]\n",
            "3     335     0.9984    0.0     [0. 0.]\n",
            "4     366     0.9984    0.0     [0. 0.]\n",
            "5     467     0.9984    3.0     [1. 1.]\n",
            "6     285     0.9984    0.0     [0. 0.]\n",
            "7     24      0.9984    0.0     [0. 0.]\n",
            "8     414     0.9984    1.0     [1. 0.]\n",
            "9     376     0.9984    0.0     [0. 0.]\n",
            "10    231     0.9984    2.0     [0. 1.]\n",
            "[Epoch 93 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 94\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       0.9988    0.0     [0. 0.]\n",
            "2     37      0.9975    0.0     [0. 0.]\n",
            "3     368     0.9974    0.0     [0. 0.]\n",
            "4     179     0.9971    1.0     [1. 0.]\n",
            "5     431     0.9970    0.0     [0. 0.]\n",
            "6     159     0.9968    1.0     [1. 0.]\n",
            "7     308     0.9967    0.0     [0. 0.]\n",
            "8     427     0.9967    1.0     [1. 0.]\n",
            "9     432     0.9966    0.0     [0. 0.]\n",
            "10    33      0.9965    0.0     [0. 0.]\n",
            "[Epoch 94 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 95\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     67      0.9987    2.0     [0. 1.]\n",
            "2     108     0.9986    0.0     [0. 0.]\n",
            "3     42      0.9986    2.0     [0. 1.]\n",
            "4     111     0.9986    0.0     [0. 0.]\n",
            "5     0       0.9986    0.0     [0. 0.]\n",
            "6     59      0.9986    3.0     [1. 1.]\n",
            "7     414     0.9986    0.0     [0. 0.]\n",
            "8     124     0.9986    0.0     [0. 0.]\n",
            "9     79      0.9986    2.0     [0. 1.]\n",
            "10    98      0.9986    2.0     [0. 1.]\n",
            "[Epoch 95 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 96\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     1       0.9998    3.0     [1. 1.]\n",
            "2     34      0.9998    0.0     [0. 0.]\n",
            "3     9       0.9998    0.0     [0. 0.]\n",
            "4     496     0.9998    3.0     [1. 1.]\n",
            "5     391     0.9998    1.0     [1. 0.]\n",
            "6     23      0.9998    1.0     [1. 0.]\n",
            "7     417     0.9998    1.0     [1. 0.]\n",
            "8     22      0.9998    0.0     [0. 0.]\n",
            "9     91      0.9998    0.0     [0. 0.]\n",
            "10    5       0.9998    0.0     [0. 0.]\n",
            "[Epoch 96 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 97\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     278     0.9999    0.0     [0. 0.]\n",
            "2     11      0.9999    0.0     [0. 0.]\n",
            "3     295     0.9994    0.0     [0. 0.]\n",
            "4     143     0.9991    1.0     [1. 0.]\n",
            "5     315     0.9988    0.0     [0. 0.]\n",
            "6     53      0.9987    3.0     [1. 1.]\n",
            "7     360     0.9984    0.0     [0. 0.]\n",
            "8     456     0.9984    2.0     [0. 1.]\n",
            "9     414     0.9984    0.0     [0. 0.]\n",
            "10    196     0.9984    1.0     [1. 0.]\n",
            "[Epoch 97 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 98\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     316     0.9979    0.0     [0. 0.]\n",
            "2     133     0.9978    0.0     [0. 0.]\n",
            "3     244     0.9977    3.0     [1. 1.]\n",
            "4     126     0.9977    3.0     [1. 1.]\n",
            "5     178     0.9975    0.0     [0. 0.]\n",
            "6     269     0.9974    1.0     [1. 0.]\n",
            "7     21      0.9972    2.0     [0. 1.]\n",
            "8     48      0.9971    0.0     [0. 0.]\n",
            "9     49      0.9970    0.0     [0. 0.]\n",
            "10    299     0.9969    1.0     [1. 0.]\n",
            "[Epoch 98 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 99\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     150     1.0000    2.0     [0. 1.]\n",
            "2     23      1.0000    3.0     [1. 1.]\n",
            "3     318     1.0000    1.0     [1. 0.]\n",
            "4     20      1.0000    2.0     [0. 1.]\n",
            "5     324     1.0000    0.0     [0. 0.]\n",
            "6     337     1.0000    0.0     [0. 0.]\n",
            "7     479     1.0000    2.0     [0. 1.]\n",
            "8     163     1.0000    2.0     [0. 1.]\n",
            "9     256     1.0000    0.0     [0. 0.]\n",
            "10    461     1.0000    2.0     [0. 1.]\n",
            "[Epoch 99 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "💾 Saved checkpoint to /home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp/shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020_099.pth.tar\n",
            "\n",
            "[Top-k Label Logging] Epoch 100\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     124     1.0000    0.0     [0. 0.]\n",
            "2     84      1.0000    0.0     [0. 0.]\n",
            "3     7       1.0000    0.0     [0. 0.]\n",
            "4     353     1.0000    0.0     [0. 0.]\n",
            "5     333     1.0000    0.0     [0. 0.]\n",
            "6     201     1.0000    2.0     [0. 1.]\n",
            "7     89      1.0000    2.0     [0. 1.]\n",
            "8     400     1.0000    2.0     [0. 1.]\n",
            "9     262     1.0000    0.0     [0. 0.]\n",
            "10    37      1.0000    3.0     [1. 1.]\n",
            "[Epoch 100 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 101\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     356     0.9986    0.0     [0. 0.]\n",
            "2     479     0.9982    0.0     [0. 0.]\n",
            "3     147     0.9980    0.0     [0. 0.]\n",
            "4     304     0.9980    1.0     [1. 0.]\n",
            "5     119     0.9980    0.0     [0. 0.]\n",
            "6     446     0.9980    0.0     [0. 0.]\n",
            "7     274     0.9980    0.0     [0. 0.]\n",
            "8     177     0.9980    0.0     [0. 0.]\n",
            "9     256     0.9980    0.0     [0. 0.]\n",
            "10    306     0.9979    0.0     [0. 0.]\n",
            "[Epoch 101 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 102\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     73      0.9997    1.0     [1. 0.]\n",
            "2     294     0.9997    0.0     [0. 0.]\n",
            "3     426     0.9997    0.0     [0. 0.]\n",
            "4     141     0.9996    0.0     [0. 0.]\n",
            "5     371     0.9994    3.0     [1. 1.]\n",
            "6     226     0.9993    3.0     [1. 1.]\n",
            "7     173     0.9992    2.0     [0. 1.]\n",
            "8     193     0.9989    0.0     [0. 0.]\n",
            "9     183     0.9988    3.0     [1. 1.]\n",
            "10    166     0.9987    2.0     [0. 1.]\n",
            "[Epoch 102 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 103\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     371     1.0000    2.0     [0. 1.]\n",
            "2     117     1.0000    2.0     [0. 1.]\n",
            "3     348     1.0000    1.0     [1. 0.]\n",
            "4     116     1.0000    0.0     [0. 0.]\n",
            "5     423     1.0000    1.0     [1. 0.]\n",
            "6     323     1.0000    0.0     [0. 0.]\n",
            "7     337     1.0000    2.0     [0. 1.]\n",
            "8     428     1.0000    0.0     [0. 0.]\n",
            "9     39      1.0000    0.0     [0. 0.]\n",
            "10    485     1.0000    0.0     [0. 0.]\n",
            "[Epoch 103 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 104\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     298     1.0000    0.0     [0. 0.]\n",
            "2     387     1.0000    2.0     [0. 1.]\n",
            "3     193     1.0000    3.0     [1. 1.]\n",
            "4     415     1.0000    2.0     [0. 1.]\n",
            "5     214     1.0000    3.0     [1. 1.]\n",
            "6     411     1.0000    1.0     [1. 0.]\n",
            "7     343     1.0000    2.0     [0. 1.]\n",
            "8     423     1.0000    0.0     [0. 0.]\n",
            "9     287     1.0000    0.0     [0. 0.]\n",
            "10    61      1.0000    0.0     [0. 0.]\n",
            "[Epoch 104 | Step 31] im_q: torch.Size([128, 1, 128, 51]), im_k: torch.Size([128, 1, 128, 51])\n",
            "\n",
            "[Top-k Label Logging] Epoch 105\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     95      0.9987    0.0     [0. 0.]\n",
            "2     395     0.9986    0.0     [0. 0.]\n",
            "3     99      0.9985    0.0     [0. 0.]\n",
            "4     487     0.9983    0.0     [0. 0.]\n",
            "5     165     0.9983    3.0     [1. 1.]\n",
            "6     26      0.9979    0.0     [0. 0.]\n",
            "7     453     0.9979    3.0     [1. 1.]\n",
            "8     282     0.9977    3.0     [1. 1.]\n",
            "9     396     0.9975    0.0     [0. 0.]\n",
            "10    335     0.9974    0.0     [0. 0.]\n",
            "[Epoch 105 | Step 31] im_q: torch.Size([128, 1, 128, 61]), im_k: torch.Size([128, 1, 128, 61])\n",
            "\n",
            "[Top-k Label Logging] Epoch 106\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     286     1.0000    2.0     [0. 1.]\n",
            "2     434     1.0000    1.0     [1. 0.]\n",
            "3     258     1.0000    0.0     [0. 0.]\n",
            "4     46      1.0000    2.0     [0. 1.]\n",
            "5     281     1.0000    1.0     [1. 0.]\n",
            "6     146     1.0000    2.0     [0. 1.]\n",
            "7     16      1.0000    1.0     [1. 0.]\n",
            "8     139     1.0000    1.0     [1. 0.]\n",
            "9     76      0.9999    0.0     [0. 0.]\n",
            "10    332     0.9999    1.0     [1. 0.]\n",
            "[Epoch 106 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 107\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     329     1.0000    0.0     [0. 0.]\n",
            "2     449     1.0000    0.0     [0. 0.]\n",
            "3     46      1.0000    1.0     [1. 0.]\n",
            "4     39      1.0000    0.0     [0. 0.]\n",
            "5     448     1.0000    0.0     [0. 0.]\n",
            "6     80      1.0000    0.0     [0. 0.]\n",
            "7     347     1.0000    1.0     [1. 0.]\n",
            "8     443     1.0000    0.0     [0. 0.]\n",
            "9     241     1.0000    0.0     [0. 0.]\n",
            "10    13      1.0000    1.0     [1. 0.]\n",
            "[Epoch 107 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 108\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     448     1.0000    2.0     [0. 1.]\n",
            "2     232     1.0000    3.0     [1. 1.]\n",
            "3     482     1.0000    1.0     [1. 0.]\n",
            "4     39      1.0000    0.0     [0. 0.]\n",
            "5     77      1.0000    0.0     [0. 0.]\n",
            "6     4       1.0000    1.0     [1. 0.]\n",
            "7     201     1.0000    1.0     [1. 0.]\n",
            "8     155     1.0000    1.0     [1. 0.]\n",
            "9     277     1.0000    0.0     [0. 0.]\n",
            "10    344     0.9999    0.0     [0. 0.]\n",
            "[Epoch 108 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 109\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     437     0.9999    0.0     [0. 0.]\n",
            "2     201     0.9999    0.0     [0. 0.]\n",
            "3     189     0.9994    0.0     [0. 0.]\n",
            "4     268     0.9990    2.0     [0. 1.]\n",
            "5     404     0.9990    3.0     [1. 1.]\n",
            "6     202     0.9989    0.0     [0. 0.]\n",
            "7     501     0.9989    3.0     [1. 1.]\n",
            "8     255     0.9987    0.0     [0. 0.]\n",
            "9     9       0.9985    1.0     [1. 0.]\n",
            "10    178     0.9984    2.0     [0. 1.]\n",
            "[Epoch 109 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 110\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     48      1.0000    0.0     [0. 0.]\n",
            "2     253     1.0000    0.0     [0. 0.]\n",
            "3     101     1.0000    0.0     [0. 0.]\n",
            "4     437     1.0000    3.0     [1. 1.]\n",
            "5     138     1.0000    0.0     [0. 0.]\n",
            "6     162     1.0000    0.0     [0. 0.]\n",
            "7     273     1.0000    0.0     [0. 0.]\n",
            "8     411     1.0000    1.0     [1. 0.]\n",
            "9     348     1.0000    2.0     [0. 1.]\n",
            "10    295     1.0000    1.0     [1. 0.]\n",
            "[Epoch 110 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 111\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     19      0.9951    0.0     [0. 0.]\n",
            "2     356     0.9949    0.0     [0. 0.]\n",
            "3     268     0.9945    0.0     [0. 0.]\n",
            "4     187     0.9944    0.0     [0. 0.]\n",
            "5     474     0.9944    0.0     [0. 0.]\n",
            "6     413     0.9944    0.0     [0. 0.]\n",
            "7     38      0.9943    0.0     [0. 0.]\n",
            "8     73      0.9943    0.0     [0. 0.]\n",
            "9     420     0.9943    0.0     [0. 0.]\n",
            "10    461     0.9941    0.0     [0. 0.]\n",
            "[Epoch 111 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "=> Saved best checkpoint (epoch: 111, loss: 6.8594)\n",
            "\n",
            "[Top-k Label Logging] Epoch 112\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     11      1.0000    0.0     [0. 0.]\n",
            "2     17      1.0000    0.0     [0. 0.]\n",
            "3     472     1.0000    0.0     [0. 0.]\n",
            "4     440     1.0000    0.0     [0. 0.]\n",
            "5     209     1.0000    0.0     [0. 0.]\n",
            "6     216     1.0000    0.0     [0. 0.]\n",
            "7     321     1.0000    0.0     [0. 0.]\n",
            "8     363     1.0000    0.0     [0. 0.]\n",
            "9     41      1.0000    0.0     [0. 0.]\n",
            "10    104     1.0000    0.0     [0. 0.]\n",
            "[Epoch 112 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 112, loss: 6.8578)\n",
            "\n",
            "[Top-k Label Logging] Epoch 113\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     180     0.9998    3.0     [1. 1.]\n",
            "2     244     0.9997    2.0     [0. 1.]\n",
            "3     289     0.9997    0.0     [0. 0.]\n",
            "4     377     0.9997    3.0     [1. 1.]\n",
            "5     100     0.9997    1.0     [1. 0.]\n",
            "6     471     0.9997    3.0     [1. 1.]\n",
            "7     362     0.9994    0.0     [0. 0.]\n",
            "8     417     0.9994    0.0     [0. 0.]\n",
            "9     268     0.9989    2.0     [0. 1.]\n",
            "10    340     0.9988    1.0     [1. 0.]\n",
            "[Epoch 113 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 114\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     481     1.0000    1.0     [1. 0.]\n",
            "2     235     1.0000    0.0     [0. 0.]\n",
            "3     16      1.0000    0.0     [0. 0.]\n",
            "4     246     1.0000    0.0     [0. 0.]\n",
            "5     96      1.0000    0.0     [0. 0.]\n",
            "6     446     1.0000    0.0     [0. 0.]\n",
            "7     142     1.0000    1.0     [1. 0.]\n",
            "8     409     1.0000    0.0     [0. 0.]\n",
            "9     491     1.0000    0.0     [0. 0.]\n",
            "10    165     1.0000    0.0     [0. 0.]\n",
            "[Epoch 114 | Step 31] im_q: torch.Size([128, 1, 128, 41]), im_k: torch.Size([128, 1, 128, 41])\n",
            "\n",
            "[Top-k Label Logging] Epoch 115\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     13      0.9997    0.0     [0. 0.]\n",
            "2     475     0.9994    0.0     [0. 0.]\n",
            "3     120     0.9994    0.0     [0. 0.]\n",
            "4     53      0.9991    1.0     [1. 0.]\n",
            "5     96      0.9991    0.0     [0. 0.]\n",
            "6     25      0.9991    0.0     [0. 0.]\n",
            "7     286     0.9990    0.0     [0. 0.]\n",
            "8     245     0.9988    2.0     [0. 1.]\n",
            "9     226     0.9987    2.0     [0. 1.]\n",
            "10    28      0.9985    0.0     [0. 0.]\n",
            "[Epoch 115 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 115, loss: 6.8468)\n",
            "\n",
            "[Top-k Label Logging] Epoch 116\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     433     0.9977    0.0     [0. 0.]\n",
            "2     503     0.9977    1.0     [1. 0.]\n",
            "3     397     0.9969    1.0     [1. 0.]\n",
            "4     414     0.9968    2.0     [0. 1.]\n",
            "5     49      0.9966    0.0     [0. 0.]\n",
            "6     60      0.9962    2.0     [0. 1.]\n",
            "7     88      0.9962    0.0     [0. 0.]\n",
            "8     396     0.9961    0.0     [0. 0.]\n",
            "9     345     0.9960    0.0     [0. 0.]\n",
            "10    250     0.9959    2.0     [0. 1.]\n",
            "[Epoch 116 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "=> Saved best checkpoint (epoch: 116, loss: 6.7438)\n",
            "\n",
            "[Top-k Label Logging] Epoch 117\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     413     1.0000    0.0     [0. 0.]\n",
            "2     307     0.9999    1.0     [1. 0.]\n",
            "3     146     0.9999    0.0     [0. 0.]\n",
            "4     468     0.9999    2.0     [0. 1.]\n",
            "5     181     0.9998    3.0     [1. 1.]\n",
            "6     333     0.9998    0.0     [0. 0.]\n",
            "7     406     0.9998    0.0     [0. 0.]\n",
            "8     346     0.9998    0.0     [0. 0.]\n",
            "9     310     0.9997    1.0     [1. 0.]\n",
            "10    277     0.9997    0.0     [0. 0.]\n",
            "[Epoch 117 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 118\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     321     1.0000    0.0     [0. 0.]\n",
            "2     229     1.0000    0.0     [0. 0.]\n",
            "3     484     1.0000    2.0     [0. 1.]\n",
            "4     471     1.0000    0.0     [0. 0.]\n",
            "5     472     1.0000    0.0     [0. 0.]\n",
            "6     40      1.0000    0.0     [0. 0.]\n",
            "7     75      1.0000    0.0     [0. 0.]\n",
            "8     89      1.0000    0.0     [0. 0.]\n",
            "9     2       1.0000    0.0     [0. 0.]\n",
            "10    282     1.0000    0.0     [0. 0.]\n",
            "[Epoch 118 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 119\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     91      0.9984    1.0     [1. 0.]\n",
            "2     80      0.9983    0.0     [0. 0.]\n",
            "3     147     0.9981    0.0     [0. 0.]\n",
            "4     42      0.9980    0.0     [0. 0.]\n",
            "5     350     0.9980    1.0     [1. 0.]\n",
            "6     345     0.9980    0.0     [0. 0.]\n",
            "7     230     0.9978    0.0     [0. 0.]\n",
            "8     234     0.9978    0.0     [0. 0.]\n",
            "9     307     0.9973    1.0     [1. 0.]\n",
            "10    384     0.9972    0.0     [0. 0.]\n",
            "[Epoch 119 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 120\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     266     1.0000    1.0     [1. 0.]\n",
            "2     84      1.0000    1.0     [1. 0.]\n",
            "3     239     1.0000    2.0     [0. 1.]\n",
            "4     231     1.0000    3.0     [1. 1.]\n",
            "5     139     1.0000    0.0     [0. 0.]\n",
            "6     440     1.0000    1.0     [1. 0.]\n",
            "7     106     1.0000    0.0     [0. 0.]\n",
            "8     172     1.0000    2.0     [0. 1.]\n",
            "9     31      1.0000    2.0     [0. 1.]\n",
            "10    135     1.0000    1.0     [1. 0.]\n",
            "[Epoch 120 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 121\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     122     0.9937    0.0     [0. 0.]\n",
            "2     201     0.9937    0.0     [0. 0.]\n",
            "3     17      0.9937    0.0     [0. 0.]\n",
            "4     284     0.9937    0.0     [0. 0.]\n",
            "5     71      0.9937    0.0     [0. 0.]\n",
            "6     162     0.9937    1.0     [1. 0.]\n",
            "7     221     0.9937    0.0     [0. 0.]\n",
            "8     101     0.9937    2.0     [0. 1.]\n",
            "9     325     0.9937    0.0     [0. 0.]\n",
            "10    317     0.9937    0.0     [0. 0.]\n",
            "[Epoch 121 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 122\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     510     0.9930    3.0     [1. 1.]\n",
            "2     65      0.9928    0.0     [0. 0.]\n",
            "3     393     0.9923    1.0     [1. 0.]\n",
            "4     258     0.9923    0.0     [0. 0.]\n",
            "5     77      0.9923    1.0     [1. 0.]\n",
            "6     478     0.9922    3.0     [1. 1.]\n",
            "7     457     0.9922    1.0     [1. 0.]\n",
            "8     386     0.9922    1.0     [1. 0.]\n",
            "9     143     0.9922    2.0     [0. 1.]\n",
            "10    240     0.9922    3.0     [1. 1.]\n",
            "[Epoch 122 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 123\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     482     0.9999    0.0     [0. 0.]\n",
            "2     489     0.9999    3.0     [1. 1.]\n",
            "3     324     0.9999    3.0     [1. 1.]\n",
            "4     84      0.9997    0.0     [0. 0.]\n",
            "5     470     0.9996    2.0     [0. 1.]\n",
            "6     253     0.9996    0.0     [0. 0.]\n",
            "7     376     0.9996    3.0     [1. 1.]\n",
            "8     441     0.9996    0.0     [0. 0.]\n",
            "9     113     0.9996    1.0     [1. 0.]\n",
            "10    495     0.9996    3.0     [1. 1.]\n",
            "[Epoch 123 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 124\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     14      0.9984    0.0     [0. 0.]\n",
            "2     178     0.9984    0.0     [0. 0.]\n",
            "3     340     0.9983    3.0     [1. 1.]\n",
            "4     443     0.9982    0.0     [0. 0.]\n",
            "5     298     0.9982    3.0     [1. 1.]\n",
            "6     415     0.9980    0.0     [0. 0.]\n",
            "7     345     0.9979    0.0     [0. 0.]\n",
            "8     228     0.9976    1.0     [1. 0.]\n",
            "9     303     0.9976    0.0     [0. 0.]\n",
            "10    506     0.9973    1.0     [1. 0.]\n",
            "[Epoch 124 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 125\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     34      0.9999    1.0     [1. 0.]\n",
            "2     209     0.9998    0.0     [0. 0.]\n",
            "3     332     0.9998    1.0     [1. 0.]\n",
            "4     222     0.9997    0.0     [0. 0.]\n",
            "5     242     0.9997    0.0     [0. 0.]\n",
            "6     0       0.9995    0.0     [0. 0.]\n",
            "7     376     0.9994    0.0     [0. 0.]\n",
            "8     297     0.9989    0.0     [0. 0.]\n",
            "9     96      0.9985    1.0     [1. 0.]\n",
            "10    330     0.9984    0.0     [0. 0.]\n",
            "[Epoch 125 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 126\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     178     0.9999    1.0     [1. 0.]\n",
            "2     11      0.9999    0.0     [0. 0.]\n",
            "3     493     0.9998    0.0     [0. 0.]\n",
            "4     160     0.9997    0.0     [0. 0.]\n",
            "5     491     0.9997    1.0     [1. 0.]\n",
            "6     22      0.9996    0.0     [0. 0.]\n",
            "7     353     0.9996    0.0     [0. 0.]\n",
            "8     184     0.9993    0.0     [0. 0.]\n",
            "9     66      0.9992    0.0     [0. 0.]\n",
            "10    0       0.9988    1.0     [1. 0.]\n",
            "[Epoch 126 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 127\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     48      0.9999    0.0     [0. 0.]\n",
            "2     421     0.9999    0.0     [0. 0.]\n",
            "3     0       0.9999    0.0     [0. 0.]\n",
            "4     504     0.9999    0.0     [0. 0.]\n",
            "5     296     0.9999    1.0     [1. 0.]\n",
            "6     483     0.9999    0.0     [0. 0.]\n",
            "7     265     0.9999    3.0     [1. 1.]\n",
            "8     85      0.9999    1.0     [1. 0.]\n",
            "9     482     0.9999    2.0     [0. 1.]\n",
            "10    59      0.9999    3.0     [1. 1.]\n",
            "[Epoch 127 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 128\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     129     0.9980    1.0     [1. 0.]\n",
            "2     69      0.9980    1.0     [1. 0.]\n",
            "3     359     0.9980    3.0     [1. 1.]\n",
            "4     111     0.9976    0.0     [0. 0.]\n",
            "5     157     0.9974    3.0     [1. 1.]\n",
            "6     150     0.9974    0.0     [0. 0.]\n",
            "7     326     0.9973    1.0     [1. 0.]\n",
            "8     133     0.9973    1.0     [1. 0.]\n",
            "9     25      0.9971    0.0     [0. 0.]\n",
            "10    414     0.9970    1.0     [1. 0.]\n",
            "[Epoch 128 | Step 31] im_q: torch.Size([128, 1, 128, 41]), im_k: torch.Size([128, 1, 128, 41])\n",
            "\n",
            "[Top-k Label Logging] Epoch 129\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     285     0.9983    0.0     [0. 0.]\n",
            "2     107     0.9982    3.0     [1. 1.]\n",
            "3     279     0.9982    3.0     [1. 1.]\n",
            "4     179     0.9981    1.0     [1. 0.]\n",
            "5     69      0.9973    3.0     [1. 1.]\n",
            "6     98      0.9971    1.0     [1. 0.]\n",
            "7     77      0.9970    2.0     [0. 1.]\n",
            "8     37      0.9969    1.0     [1. 0.]\n",
            "9     362     0.9969    1.0     [1. 0.]\n",
            "10    326     0.9969    0.0     [0. 0.]\n",
            "[Epoch 129 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 129, loss: 6.6993)\n",
            "\n",
            "[Top-k Label Logging] Epoch 130\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     225     0.9983    0.0     [0. 0.]\n",
            "2     466     0.9982    1.0     [1. 0.]\n",
            "3     0       0.9982    1.0     [1. 0.]\n",
            "4     119     0.9982    0.0     [0. 0.]\n",
            "5     25      0.9981    1.0     [1. 0.]\n",
            "6     509     0.9980    0.0     [0. 0.]\n",
            "7     52      0.9979    1.0     [1. 0.]\n",
            "8     337     0.9977    0.0     [0. 0.]\n",
            "9     125     0.9971    0.0     [0. 0.]\n",
            "10    186     0.9970    0.0     [0. 0.]\n",
            "[Epoch 130 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 131\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     293     0.9982    0.0     [0. 0.]\n",
            "2     224     0.9981    0.0     [0. 0.]\n",
            "3     254     0.9975    3.0     [1. 1.]\n",
            "4     500     0.9975    1.0     [1. 0.]\n",
            "5     195     0.9973    0.0     [0. 0.]\n",
            "6     257     0.9971    0.0     [0. 0.]\n",
            "7     268     0.9971    0.0     [0. 0.]\n",
            "8     21      0.9970    0.0     [0. 0.]\n",
            "9     362     0.9970    1.0     [1. 0.]\n",
            "10    80      0.9970    0.0     [0. 0.]\n",
            "[Epoch 131 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "\n",
            "[Top-k Label Logging] Epoch 132\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     43      0.9983    3.0     [1. 1.]\n",
            "2     263     0.9975    0.0     [0. 0.]\n",
            "3     128     0.9972    1.0     [1. 0.]\n",
            "4     366     0.9971    1.0     [1. 0.]\n",
            "5     248     0.9970    0.0     [0. 0.]\n",
            "6     32      0.9969    2.0     [0. 1.]\n",
            "7     145     0.9968    1.0     [1. 0.]\n",
            "8     445     0.9968    1.0     [1. 0.]\n",
            "9     56      0.9968    2.0     [0. 1.]\n",
            "10    298     0.9968    0.0     [0. 0.]\n",
            "[Epoch 132 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 133\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     161     0.9998    3.0     [1. 1.]\n",
            "2     48      0.9997    0.0     [0. 0.]\n",
            "3     24      0.9997    3.0     [1. 1.]\n",
            "4     77      0.9996    0.0     [0. 0.]\n",
            "5     83      0.9996    0.0     [0. 0.]\n",
            "6     98      0.9995    0.0     [0. 0.]\n",
            "7     35      0.9995    0.0     [0. 0.]\n",
            "8     274     0.9995    2.0     [0. 1.]\n",
            "9     394     0.9995    1.0     [1. 0.]\n",
            "10    483     0.9995    0.0     [0. 0.]\n",
            "[Epoch 133 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 134\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     100     1.0000    0.0     [0. 0.]\n",
            "2     86      1.0000    1.0     [1. 0.]\n",
            "3     85      1.0000    3.0     [1. 1.]\n",
            "4     182     1.0000    3.0     [1. 1.]\n",
            "5     304     1.0000    2.0     [0. 1.]\n",
            "6     311     1.0000    0.0     [0. 0.]\n",
            "7     472     1.0000    0.0     [0. 0.]\n",
            "8     280     1.0000    1.0     [1. 0.]\n",
            "9     255     1.0000    0.0     [0. 0.]\n",
            "10    376     1.0000    1.0     [1. 0.]\n",
            "[Epoch 134 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 135\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     313     1.0000    2.0     [0. 1.]\n",
            "2     174     1.0000    1.0     [1. 0.]\n",
            "3     373     1.0000    1.0     [1. 0.]\n",
            "4     332     1.0000    1.0     [1. 0.]\n",
            "5     190     1.0000    1.0     [1. 0.]\n",
            "6     391     1.0000    2.0     [0. 1.]\n",
            "7     433     1.0000    0.0     [0. 0.]\n",
            "8     242     1.0000    3.0     [1. 1.]\n",
            "9     133     1.0000    2.0     [0. 1.]\n",
            "10    478     1.0000    0.0     [0. 0.]\n",
            "[Epoch 135 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 136\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     303     0.9984    0.0     [0. 0.]\n",
            "2     296     0.9983    2.0     [0. 1.]\n",
            "3     393     0.9982    2.0     [0. 1.]\n",
            "4     337     0.9982    0.0     [0. 0.]\n",
            "5     348     0.9981    0.0     [0. 0.]\n",
            "6     489     0.9978    0.0     [0. 0.]\n",
            "7     244     0.9978    0.0     [0. 0.]\n",
            "8     336     0.9978    0.0     [0. 0.]\n",
            "9     493     0.9978    0.0     [0. 0.]\n",
            "10    422     0.9978    0.0     [0. 0.]\n",
            "[Epoch 136 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 137\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     216     0.9977    0.0     [0. 0.]\n",
            "2     466     0.9976    0.0     [0. 0.]\n",
            "3     113     0.9976    1.0     [1. 0.]\n",
            "4     145     0.9973    0.0     [0. 0.]\n",
            "5     97      0.9972    0.0     [0. 0.]\n",
            "6     195     0.9971    1.0     [1. 0.]\n",
            "7     190     0.9971    0.0     [0. 0.]\n",
            "8     116     0.9971    0.0     [0. 0.]\n",
            "9     66      0.9971    0.0     [0. 0.]\n",
            "10    114     0.9971    1.0     [1. 0.]\n",
            "[Epoch 137 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 138\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     342     0.9983    1.0     [1. 0.]\n",
            "2     108     0.9982    1.0     [1. 0.]\n",
            "3     243     0.9981    0.0     [0. 0.]\n",
            "4     195     0.9980    0.0     [0. 0.]\n",
            "5     203     0.9980    0.0     [0. 0.]\n",
            "6     52      0.9979    0.0     [0. 0.]\n",
            "7     173     0.9979    1.0     [1. 0.]\n",
            "8     472     0.9978    0.0     [0. 0.]\n",
            "9     180     0.9978    0.0     [0. 0.]\n",
            "10    260     0.9978    1.0     [1. 0.]\n",
            "[Epoch 138 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 139\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     339     0.9982    3.0     [1. 1.]\n",
            "2     147     0.9977    1.0     [1. 0.]\n",
            "3     233     0.9971    0.0     [0. 0.]\n",
            "4     420     0.9970    0.0     [0. 0.]\n",
            "5     503     0.9969    0.0     [0. 0.]\n",
            "6     97      0.9968    2.0     [0. 1.]\n",
            "7     473     0.9968    2.0     [0. 1.]\n",
            "8     300     0.9968    3.0     [1. 1.]\n",
            "9     230     0.9967    0.0     [0. 0.]\n",
            "10    337     0.9967    1.0     [1. 0.]\n",
            "[Epoch 139 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 140\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     78      0.9984    1.0     [1. 0.]\n",
            "2     361     0.9984    0.0     [0. 0.]\n",
            "3     461     0.9984    0.0     [0. 0.]\n",
            "4     460     0.9984    2.0     [0. 1.]\n",
            "5     436     0.9984    2.0     [0. 1.]\n",
            "6     500     0.9984    2.0     [0. 1.]\n",
            "7     61      0.9984    3.0     [1. 1.]\n",
            "8     426     0.9984    0.0     [0. 0.]\n",
            "9     441     0.9984    0.0     [0. 0.]\n",
            "10    245     0.9984    0.0     [0. 0.]\n",
            "[Epoch 140 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 141\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     208     0.9965    0.0     [0. 0.]\n",
            "2     267     0.9959    0.0     [0. 0.]\n",
            "3     182     0.9955    0.0     [0. 0.]\n",
            "4     229     0.9955    2.0     [0. 1.]\n",
            "5     237     0.9955    0.0     [0. 0.]\n",
            "6     448     0.9955    2.0     [0. 1.]\n",
            "7     153     0.9954    1.0     [1. 0.]\n",
            "8     260     0.9954    0.0     [0. 0.]\n",
            "9     204     0.9952    1.0     [1. 0.]\n",
            "10    21      0.9951    1.0     [1. 0.]\n",
            "[Epoch 141 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 142\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     317     0.9990    0.0     [0. 0.]\n",
            "2     344     0.9981    0.0     [0. 0.]\n",
            "3     287     0.9981    0.0     [0. 0.]\n",
            "4     286     0.9981    0.0     [0. 0.]\n",
            "5     369     0.9981    0.0     [0. 0.]\n",
            "6     487     0.9981    0.0     [0. 0.]\n",
            "7     244     0.9981    0.0     [0. 0.]\n",
            "8     61      0.9981    0.0     [0. 0.]\n",
            "9     265     0.9981    0.0     [0. 0.]\n",
            "10    279     0.9981    0.0     [0. 0.]\n",
            "[Epoch 142 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 143\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     338     0.9969    0.0     [0. 0.]\n",
            "2     52      0.9968    1.0     [1. 0.]\n",
            "3     103     0.9968    0.0     [0. 0.]\n",
            "4     293     0.9965    1.0     [1. 0.]\n",
            "5     321     0.9964    1.0     [1. 0.]\n",
            "6     60      0.9964    1.0     [1. 0.]\n",
            "7     76      0.9964    0.0     [0. 0.]\n",
            "8     82      0.9963    0.0     [0. 0.]\n",
            "9     58      0.9963    0.0     [0. 0.]\n",
            "10    72      0.9963    1.0     [1. 0.]\n",
            "[Epoch 143 | Step 31] im_q: torch.Size([128, 1, 128, 45]), im_k: torch.Size([128, 1, 128, 45])\n",
            "\n",
            "[Top-k Label Logging] Epoch 144\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     350     0.9978    0.0     [0. 0.]\n",
            "2     248     0.9974    1.0     [1. 0.]\n",
            "3     9       0.9971    2.0     [0. 1.]\n",
            "4     244     0.9969    2.0     [0. 1.]\n",
            "5     318     0.9967    2.0     [0. 1.]\n",
            "6     306     0.9967    0.0     [0. 0.]\n",
            "7     446     0.9966    1.0     [1. 0.]\n",
            "8     476     0.9964    0.0     [0. 0.]\n",
            "9     18      0.9962    1.0     [1. 0.]\n",
            "10    296     0.9962    1.0     [1. 0.]\n",
            "[Epoch 144 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 145\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     71      0.9985    0.0     [0. 0.]\n",
            "2     323     0.9985    0.0     [0. 0.]\n",
            "3     122     0.9985    0.0     [0. 0.]\n",
            "4     180     0.9985    0.0     [0. 0.]\n",
            "5     406     0.9985    3.0     [1. 1.]\n",
            "6     486     0.9985    2.0     [0. 1.]\n",
            "7     507     0.9985    0.0     [0. 0.]\n",
            "8     279     0.9985    0.0     [0. 0.]\n",
            "9     454     0.9985    2.0     [0. 1.]\n",
            "10    483     0.9985    0.0     [0. 0.]\n",
            "[Epoch 145 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 146\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     501     0.9987    1.0     [1. 0.]\n",
            "2     77      0.9987    1.0     [1. 0.]\n",
            "3     21      0.9987    0.0     [0. 0.]\n",
            "4     482     0.9987    0.0     [0. 0.]\n",
            "5     458     0.9987    0.0     [0. 0.]\n",
            "6     1       0.9987    1.0     [1. 0.]\n",
            "7     481     0.9987    0.0     [0. 0.]\n",
            "8     370     0.9987    0.0     [0. 0.]\n",
            "9     125     0.9987    2.0     [0. 1.]\n",
            "10    317     0.9987    0.0     [0. 0.]\n",
            "[Epoch 146 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 147\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     77      1.0000    3.0     [1. 1.]\n",
            "2     406     1.0000    3.0     [1. 1.]\n",
            "3     296     1.0000    2.0     [0. 1.]\n",
            "4     507     1.0000    3.0     [1. 1.]\n",
            "5     211     1.0000    3.0     [1. 1.]\n",
            "6     394     1.0000    2.0     [0. 1.]\n",
            "7     212     1.0000    0.0     [0. 0.]\n",
            "8     134     1.0000    2.0     [0. 1.]\n",
            "9     62      1.0000    0.0     [0. 0.]\n",
            "10    70      1.0000    1.0     [1. 0.]\n",
            "[Epoch 147 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 148\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     157     0.9998    0.0     [0. 0.]\n",
            "2     46      0.9997    0.0     [0. 0.]\n",
            "3     227     0.9988    1.0     [1. 0.]\n",
            "4     88      0.9988    1.0     [1. 0.]\n",
            "5     77      0.9987    1.0     [1. 0.]\n",
            "6     440     0.9985    1.0     [1. 0.]\n",
            "7     202     0.9983    1.0     [1. 0.]\n",
            "8     92      0.9983    1.0     [1. 0.]\n",
            "9     50      0.9982    1.0     [1. 0.]\n",
            "10    4       0.9981    1.0     [1. 0.]\n",
            "[Epoch 148 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 149\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     2       0.9983    3.0     [1. 1.]\n",
            "2     11      0.9982    0.0     [0. 0.]\n",
            "3     363     0.9981    0.0     [0. 0.]\n",
            "4     195     0.9978    1.0     [1. 0.]\n",
            "5     43      0.9977    0.0     [0. 0.]\n",
            "6     262     0.9977    1.0     [1. 0.]\n",
            "7     99      0.9977    2.0     [0. 1.]\n",
            "8     248     0.9977    1.0     [1. 0.]\n",
            "9     475     0.9976    0.0     [0. 0.]\n",
            "10    307     0.9972    2.0     [0. 1.]\n",
            "[Epoch 149 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 150\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     128     0.9994    0.0     [0. 0.]\n",
            "2     212     0.9986    2.0     [0. 1.]\n",
            "3     246     0.9985    1.0     [1. 0.]\n",
            "4     137     0.9984    0.0     [0. 0.]\n",
            "5     65      0.9984    1.0     [1. 0.]\n",
            "6     217     0.9982    0.0     [0. 0.]\n",
            "7     318     0.9982    0.0     [0. 0.]\n",
            "8     325     0.9981    1.0     [1. 0.]\n",
            "9     127     0.9981    0.0     [0. 0.]\n",
            "10    23      0.9976    2.0     [0. 1.]\n",
            "[Epoch 150 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 150, loss: 6.6682)\n",
            "\n",
            "[Top-k Label Logging] Epoch 151\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     67      0.9998    3.0     [1. 1.]\n",
            "2     364     0.9997    0.0     [0. 0.]\n",
            "3     103     0.9996    0.0     [0. 0.]\n",
            "4     7       0.9996    1.0     [1. 0.]\n",
            "5     264     0.9995    0.0     [0. 0.]\n",
            "6     220     0.9994    0.0     [0. 0.]\n",
            "7     53      0.9993    0.0     [0. 0.]\n",
            "8     120     0.9992    0.0     [0. 0.]\n",
            "9     342     0.9992    1.0     [1. 0.]\n",
            "10    55      0.9992    0.0     [0. 0.]\n",
            "[Epoch 151 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 152\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     504     1.0000    0.0     [0. 0.]\n",
            "2     465     1.0000    0.0     [0. 0.]\n",
            "3     165     1.0000    0.0     [0. 0.]\n",
            "4     256     1.0000    1.0     [1. 0.]\n",
            "5     171     1.0000    0.0     [0. 0.]\n",
            "6     279     1.0000    2.0     [0. 1.]\n",
            "7     241     1.0000    0.0     [0. 0.]\n",
            "8     186     1.0000    0.0     [0. 0.]\n",
            "9     507     1.0000    0.0     [0. 0.]\n",
            "10    234     1.0000    0.0     [0. 0.]\n",
            "[Epoch 152 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 152, loss: 6.6257)\n",
            "\n",
            "[Top-k Label Logging] Epoch 153\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     309     1.0000    0.0     [0. 0.]\n",
            "2     288     1.0000    0.0     [0. 0.]\n",
            "3     2       1.0000    0.0     [0. 0.]\n",
            "4     444     1.0000    0.0     [0. 0.]\n",
            "5     449     1.0000    1.0     [1. 0.]\n",
            "6     193     1.0000    1.0     [1. 0.]\n",
            "7     352     1.0000    0.0     [0. 0.]\n",
            "8     100     1.0000    2.0     [0. 1.]\n",
            "9     332     1.0000    0.0     [0. 0.]\n",
            "10    360     1.0000    0.0     [0. 0.]\n",
            "[Epoch 153 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 154\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     244     1.0000    0.0     [0. 0.]\n",
            "2     85      1.0000    0.0     [0. 0.]\n",
            "3     5       1.0000    0.0     [0. 0.]\n",
            "4     495     1.0000    1.0     [1. 0.]\n",
            "5     441     1.0000    0.0     [0. 0.]\n",
            "6     106     1.0000    0.0     [0. 0.]\n",
            "7     312     1.0000    0.0     [0. 0.]\n",
            "8     126     1.0000    0.0     [0. 0.]\n",
            "9     140     1.0000    0.0     [0. 0.]\n",
            "10    10      1.0000    2.0     [0. 1.]\n",
            "[Epoch 154 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 155\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     201     1.0000    0.0     [0. 0.]\n",
            "2     84      1.0000    0.0     [0. 0.]\n",
            "3     20      1.0000    1.0     [1. 0.]\n",
            "4     276     1.0000    0.0     [0. 0.]\n",
            "5     68      1.0000    0.0     [0. 0.]\n",
            "6     184     1.0000    0.0     [0. 0.]\n",
            "7     319     1.0000    0.0     [0. 0.]\n",
            "8     106     1.0000    2.0     [0. 1.]\n",
            "9     76      1.0000    0.0     [0. 0.]\n",
            "10    215     1.0000    2.0     [0. 1.]\n",
            "[Epoch 155 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 156\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     457     1.0000    1.0     [1. 0.]\n",
            "2     83      1.0000    0.0     [0. 0.]\n",
            "3     315     1.0000    2.0     [0. 1.]\n",
            "4     437     1.0000    0.0     [0. 0.]\n",
            "5     35      1.0000    0.0     [0. 0.]\n",
            "6     119     1.0000    0.0     [0. 0.]\n",
            "7     223     1.0000    2.0     [0. 1.]\n",
            "8     423     1.0000    2.0     [0. 1.]\n",
            "9     486     1.0000    0.0     [0. 0.]\n",
            "10    58      1.0000    0.0     [0. 0.]\n",
            "[Epoch 156 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 157\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     40      1.0000    0.0     [0. 0.]\n",
            "2     291     1.0000    0.0     [0. 0.]\n",
            "3     30      1.0000    1.0     [1. 0.]\n",
            "4     357     1.0000    1.0     [1. 0.]\n",
            "5     495     1.0000    0.0     [0. 0.]\n",
            "6     310     1.0000    2.0     [0. 1.]\n",
            "7     176     1.0000    1.0     [1. 0.]\n",
            "8     207     1.0000    0.0     [0. 0.]\n",
            "9     204     1.0000    2.0     [0. 1.]\n",
            "10    241     1.0000    3.0     [1. 1.]\n",
            "[Epoch 157 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 158\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     337     0.9981    0.0     [0. 0.]\n",
            "2     486     0.9967    0.0     [0. 0.]\n",
            "3     358     0.9964    3.0     [1. 1.]\n",
            "4     0       0.9964    0.0     [0. 0.]\n",
            "5     392     0.9961    3.0     [1. 1.]\n",
            "6     510     0.9961    0.0     [0. 0.]\n",
            "7     327     0.9961    2.0     [0. 1.]\n",
            "8     244     0.9960    1.0     [1. 0.]\n",
            "9     87      0.9958    0.0     [0. 0.]\n",
            "10    432     0.9956    1.0     [1. 0.]\n",
            "[Epoch 158 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 159\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     187     0.9984    0.0     [0. 0.]\n",
            "2     235     0.9984    1.0     [1. 0.]\n",
            "3     128     0.9984    3.0     [1. 1.]\n",
            "4     58      0.9984    0.0     [0. 0.]\n",
            "5     89      0.9984    0.0     [0. 0.]\n",
            "6     320     0.9984    0.0     [0. 0.]\n",
            "7     60      0.9984    1.0     [1. 0.]\n",
            "8     177     0.9984    0.0     [0. 0.]\n",
            "9     388     0.9984    3.0     [1. 1.]\n",
            "10    473     0.9984    2.0     [0. 1.]\n",
            "[Epoch 159 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 160\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     39      0.9969    0.0     [0. 0.]\n",
            "2     135     0.9969    3.0     [1. 1.]\n",
            "3     206     0.9969    3.0     [1. 1.]\n",
            "4     200     0.9969    1.0     [1. 0.]\n",
            "5     264     0.9969    0.0     [0. 0.]\n",
            "6     346     0.9969    1.0     [1. 0.]\n",
            "7     194     0.9969    3.0     [1. 1.]\n",
            "8     448     0.9969    0.0     [0. 0.]\n",
            "9     242     0.9969    0.0     [0. 0.]\n",
            "10    72      0.9969    0.0     [0. 0.]\n",
            "[Epoch 160 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 161\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     90      0.9970    2.0     [0. 1.]\n",
            "2     284     0.9969    0.0     [0. 0.]\n",
            "3     20      0.9969    0.0     [0. 0.]\n",
            "4     398     0.9969    0.0     [0. 0.]\n",
            "5     192     0.9969    2.0     [0. 1.]\n",
            "6     472     0.9969    1.0     [1. 0.]\n",
            "7     415     0.9969    0.0     [0. 0.]\n",
            "8     462     0.9969    1.0     [1. 0.]\n",
            "9     286     0.9969    0.0     [0. 0.]\n",
            "10    268     0.9969    0.0     [0. 0.]\n",
            "[Epoch 161 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "=> Saved best checkpoint (epoch: 161, loss: 6.4629)\n",
            "\n",
            "[Top-k Label Logging] Epoch 162\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     247     0.9972    0.0     [0. 0.]\n",
            "2     470     0.9972    0.0     [0. 0.]\n",
            "3     32      0.9972    3.0     [1. 1.]\n",
            "4     185     0.9972    0.0     [0. 0.]\n",
            "5     432     0.9971    0.0     [0. 0.]\n",
            "6     248     0.9970    3.0     [1. 1.]\n",
            "7     391     0.9970    1.0     [1. 0.]\n",
            "8     103     0.9970    1.0     [1. 0.]\n",
            "9     303     0.9969    2.0     [0. 1.]\n",
            "10    235     0.9969    1.0     [1. 0.]\n",
            "[Epoch 162 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 163\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     364     0.9984    0.0     [0. 0.]\n",
            "2     231     0.9983    1.0     [1. 0.]\n",
            "3     116     0.9983    0.0     [0. 0.]\n",
            "4     167     0.9983    0.0     [0. 0.]\n",
            "5     473     0.9983    0.0     [0. 0.]\n",
            "6     423     0.9983    0.0     [0. 0.]\n",
            "7     234     0.9983    0.0     [0. 0.]\n",
            "8     268     0.9983    1.0     [1. 0.]\n",
            "9     386     0.9983    0.0     [0. 0.]\n",
            "10    294     0.9983    0.0     [0. 0.]\n",
            "[Epoch 163 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 164\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     53      0.9970    0.0     [0. 0.]\n",
            "2     85      0.9969    0.0     [0. 0.]\n",
            "3     141     0.9967    0.0     [0. 0.]\n",
            "4     436     0.9955    0.0     [0. 0.]\n",
            "5     262     0.9953    1.0     [1. 0.]\n",
            "6     144     0.9953    1.0     [1. 0.]\n",
            "7     243     0.9953    0.0     [0. 0.]\n",
            "8     225     0.9952    1.0     [1. 0.]\n",
            "9     384     0.9951    1.0     [1. 0.]\n",
            "10    163     0.9950    3.0     [1. 1.]\n",
            "[Epoch 164 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 165\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     346     0.9982    0.0     [0. 0.]\n",
            "2     406     0.9982    2.0     [0. 1.]\n",
            "3     397     0.9981    0.0     [0. 0.]\n",
            "4     17      0.9980    1.0     [1. 0.]\n",
            "5     242     0.9974    0.0     [0. 0.]\n",
            "6     470     0.9974    1.0     [1. 0.]\n",
            "7     498     0.9971    0.0     [0. 0.]\n",
            "8     420     0.9971    0.0     [0. 0.]\n",
            "9     393     0.9971    3.0     [1. 1.]\n",
            "10    490     0.9971    2.0     [0. 1.]\n",
            "[Epoch 165 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 166\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     176     0.9984    0.0     [0. 0.]\n",
            "2     423     0.9982    1.0     [1. 0.]\n",
            "3     237     0.9982    1.0     [1. 0.]\n",
            "4     191     0.9982    1.0     [1. 0.]\n",
            "5     109     0.9981    1.0     [1. 0.]\n",
            "6     86      0.9981    1.0     [1. 0.]\n",
            "7     57      0.9980    2.0     [0. 1.]\n",
            "8     475     0.9980    0.0     [0. 0.]\n",
            "9     304     0.9980    0.0     [0. 0.]\n",
            "10    201     0.9978    0.0     [0. 0.]\n",
            "[Epoch 166 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 167\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     402     0.9984    2.0     [0. 1.]\n",
            "2     437     0.9982    0.0     [0. 0.]\n",
            "3     3       0.9981    1.0     [1. 0.]\n",
            "4     471     0.9977    1.0     [1. 0.]\n",
            "5     290     0.9968    0.0     [0. 0.]\n",
            "6     490     0.9968    3.0     [1. 1.]\n",
            "7     19      0.9968    3.0     [1. 1.]\n",
            "8     188     0.9968    0.0     [0. 0.]\n",
            "9     112     0.9967    0.0     [0. 0.]\n",
            "10    159     0.9967    0.0     [0. 0.]\n",
            "[Epoch 167 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 168\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     331     0.9984    2.0     [0. 1.]\n",
            "2     468     0.9982    1.0     [1. 0.]\n",
            "3     295     0.9981    0.0     [0. 0.]\n",
            "4     505     0.9974    2.0     [0. 1.]\n",
            "5     317     0.9972    0.0     [0. 0.]\n",
            "6     419     0.9972    1.0     [1. 0.]\n",
            "7     235     0.9972    0.0     [0. 0.]\n",
            "8     407     0.9971    3.0     [1. 1.]\n",
            "9     0       0.9969    1.0     [1. 0.]\n",
            "10    378     0.9969    3.0     [1. 1.]\n",
            "[Epoch 168 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 169\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     437     0.9984    0.0     [0. 0.]\n",
            "2     154     0.9984    0.0     [0. 0.]\n",
            "3     359     0.9984    1.0     [1. 0.]\n",
            "4     232     0.9984    1.0     [1. 0.]\n",
            "5     263     0.9984    0.0     [0. 0.]\n",
            "6     374     0.9984    2.0     [0. 1.]\n",
            "7     423     0.9983    1.0     [1. 0.]\n",
            "8     251     0.9983    3.0     [1. 1.]\n",
            "9     23      0.9983    1.0     [1. 0.]\n",
            "10    287     0.9983    1.0     [1. 0.]\n",
            "[Epoch 169 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 170\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     77      0.9986    0.0     [0. 0.]\n",
            "2     14      0.9986    1.0     [1. 0.]\n",
            "3     108     0.9986    1.0     [1. 0.]\n",
            "4     385     0.9986    0.0     [0. 0.]\n",
            "5     484     0.9986    1.0     [1. 0.]\n",
            "6     481     0.9986    0.0     [0. 0.]\n",
            "7     451     0.9986    0.0     [0. 0.]\n",
            "8     0       0.9986    1.0     [1. 0.]\n",
            "9     478     0.9986    0.0     [0. 0.]\n",
            "10    98      0.9986    2.0     [0. 1.]\n",
            "[Epoch 170 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "=> Saved best checkpoint (epoch: 170, loss: 6.4442)\n",
            "\n",
            "[Top-k Label Logging] Epoch 171\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     331     0.9972    0.0     [0. 0.]\n",
            "2     424     0.9971    0.0     [0. 0.]\n",
            "3     106     0.9970    1.0     [1. 0.]\n",
            "4     184     0.9970    0.0     [0. 0.]\n",
            "5     404     0.9970    0.0     [0. 0.]\n",
            "6     243     0.9969    1.0     [1. 0.]\n",
            "7     503     0.9968    3.0     [1. 1.]\n",
            "8     0       0.9968    3.0     [1. 1.]\n",
            "9     69      0.9968    0.0     [0. 0.]\n",
            "10    7       0.9968    2.0     [0. 1.]\n",
            "[Epoch 171 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 172\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     454     0.9992    3.0     [1. 1.]\n",
            "2     218     0.9992    0.0     [0. 0.]\n",
            "3     120     0.9992    1.0     [1. 0.]\n",
            "4     20      0.9992    0.0     [0. 0.]\n",
            "5     107     0.9992    1.0     [1. 0.]\n",
            "6     282     0.9992    1.0     [1. 0.]\n",
            "7     37      0.9992    3.0     [1. 1.]\n",
            "8     60      0.9992    0.0     [0. 0.]\n",
            "9     260     0.9992    0.0     [0. 0.]\n",
            "10    439     0.9992    0.0     [0. 0.]\n",
            "[Epoch 172 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 173\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     443     0.9995    1.0     [1. 0.]\n",
            "2     93      0.9992    0.0     [0. 0.]\n",
            "3     0       0.9987    1.0     [1. 0.]\n",
            "4     425     0.9987    1.0     [1. 0.]\n",
            "5     407     0.9985    0.0     [0. 0.]\n",
            "6     213     0.9985    0.0     [0. 0.]\n",
            "7     347     0.9982    0.0     [0. 0.]\n",
            "8     418     0.9981    0.0     [0. 0.]\n",
            "9     102     0.9981    2.0     [0. 1.]\n",
            "10    2       0.9981    1.0     [1. 0.]\n",
            "[Epoch 173 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "\n",
            "[Top-k Label Logging] Epoch 174\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     177     0.9991    0.0     [0. 0.]\n",
            "2     447     0.9982    0.0     [0. 0.]\n",
            "3     505     0.9979    0.0     [0. 0.]\n",
            "4     29      0.9975    0.0     [0. 0.]\n",
            "5     386     0.9974    1.0     [1. 0.]\n",
            "6     287     0.9966    3.0     [1. 1.]\n",
            "7     279     0.9964    1.0     [1. 0.]\n",
            "8     102     0.9964    3.0     [1. 1.]\n",
            "9     135     0.9963    0.0     [0. 0.]\n",
            "10    416     0.9963    0.0     [0. 0.]\n",
            "[Epoch 174 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 175\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     495     0.9999    0.0     [0. 0.]\n",
            "2     504     0.9999    0.0     [0. 0.]\n",
            "3     358     0.9999    0.0     [0. 0.]\n",
            "4     263     0.9999    0.0     [0. 0.]\n",
            "5     464     0.9999    0.0     [0. 0.]\n",
            "6     126     0.9999    0.0     [0. 0.]\n",
            "7     296     0.9999    0.0     [0. 0.]\n",
            "8     132     0.9999    2.0     [0. 1.]\n",
            "9     22      0.9999    2.0     [0. 1.]\n",
            "10    468     0.9999    3.0     [1. 1.]\n",
            "[Epoch 175 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 176\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     376     1.0000    0.0     [0. 0.]\n",
            "2     430     1.0000    2.0     [0. 1.]\n",
            "3     370     1.0000    0.0     [0. 0.]\n",
            "4     261     1.0000    0.0     [0. 0.]\n",
            "5     307     1.0000    0.0     [0. 0.]\n",
            "6     147     1.0000    2.0     [0. 1.]\n",
            "7     53      1.0000    0.0     [0. 0.]\n",
            "8     33      1.0000    0.0     [0. 0.]\n",
            "9     456     1.0000    0.0     [0. 0.]\n",
            "10    499     1.0000    0.0     [0. 0.]\n",
            "[Epoch 176 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 177\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     285     0.9978    1.0     [1. 0.]\n",
            "2     366     0.9971    1.0     [1. 0.]\n",
            "3     393     0.9970    1.0     [1. 0.]\n",
            "4     436     0.9970    1.0     [1. 0.]\n",
            "5     207     0.9970    0.0     [0. 0.]\n",
            "6     139     0.9969    0.0     [0. 0.]\n",
            "7     340     0.9968    1.0     [1. 0.]\n",
            "8     359     0.9967    0.0     [0. 0.]\n",
            "9     388     0.9967    2.0     [0. 1.]\n",
            "10    117     0.9966    0.0     [0. 0.]\n",
            "[Epoch 177 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 178\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       0.9999    0.0     [0. 0.]\n",
            "2     248     0.9998    0.0     [0. 0.]\n",
            "3     37      0.9998    0.0     [0. 0.]\n",
            "4     490     0.9996    1.0     [1. 0.]\n",
            "5     90      0.9995    0.0     [0. 0.]\n",
            "6     271     0.9995    0.0     [0. 0.]\n",
            "7     434     0.9994    0.0     [0. 0.]\n",
            "8     503     0.9994    0.0     [0. 0.]\n",
            "9     169     0.9994    0.0     [0. 0.]\n",
            "10    55      0.9994    1.0     [1. 0.]\n",
            "[Epoch 178 | Step 31] im_q: torch.Size([128, 1, 128, 48]), im_k: torch.Size([128, 1, 128, 48])\n",
            "\n",
            "[Top-k Label Logging] Epoch 179\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     94      0.9999    1.0     [1. 0.]\n",
            "2     0       0.9997    1.0     [1. 0.]\n",
            "3     434     0.9996    1.0     [1. 0.]\n",
            "4     109     0.9996    0.0     [0. 0.]\n",
            "5     507     0.9996    0.0     [0. 0.]\n",
            "6     353     0.9994    0.0     [0. 0.]\n",
            "7     207     0.9993    0.0     [0. 0.]\n",
            "8     330     0.9993    0.0     [0. 0.]\n",
            "9     161     0.9993    3.0     [1. 1.]\n",
            "10    420     0.9992    3.0     [1. 1.]\n",
            "[Epoch 179 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 180\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     377     1.0000    0.0     [0. 0.]\n",
            "2     109     1.0000    3.0     [1. 1.]\n",
            "3     372     1.0000    0.0     [0. 0.]\n",
            "4     315     1.0000    0.0     [0. 0.]\n",
            "5     212     1.0000    1.0     [1. 0.]\n",
            "6     251     1.0000    2.0     [0. 1.]\n",
            "7     244     1.0000    0.0     [0. 0.]\n",
            "8     14      1.0000    0.0     [0. 0.]\n",
            "9     402     1.0000    0.0     [0. 0.]\n",
            "10    467     1.0000    3.0     [1. 1.]\n",
            "[Epoch 180 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 181\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     228     0.9937    0.0     [0. 0.]\n",
            "2     245     0.9937    0.0     [0. 0.]\n",
            "3     198     0.9937    0.0     [0. 0.]\n",
            "4     445     0.9934    1.0     [1. 0.]\n",
            "5     10      0.9934    2.0     [0. 1.]\n",
            "6     263     0.9934    0.0     [0. 0.]\n",
            "7     438     0.9933    0.0     [0. 0.]\n",
            "8     276     0.9933    2.0     [0. 1.]\n",
            "9     53      0.9932    0.0     [0. 0.]\n",
            "10    417     0.9931    0.0     [0. 0.]\n",
            "[Epoch 181 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 182\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     36      0.9936    0.0     [0. 0.]\n",
            "2     226     0.9936    1.0     [1. 0.]\n",
            "3     164     0.9925    1.0     [1. 0.]\n",
            "4     494     0.9925    0.0     [0. 0.]\n",
            "5     287     0.9924    1.0     [1. 0.]\n",
            "6     301     0.9923    0.0     [0. 0.]\n",
            "7     327     0.9923    1.0     [1. 0.]\n",
            "8     281     0.9922    0.0     [0. 0.]\n",
            "9     435     0.9922    1.0     [1. 0.]\n",
            "10    85      0.9922    3.0     [1. 1.]\n",
            "[Epoch 182 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 183\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     37      0.9933    0.0     [0. 0.]\n",
            "2     424     0.9930    3.0     [1. 1.]\n",
            "3     308     0.9928    2.0     [0. 1.]\n",
            "4     2       0.9927    1.0     [1. 0.]\n",
            "5     270     0.9927    0.0     [0. 0.]\n",
            "6     300     0.9926    0.0     [0. 0.]\n",
            "7     377     0.9926    0.0     [0. 0.]\n",
            "8     368     0.9925    1.0     [1. 0.]\n",
            "9     181     0.9924    0.0     [0. 0.]\n",
            "10    66      0.9922    3.0     [1. 1.]\n",
            "[Epoch 183 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 184\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     397     0.9946    0.0     [0. 0.]\n",
            "2     396     0.9927    1.0     [1. 0.]\n",
            "3     82      0.9878    1.0     [1. 0.]\n",
            "4     0       0.9858    0.0     [0. 0.]\n",
            "5     155     0.9856    3.0     [1. 1.]\n",
            "6     356     0.9842    0.0     [0. 0.]\n",
            "7     326     0.9836    0.0     [0. 0.]\n",
            "8     193     0.9835    1.0     [1. 0.]\n",
            "9     103     0.9833    1.0     [1. 0.]\n",
            "10    227     0.9828    1.0     [1. 0.]\n",
            "[Epoch 184 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 185\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     415     1.0000    0.0     [0. 0.]\n",
            "2     298     1.0000    0.0     [0. 0.]\n",
            "3     0       1.0000    0.0     [0. 0.]\n",
            "4     316     1.0000    2.0     [0. 1.]\n",
            "5     318     1.0000    0.0     [0. 0.]\n",
            "6     317     1.0000    0.0     [0. 0.]\n",
            "7     237     1.0000    0.0     [0. 0.]\n",
            "8     197     1.0000    0.0     [0. 0.]\n",
            "9     169     1.0000    2.0     [0. 1.]\n",
            "10    69      1.0000    0.0     [0. 0.]\n",
            "[Epoch 185 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "=> Saved best checkpoint (epoch: 185, loss: 6.3468)\n",
            "\n",
            "[Top-k Label Logging] Epoch 186\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     240     0.9982    0.0     [0. 0.]\n",
            "2     395     0.9977    0.0     [0. 0.]\n",
            "3     0       0.9971    3.0     [1. 1.]\n",
            "4     115     0.9960    1.0     [1. 0.]\n",
            "5     149     0.9948    0.0     [0. 0.]\n",
            "6     282     0.9940    1.0     [1. 0.]\n",
            "7     257     0.9938    3.0     [1. 1.]\n",
            "8     502     0.9930    0.0     [0. 0.]\n",
            "9     472     0.9929    2.0     [0. 1.]\n",
            "10    233     0.9928    1.0     [1. 0.]\n",
            "[Epoch 186 | Step 31] im_q: torch.Size([128, 1, 128, 41]), im_k: torch.Size([128, 1, 128, 41])\n",
            "\n",
            "[Top-k Label Logging] Epoch 187\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     44      1.0000    0.0     [0. 0.]\n",
            "2     111     1.0000    0.0     [0. 0.]\n",
            "3     125     1.0000    0.0     [0. 0.]\n",
            "4     302     1.0000    2.0     [0. 1.]\n",
            "5     379     1.0000    0.0     [0. 0.]\n",
            "6     122     1.0000    2.0     [0. 1.]\n",
            "7     17      1.0000    0.0     [0. 0.]\n",
            "8     217     1.0000    0.0     [0. 0.]\n",
            "9     435     1.0000    0.0     [0. 0.]\n",
            "10    6       1.0000    0.0     [0. 0.]\n",
            "[Epoch 187 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 188\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     442     0.9972    0.0     [0. 0.]\n",
            "2     0       0.9969    1.0     [1. 0.]\n",
            "3     97      0.9968    0.0     [0. 0.]\n",
            "4     292     0.9968    0.0     [0. 0.]\n",
            "5     468     0.9967    0.0     [0. 0.]\n",
            "6     305     0.9965    0.0     [0. 0.]\n",
            "7     153     0.9962    1.0     [1. 0.]\n",
            "8     388     0.9958    0.0     [0. 0.]\n",
            "9     299     0.9957    0.0     [0. 0.]\n",
            "10    101     0.9955    0.0     [0. 0.]\n",
            "[Epoch 188 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 188, loss: 6.2357)\n",
            "\n",
            "[Top-k Label Logging] Epoch 189\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     34      1.0000    0.0     [0. 0.]\n",
            "2     334     1.0000    0.0     [0. 0.]\n",
            "3     431     1.0000    0.0     [0. 0.]\n",
            "4     322     1.0000    2.0     [0. 1.]\n",
            "5     72      1.0000    0.0     [0. 0.]\n",
            "6     9       1.0000    2.0     [0. 1.]\n",
            "7     108     1.0000    0.0     [0. 0.]\n",
            "8     459     1.0000    0.0     [0. 0.]\n",
            "9     504     1.0000    0.0     [0. 0.]\n",
            "10    136     1.0000    2.0     [0. 1.]\n",
            "[Epoch 189 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 190\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     55      1.0000    0.0     [0. 0.]\n",
            "2     162     1.0000    0.0     [0. 0.]\n",
            "3     3       1.0000    3.0     [1. 1.]\n",
            "4     167     1.0000    0.0     [0. 0.]\n",
            "5     65      1.0000    2.0     [0. 1.]\n",
            "6     467     1.0000    0.0     [0. 0.]\n",
            "7     40      1.0000    1.0     [1. 0.]\n",
            "8     222     1.0000    0.0     [0. 0.]\n",
            "9     269     1.0000    0.0     [0. 0.]\n",
            "10    313     1.0000    0.0     [0. 0.]\n",
            "[Epoch 190 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 191\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     404     1.0000    0.0     [0. 0.]\n",
            "2     277     1.0000    0.0     [0. 0.]\n",
            "3     342     1.0000    0.0     [0. 0.]\n",
            "4     317     1.0000    2.0     [0. 1.]\n",
            "5     254     1.0000    0.0     [0. 0.]\n",
            "6     396     1.0000    2.0     [0. 1.]\n",
            "7     319     1.0000    2.0     [0. 1.]\n",
            "8     489     1.0000    0.0     [0. 0.]\n",
            "9     322     1.0000    3.0     [1. 1.]\n",
            "10    508     1.0000    3.0     [1. 1.]\n",
            "[Epoch 191 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 192\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     498     1.0000    0.0     [0. 0.]\n",
            "2     420     1.0000    0.0     [0. 0.]\n",
            "3     56      1.0000    0.0     [0. 0.]\n",
            "4     489     1.0000    0.0     [0. 0.]\n",
            "5     143     1.0000    0.0     [0. 0.]\n",
            "6     430     1.0000    0.0     [0. 0.]\n",
            "7     417     1.0000    0.0     [0. 0.]\n",
            "8     150     1.0000    2.0     [0. 1.]\n",
            "9     455     1.0000    0.0     [0. 0.]\n",
            "10    91      1.0000    0.0     [0. 0.]\n",
            "[Epoch 192 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 193\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       1.0000    0.0     [0. 0.]\n",
            "2     491     0.9999    2.0     [0. 1.]\n",
            "3     198     0.9996    1.0     [1. 0.]\n",
            "4     265     0.9990    3.0     [1. 1.]\n",
            "5     500     0.9985    1.0     [1. 0.]\n",
            "6     46      0.9984    0.0     [0. 0.]\n",
            "7     12      0.9984    2.0     [0. 1.]\n",
            "8     68      0.9984    0.0     [0. 0.]\n",
            "9     107     0.9984    3.0     [1. 1.]\n",
            "10    422     0.9984    0.0     [0. 0.]\n",
            "[Epoch 193 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 194\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     17      1.0000    2.0     [0. 1.]\n",
            "2     96      1.0000    0.0     [0. 0.]\n",
            "3     176     1.0000    1.0     [1. 0.]\n",
            "4     241     1.0000    0.0     [0. 0.]\n",
            "5     318     1.0000    1.0     [1. 0.]\n",
            "6     143     1.0000    3.0     [1. 1.]\n",
            "7     439     0.9999    0.0     [0. 0.]\n",
            "8     67      0.9999    3.0     [1. 1.]\n",
            "9     324     0.9999    0.0     [0. 0.]\n",
            "10    430     0.9999    0.0     [0. 0.]\n",
            "[Epoch 194 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 195\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     456     0.9976    1.0     [1. 0.]\n",
            "2     362     0.9973    0.0     [0. 0.]\n",
            "3     69      0.9972    1.0     [1. 0.]\n",
            "4     75      0.9970    0.0     [0. 0.]\n",
            "5     35      0.9969    1.0     [1. 0.]\n",
            "6     111     0.9968    0.0     [0. 0.]\n",
            "7     173     0.9968    0.0     [0. 0.]\n",
            "8     317     0.9968    0.0     [0. 0.]\n",
            "9     223     0.9968    1.0     [1. 0.]\n",
            "10    340     0.9967    0.0     [0. 0.]\n",
            "[Epoch 195 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 196\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     47      0.9997    0.0     [0. 0.]\n",
            "2     37      0.9993    1.0     [1. 0.]\n",
            "3     299     0.9992    1.0     [1. 0.]\n",
            "4     226     0.9990    2.0     [0. 1.]\n",
            "5     315     0.9989    1.0     [1. 0.]\n",
            "6     258     0.9988    0.0     [0. 0.]\n",
            "7     58      0.9988    1.0     [1. 0.]\n",
            "8     19      0.9987    1.0     [1. 0.]\n",
            "9     76      0.9987    1.0     [1. 0.]\n",
            "10    370     0.9987    1.0     [1. 0.]\n",
            "[Epoch 196 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 197\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     320     1.0000    1.0     [1. 0.]\n",
            "2     100     1.0000    0.0     [0. 0.]\n",
            "3     282     1.0000    1.0     [1. 0.]\n",
            "4     3       1.0000    0.0     [0. 0.]\n",
            "5     294     1.0000    0.0     [0. 0.]\n",
            "6     368     1.0000    0.0     [0. 0.]\n",
            "7     163     1.0000    2.0     [0. 1.]\n",
            "8     283     1.0000    0.0     [0. 0.]\n",
            "9     46      1.0000    2.0     [0. 1.]\n",
            "10    312     1.0000    2.0     [0. 1.]\n",
            "[Epoch 197 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 198\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     54      1.0000    2.0     [0. 1.]\n",
            "2     47      1.0000    0.0     [0. 0.]\n",
            "3     277     1.0000    3.0     [1. 1.]\n",
            "4     462     1.0000    0.0     [0. 0.]\n",
            "5     17      1.0000    3.0     [1. 1.]\n",
            "6     366     1.0000    0.0     [0. 0.]\n",
            "7     439     1.0000    2.0     [0. 1.]\n",
            "8     106     1.0000    3.0     [1. 1.]\n",
            "9     363     1.0000    3.0     [1. 1.]\n",
            "10    295     1.0000    0.0     [0. 0.]\n",
            "[Epoch 198 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 199\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     315     0.9998    0.0     [0. 0.]\n",
            "2     216     0.9998    0.0     [0. 0.]\n",
            "3     208     0.9997    0.0     [0. 0.]\n",
            "4     202     0.9997    0.0     [0. 0.]\n",
            "5     438     0.9995    1.0     [1. 0.]\n",
            "6     379     0.9993    0.0     [0. 0.]\n",
            "7     243     0.9989    2.0     [0. 1.]\n",
            "8     64      0.9987    1.0     [1. 0.]\n",
            "9     36      0.9985    0.0     [0. 0.]\n",
            "10    129     0.9985    1.0     [1. 0.]\n",
            "[Epoch 199 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "💾 Saved checkpoint to /home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp/shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020_199.pth.tar\n",
            "\n",
            "[Top-k Label Logging] Epoch 200\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     147     1.0000    0.0     [0. 0.]\n",
            "2     245     1.0000    1.0     [1. 0.]\n",
            "3     275     1.0000    3.0     [1. 1.]\n",
            "4     420     1.0000    0.0     [0. 0.]\n",
            "5     219     1.0000    3.0     [1. 1.]\n",
            "6     113     1.0000    0.0     [0. 0.]\n",
            "7     242     1.0000    0.0     [0. 0.]\n",
            "8     510     1.0000    3.0     [1. 1.]\n",
            "9     334     1.0000    0.0     [0. 0.]\n",
            "10    4       0.9999    2.0     [0. 1.]\n",
            "[Epoch 200 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 201\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     431     0.9997    3.0     [1. 1.]\n",
            "2     20      0.9996    0.0     [0. 0.]\n",
            "3     113     0.9995    3.0     [1. 1.]\n",
            "4     42      0.9994    2.0     [0. 1.]\n",
            "5     163     0.9994    2.0     [0. 1.]\n",
            "6     469     0.9993    3.0     [1. 1.]\n",
            "7     154     0.9983    3.0     [1. 1.]\n",
            "8     417     0.9983    0.0     [0. 0.]\n",
            "9     337     0.9983    0.0     [0. 0.]\n",
            "10    467     0.9982    0.0     [0. 0.]\n",
            "[Epoch 201 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 202\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     384     0.9999    1.0     [1. 0.]\n",
            "2     24      0.9998    0.0     [0. 0.]\n",
            "3     52      0.9997    1.0     [1. 0.]\n",
            "4     64      0.9995    1.0     [1. 0.]\n",
            "5     130     0.9984    1.0     [1. 0.]\n",
            "6     416     0.9984    0.0     [0. 0.]\n",
            "7     330     0.9984    2.0     [0. 1.]\n",
            "8     295     0.9984    2.0     [0. 1.]\n",
            "9     291     0.9984    1.0     [1. 0.]\n",
            "10    473     0.9983    0.0     [0. 0.]\n",
            "[Epoch 202 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 203\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     74      0.9999    0.0     [0. 0.]\n",
            "2     504     0.9999    0.0     [0. 0.]\n",
            "3     14      0.9999    0.0     [0. 0.]\n",
            "4     355     0.9999    1.0     [1. 0.]\n",
            "5     276     0.9999    2.0     [0. 1.]\n",
            "6     33      0.9998    2.0     [0. 1.]\n",
            "7     167     0.9998    0.0     [0. 0.]\n",
            "8     119     0.9998    1.0     [1. 0.]\n",
            "9     381     0.9997    0.0     [0. 0.]\n",
            "10    382     0.9996    0.0     [0. 0.]\n",
            "[Epoch 203 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 204\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     317     0.9971    0.0     [0. 0.]\n",
            "2     205     0.9966    3.0     [1. 1.]\n",
            "3     74      0.9966    3.0     [1. 1.]\n",
            "4     27      0.9965    0.0     [0. 0.]\n",
            "5     178     0.9964    1.0     [1. 0.]\n",
            "6     452     0.9964    2.0     [0. 1.]\n",
            "7     454     0.9962    0.0     [0. 0.]\n",
            "8     34      0.9962    2.0     [0. 1.]\n",
            "9     342     0.9962    1.0     [1. 0.]\n",
            "10    321     0.9962    1.0     [1. 0.]\n",
            "[Epoch 204 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 205\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     500     1.0000    0.0     [0. 0.]\n",
            "2     455     1.0000    0.0     [0. 0.]\n",
            "3     347     1.0000    0.0     [0. 0.]\n",
            "4     311     1.0000    0.0     [0. 0.]\n",
            "5     423     1.0000    0.0     [0. 0.]\n",
            "6     282     1.0000    0.0     [0. 0.]\n",
            "7     240     1.0000    2.0     [0. 1.]\n",
            "8     442     1.0000    2.0     [0. 1.]\n",
            "9     65      1.0000    2.0     [0. 1.]\n",
            "10    313     1.0000    0.0     [0. 0.]\n",
            "[Epoch 205 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 206\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     179     1.0000    0.0     [0. 0.]\n",
            "2     40      1.0000    0.0     [0. 0.]\n",
            "3     7       1.0000    0.0     [0. 0.]\n",
            "4     251     1.0000    0.0     [0. 0.]\n",
            "5     272     1.0000    0.0     [0. 0.]\n",
            "6     479     1.0000    0.0     [0. 0.]\n",
            "7     328     1.0000    2.0     [0. 1.]\n",
            "8     264     1.0000    2.0     [0. 1.]\n",
            "9     14      1.0000    2.0     [0. 1.]\n",
            "10    303     1.0000    0.0     [0. 0.]\n",
            "[Epoch 206 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 207\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     59      1.0000    0.0     [0. 0.]\n",
            "2     352     1.0000    0.0     [0. 0.]\n",
            "3     384     1.0000    1.0     [1. 0.]\n",
            "4     104     1.0000    0.0     [0. 0.]\n",
            "5     241     1.0000    3.0     [1. 1.]\n",
            "6     160     1.0000    3.0     [1. 1.]\n",
            "7     308     1.0000    2.0     [0. 1.]\n",
            "8     468     1.0000    3.0     [1. 1.]\n",
            "9     447     1.0000    0.0     [0. 0.]\n",
            "10    276     1.0000    0.0     [0. 0.]\n",
            "[Epoch 207 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 208\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     445     1.0000    0.0     [0. 0.]\n",
            "2     177     1.0000    0.0     [0. 0.]\n",
            "3     139     1.0000    0.0     [0. 0.]\n",
            "4     207     1.0000    0.0     [0. 0.]\n",
            "5     247     1.0000    1.0     [1. 0.]\n",
            "6     166     1.0000    0.0     [0. 0.]\n",
            "7     434     1.0000    0.0     [0. 0.]\n",
            "8     295     1.0000    2.0     [0. 1.]\n",
            "9     313     1.0000    2.0     [0. 1.]\n",
            "10    22      1.0000    2.0     [0. 1.]\n",
            "[Epoch 208 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 209\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     406     1.0000    1.0     [1. 0.]\n",
            "2     346     1.0000    0.0     [0. 0.]\n",
            "3     293     1.0000    0.0     [0. 0.]\n",
            "4     313     1.0000    0.0     [0. 0.]\n",
            "5     304     1.0000    0.0     [0. 0.]\n",
            "6     372     1.0000    3.0     [1. 1.]\n",
            "7     29      1.0000    0.0     [0. 0.]\n",
            "8     411     1.0000    0.0     [0. 0.]\n",
            "9     168     1.0000    2.0     [0. 1.]\n",
            "10    401     1.0000    0.0     [0. 0.]\n",
            "[Epoch 209 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 210\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     20      1.0000    0.0     [0. 0.]\n",
            "2     377     1.0000    0.0     [0. 0.]\n",
            "3     182     1.0000    3.0     [1. 1.]\n",
            "4     108     1.0000    1.0     [1. 0.]\n",
            "5     308     1.0000    3.0     [1. 1.]\n",
            "6     32      1.0000    0.0     [0. 0.]\n",
            "7     194     1.0000    2.0     [0. 1.]\n",
            "8     13      1.0000    1.0     [1. 0.]\n",
            "9     40      1.0000    0.0     [0. 0.]\n",
            "10    242     1.0000    0.0     [0. 0.]\n",
            "[Epoch 210 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 211\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     293     0.9989    0.0     [0. 0.]\n",
            "2     346     0.9988    0.0     [0. 0.]\n",
            "3     121     0.9982    1.0     [1. 0.]\n",
            "4     331     0.9980    1.0     [1. 0.]\n",
            "5     504     0.9980    1.0     [1. 0.]\n",
            "6     11      0.9979    3.0     [1. 1.]\n",
            "7     358     0.9977    3.0     [1. 1.]\n",
            "8     405     0.9977    0.0     [0. 0.]\n",
            "9     83      0.9977    0.0     [0. 0.]\n",
            "10    184     0.9976    0.0     [0. 0.]\n",
            "[Epoch 211 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 212\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     433     1.0000    0.0     [0. 0.]\n",
            "2     200     1.0000    2.0     [0. 1.]\n",
            "3     194     1.0000    0.0     [0. 0.]\n",
            "4     230     1.0000    0.0     [0. 0.]\n",
            "5     79      1.0000    0.0     [0. 0.]\n",
            "6     341     1.0000    0.0     [0. 0.]\n",
            "7     394     1.0000    0.0     [0. 0.]\n",
            "8     140     1.0000    0.0     [0. 0.]\n",
            "9     63      1.0000    1.0     [1. 0.]\n",
            "10    485     1.0000    2.0     [0. 1.]\n",
            "[Epoch 212 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 212, loss: 6.2099)\n",
            "\n",
            "[Top-k Label Logging] Epoch 213\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     378     1.0000    0.0     [0. 0.]\n",
            "2     466     1.0000    0.0     [0. 0.]\n",
            "3     47      1.0000    0.0     [0. 0.]\n",
            "4     237     1.0000    0.0     [0. 0.]\n",
            "5     307     1.0000    0.0     [0. 0.]\n",
            "6     398     1.0000    0.0     [0. 0.]\n",
            "7     61      1.0000    0.0     [0. 0.]\n",
            "8     187     1.0000    2.0     [0. 1.]\n",
            "9     54      1.0000    0.0     [0. 0.]\n",
            "10    39      1.0000    0.0     [0. 0.]\n",
            "[Epoch 213 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 214\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     471     0.9996    1.0     [1. 0.]\n",
            "2     370     0.9996    1.0     [1. 0.]\n",
            "3     83      0.9995    0.0     [0. 0.]\n",
            "4     207     0.9995    0.0     [0. 0.]\n",
            "5     112     0.9994    0.0     [0. 0.]\n",
            "6     244     0.9994    0.0     [0. 0.]\n",
            "7     491     0.9994    0.0     [0. 0.]\n",
            "8     294     0.9993    0.0     [0. 0.]\n",
            "9     408     0.9991    0.0     [0. 0.]\n",
            "10    489     0.9991    0.0     [0. 0.]\n",
            "[Epoch 214 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "\n",
            "[Top-k Label Logging] Epoch 215\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     185     1.0000    0.0     [0. 0.]\n",
            "2     42      1.0000    1.0     [1. 0.]\n",
            "3     317     1.0000    0.0     [0. 0.]\n",
            "4     200     1.0000    0.0     [0. 0.]\n",
            "5     492     1.0000    0.0     [0. 0.]\n",
            "6     5       1.0000    1.0     [1. 0.]\n",
            "7     375     1.0000    0.0     [0. 0.]\n",
            "8     138     1.0000    0.0     [0. 0.]\n",
            "9     111     0.9999    0.0     [0. 0.]\n",
            "10    511     0.9999    3.0     [1. 1.]\n",
            "[Epoch 215 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 216\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     49      1.0000    2.0     [0. 1.]\n",
            "2     347     1.0000    0.0     [0. 0.]\n",
            "3     34      1.0000    0.0     [0. 0.]\n",
            "4     47      1.0000    0.0     [0. 0.]\n",
            "5     343     1.0000    0.0     [0. 0.]\n",
            "6     0       1.0000    0.0     [0. 0.]\n",
            "7     101     1.0000    2.0     [0. 1.]\n",
            "8     322     1.0000    0.0     [0. 0.]\n",
            "9     385     1.0000    2.0     [0. 1.]\n",
            "10    355     1.0000    3.0     [1. 1.]\n",
            "[Epoch 216 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 217\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     86      0.9999    1.0     [1. 0.]\n",
            "2     397     0.9999    0.0     [0. 0.]\n",
            "3     146     0.9999    0.0     [0. 0.]\n",
            "4     412     0.9999    0.0     [0. 0.]\n",
            "5     343     0.9998    1.0     [1. 0.]\n",
            "6     116     0.9998    1.0     [1. 0.]\n",
            "7     90      0.9997    0.0     [0. 0.]\n",
            "8     209     0.9997    0.0     [0. 0.]\n",
            "9     417     0.9995    0.0     [0. 0.]\n",
            "10    77      0.9994    0.0     [0. 0.]\n",
            "[Epoch 217 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 218\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       0.9996    0.0     [0. 0.]\n",
            "2     495     0.9991    0.0     [0. 0.]\n",
            "3     299     0.9984    3.0     [1. 1.]\n",
            "4     362     0.9984    3.0     [1. 1.]\n",
            "5     334     0.9984    2.0     [0. 1.]\n",
            "6     388     0.9984    1.0     [1. 0.]\n",
            "7     363     0.9984    0.0     [0. 0.]\n",
            "8     80      0.9984    1.0     [1. 0.]\n",
            "9     436     0.9984    1.0     [1. 0.]\n",
            "10    431     0.9984    1.0     [1. 0.]\n",
            "[Epoch 218 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 219\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     56      0.9997    1.0     [1. 0.]\n",
            "2     0       0.9996    1.0     [1. 0.]\n",
            "3     3       0.9995    0.0     [0. 0.]\n",
            "4     455     0.9994    0.0     [0. 0.]\n",
            "5     289     0.9992    3.0     [1. 1.]\n",
            "6     426     0.9992    0.0     [0. 0.]\n",
            "7     375     0.9992    0.0     [0. 0.]\n",
            "8     448     0.9992    0.0     [0. 0.]\n",
            "9     133     0.9991    0.0     [0. 0.]\n",
            "10    389     0.9991    1.0     [1. 0.]\n",
            "[Epoch 219 | Step 31] im_q: torch.Size([128, 1, 128, 54]), im_k: torch.Size([128, 1, 128, 54])\n",
            "\n",
            "[Top-k Label Logging] Epoch 220\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     256     1.0000    0.0     [0. 0.]\n",
            "2     177     1.0000    0.0     [0. 0.]\n",
            "3     0       1.0000    0.0     [0. 0.]\n",
            "4     342     1.0000    1.0     [1. 0.]\n",
            "5     308     1.0000    0.0     [0. 0.]\n",
            "6     437     1.0000    2.0     [0. 1.]\n",
            "7     299     1.0000    0.0     [0. 0.]\n",
            "8     318     1.0000    1.0     [1. 0.]\n",
            "9     15      1.0000    3.0     [1. 1.]\n",
            "10    456     1.0000    0.0     [0. 0.]\n",
            "[Epoch 220 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 221\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     46      0.9997    0.0     [0. 0.]\n",
            "2     405     0.9996    0.0     [0. 0.]\n",
            "3     398     0.9996    1.0     [1. 0.]\n",
            "4     98      0.9994    3.0     [1. 1.]\n",
            "5     17      0.9991    0.0     [0. 0.]\n",
            "6     37      0.9991    2.0     [0. 1.]\n",
            "7     247     0.9989    2.0     [0. 1.]\n",
            "8     301     0.9989    0.0     [0. 0.]\n",
            "9     79      0.9989    0.0     [0. 0.]\n",
            "10    475     0.9988    0.0     [0. 0.]\n",
            "[Epoch 221 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "=> Saved best checkpoint (epoch: 221, loss: 6.1905)\n",
            "\n",
            "[Top-k Label Logging] Epoch 222\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     30      0.9999    0.0     [0. 0.]\n",
            "2     337     0.9999    0.0     [0. 0.]\n",
            "3     23      0.9998    1.0     [1. 0.]\n",
            "4     299     0.9997    3.0     [1. 1.]\n",
            "5     469     0.9995    1.0     [1. 0.]\n",
            "6     325     0.9995    1.0     [1. 0.]\n",
            "7     29      0.9995    1.0     [1. 0.]\n",
            "8     151     0.9994    1.0     [1. 0.]\n",
            "9     470     0.9992    0.0     [0. 0.]\n",
            "10    0       0.9992    1.0     [1. 0.]\n",
            "[Epoch 222 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 223\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     408     1.0000    0.0     [0. 0.]\n",
            "2     248     1.0000    2.0     [0. 1.]\n",
            "3     485     1.0000    0.0     [0. 0.]\n",
            "4     7       1.0000    0.0     [0. 0.]\n",
            "5     507     1.0000    0.0     [0. 0.]\n",
            "6     377     1.0000    0.0     [0. 0.]\n",
            "7     325     1.0000    0.0     [0. 0.]\n",
            "8     3       1.0000    2.0     [0. 1.]\n",
            "9     209     1.0000    0.0     [0. 0.]\n",
            "10    423     1.0000    2.0     [0. 1.]\n",
            "[Epoch 223 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 224\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     353     0.9979    0.0     [0. 0.]\n",
            "2     220     0.9968    0.0     [0. 0.]\n",
            "3     218     0.9967    1.0     [1. 0.]\n",
            "4     372     0.9966    0.0     [0. 0.]\n",
            "5     22      0.9964    1.0     [1. 0.]\n",
            "6     60      0.9963    3.0     [1. 1.]\n",
            "7     198     0.9962    1.0     [1. 0.]\n",
            "8     289     0.9962    1.0     [1. 0.]\n",
            "9     247     0.9962    0.0     [0. 0.]\n",
            "10    332     0.9962    1.0     [1. 0.]\n",
            "[Epoch 224 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "\n",
            "[Top-k Label Logging] Epoch 225\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     114     1.0000    0.0     [0. 0.]\n",
            "2     44      1.0000    0.0     [0. 0.]\n",
            "3     390     1.0000    0.0     [0. 0.]\n",
            "4     287     1.0000    3.0     [1. 1.]\n",
            "5     482     1.0000    2.0     [0. 1.]\n",
            "6     333     1.0000    2.0     [0. 1.]\n",
            "7     65      1.0000    0.0     [0. 0.]\n",
            "8     386     1.0000    0.0     [0. 0.]\n",
            "9     355     1.0000    2.0     [0. 1.]\n",
            "10    266     1.0000    0.0     [0. 0.]\n",
            "[Epoch 225 | Step 31] im_q: torch.Size([128, 1, 128, 61]), im_k: torch.Size([128, 1, 128, 61])\n",
            "\n",
            "[Top-k Label Logging] Epoch 226\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     118     0.9998    0.0     [0. 0.]\n",
            "2     240     0.9997    3.0     [1. 1.]\n",
            "3     461     0.9996    0.0     [0. 0.]\n",
            "4     0       0.9996    0.0     [0. 0.]\n",
            "5     404     0.9995    1.0     [1. 0.]\n",
            "6     168     0.9993    0.0     [0. 0.]\n",
            "7     311     0.9993    3.0     [1. 1.]\n",
            "8     279     0.9990    0.0     [0. 0.]\n",
            "9     487     0.9990    1.0     [1. 0.]\n",
            "10    270     0.9989    0.0     [0. 0.]\n",
            "[Epoch 226 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "=> Saved best checkpoint (epoch: 226, loss: 6.1665)\n",
            "\n",
            "[Top-k Label Logging] Epoch 227\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     446     1.0000    0.0     [0. 0.]\n",
            "2     153     1.0000    0.0     [0. 0.]\n",
            "3     347     1.0000    0.0     [0. 0.]\n",
            "4     256     1.0000    0.0     [0. 0.]\n",
            "5     286     1.0000    2.0     [0. 1.]\n",
            "6     341     1.0000    2.0     [0. 1.]\n",
            "7     414     1.0000    2.0     [0. 1.]\n",
            "8     201     1.0000    2.0     [0. 1.]\n",
            "9     110     1.0000    2.0     [0. 1.]\n",
            "10    343     1.0000    0.0     [0. 0.]\n",
            "[Epoch 227 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 228\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     93      1.0000    0.0     [0. 0.]\n",
            "2     128     1.0000    0.0     [0. 0.]\n",
            "3     32      1.0000    2.0     [0. 1.]\n",
            "4     322     1.0000    2.0     [0. 1.]\n",
            "5     11      1.0000    2.0     [0. 1.]\n",
            "6     111     1.0000    0.0     [0. 0.]\n",
            "7     304     1.0000    2.0     [0. 1.]\n",
            "8     212     1.0000    0.0     [0. 0.]\n",
            "9     395     1.0000    0.0     [0. 0.]\n",
            "10    7       1.0000    0.0     [0. 0.]\n",
            "[Epoch 228 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "=> Saved best checkpoint (epoch: 228, loss: 6.1177)\n",
            "\n",
            "[Top-k Label Logging] Epoch 229\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     175     1.0000    0.0     [0. 0.]\n",
            "2     45      1.0000    1.0     [1. 0.]\n",
            "3     149     1.0000    0.0     [0. 0.]\n",
            "4     452     1.0000    3.0     [1. 1.]\n",
            "5     254     1.0000    0.0     [0. 0.]\n",
            "6     164     1.0000    2.0     [0. 1.]\n",
            "7     22      1.0000    0.0     [0. 0.]\n",
            "8     378     1.0000    0.0     [0. 0.]\n",
            "9     448     1.0000    0.0     [0. 0.]\n",
            "10    28      1.0000    3.0     [1. 1.]\n",
            "[Epoch 229 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "\n",
            "[Top-k Label Logging] Epoch 230\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     47      0.9988    2.0     [0. 1.]\n",
            "2     500     0.9987    2.0     [0. 1.]\n",
            "3     285     0.9984    0.0     [0. 0.]\n",
            "4     294     0.9980    0.0     [0. 0.]\n",
            "5     134     0.9980    1.0     [1. 0.]\n",
            "6     116     0.9979    1.0     [1. 0.]\n",
            "7     410     0.9979    1.0     [1. 0.]\n",
            "8     164     0.9977    3.0     [1. 1.]\n",
            "9     457     0.9976    3.0     [1. 1.]\n",
            "10    438     0.9975    2.0     [0. 1.]\n",
            "[Epoch 230 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 231\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     258     1.0000    0.0     [0. 0.]\n",
            "2     26      1.0000    0.0     [0. 0.]\n",
            "3     237     1.0000    0.0     [0. 0.]\n",
            "4     9       1.0000    0.0     [0. 0.]\n",
            "5     184     1.0000    0.0     [0. 0.]\n",
            "6     249     1.0000    0.0     [0. 0.]\n",
            "7     327     1.0000    0.0     [0. 0.]\n",
            "8     287     1.0000    0.0     [0. 0.]\n",
            "9     315     1.0000    0.0     [0. 0.]\n",
            "10    136     1.0000    0.0     [0. 0.]\n",
            "[Epoch 231 | Step 31] im_q: torch.Size([128, 1, 128, 43]), im_k: torch.Size([128, 1, 128, 43])\n",
            "\n",
            "[Top-k Label Logging] Epoch 232\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     302     0.9996    3.0     [1. 1.]\n",
            "2     174     0.9989    0.0     [0. 0.]\n",
            "3     415     0.9988    0.0     [0. 0.]\n",
            "4     22      0.9985    1.0     [1. 0.]\n",
            "5     18      0.9984    1.0     [1. 0.]\n",
            "6     260     0.9984    1.0     [1. 0.]\n",
            "7     268     0.9983    2.0     [0. 1.]\n",
            "8     477     0.9983    1.0     [1. 0.]\n",
            "9     386     0.9982    1.0     [1. 0.]\n",
            "10    32      0.9982    3.0     [1. 1.]\n",
            "[Epoch 232 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 233\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     361     1.0000    0.0     [0. 0.]\n",
            "2     268     1.0000    1.0     [1. 0.]\n",
            "3     504     1.0000    0.0     [0. 0.]\n",
            "4     51      1.0000    0.0     [0. 0.]\n",
            "5     81      1.0000    3.0     [1. 1.]\n",
            "6     327     1.0000    0.0     [0. 0.]\n",
            "7     307     1.0000    1.0     [1. 0.]\n",
            "8     355     1.0000    0.0     [0. 0.]\n",
            "9     37      0.9999    0.0     [0. 0.]\n",
            "10    259     0.9999    0.0     [0. 0.]\n",
            "[Epoch 233 | Step 31] im_q: torch.Size([128, 1, 128, 42]), im_k: torch.Size([128, 1, 128, 42])\n",
            "=> Saved best checkpoint (epoch: 233, loss: 6.1070)\n",
            "\n",
            "[Top-k Label Logging] Epoch 234\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     30      1.0000    0.0     [0. 0.]\n",
            "2     56      1.0000    0.0     [0. 0.]\n",
            "3     237     1.0000    1.0     [1. 0.]\n",
            "4     441     1.0000    3.0     [1. 1.]\n",
            "5     399     1.0000    0.0     [0. 0.]\n",
            "6     333     1.0000    0.0     [0. 0.]\n",
            "7     162     1.0000    0.0     [0. 0.]\n",
            "8     397     1.0000    1.0     [1. 0.]\n",
            "9     416     1.0000    0.0     [0. 0.]\n",
            "10    483     1.0000    2.0     [0. 1.]\n",
            "[Epoch 234 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 235\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     187     1.0000    0.0     [0. 0.]\n",
            "2     255     1.0000    0.0     [0. 0.]\n",
            "3     154     1.0000    0.0     [0. 0.]\n",
            "4     393     1.0000    0.0     [0. 0.]\n",
            "5     198     1.0000    0.0     [0. 0.]\n",
            "6     218     1.0000    1.0     [1. 0.]\n",
            "7     292     1.0000    2.0     [0. 1.]\n",
            "8     114     1.0000    1.0     [1. 0.]\n",
            "9     161     1.0000    0.0     [0. 0.]\n",
            "10    250     1.0000    3.0     [1. 1.]\n",
            "[Epoch 235 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 236\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     402     0.9999    2.0     [0. 1.]\n",
            "2     321     0.9999    0.0     [0. 0.]\n",
            "3     111     0.9996    0.0     [0. 0.]\n",
            "4     195     0.9990    0.0     [0. 0.]\n",
            "5     259     0.9987    1.0     [1. 0.]\n",
            "6     136     0.9983    2.0     [0. 1.]\n",
            "7     74      0.9982    0.0     [0. 0.]\n",
            "8     460     0.9982    0.0     [0. 0.]\n",
            "9     179     0.9981    0.0     [0. 0.]\n",
            "10    343     0.9981    0.0     [0. 0.]\n",
            "[Epoch 236 | Step 31] im_q: torch.Size([128, 1, 128, 48]), im_k: torch.Size([128, 1, 128, 48])\n",
            "=> Saved best checkpoint (epoch: 236, loss: 6.0286)\n",
            "\n",
            "[Top-k Label Logging] Epoch 237\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     263     1.0000    1.0     [1. 0.]\n",
            "2     241     1.0000    0.0     [0. 0.]\n",
            "3     259     1.0000    0.0     [0. 0.]\n",
            "4     368     1.0000    0.0     [0. 0.]\n",
            "5     329     1.0000    0.0     [0. 0.]\n",
            "6     313     1.0000    0.0     [0. 0.]\n",
            "7     89      1.0000    2.0     [0. 1.]\n",
            "8     87      1.0000    0.0     [0. 0.]\n",
            "9     49      1.0000    0.0     [0. 0.]\n",
            "10    13      1.0000    1.0     [1. 0.]\n",
            "[Epoch 237 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 238\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     139     0.9995    1.0     [1. 0.]\n",
            "2     6       0.9993    0.0     [0. 0.]\n",
            "3     161     0.9986    1.0     [1. 0.]\n",
            "4     169     0.9982    0.0     [0. 0.]\n",
            "5     232     0.9981    1.0     [1. 0.]\n",
            "6     119     0.9980    0.0     [0. 0.]\n",
            "7     333     0.9979    1.0     [1. 0.]\n",
            "8     509     0.9979    1.0     [1. 0.]\n",
            "9     469     0.9979    0.0     [0. 0.]\n",
            "10    66      0.9978    0.0     [0. 0.]\n",
            "[Epoch 238 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 239\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     180     0.9986    0.0     [0. 0.]\n",
            "2     367     0.9986    1.0     [1. 0.]\n",
            "3     139     0.9983    0.0     [0. 0.]\n",
            "4     11      0.9983    0.0     [0. 0.]\n",
            "5     182     0.9978    1.0     [1. 0.]\n",
            "6     391     0.9978    3.0     [1. 1.]\n",
            "7     228     0.9975    0.0     [0. 0.]\n",
            "8     226     0.9971    2.0     [0. 1.]\n",
            "9     259     0.9971    1.0     [1. 0.]\n",
            "10    203     0.9971    0.0     [0. 0.]\n",
            "[Epoch 239 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 240\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     425     0.9999    2.0     [0. 1.]\n",
            "2     0       0.9999    1.0     [1. 0.]\n",
            "3     411     0.9998    1.0     [1. 0.]\n",
            "4     73      0.9998    0.0     [0. 0.]\n",
            "5     412     0.9998    0.0     [0. 0.]\n",
            "6     158     0.9998    0.0     [0. 0.]\n",
            "7     39      0.9997    0.0     [0. 0.]\n",
            "8     367     0.9997    0.0     [0. 0.]\n",
            "9     474     0.9997    0.0     [0. 0.]\n",
            "10    88      0.9995    0.0     [0. 0.]\n",
            "[Epoch 240 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 241\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     352     1.0000    2.0     [0. 1.]\n",
            "2     119     1.0000    2.0     [0. 1.]\n",
            "3     87      1.0000    3.0     [1. 1.]\n",
            "4     388     1.0000    1.0     [1. 0.]\n",
            "5     170     0.9999    0.0     [0. 0.]\n",
            "6     424     0.9999    2.0     [0. 1.]\n",
            "7     201     0.9999    2.0     [0. 1.]\n",
            "8     88      0.9999    0.0     [0. 0.]\n",
            "9     173     0.9999    0.0     [0. 0.]\n",
            "10    423     0.9999    0.0     [0. 0.]\n",
            "[Epoch 241 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 242\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     435     0.9999    0.0     [0. 0.]\n",
            "2     92      0.9998    0.0     [0. 0.]\n",
            "3     329     0.9998    0.0     [0. 0.]\n",
            "4     239     0.9998    1.0     [1. 0.]\n",
            "5     273     0.9998    3.0     [1. 1.]\n",
            "6     91      0.9997    3.0     [1. 1.]\n",
            "7     160     0.9996    1.0     [1. 0.]\n",
            "8     505     0.9994    0.0     [0. 0.]\n",
            "9     291     0.9993    0.0     [0. 0.]\n",
            "10    0       0.9992    0.0     [0. 0.]\n",
            "[Epoch 242 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 243\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     178     0.9984    1.0     [1. 0.]\n",
            "2     482     0.9980    2.0     [0. 1.]\n",
            "3     149     0.9980    0.0     [0. 0.]\n",
            "4     272     0.9973    3.0     [1. 1.]\n",
            "5     241     0.9973    1.0     [1. 0.]\n",
            "6     294     0.9973    0.0     [0. 0.]\n",
            "7     127     0.9973    0.0     [0. 0.]\n",
            "8     114     0.9969    0.0     [0. 0.]\n",
            "9     143     0.9969    0.0     [0. 0.]\n",
            "10    157     0.9969    1.0     [1. 0.]\n",
            "[Epoch 243 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "=> Saved best checkpoint (epoch: 243, loss: 6.0194)\n",
            "\n",
            "[Top-k Label Logging] Epoch 244\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     440     0.9979    0.0     [0. 0.]\n",
            "2     455     0.9979    0.0     [0. 0.]\n",
            "3     249     0.9968    1.0     [1. 0.]\n",
            "4     494     0.9965    2.0     [0. 1.]\n",
            "5     453     0.9964    2.0     [0. 1.]\n",
            "6     358     0.9964    1.0     [1. 0.]\n",
            "7     157     0.9963    3.0     [1. 1.]\n",
            "8     282     0.9963    3.0     [1. 1.]\n",
            "9     370     0.9963    1.0     [1. 0.]\n",
            "10    419     0.9963    0.0     [0. 0.]\n",
            "[Epoch 244 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 245\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     133     1.0000    1.0     [1. 0.]\n",
            "2     65      1.0000    0.0     [0. 0.]\n",
            "3     432     1.0000    1.0     [1. 0.]\n",
            "4     179     1.0000    3.0     [1. 1.]\n",
            "5     457     1.0000    0.0     [0. 0.]\n",
            "6     257     0.9999    1.0     [1. 0.]\n",
            "7     145     0.9999    0.0     [0. 0.]\n",
            "8     403     0.9999    2.0     [0. 1.]\n",
            "9     180     0.9999    0.0     [0. 0.]\n",
            "10    128     0.9999    2.0     [0. 1.]\n",
            "[Epoch 245 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 246\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     114     0.9997    0.0     [0. 0.]\n",
            "2     430     0.9995    2.0     [0. 1.]\n",
            "3     73      0.9987    0.0     [0. 0.]\n",
            "4     257     0.9984    0.0     [0. 0.]\n",
            "5     34      0.9983    2.0     [0. 1.]\n",
            "6     17      0.9983    0.0     [0. 0.]\n",
            "7     324     0.9983    0.0     [0. 0.]\n",
            "8     500     0.9983    1.0     [1. 0.]\n",
            "9     398     0.9982    2.0     [0. 1.]\n",
            "10    131     0.9982    1.0     [1. 0.]\n",
            "[Epoch 246 | Step 31] im_q: torch.Size([128, 1, 128, 69]), im_k: torch.Size([128, 1, 128, 69])\n",
            "\n",
            "[Top-k Label Logging] Epoch 247\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     337     0.9983    1.0     [1. 0.]\n",
            "2     159     0.9974    0.0     [0. 0.]\n",
            "3     273     0.9962    3.0     [1. 1.]\n",
            "4     213     0.9962    0.0     [0. 0.]\n",
            "5     103     0.9962    1.0     [1. 0.]\n",
            "6     302     0.9961    1.0     [1. 0.]\n",
            "7     277     0.9961    1.0     [1. 0.]\n",
            "8     354     0.9960    1.0     [1. 0.]\n",
            "9     125     0.9960    3.0     [1. 1.]\n",
            "10    247     0.9960    1.0     [1. 0.]\n",
            "[Epoch 247 | Step 31] im_q: torch.Size([128, 1, 128, 42]), im_k: torch.Size([128, 1, 128, 42])\n",
            "=> Saved best checkpoint (epoch: 247, loss: 5.9325)\n",
            "\n",
            "[Top-k Label Logging] Epoch 248\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     46      1.0000    0.0     [0. 0.]\n",
            "2     368     1.0000    3.0     [1. 1.]\n",
            "3     8       1.0000    1.0     [1. 0.]\n",
            "4     43      1.0000    0.0     [0. 0.]\n",
            "5     229     1.0000    2.0     [0. 1.]\n",
            "6     316     0.9999    0.0     [0. 0.]\n",
            "7     144     0.9999    0.0     [0. 0.]\n",
            "8     29      0.9999    2.0     [0. 1.]\n",
            "9     189     0.9999    2.0     [0. 1.]\n",
            "10    292     0.9999    0.0     [0. 0.]\n",
            "[Epoch 248 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 249\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     43      1.0000    1.0     [1. 0.]\n",
            "2     63      1.0000    0.0     [0. 0.]\n",
            "3     132     1.0000    1.0     [1. 0.]\n",
            "4     349     1.0000    1.0     [1. 0.]\n",
            "5     133     1.0000    0.0     [0. 0.]\n",
            "6     97      1.0000    0.0     [0. 0.]\n",
            "7     73      1.0000    2.0     [0. 1.]\n",
            "8     184     1.0000    0.0     [0. 0.]\n",
            "9     158     1.0000    0.0     [0. 0.]\n",
            "10    251     1.0000    2.0     [0. 1.]\n",
            "[Epoch 249 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 250\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     71      0.9997    0.0     [0. 0.]\n",
            "2     503     0.9996    1.0     [1. 0.]\n",
            "3     334     0.9995    0.0     [0. 0.]\n",
            "4     14      0.9984    0.0     [0. 0.]\n",
            "5     81      0.9983    0.0     [0. 0.]\n",
            "6     202     0.9982    0.0     [0. 0.]\n",
            "7     7       0.9982    2.0     [0. 1.]\n",
            "8     11      0.9979    0.0     [0. 0.]\n",
            "9     207     0.9978    1.0     [1. 0.]\n",
            "10    354     0.9976    1.0     [1. 0.]\n",
            "[Epoch 250 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "=> Saved best checkpoint (epoch: 250, loss: 5.9291)\n",
            "\n",
            "[Top-k Label Logging] Epoch 251\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     356     1.0000    0.0     [0. 0.]\n",
            "2     174     1.0000    0.0     [0. 0.]\n",
            "3     297     1.0000    3.0     [1. 1.]\n",
            "4     213     1.0000    0.0     [0. 0.]\n",
            "5     237     1.0000    3.0     [1. 1.]\n",
            "6     173     1.0000    0.0     [0. 0.]\n",
            "7     194     1.0000    0.0     [0. 0.]\n",
            "8     1       1.0000    0.0     [0. 0.]\n",
            "9     26      1.0000    2.0     [0. 1.]\n",
            "10    19      1.0000    1.0     [1. 0.]\n",
            "[Epoch 251 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 252\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     174     0.9988    0.0     [0. 0.]\n",
            "2     385     0.9986    0.0     [0. 0.]\n",
            "3     212     0.9975    2.0     [0. 1.]\n",
            "4     65      0.9971    0.0     [0. 0.]\n",
            "5     140     0.9971    2.0     [0. 1.]\n",
            "6     117     0.9969    2.0     [0. 1.]\n",
            "7     250     0.9968    1.0     [1. 0.]\n",
            "8     443     0.9965    3.0     [1. 1.]\n",
            "9     252     0.9965    0.0     [0. 0.]\n",
            "10    29      0.9962    1.0     [1. 0.]\n",
            "[Epoch 252 | Step 31] im_q: torch.Size([128, 1, 128, 42]), im_k: torch.Size([128, 1, 128, 42])\n",
            "\n",
            "[Top-k Label Logging] Epoch 253\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     487     0.9993    0.0     [0. 0.]\n",
            "2     502     0.9969    1.0     [1. 0.]\n",
            "3     425     0.9968    0.0     [0. 0.]\n",
            "4     438     0.9968    0.0     [0. 0.]\n",
            "5     220     0.9967    0.0     [0. 0.]\n",
            "6     94      0.9966    0.0     [0. 0.]\n",
            "7     503     0.9966    0.0     [0. 0.]\n",
            "8     433     0.9966    3.0     [1. 1.]\n",
            "9     341     0.9965    0.0     [0. 0.]\n",
            "10    410     0.9965    1.0     [1. 0.]\n",
            "[Epoch 253 | Step 31] im_q: torch.Size([128, 1, 128, 49]), im_k: torch.Size([128, 1, 128, 49])\n",
            "=> Saved best checkpoint (epoch: 253, loss: 5.8539)\n",
            "\n",
            "[Top-k Label Logging] Epoch 254\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     300     1.0000    0.0     [0. 0.]\n",
            "2     169     1.0000    0.0     [0. 0.]\n",
            "3     75      1.0000    0.0     [0. 0.]\n",
            "4     404     1.0000    0.0     [0. 0.]\n",
            "5     286     1.0000    0.0     [0. 0.]\n",
            "6     475     1.0000    0.0     [0. 0.]\n",
            "7     295     1.0000    0.0     [0. 0.]\n",
            "8     63      1.0000    2.0     [0. 1.]\n",
            "9     281     1.0000    0.0     [0. 0.]\n",
            "10    429     1.0000    0.0     [0. 0.]\n",
            "[Epoch 254 | Step 31] im_q: torch.Size([128, 1, 128, 60]), im_k: torch.Size([128, 1, 128, 60])\n",
            "\n",
            "[Top-k Label Logging] Epoch 255\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     453     0.9997    0.0     [0. 0.]\n",
            "2     89      0.9996    0.0     [0. 0.]\n",
            "3     38      0.9996    0.0     [0. 0.]\n",
            "4     405     0.9995    0.0     [0. 0.]\n",
            "5     40      0.9991    0.0     [0. 0.]\n",
            "6     59      0.9988    0.0     [0. 0.]\n",
            "7     326     0.9986    1.0     [1. 0.]\n",
            "8     354     0.9986    0.0     [0. 0.]\n",
            "9     129     0.9985    3.0     [1. 1.]\n",
            "10    88      0.9984    2.0     [0. 1.]\n",
            "[Epoch 255 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 256\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     487     0.9998    1.0     [1. 0.]\n",
            "2     418     0.9998    1.0     [1. 0.]\n",
            "3     252     0.9997    0.0     [0. 0.]\n",
            "4     52      0.9996    2.0     [0. 1.]\n",
            "5     109     0.9993    0.0     [0. 0.]\n",
            "6     180     0.9992    0.0     [0. 0.]\n",
            "7     136     0.9992    3.0     [1. 1.]\n",
            "8     201     0.9992    2.0     [0. 1.]\n",
            "9     312     0.9991    0.0     [0. 0.]\n",
            "10    245     0.9991    1.0     [1. 0.]\n",
            "[Epoch 256 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 257\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     442     0.9994    1.0     [1. 0.]\n",
            "2     60      0.9993    0.0     [0. 0.]\n",
            "3     208     0.9992    0.0     [0. 0.]\n",
            "4     358     0.9984    1.0     [1. 0.]\n",
            "5     449     0.9984    1.0     [1. 0.]\n",
            "6     245     0.9983    3.0     [1. 1.]\n",
            "7     79      0.9980    3.0     [1. 1.]\n",
            "8     202     0.9979    2.0     [0. 1.]\n",
            "9     382     0.9979    1.0     [1. 0.]\n",
            "10    299     0.9978    0.0     [0. 0.]\n",
            "[Epoch 257 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 258\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     152     0.9987    3.0     [1. 1.]\n",
            "2     356     0.9984    0.0     [0. 0.]\n",
            "3     90      0.9983    0.0     [0. 0.]\n",
            "4     217     0.9980    0.0     [0. 0.]\n",
            "5     38      0.9978    2.0     [0. 1.]\n",
            "6     16      0.9977    3.0     [1. 1.]\n",
            "7     127     0.9977    0.0     [0. 0.]\n",
            "8     108     0.9977    0.0     [0. 0.]\n",
            "9     336     0.9976    2.0     [0. 1.]\n",
            "10    416     0.9976    2.0     [0. 1.]\n",
            "[Epoch 258 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 259\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     444     0.9999    2.0     [0. 1.]\n",
            "2     464     0.9999    2.0     [0. 1.]\n",
            "3     219     0.9999    0.0     [0. 0.]\n",
            "4     35      0.9999    0.0     [0. 0.]\n",
            "5     389     0.9999    0.0     [0. 0.]\n",
            "6     104     0.9999    1.0     [1. 0.]\n",
            "7     66      0.9998    2.0     [0. 1.]\n",
            "8     455     0.9997    0.0     [0. 0.]\n",
            "9     368     0.9997    1.0     [1. 0.]\n",
            "10    64      0.9996    0.0     [0. 0.]\n",
            "[Epoch 259 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 260\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     157     0.9999    0.0     [0. 0.]\n",
            "2     360     0.9999    3.0     [1. 1.]\n",
            "3     4       0.9999    2.0     [0. 1.]\n",
            "4     382     0.9999    0.0     [0. 0.]\n",
            "5     198     0.9999    3.0     [1. 1.]\n",
            "6     56      0.9999    2.0     [0. 1.]\n",
            "7     383     0.9999    1.0     [1. 0.]\n",
            "8     152     0.9999    0.0     [0. 0.]\n",
            "9     74      0.9999    0.0     [0. 0.]\n",
            "10    487     0.9999    0.0     [0. 0.]\n",
            "[Epoch 260 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 261\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     489     1.0000    0.0     [0. 0.]\n",
            "2     418     1.0000    1.0     [1. 0.]\n",
            "3     150     1.0000    1.0     [1. 0.]\n",
            "4     343     1.0000    0.0     [0. 0.]\n",
            "5     230     1.0000    0.0     [0. 0.]\n",
            "6     497     1.0000    0.0     [0. 0.]\n",
            "7     6       1.0000    0.0     [0. 0.]\n",
            "8     423     1.0000    0.0     [0. 0.]\n",
            "9     81      1.0000    2.0     [0. 1.]\n",
            "10    395     1.0000    2.0     [0. 1.]\n",
            "[Epoch 261 | Step 31] im_q: torch.Size([128, 1, 128, 55]), im_k: torch.Size([128, 1, 128, 55])\n",
            "\n",
            "[Top-k Label Logging] Epoch 262\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     42      0.9999    0.0     [0. 0.]\n",
            "2     471     0.9999    0.0     [0. 0.]\n",
            "3     200     0.9999    0.0     [0. 0.]\n",
            "4     462     0.9998    0.0     [0. 0.]\n",
            "5     215     0.9998    0.0     [0. 0.]\n",
            "6     328     0.9997    1.0     [1. 0.]\n",
            "7     272     0.9997    0.0     [0. 0.]\n",
            "8     0       0.9997    0.0     [0. 0.]\n",
            "9     329     0.9996    0.0     [0. 0.]\n",
            "10    386     0.9995    0.0     [0. 0.]\n",
            "[Epoch 262 | Step 31] im_q: torch.Size([128, 1, 128, 51]), im_k: torch.Size([128, 1, 128, 51])\n",
            "\n",
            "[Top-k Label Logging] Epoch 263\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     90      1.0000    0.0     [0. 0.]\n",
            "2     212     1.0000    1.0     [1. 0.]\n",
            "3     13      1.0000    0.0     [0. 0.]\n",
            "4     510     1.0000    0.0     [0. 0.]\n",
            "5     180     1.0000    2.0     [0. 1.]\n",
            "6     443     1.0000    0.0     [0. 0.]\n",
            "7     75      1.0000    1.0     [1. 0.]\n",
            "8     277     1.0000    1.0     [1. 0.]\n",
            "9     362     1.0000    2.0     [0. 1.]\n",
            "10    240     1.0000    0.0     [0. 0.]\n",
            "[Epoch 263 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 264\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     20      0.9986    0.0     [0. 0.]\n",
            "2     86      0.9986    0.0     [0. 0.]\n",
            "3     500     0.9985    1.0     [1. 0.]\n",
            "4     436     0.9985    0.0     [0. 0.]\n",
            "5     274     0.9984    0.0     [0. 0.]\n",
            "6     344     0.9984    1.0     [1. 0.]\n",
            "7     1       0.9983    1.0     [1. 0.]\n",
            "8     338     0.9983    0.0     [0. 0.]\n",
            "9     353     0.9983    1.0     [1. 0.]\n",
            "10    50      0.9982    0.0     [0. 0.]\n",
            "[Epoch 264 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 265\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     263     0.9998    0.0     [0. 0.]\n",
            "2     183     0.9998    0.0     [0. 0.]\n",
            "3     191     0.9997    2.0     [0. 1.]\n",
            "4     434     0.9996    0.0     [0. 0.]\n",
            "5     371     0.9996    0.0     [0. 0.]\n",
            "6     0       0.9993    0.0     [0. 0.]\n",
            "7     354     0.9990    0.0     [0. 0.]\n",
            "8     399     0.9988    0.0     [0. 0.]\n",
            "9     418     0.9988    1.0     [1. 0.]\n",
            "10    236     0.9988    0.0     [0. 0.]\n",
            "[Epoch 265 | Step 31] im_q: torch.Size([128, 1, 128, 48]), im_k: torch.Size([128, 1, 128, 48])\n",
            "\n",
            "[Top-k Label Logging] Epoch 266\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     387     0.9998    0.0     [0. 0.]\n",
            "2     198     0.9998    1.0     [1. 0.]\n",
            "3     466     0.9996    1.0     [1. 0.]\n",
            "4     312     0.9995    0.0     [0. 0.]\n",
            "5     480     0.9995    2.0     [0. 1.]\n",
            "6     486     0.9995    1.0     [1. 0.]\n",
            "7     179     0.9994    0.0     [0. 0.]\n",
            "8     302     0.9993    3.0     [1. 1.]\n",
            "9     122     0.9990    1.0     [1. 0.]\n",
            "10    137     0.9989    1.0     [1. 0.]\n",
            "[Epoch 266 | Step 31] im_q: torch.Size([128, 1, 128, 57]), im_k: torch.Size([128, 1, 128, 57])\n",
            "\n",
            "[Top-k Label Logging] Epoch 267\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     0       0.9998    1.0     [1. 0.]\n",
            "2     131     0.9997    0.0     [0. 0.]\n",
            "3     249     0.9996    0.0     [0. 0.]\n",
            "4     48      0.9995    0.0     [0. 0.]\n",
            "5     412     0.9992    0.0     [0. 0.]\n",
            "6     311     0.9987    1.0     [1. 0.]\n",
            "7     70      0.9987    0.0     [0. 0.]\n",
            "8     484     0.9986    0.0     [0. 0.]\n",
            "9     168     0.9986    0.0     [0. 0.]\n",
            "10    318     0.9986    0.0     [0. 0.]\n",
            "[Epoch 267 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 268\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     263     0.9993    2.0     [0. 1.]\n",
            "2     173     0.9986    3.0     [1. 1.]\n",
            "3     70      0.9986    3.0     [1. 1.]\n",
            "4     206     0.9986    3.0     [1. 1.]\n",
            "5     179     0.9986    0.0     [0. 0.]\n",
            "6     493     0.9985    0.0     [0. 0.]\n",
            "7     147     0.9985    3.0     [1. 1.]\n",
            "8     414     0.9985    3.0     [1. 1.]\n",
            "9     286     0.9980    0.0     [0. 0.]\n",
            "10    479     0.9980    1.0     [1. 0.]\n",
            "[Epoch 268 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "=> Saved best checkpoint (epoch: 268, loss: 5.8136)\n",
            "\n",
            "[Top-k Label Logging] Epoch 269\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     498     1.0000    0.0     [0. 0.]\n",
            "2     148     1.0000    3.0     [1. 1.]\n",
            "3     412     1.0000    2.0     [0. 1.]\n",
            "4     195     1.0000    0.0     [0. 0.]\n",
            "5     255     1.0000    0.0     [0. 0.]\n",
            "6     511     1.0000    0.0     [0. 0.]\n",
            "7     489     1.0000    1.0     [1. 0.]\n",
            "8     271     1.0000    0.0     [0. 0.]\n",
            "9     445     1.0000    3.0     [1. 1.]\n",
            "10    394     1.0000    0.0     [0. 0.]\n",
            "[Epoch 269 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 270\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     110     0.9999    2.0     [0. 1.]\n",
            "2     444     0.9999    0.0     [0. 0.]\n",
            "3     281     0.9998    0.0     [0. 0.]\n",
            "4     113     0.9998    0.0     [0. 0.]\n",
            "5     184     0.9995    0.0     [0. 0.]\n",
            "6     303     0.9995    0.0     [0. 0.]\n",
            "7     240     0.9994    0.0     [0. 0.]\n",
            "8     18      0.9992    1.0     [1. 0.]\n",
            "9     440     0.9992    3.0     [1. 1.]\n",
            "10    337     0.9991    1.0     [1. 0.]\n",
            "[Epoch 270 | Step 31] im_q: torch.Size([128, 1, 128, 53]), im_k: torch.Size([128, 1, 128, 53])\n",
            "\n",
            "[Top-k Label Logging] Epoch 271\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     510     1.0000    0.0     [0. 0.]\n",
            "2     299     1.0000    0.0     [0. 0.]\n",
            "3     46      1.0000    0.0     [0. 0.]\n",
            "4     105     1.0000    1.0     [1. 0.]\n",
            "5     31      1.0000    0.0     [0. 0.]\n",
            "6     459     1.0000    1.0     [1. 0.]\n",
            "7     450     0.9999    0.0     [0. 0.]\n",
            "8     399     0.9999    3.0     [1. 1.]\n",
            "9     271     0.9999    0.0     [0. 0.]\n",
            "10    235     0.9999    1.0     [1. 0.]\n",
            "[Epoch 271 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "=> Saved best checkpoint (epoch: 271, loss: 5.7948)\n",
            "\n",
            "[Top-k Label Logging] Epoch 272\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     253     0.9999    2.0     [0. 1.]\n",
            "2     142     0.9999    0.0     [0. 0.]\n",
            "3     511     0.9997    0.0     [0. 0.]\n",
            "4     282     0.9997    2.0     [0. 1.]\n",
            "5     393     0.9997    3.0     [1. 1.]\n",
            "6     433     0.9996    1.0     [1. 0.]\n",
            "7     495     0.9995    0.0     [0. 0.]\n",
            "8     242     0.9994    0.0     [0. 0.]\n",
            "9     78      0.9994    2.0     [0. 1.]\n",
            "10    228     0.9993    2.0     [0. 1.]\n",
            "[Epoch 272 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 273\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     281     1.0000    0.0     [0. 0.]\n",
            "2     353     1.0000    2.0     [0. 1.]\n",
            "3     484     1.0000    0.0     [0. 0.]\n",
            "4     38      1.0000    0.0     [0. 0.]\n",
            "5     190     1.0000    0.0     [0. 0.]\n",
            "6     375     1.0000    1.0     [1. 0.]\n",
            "7     327     1.0000    2.0     [0. 1.]\n",
            "8     145     1.0000    0.0     [0. 0.]\n",
            "9     298     1.0000    0.0     [0. 0.]\n",
            "10    414     1.0000    0.0     [0. 0.]\n",
            "[Epoch 273 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 274\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     213     1.0000    0.0     [0. 0.]\n",
            "2     14      1.0000    0.0     [0. 0.]\n",
            "3     168     1.0000    1.0     [1. 0.]\n",
            "4     381     1.0000    2.0     [0. 1.]\n",
            "5     388     1.0000    1.0     [1. 0.]\n",
            "6     202     1.0000    2.0     [0. 1.]\n",
            "7     173     1.0000    2.0     [0. 1.]\n",
            "8     471     1.0000    0.0     [0. 0.]\n",
            "9     141     1.0000    0.0     [0. 0.]\n",
            "10    337     1.0000    0.0     [0. 0.]\n",
            "[Epoch 274 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 275\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     233     1.0000    0.0     [0. 0.]\n",
            "2     397     1.0000    3.0     [1. 1.]\n",
            "3     374     1.0000    0.0     [0. 0.]\n",
            "4     402     1.0000    2.0     [0. 1.]\n",
            "5     240     1.0000    3.0     [1. 1.]\n",
            "6     427     1.0000    3.0     [1. 1.]\n",
            "7     156     1.0000    0.0     [0. 0.]\n",
            "8     12      1.0000    0.0     [0. 0.]\n",
            "9     393     1.0000    0.0     [0. 0.]\n",
            "10    138     1.0000    3.0     [1. 1.]\n",
            "[Epoch 275 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 276\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     273     1.0000    0.0     [0. 0.]\n",
            "2     466     1.0000    2.0     [0. 1.]\n",
            "3     302     1.0000    0.0     [0. 0.]\n",
            "4     143     1.0000    0.0     [0. 0.]\n",
            "5     299     1.0000    1.0     [1. 0.]\n",
            "6     29      1.0000    0.0     [0. 0.]\n",
            "7     209     1.0000    0.0     [0. 0.]\n",
            "8     275     1.0000    0.0     [0. 0.]\n",
            "9     84      1.0000    1.0     [1. 0.]\n",
            "10    292     1.0000    0.0     [0. 0.]\n",
            "[Epoch 276 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 277\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     32      1.0000    0.0     [0. 0.]\n",
            "2     242     1.0000    0.0     [0. 0.]\n",
            "3     375     1.0000    0.0     [0. 0.]\n",
            "4     403     1.0000    0.0     [0. 0.]\n",
            "5     191     1.0000    1.0     [1. 0.]\n",
            "6     365     1.0000    0.0     [0. 0.]\n",
            "7     91      1.0000    0.0     [0. 0.]\n",
            "8     117     1.0000    0.0     [0. 0.]\n",
            "9     115     1.0000    2.0     [0. 1.]\n",
            "10    465     1.0000    0.0     [0. 0.]\n",
            "[Epoch 277 | Step 31] im_q: torch.Size([128, 1, 128, 88]), im_k: torch.Size([128, 1, 128, 88])\n",
            "\n",
            "[Top-k Label Logging] Epoch 278\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     228     0.9997    3.0     [1. 1.]\n",
            "2     492     0.9989    1.0     [1. 0.]\n",
            "3     134     0.9987    1.0     [1. 0.]\n",
            "4     126     0.9981    1.0     [1. 0.]\n",
            "5     213     0.9974    2.0     [0. 1.]\n",
            "6     438     0.9972    0.0     [0. 0.]\n",
            "7     455     0.9971    1.0     [1. 0.]\n",
            "8     5       0.9971    0.0     [0. 0.]\n",
            "9     410     0.9970    0.0     [0. 0.]\n",
            "10    196     0.9968    0.0     [0. 0.]\n",
            "[Epoch 278 | Step 31] im_q: torch.Size([128, 1, 128, 52]), im_k: torch.Size([128, 1, 128, 52])\n",
            "\n",
            "[Top-k Label Logging] Epoch 279\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     428     0.9998    0.0     [0. 0.]\n",
            "2     455     0.9997    0.0     [0. 0.]\n",
            "3     142     0.9996    0.0     [0. 0.]\n",
            "4     435     0.9996    0.0     [0. 0.]\n",
            "5     28      0.9995    1.0     [1. 0.]\n",
            "6     186     0.9992    2.0     [0. 1.]\n",
            "7     124     0.9992    0.0     [0. 0.]\n",
            "8     95      0.9992    3.0     [1. 1.]\n",
            "9     23      0.9987    1.0     [1. 0.]\n",
            "10    439     0.9985    3.0     [1. 1.]\n",
            "[Epoch 279 | Step 31] im_q: torch.Size([128, 1, 128, 45]), im_k: torch.Size([128, 1, 128, 45])\n",
            "\n",
            "[Top-k Label Logging] Epoch 280\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     503     1.0000    0.0     [0. 0.]\n",
            "2     340     1.0000    0.0     [0. 0.]\n",
            "3     23      1.0000    1.0     [1. 0.]\n",
            "4     333     1.0000    2.0     [0. 1.]\n",
            "5     492     1.0000    0.0     [0. 0.]\n",
            "6     194     0.9999    0.0     [0. 0.]\n",
            "7     161     0.9999    1.0     [1. 0.]\n",
            "8     417     0.9999    1.0     [1. 0.]\n",
            "9     179     0.9999    0.0     [0. 0.]\n",
            "10    193     0.9999    3.0     [1. 1.]\n",
            "[Epoch 280 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 281\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     149     0.9994    0.0     [0. 0.]\n",
            "2     500     0.9991    1.0     [1. 0.]\n",
            "3     252     0.9990    0.0     [0. 0.]\n",
            "4     382     0.9990    1.0     [1. 0.]\n",
            "5     459     0.9988    1.0     [1. 0.]\n",
            "6     259     0.9988    1.0     [1. 0.]\n",
            "7     177     0.9987    0.0     [0. 0.]\n",
            "8     74      0.9986    0.0     [0. 0.]\n",
            "9     185     0.9986    2.0     [0. 1.]\n",
            "10    35      0.9985    1.0     [1. 0.]\n",
            "[Epoch 281 | Step 31] im_q: torch.Size([128, 1, 128, 68]), im_k: torch.Size([128, 1, 128, 68])\n",
            "\n",
            "[Top-k Label Logging] Epoch 282\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     62      1.0000    0.0     [0. 0.]\n",
            "2     206     0.9999    0.0     [0. 0.]\n",
            "3     23      0.9998    0.0     [0. 0.]\n",
            "4     396     0.9998    0.0     [0. 0.]\n",
            "5     373     0.9998    0.0     [0. 0.]\n",
            "6     458     0.9997    0.0     [0. 0.]\n",
            "7     428     0.9997    0.0     [0. 0.]\n",
            "8     161     0.9996    0.0     [0. 0.]\n",
            "9     443     0.9996    0.0     [0. 0.]\n",
            "10    407     0.9996    0.0     [0. 0.]\n",
            "[Epoch 282 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 283\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     24      0.9989    2.0     [0. 1.]\n",
            "2     496     0.9984    0.0     [0. 0.]\n",
            "3     349     0.9983    1.0     [1. 0.]\n",
            "4     414     0.9983    0.0     [0. 0.]\n",
            "5     478     0.9983    2.0     [0. 1.]\n",
            "6     147     0.9983    1.0     [1. 0.]\n",
            "7     7       0.9982    0.0     [0. 0.]\n",
            "8     360     0.9982    3.0     [1. 1.]\n",
            "9     326     0.9982    3.0     [1. 1.]\n",
            "10    504     0.9982    2.0     [0. 1.]\n",
            "[Epoch 283 | Step 31] im_q: torch.Size([128, 1, 128, 59]), im_k: torch.Size([128, 1, 128, 59])\n",
            "\n",
            "[Top-k Label Logging] Epoch 284\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     243     0.9987    0.0     [0. 0.]\n",
            "2     468     0.9986    2.0     [0. 1.]\n",
            "3     104     0.9980    1.0     [1. 0.]\n",
            "4     33      0.9980    1.0     [1. 0.]\n",
            "5     420     0.9980    1.0     [1. 0.]\n",
            "6     379     0.9979    1.0     [1. 0.]\n",
            "7     162     0.9978    3.0     [1. 1.]\n",
            "8     264     0.9977    0.0     [0. 0.]\n",
            "9     460     0.9977    1.0     [1. 0.]\n",
            "10    161     0.9977    1.0     [1. 0.]\n",
            "[Epoch 284 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 285\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     211     0.9997    1.0     [1. 0.]\n",
            "2     264     0.9996    0.0     [0. 0.]\n",
            "3     151     0.9995    1.0     [1. 0.]\n",
            "4     24      0.9995    0.0     [0. 0.]\n",
            "5     436     0.9994    1.0     [1. 0.]\n",
            "6     109     0.9994    1.0     [1. 0.]\n",
            "7     51      0.9993    0.0     [0. 0.]\n",
            "8     333     0.9993    0.0     [0. 0.]\n",
            "9     275     0.9993    0.0     [0. 0.]\n",
            "10    57      0.9993    1.0     [1. 0.]\n",
            "[Epoch 285 | Step 31] im_q: torch.Size([128, 1, 128, 43]), im_k: torch.Size([128, 1, 128, 43])\n",
            "\n",
            "[Top-k Label Logging] Epoch 286\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     82      0.9998    0.0     [0. 0.]\n",
            "2     218     0.9998    0.0     [0. 0.]\n",
            "3     135     0.9998    0.0     [0. 0.]\n",
            "4     492     0.9996    1.0     [1. 0.]\n",
            "5     193     0.9995    0.0     [0. 0.]\n",
            "6     282     0.9995    0.0     [0. 0.]\n",
            "7     272     0.9994    3.0     [1. 1.]\n",
            "8     162     0.9992    0.0     [0. 0.]\n",
            "9     172     0.9992    0.0     [0. 0.]\n",
            "10    160     0.9992    1.0     [1. 0.]\n",
            "[Epoch 286 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 287\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     290     0.9996    0.0     [0. 0.]\n",
            "2     476     0.9996    0.0     [0. 0.]\n",
            "3     52      0.9994    3.0     [1. 1.]\n",
            "4     95      0.9993    0.0     [0. 0.]\n",
            "5     259     0.9990    0.0     [0. 0.]\n",
            "6     238     0.9990    1.0     [1. 0.]\n",
            "7     437     0.9989    1.0     [1. 0.]\n",
            "8     270     0.9988    3.0     [1. 1.]\n",
            "9     50      0.9987    1.0     [1. 0.]\n",
            "10    7       0.9987    0.0     [0. 0.]\n",
            "[Epoch 287 | Step 31] im_q: torch.Size([128, 1, 128, 127]), im_k: torch.Size([128, 1, 128, 127])\n",
            "\n",
            "[Top-k Label Logging] Epoch 288\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     10      0.9998    0.0     [0. 0.]\n",
            "2     373     0.9996    0.0     [0. 0.]\n",
            "3     398     0.9995    0.0     [0. 0.]\n",
            "4     186     0.9993    3.0     [1. 1.]\n",
            "5     37      0.9991    0.0     [0. 0.]\n",
            "6     313     0.9991    0.0     [0. 0.]\n",
            "7     277     0.9990    1.0     [1. 0.]\n",
            "8     87      0.9990    0.0     [0. 0.]\n",
            "9     0       0.9989    0.0     [0. 0.]\n",
            "10    57      0.9989    1.0     [1. 0.]\n",
            "[Epoch 288 | Step 31] im_q: torch.Size([128, 1, 128, 56]), im_k: torch.Size([128, 1, 128, 56])\n",
            "\n",
            "[Top-k Label Logging] Epoch 289\n",
            " - Query label (multi-class): 3.0 / Raw: [[1.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     494     1.0000    0.0     [0. 0.]\n",
            "2     4       1.0000    0.0     [0. 0.]\n",
            "3     466     1.0000    0.0     [0. 0.]\n",
            "4     167     1.0000    2.0     [0. 1.]\n",
            "5     99      1.0000    2.0     [0. 1.]\n",
            "6     195     1.0000    0.0     [0. 0.]\n",
            "7     175     1.0000    3.0     [1. 1.]\n",
            "8     456     1.0000    0.0     [0. 0.]\n",
            "9     375     1.0000    2.0     [0. 1.]\n",
            "10    337     1.0000    2.0     [0. 1.]\n",
            "[Epoch 289 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "\n",
            "[Top-k Label Logging] Epoch 290\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     6       1.0000    0.0     [0. 0.]\n",
            "2     40      1.0000    0.0     [0. 0.]\n",
            "3     428     1.0000    0.0     [0. 0.]\n",
            "4     280     1.0000    0.0     [0. 0.]\n",
            "5     195     1.0000    1.0     [1. 0.]\n",
            "6     168     1.0000    0.0     [0. 0.]\n",
            "7     105     1.0000    1.0     [1. 0.]\n",
            "8     237     1.0000    0.0     [0. 0.]\n",
            "9     401     1.0000    0.0     [0. 0.]\n",
            "10    151     1.0000    0.0     [0. 0.]\n",
            "[Epoch 290 | Step 31] im_q: torch.Size([128, 1, 128, 58]), im_k: torch.Size([128, 1, 128, 58])\n",
            "=> Saved best checkpoint (epoch: 290, loss: 5.6405)\n",
            "\n",
            "[Top-k Label Logging] Epoch 291\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     281     0.9999    2.0     [0. 1.]\n",
            "2     507     0.9999    3.0     [1. 1.]\n",
            "3     17      0.9999    2.0     [0. 1.]\n",
            "4     245     0.9999    1.0     [1. 0.]\n",
            "5     12      0.9999    0.0     [0. 0.]\n",
            "6     405     0.9999    1.0     [1. 0.]\n",
            "7     396     0.9998    0.0     [0. 0.]\n",
            "8     264     0.9998    1.0     [1. 0.]\n",
            "9     215     0.9998    0.0     [0. 0.]\n",
            "10    14      0.9998    2.0     [0. 1.]\n",
            "[Epoch 291 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 292\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     195     1.0000    0.0     [0. 0.]\n",
            "2     476     1.0000    0.0     [0. 0.]\n",
            "3     1       1.0000    0.0     [0. 0.]\n",
            "4     494     1.0000    0.0     [0. 0.]\n",
            "5     223     1.0000    0.0     [0. 0.]\n",
            "6     219     1.0000    0.0     [0. 0.]\n",
            "7     201     1.0000    0.0     [0. 0.]\n",
            "8     145     1.0000    0.0     [0. 0.]\n",
            "9     472     1.0000    2.0     [0. 1.]\n",
            "10    24      1.0000    0.0     [0. 0.]\n",
            "[Epoch 292 | Step 31] im_q: torch.Size([128, 1, 128, 62]), im_k: torch.Size([128, 1, 128, 62])\n",
            "\n",
            "[Top-k Label Logging] Epoch 293\n",
            " - Query label (multi-class): 2.0 / Raw: [[0.0, 1.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     316     0.9971    2.0     [0. 1.]\n",
            "2     213     0.9970    0.0     [0. 0.]\n",
            "3     75      0.9969    1.0     [1. 0.]\n",
            "4     489     0.9968    1.0     [1. 0.]\n",
            "5     115     0.9966    0.0     [0. 0.]\n",
            "6     133     0.9964    1.0     [1. 0.]\n",
            "7     499     0.9963    0.0     [0. 0.]\n",
            "8     254     0.9961    2.0     [0. 1.]\n",
            "9     420     0.9960    0.0     [0. 0.]\n",
            "10    271     0.9960    1.0     [1. 0.]\n",
            "[Epoch 293 | Step 31] im_q: torch.Size([128, 1, 128, 48]), im_k: torch.Size([128, 1, 128, 48])\n",
            "\n",
            "[Top-k Label Logging] Epoch 294\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     424     0.9995    1.0     [1. 0.]\n",
            "2     355     0.9993    0.0     [0. 0.]\n",
            "3     484     0.9990    0.0     [0. 0.]\n",
            "4     321     0.9988    1.0     [1. 0.]\n",
            "5     291     0.9984    1.0     [1. 0.]\n",
            "6     331     0.9983    1.0     [1. 0.]\n",
            "7     216     0.9983    1.0     [1. 0.]\n",
            "8     510     0.9980    0.0     [0. 0.]\n",
            "9     440     0.9980    0.0     [0. 0.]\n",
            "10    109     0.9978    0.0     [0. 0.]\n",
            "[Epoch 294 | Step 31] im_q: torch.Size([128, 1, 128, 51]), im_k: torch.Size([128, 1, 128, 51])\n",
            "\n",
            "[Top-k Label Logging] Epoch 295\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     17      0.9995    1.0     [1. 0.]\n",
            "2     506     0.9993    1.0     [1. 0.]\n",
            "3     447     0.9992    0.0     [0. 0.]\n",
            "4     330     0.9988    0.0     [0. 0.]\n",
            "5     23      0.9987    2.0     [0. 1.]\n",
            "6     418     0.9987    3.0     [1. 1.]\n",
            "7     240     0.9986    0.0     [0. 0.]\n",
            "8     0       0.9986    1.0     [1. 0.]\n",
            "9     475     0.9986    0.0     [0. 0.]\n",
            "10    435     0.9986    0.0     [0. 0.]\n",
            "[Epoch 295 | Step 31] im_q: torch.Size([128, 1, 128, 78]), im_k: torch.Size([128, 1, 128, 78])\n",
            "\n",
            "[Top-k Label Logging] Epoch 296\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     424     1.0000    0.0     [0. 0.]\n",
            "2     226     1.0000    0.0     [0. 0.]\n",
            "3     179     1.0000    2.0     [0. 1.]\n",
            "4     260     1.0000    2.0     [0. 1.]\n",
            "5     119     1.0000    2.0     [0. 1.]\n",
            "6     477     1.0000    0.0     [0. 0.]\n",
            "7     158     1.0000    0.0     [0. 0.]\n",
            "8     307     1.0000    0.0     [0. 0.]\n",
            "9     294     1.0000    0.0     [0. 0.]\n",
            "10    201     1.0000    0.0     [0. 0.]\n",
            "[Epoch 296 | Step 31] im_q: torch.Size([128, 1, 128, 50]), im_k: torch.Size([128, 1, 128, 50])\n",
            "\n",
            "[Top-k Label Logging] Epoch 297\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     9       0.9998    0.0     [0. 0.]\n",
            "2     158     0.9998    1.0     [1. 0.]\n",
            "3     179     0.9998    0.0     [0. 0.]\n",
            "4     53      0.9998    1.0     [1. 0.]\n",
            "5     260     0.9998    0.0     [0. 0.]\n",
            "6     507     0.9997    0.0     [0. 0.]\n",
            "7     142     0.9997    0.0     [0. 0.]\n",
            "8     0       0.9996    0.0     [0. 0.]\n",
            "9     365     0.9996    0.0     [0. 0.]\n",
            "10    198     0.9995    1.0     [1. 0.]\n",
            "[Epoch 297 | Step 31] im_q: torch.Size([128, 1, 128, 65]), im_k: torch.Size([128, 1, 128, 65])\n",
            "\n",
            "[Top-k Label Logging] Epoch 298\n",
            " - Query label (multi-class): 0.0 / Raw: [[0.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     44      1.0000    0.0     [0. 0.]\n",
            "2     144     0.9999    0.0     [0. 0.]\n",
            "3     52      0.9999    3.0     [1. 1.]\n",
            "4     481     0.9999    3.0     [1. 1.]\n",
            "5     489     0.9999    0.0     [0. 0.]\n",
            "6     81      0.9999    0.0     [0. 0.]\n",
            "7     153     0.9999    1.0     [1. 0.]\n",
            "8     500     0.9998    0.0     [0. 0.]\n",
            "9     4       0.9998    1.0     [1. 0.]\n",
            "10    15      0.9998    0.0     [0. 0.]\n",
            "[Epoch 298 | Step 31] im_q: torch.Size([128, 1, 128, 64]), im_k: torch.Size([128, 1, 128, 64])\n",
            "\n",
            "[Top-k Label Logging] Epoch 299\n",
            " - Query label (multi-class): 1.0 / Raw: [[1.0, 0.0]]\n",
            "Rank  Index   Sim       Class   Raw Label\n",
            "---------------------------------------------\n",
            "1     217     1.0000    0.0     [0. 0.]\n",
            "2     449     1.0000    0.0     [0. 0.]\n",
            "3     5       1.0000    0.0     [0. 0.]\n",
            "4     9       1.0000    0.0     [0. 0.]\n",
            "5     296     1.0000    0.0     [0. 0.]\n",
            "6     106     1.0000    2.0     [0. 1.]\n",
            "7     108     1.0000    0.0     [0. 0.]\n",
            "8     477     1.0000    0.0     [0. 0.]\n",
            "9     399     1.0000    0.0     [0. 0.]\n",
            "10    394     1.0000    2.0     [0. 1.]\n",
            "[Epoch 299 | Step 31] im_q: torch.Size([128, 1, 128, 74]), im_k: torch.Size([128, 1, 128, 74])\n",
            "💾 Saved checkpoint to /home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp/shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020_299.pth.tar\n"
          ]
        }
      ],
      "source": [
        "# 모델 지정하기 전 seed 고정 필요\n",
        "seed_everything(args.seed) # Seed 고정\n",
        "\n",
        "pretrain_project_name = f'shuffle_GRU+ATT500_MLS_PT_{args.batch_size}bs_N+PS_{get_timestamp()}'\n",
        "\n",
        "# wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "wandb.init(\n",
        "    project=\"0718_SBW_ICBHI_MSL_all\", # 프로젝트 이름\n",
        "    name=f\"{pretrain_project_name}\",  # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay\n",
        "    }\n",
        ")\n",
        "\n",
        "# 1. MoCo 모델 생성\n",
        "model = MoCo(\n",
        "    base_encoder = backbone_han_gru,\n",
        "    dim_enc = 500, # CNN6의 출력 feature dim (default=2048)\n",
        "    dim_prj = args.dim_prj,\n",
        "    K = args.K,\n",
        "    m = args.momentum,\n",
        "    T = args.T,\n",
        "    top_k = args.top_k,\n",
        "    lambda_bce = args.lambda_bce\n",
        ").cuda()\n",
        "\n",
        "# 2. Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "# 3. Cosine Scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)\n",
        "\n",
        "# 4. Train\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "def multilabel_to_multiclass(y):\n",
        "    # Crackle → 1, Wheeze → 2, Both → 3, None → 0\n",
        "    y = np.array(y)\n",
        "    return y[:, 0] + y[:, 1] * 2\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    # ===============================\n",
        "    # Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    for i, (repeat_mel, label, mask, _) in enumerate(pretrain_loader): # label 여기선 사용 X\n",
        "        im_q, im_k, _ = aug(repeat_mel)\n",
        "        # 디버깅: 데이터 자체 확인\n",
        "        im_q = im_q.cuda(device=args.gpu, non_blocking=True)\n",
        "        im_k = im_k.cuda(device=args.gpu, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, output, target = model(im_q=im_q, im_k=im_k, labels_k=label.cuda(), mask=mask.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i == 0:\n",
        "            first_feature = F.normalize(model.encoder_q(im_q[0:1]), dim=1)\n",
        "            sim = torch.matmul(first_feature, model.queue_g.clone().detach())\n",
        "            topk_indices = torch.topk(sim, model.top_k, dim=1).indices[0]\n",
        "\n",
        "            # 🔽 상위 10개만 사용하도록 슬라이싱\n",
        "            topk_indices_10 = topk_indices[:10]\n",
        "            topk_sims = sim[0, topk_indices_10].detach().cpu().numpy()\n",
        "            topk_labels = model.queue_label[topk_indices_10].cpu().numpy()\n",
        "\n",
        "            true_label = label[0].cpu().numpy().reshape(1, -1)\n",
        "            true_class = multilabel_to_multiclass(true_label)[0]\n",
        "            topk_classes = multilabel_to_multiclass(topk_labels)\n",
        "\n",
        "            print(f\"\\n[Top-k Label Logging] Epoch {epoch}\")\n",
        "            print(f\" - Query label (multi-class): {true_class} / Raw: {true_label.tolist()}\")\n",
        "            print(f\"{'Rank':<6}{'Index':<8}{'Sim':<10}{'Class':<8}{'Raw Label'}\")\n",
        "            print(\"-\" * 45)\n",
        "\n",
        "            # wandb Table 생성\n",
        "            topk_table = wandb.Table(columns=[\"Rank\", \"Index\", \"Similarity\", \"Class\", \"Raw Label\"])\n",
        "            for rank, (idx, sim_val, cls, raw_lbl) in enumerate(zip(topk_indices_10.cpu().numpy(), topk_sims, topk_classes, topk_labels)):\n",
        "                print(f\"{rank+1:<6}{idx:<8}{sim_val:<10.4f}{cls:<8}{raw_lbl}\")\n",
        "                topk_table.add_data(rank+1, idx, float(sim_val), int(cls), raw_lbl.tolist())\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        total_train_loss += loss.item() \n",
        "        \n",
        "    avg_train_loss = total_train_loss / len(pretrain_loader)\n",
        "    print(f\"[Epoch {epoch} | Step {i}] im_q: {im_q.shape}, im_k: {im_k.shape}\")\n",
        "\n",
        "\n",
        "    # =====================================\n",
        "    # Scheduler\n",
        "    # =====================================\n",
        "    scheduler.step()\n",
        "\n",
        "    # =====================================\n",
        "    # Logging with wandb\n",
        "    # =====================================\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"lr\": current_lr,\n",
        "        \"Pretrain_TopK\": topk_table\n",
        "    })\n",
        "\n",
        "    # =====================================\n",
        "    # Checkpoint (Every 100 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"💾 Saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "    # ===============================\n",
        "    # Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if avg_train_loss < best_loss:\n",
        "        best_loss = avg_train_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZSwN7t7l2n5",
      "metadata": {
        "id": "sZSwN7t7l2n5"
      },
      "source": [
        "## 5. Linear Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e28bc03",
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646538df",
      "metadata": {
        "id": "646538df"
      },
      "source": [
        "#### validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "33da3ad9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33da3ad9",
        "outputId": "beede0b6-de7b-43dd-e26d-b172e086e784"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2756"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e66818a3",
      "metadata": {
        "id": "e66818a3"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, mask, _ in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).int()  # threshold = 0.5\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()   # [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy() # [N, 2]\n",
        "\n",
        "    avg_loss = running_loss / len(val_loader)\n",
        "\n",
        "    # # 개별 label별 sensitivity/specificity 계산\n",
        "    # crackle_sens = crackle_spec = wheeze_sens = wheeze_spec = 0\n",
        "\n",
        "    # for i in range(2):\n",
        "    #     y_true = all_labels[:, i]\n",
        "    #     y_pred = all_preds[:, i]\n",
        "\n",
        "    #     cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    #     if cm.shape == (2, 2):\n",
        "    #         TN, FP, FN, TP = cm.ravel()\n",
        "    #     else:\n",
        "    #         TN = FP = FN = TP = 0  # 안전처리\n",
        "\n",
        "    #     sens = TP / (TP + FN + 1e-6)\n",
        "    #     spec = TN / (TN + FP + 1e-6)\n",
        "\n",
        "    #     if i == 0:\n",
        "    #         crackle_sens, crackle_spec = sens, spec\n",
        "    #     else:\n",
        "    #         wheeze_sens, wheeze_spec = sens, spec\n",
        "\n",
        "    # avg_sens = (crackle_sens + wheeze_sens) / 2\n",
        "    # avg_spec = (crackle_spec + wheeze_spec) / 2\n",
        "    # icbhi_score = (avg_sens + avg_spec) / 2\n",
        "\n",
        "    return avg_loss, all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b5fa31",
      "metadata": {
        "id": "d3b5fa31"
      },
      "source": [
        "### Weighted loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4475c581",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4475c581",
        "outputId": "22192551-0857-46fa-8998-8c4b6319c1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 - Positives (1): 792 / 2756 samples\n",
            "Class 1 - Positives (1): 528 / 2756 samples\n",
            "Class Weights: tensor([1.7399, 2.6098], device='cuda:0')\n",
            "alpha_norm: tensor([0.4000, 0.6000], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 💡 다중 라벨 예시: targets는 [B, C] binary matrix (e.g., [1, 0, 1, 0])\n",
        "label_list = []\n",
        "\n",
        "# 👇 train_dataset이 (x, multi_label_tensor, _) 형태라고 가정\n",
        "for _, label, _ in test_dataset:\n",
        "    label_list.append(label)  # label: Tensor([0, 1, 0, 1])처럼\n",
        "\n",
        "# 전체 label을 합치기\n",
        "all_labels = torch.stack(label_list, dim=0)  # shape: [N, C]\n",
        "num_classes = all_labels.size(1)\n",
        "total_samples = all_labels.size(0)\n",
        "\n",
        "# 클래스별 1의 개수 세기\n",
        "class_counts = all_labels.sum(dim=0)  # shape: [C]\n",
        "class_weights = total_samples / (num_classes * class_counts + 1e-6)  # smoothed\n",
        "\n",
        "# tensor로 변환\n",
        "class_weights_tensor = class_weights.float().to(device)\n",
        "\n",
        "# 🔹 출력\n",
        "for i, count in enumerate(class_counts.tolist()):\n",
        "    print(f\"Class {i} - Positives (1): {int(count)} / {total_samples} samples\")\n",
        "print(f\"Class Weights: {class_weights_tensor}\")\n",
        "\n",
        "alpha_norm = class_weights_tensor / class_weights_tensor.sum()\n",
        "print(f\"alpha_norm: {alpha_norm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "N6RiJJnHjnRg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6RiJJnHjnRg",
        "outputId": "78432bce-ea4d-4474-81b5-d5ee2af0c497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw Class Weights: tensor([1.2826, 2.6497])\n",
            "Normalized Alpha (sum=1): tensor([0.3262, 0.6738])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ⚙️ 각 클래스의 positive 개수 (from label distribution)\n",
        "crackle_pos = 262 + 83  # label 1 or 3\n",
        "wheeze_pos  = 84 + 83   # label 2 or 3\n",
        "\n",
        "total_samples = 885\n",
        "num_classes = 2\n",
        "\n",
        "# ⚖️ 기본 class weight 계산: inverse frequency\n",
        "class_counts = torch.tensor([crackle_pos, wheeze_pos], dtype=torch.float)\n",
        "class_weights = total_samples / (num_classes * class_counts + 1e-6)\n",
        "\n",
        "# ✅ 정규화: sum = 1\n",
        "alpha_norm = class_weights / class_weights.sum()\n",
        "\n",
        "# 출력\n",
        "print(\"Raw Class Weights:\", class_weights)\n",
        "print(\"Normalized Alpha (sum=1):\", alpha_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e58ee2",
      "metadata": {
        "id": "86e58ee2"
      },
      "source": [
        "### Multi-label Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "72d6150e",
      "metadata": {
        "id": "72d6150e"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiLabelFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Tensor of shape [C], or scalar\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        logits: [B, C] - raw scores\n",
        "        targets: [B, C] - binary or soft labels\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)  # [B, C]\n",
        "        ce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')  # [B, C]\n",
        "\n",
        "        pt = probs * targets + (1 - probs) * (1 - targets)  # p_t\n",
        "        focal_weight = (1 - pt) ** self.gamma               # (1 - pt)^γ\n",
        "\n",
        "        loss = focal_weight * ce_loss                       # focal weight 적용\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)  # [B, C]\n",
        "            loss = alpha_factor * loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "class StableMultiLabelFocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # tensor of shape [C] or None\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        probs = torch.clamp(probs, min=self.eps, max=1.0 - self.eps)\n",
        "\n",
        "        # Focal weight\n",
        "        pt = probs * targets + (1 - probs) * (1 - targets)\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        # BCE loss\n",
        "        ce_loss = - (targets * torch.log(probs) + (1 - targets) * torch.log(1 - probs))\n",
        "\n",
        "        loss = focal_weight * ce_loss\n",
        "\n",
        "        # Safe alpha (class weights) application\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.dim() == 1:\n",
        "                alpha = self.alpha.view(1, -1)  # reshape for broadcasting\n",
        "            else:\n",
        "                alpha = self.alpha\n",
        "            loss = alpha * loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "zTgAvNcjFdzA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTgAvNcjFdzA",
        "outputId": "be2b4f33-fdbe-445c-874c-8fd11fe03c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.5652, 4.2994], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "label_dist = Counter({0:456, 1:262, 2:84, 3:83})  # Finetune 분포\n",
        "\n",
        "# Crackle: (1 + Both), Wheeze: (2 + Both)\n",
        "n_crackle = label_dist[1] + label_dist[3]  # 262 + 83\n",
        "n_wheeze  = label_dist[2] + label_dist[3]  # 84 + 83\n",
        "n_total   = sum(label_dist.values())       # 885\n",
        "\n",
        "pos_weight = torch.tensor([\n",
        "    (n_total - n_crackle) / (n_crackle + 1e-6),\n",
        "    (n_total - n_wheeze) / (n_wheeze + 1e-6)\n",
        "], device=device)\n",
        "\n",
        "print(pos_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea74a2d",
      "metadata": {
        "id": "aea74a2d"
      },
      "source": [
        "#### Linear Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "Nm8yaHDRZrT1",
      "metadata": {
        "id": "Nm8yaHDRZrT1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▄▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>4.7661</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">shuffle_GRU+ATT_MLS_PT_128bs_N+PS_2507182356</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/a0roanet' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/a0roanet</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all</a><br>Synced 5 W&B file(s), 50 media file(s), 100 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_145637-a0roanet/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e8c5369e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "e8c5369e",
        "outputId": "d11eb9f9-a396-4856-e0aa-e66d7b984270"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>lr</td><td>█████████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆█▇▇▆▅▅▅▄▄▅▅▅▅▄▄▃▄▃▃▃▃▄▃▂▂▂▂▂▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>299</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>5.95263</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/k3fjim4u' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/k3fjim4u</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all</a><br>Synced 5 W&B file(s), 300 media file(s), 600 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250718_152055-k3fjim4u/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ressera3/boaz/wandb/run-20250718_153706-d1giegz4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/d1giegz4' target=\"_blank\">GRU+ATT_500_MLS_LE_Abl(3.2)_alphaX_gamma2.0_best_N+PS_128bs_2507190037</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/d1giegz4' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/d1giegz4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/boaz_woony-boaz/0718_SBW_ICBHI_MSL_all/runs/d1giegz4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc62208fe80>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Wandb 정의\n",
        "\n",
        "# import wandb\n",
        "finetune_project_name = f'GRU+ATT_500_MLS_LE_Abl(3.2)_alphaX_gamma2.0_best_N+PS_{args.batch_size}bs_{get_timestamp()}'\n",
        "\n",
        "# wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "wandb.init(\n",
        "    project=\"0718_SBW_ICBHI_MSL_all\",           # 프로젝트 이름\n",
        "    name=f\"{finetune_project_name}\", # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.ft_epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b824a4ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===GemPooling (적응형 pooling)===\n",
        "class GeM2DSequential(nn.Module):\n",
        "    def __init__(self, p=3.0):\n",
        "        super().__init__()\n",
        "        self.freq_pool = GeMPool2d_dim(2, p=p)  # frequency\n",
        "        self.time_pool = GeMPool2d_dim(3, p=p)  # time\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.freq_pool(x)  # [B, C, 1, T]\n",
        "        x = self.time_pool(x)  # [B, C, 1, 1]\n",
        "        return x.squeeze(-1).squeeze(-1)  # [B, C]\n",
        "\n",
        "class GeMPool2d_dim(nn.Module):\n",
        "    def __init__(self, dim, p=3.0, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        # reduce specified dim only\n",
        "        if self.dim == 2:  # frequency\n",
        "            return x.clamp(min=self.eps).pow(self.p).mean(dim=2, keepdim=True).pow(1. / self.p)\n",
        "        elif self.dim == 3:  # time\n",
        "            return x.clamp(min=self.eps).pow(self.p).mean(dim=3, keepdim=True).pow(1. / self.p)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid dimension for GeM pooling\")\n",
        "\n",
        "# ======================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "06e2372b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "06e2372b",
        "outputId": "27e4e131-8945-4f93-9a19-3f72dcc6de7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_78755/996117279.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(load_ckpt_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using CNN6 backbone with dim_enc=500 and dim_prj=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation:  19%|█▉        | 6/32 [00:00<00:00, 53.29it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 60.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 1.0986\n",
            "4-Class Confusion Matrix:\n",
            " [[1158  616  150  119]\n",
            " [ 639  383  102   72]\n",
            " [ 267  156   38   37]\n",
            " [ 184  118   29   28]]\n",
            "Sensitivity: 0.2187, Specificity: 0.5668, ICBHI Score: 0.3928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1579    0    0    0]\n",
            " [ 649    0    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.6015\n",
            "[VALIDATION] Sensitivity: 0.0000, Specificity: 1.0000, Avg ICBHI Score: 0.5000\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 0, loss: 0.6015)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 66.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Train Loss: 0.5970\n",
            "4-Class Confusion Matrix:\n",
            " [[1656  380    0    0]\n",
            " [ 864  337    0    0]\n",
            " [ 365  133    0    0]\n",
            " [ 247  114    0    0]]\n",
            "Sensitivity: 0.1636, Specificity: 0.8134, ICBHI Score: 0.4885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[900 679   0   0]\n",
            " [259 390   0   0]\n",
            " [174 211   0   0]\n",
            " [ 75  68   0   0]]\n",
            "Test Loss: 0.6210\n",
            "[VALIDATION] Sensitivity: 0.3314, Specificity: 0.5700, Avg ICBHI Score: 0.4507\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 68.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, Train Loss: 0.5967\n",
            "4-Class Confusion Matrix:\n",
            " [[1641  369    0   35]\n",
            " [ 802  374    1   24]\n",
            " [ 363  128    0    4]\n",
            " [ 227  118    0   10]]\n",
            "Sensitivity: 0.1872, Specificity: 0.8024, ICBHI Score: 0.4948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1579    0    0    0]\n",
            " [ 649    0    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5478\n",
            "[VALIDATION] Sensitivity: 0.0000, Specificity: 1.0000, Avg ICBHI Score: 0.5000\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 2, loss: 0.5478)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 73.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, Train Loss: 0.6191\n",
            "4-Class Confusion Matrix:\n",
            " [[1682  269   26   63]\n",
            " [ 803  315   26   57]\n",
            " [ 379   91    6   22]\n",
            " [ 240   76    8   33]]\n",
            "Sensitivity: 0.1722, Specificity: 0.8245, ICBHI Score: 0.4983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1573    6    0    0]\n",
            " [ 644    5    0    0]\n",
            " [ 384    1    0    0]\n",
            " [ 142    1    0    0]]\n",
            "Test Loss: 0.5424\n",
            "[VALIDATION] Sensitivity: 0.0042, Specificity: 0.9962, Avg ICBHI Score: 0.5002\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 3, loss: 0.5424)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 76.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, Train Loss: 0.5928\n",
            "4-Class Confusion Matrix:\n",
            " [[1679  358    0    4]\n",
            " [ 838  360    0    3]\n",
            " [ 377  115    0    1]\n",
            " [ 236  125    0    0]]\n",
            "Sensitivity: 0.1752, Specificity: 0.8226, ICBHI Score: 0.4989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[932 647   0   0]\n",
            " [279 370   0   0]\n",
            " [196 189   0   0]\n",
            " [ 81  62   0   0]]\n",
            "Test Loss: 0.6014\n",
            "[VALIDATION] Sensitivity: 0.3144, Specificity: 0.5902, Avg ICBHI Score: 0.4523\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, Train Loss: 0.6173\n",
            "4-Class Confusion Matrix:\n",
            " [[1556  477    8    5]\n",
            " [ 808  382    9    2]\n",
            " [ 364  126    1    2]\n",
            " [ 216  135    4    1]]\n",
            "Sensitivity: 0.1873, Specificity: 0.7605, ICBHI Score: 0.4739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[759 820   0   0]\n",
            " [183 466   0   0]\n",
            " [131 254   0   0]\n",
            " [ 48  95   0   0]]\n",
            "Test Loss: 0.6851\n",
            "[VALIDATION] Sensitivity: 0.3959, Specificity: 0.4807, Avg ICBHI Score: 0.4383\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, Train Loss: 0.6162\n",
            "4-Class Confusion Matrix:\n",
            " [[1570  458   12    0]\n",
            " [ 765  431    9    0]\n",
            " [ 340  148    9    0]\n",
            " [ 219  131    4    0]]\n",
            "Sensitivity: 0.2140, Specificity: 0.7696, ICBHI Score: 0.4918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1551   28    0    0]\n",
            " [ 614   35    0    0]\n",
            " [ 376    9    0    0]\n",
            " [ 136    7    0    0]]\n",
            "Test Loss: 0.5446\n",
            "[VALIDATION] Sensitivity: 0.0297, Specificity: 0.9823, Avg ICBHI Score: 0.5060\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, Train Loss: 0.6199\n",
            "4-Class Confusion Matrix:\n",
            " [[1578  445    1   15]\n",
            " [ 758  424    0   18]\n",
            " [ 348  138    1    7]\n",
            " [ 228  125    0   10]]\n",
            "Sensitivity: 0.2115, Specificity: 0.7739, ICBHI Score: 0.4927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1577    2    0    0]\n",
            " [ 649    0    0    0]\n",
            " [ 384    1    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5485\n",
            "[VALIDATION] Sensitivity: 0.0000, Specificity: 0.9987, Avg ICBHI Score: 0.4994\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 76.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, Train Loss: 0.5974\n",
            "4-Class Confusion Matrix:\n",
            " [[1673  353   18    1]\n",
            " [ 837  353   10    1]\n",
            " [ 373  109   12    1]\n",
            " [ 234  112    9    0]]\n",
            "Sensitivity: 0.1780, Specificity: 0.8181, ICBHI Score: 0.4980\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[920 659   0   0]\n",
            " [258 391   0   0]\n",
            " [195 190   0   0]\n",
            " [ 75  68   0   0]]\n",
            "Test Loss: 0.6030\n",
            "[VALIDATION] Sensitivity: 0.3322, Specificity: 0.5826, Avg ICBHI Score: 0.4574\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train Loss: 0.6165\n",
            "4-Class Confusion Matrix:\n",
            " [[1595  410    7   28]\n",
            " [ 763  393   12   34]\n",
            " [ 351  130    6    8]\n",
            " [ 231  120    2    6]]\n",
            "Sensitivity: 0.1970, Specificity: 0.7819, ICBHI Score: 0.4894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1562    0   17    0]\n",
            " [ 641    0    8    0]\n",
            " [ 382    0    3    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5810\n",
            "[VALIDATION] Sensitivity: 0.0025, Specificity: 0.9892, Avg ICBHI Score: 0.4959\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, Train Loss: 0.5977\n",
            "4-Class Confusion Matrix:\n",
            " [[1637  363   16   24]\n",
            " [ 764  406    7   27]\n",
            " [ 362  107   12   12]\n",
            " [ 224  126    2    7]]\n",
            "Sensitivity: 0.2067, Specificity: 0.8025, ICBHI Score: 0.5046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1488   91    0    0]\n",
            " [ 547  102    0    0]\n",
            " [ 358   27    0    0]\n",
            " [ 128   15    0    0]]\n",
            "Test Loss: 0.5417\n",
            "[VALIDATION] Sensitivity: 0.0867, Specificity: 0.9424, Avg ICBHI Score: 0.5145\n",
            "##################################################\n",
            "=> Saved best checkpoint (epoch: 10, loss: 0.5417)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, Train Loss: 0.5828\n",
            "4-Class Confusion Matrix:\n",
            " [[1656  373    1    8]\n",
            " [ 763  438    1    6]\n",
            " [ 372  116    1    5]\n",
            " [ 213  139    0    4]]\n",
            "Sensitivity: 0.2153, Specificity: 0.8126, ICBHI Score: 0.5139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1451  128    0    0]\n",
            " [ 515  134    0    0]\n",
            " [ 342   43    0    0]\n",
            " [ 125   18    0    0]]\n",
            "Test Loss: 0.5515\n",
            "[VALIDATION] Sensitivity: 0.1138, Specificity: 0.9189, Avg ICBHI Score: 0.5164\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13, Train Loss: 0.6077\n",
            "4-Class Confusion Matrix:\n",
            " [[1626  378   14   18]\n",
            " [ 791  365   12   37]\n",
            " [ 366  108   10   10]\n",
            " [ 239  109    5    8]]\n",
            "Sensitivity: 0.1859, Specificity: 0.7986, ICBHI Score: 0.4923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1057  522    0    0]\n",
            " [ 312  337    0    0]\n",
            " [ 229  156    0    0]\n",
            " [  91   52    0    0]]\n",
            "Test Loss: 0.5754\n",
            "[VALIDATION] Sensitivity: 0.2863, Specificity: 0.6694, Avg ICBHI Score: 0.4779\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 80.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14, Train Loss: 0.6488\n",
            "4-Class Confusion Matrix:\n",
            " [[1455  424  141   19]\n",
            " [ 661  408  102   33]\n",
            " [ 322  114   44   12]\n",
            " [ 190  126   35   10]]\n",
            "Sensitivity: 0.2246, Specificity: 0.7136, ICBHI Score: 0.4691\n",
            "[Validation] Confusion Matrix:\n",
            " [[701 819   0  59]\n",
            " [151 440   0  58]\n",
            " [109 260   0  16]\n",
            " [ 37 100   0   6]]\n",
            "Test Loss: 0.6955\n",
            "[VALIDATION] Sensitivity: 0.3789, Specificity: 0.4440, Avg ICBHI Score: 0.4114\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 75.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15, Train Loss: 0.5911\n",
            "4-Class Confusion Matrix:\n",
            " [[1627  412    4    4]\n",
            " [ 763  430    1    0]\n",
            " [ 368  119    4    4]\n",
            " [ 222  132    5    1]]\n",
            "Sensitivity: 0.2123, Specificity: 0.7948, ICBHI Score: 0.5036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1579    0    0    0]\n",
            " [ 649    0    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5616\n",
            "[VALIDATION] Sensitivity: 0.0000, Specificity: 1.0000, Avg ICBHI Score: 0.5000\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16, Train Loss: 0.5957\n",
            "4-Class Confusion Matrix:\n",
            " [[1630  406    0    0]\n",
            " [ 783  420    0    0]\n",
            " [ 374  120    3    0]\n",
            " [ 228  132    0    0]]\n",
            "Sensitivity: 0.2053, Specificity: 0.8006, ICBHI Score: 0.5030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1577    2    0    0]\n",
            " [ 640    9    0    0]\n",
            " [ 383    2    0    0]\n",
            " [ 142    1    0    0]]\n",
            "Test Loss: 0.5487\n",
            "[VALIDATION] Sensitivity: 0.0076, Specificity: 0.9987, Avg ICBHI Score: 0.5032\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 77.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17, Train Loss: 0.5821\n",
            "4-Class Confusion Matrix:\n",
            " [[1674  346    8   10]\n",
            " [ 754  433    3   10]\n",
            " [ 373  115    5    4]\n",
            " [ 220  134    1    6]]\n",
            "Sensitivity: 0.2157, Specificity: 0.8214, ICBHI Score: 0.5186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1185  394    0    0]\n",
            " [ 360  289    0    0]\n",
            " [ 264  121    0    0]\n",
            " [ 105   38    0    0]]\n",
            "Test Loss: 0.5532\n",
            "[VALIDATION] Sensitivity: 0.2455, Specificity: 0.7505, Avg ICBHI Score: 0.4980\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18, Train Loss: 0.5963\n",
            "4-Class Confusion Matrix:\n",
            " [[1643  379   10    8]\n",
            " [ 758  425    9    9]\n",
            " [ 356  129    7    4]\n",
            " [ 228  124    1    6]]\n",
            "Sensitivity: 0.2130, Specificity: 0.8054, ICBHI Score: 0.5092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1409  170    0    0]\n",
            " [ 488  161    0    0]\n",
            " [ 331   54    0    0]\n",
            " [ 122   21    0    0]]\n",
            "Test Loss: 0.5775\n",
            "[VALIDATION] Sensitivity: 0.1368, Specificity: 0.8923, Avg ICBHI Score: 0.5146\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19, Train Loss: 0.6174\n",
            "4-Class Confusion Matrix:\n",
            " [[1555  450   15   20]\n",
            " [ 758  414   10   22]\n",
            " [ 362  121    7    5]\n",
            " [ 210  134    2   11]]\n",
            "Sensitivity: 0.2101, Specificity: 0.7623, ICBHI Score: 0.4862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1122  457    0    0]\n",
            " [ 342  307    0    0]\n",
            " [ 258  127    0    0]\n",
            " [  97   46    0    0]]\n",
            "Test Loss: 0.5610\n",
            "[VALIDATION] Sensitivity: 0.2608, Specificity: 0.7106, Avg ICBHI Score: 0.4857\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 77.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20, Train Loss: 0.6177\n",
            "4-Class Confusion Matrix:\n",
            " [[1565  359  101   15]\n",
            " [ 685  435   59   25]\n",
            " [ 337  122   26    8]\n",
            " [ 198  136   20    5]]\n",
            "Sensitivity: 0.2267, Specificity: 0.7672, ICBHI Score: 0.4969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1134  445    0    0]\n",
            " [ 329  320    0    0]\n",
            " [ 256  129    0    0]\n",
            " [  98   45    0    0]]\n",
            "Test Loss: 0.5816\n",
            "[VALIDATION] Sensitivity: 0.2719, Specificity: 0.7182, Avg ICBHI Score: 0.4950\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 21, Train Loss: 0.5989\n",
            "4-Class Confusion Matrix:\n",
            " [[1637  368   22   18]\n",
            " [ 758  397   21   25]\n",
            " [ 354  113   15   10]\n",
            " [ 209  132    8    9]]\n",
            "Sensitivity: 0.2053, Specificity: 0.8005, ICBHI Score: 0.5029\n",
            "[Validation] Confusion Matrix:\n",
            " [[1576    1    2    0]\n",
            " [ 646    0    3    0]\n",
            " [ 384    0    1    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5724\n",
            "[VALIDATION] Sensitivity: 0.0008, Specificity: 0.9981, Avg ICBHI Score: 0.4995\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 22, Train Loss: 0.5908\n",
            "4-Class Confusion Matrix:\n",
            " [[1605  421   12    1]\n",
            " [ 716  472   17    1]\n",
            " [ 370  119    8    1]\n",
            " [ 222  127    2    2]]\n",
            "Sensitivity: 0.2343, Specificity: 0.7872, ICBHI Score: 0.5107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1218  361    0    0]\n",
            " [ 374  275    0    0]\n",
            " [ 276  109    0    0]\n",
            " [ 105   38    0    0]]\n",
            "Test Loss: 0.5556\n",
            "[VALIDATION] Sensitivity: 0.2336, Specificity: 0.7714, Avg ICBHI Score: 0.5025\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 76.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 23, Train Loss: 0.5860\n",
            "4-Class Confusion Matrix:\n",
            " [[1672  359    3    2]\n",
            " [ 760  424    1   12]\n",
            " [ 382  113    3    3]\n",
            " [ 230  129    1    2]]\n",
            "Sensitivity: 0.2083, Specificity: 0.8212, ICBHI Score: 0.5147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1112  467    0    0]\n",
            " [ 315  334    0    0]\n",
            " [ 250  135    0    0]\n",
            " [  98   45    0    0]]\n",
            "Test Loss: 0.5673\n",
            "[VALIDATION] Sensitivity: 0.2838, Specificity: 0.7042, Avg ICBHI Score: 0.4940\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 24, Train Loss: 0.6037\n",
            "4-Class Confusion Matrix:\n",
            " [[1582  428   24    3]\n",
            " [ 725  437   34    6]\n",
            " [ 355  123   18    1]\n",
            " [ 197  147   15    1]]\n",
            "Sensitivity: 0.2215, Specificity: 0.7766, ICBHI Score: 0.4990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1463  116    0    0]\n",
            " [ 527  122    0    0]\n",
            " [ 340   45    0    0]\n",
            " [ 125   18    0    0]]\n",
            "Test Loss: 0.5447\n",
            "[VALIDATION] Sensitivity: 0.1037, Specificity: 0.9265, Avg ICBHI Score: 0.5151\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 77.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 25, Train Loss: 0.5831\n",
            "4-Class Confusion Matrix:\n",
            " [[1671  366    2    0]\n",
            " [ 769  425    3    1]\n",
            " [ 367  128    4    1]\n",
            " [ 238  120    1    0]]\n",
            "Sensitivity: 0.2086, Specificity: 0.8195, ICBHI Score: 0.5140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1579    0    0    0]\n",
            " [ 646    3    0    0]\n",
            " [ 384    1    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5538\n",
            "[VALIDATION] Sensitivity: 0.0025, Specificity: 1.0000, Avg ICBHI Score: 0.5013\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 26, Train Loss: 0.6058\n",
            "4-Class Confusion Matrix:\n",
            " [[1636  360   37    5]\n",
            " [ 697  452   47    9]\n",
            " [ 332  140   21    1]\n",
            " [ 200  145   13    1]]\n",
            "Sensitivity: 0.2303, Specificity: 0.8027, ICBHI Score: 0.5165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1403  176    0    0]\n",
            " [ 458  191    0    0]\n",
            " [ 319   66    0    0]\n",
            " [ 119   24    0    0]]\n",
            "Test Loss: 0.5484\n",
            "[VALIDATION] Sensitivity: 0.1623, Specificity: 0.8885, Avg ICBHI Score: 0.5254\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 27, Train Loss: 0.5977\n",
            "4-Class Confusion Matrix:\n",
            " [[1614  425    3    0]\n",
            " [ 769  433    0    1]\n",
            " [ 358  128    5    1]\n",
            " [ 229  128    0    2]]\n",
            "Sensitivity: 0.2142, Specificity: 0.7904, ICBHI Score: 0.5023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1579    0    0    0]\n",
            " [ 649    0    0    0]\n",
            " [ 385    0    0    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5772\n",
            "[VALIDATION] Sensitivity: 0.0000, Specificity: 1.0000, Avg ICBHI Score: 0.5000\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 78.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 28, Train Loss: 0.6007\n",
            "4-Class Confusion Matrix:\n",
            " [[1561  475    2    1]\n",
            " [ 745  458    0    0]\n",
            " [ 357  136    4    0]\n",
            " [ 200  157    0    0]]\n",
            "Sensitivity: 0.2246, Specificity: 0.7656, ICBHI Score: 0.4951\n",
            "[Validation] Confusion Matrix:\n",
            " [[1578    1    0    0]\n",
            " [ 646    3    0    0]\n",
            " [ 381    3    1    0]\n",
            " [ 143    0    0    0]]\n",
            "Test Loss: 0.5622\n",
            "[VALIDATION] Sensitivity: 0.0034, Specificity: 0.9994, Avg ICBHI Score: 0.5014\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation: 100%|██████████| 32/32 [00:00<00:00, 79.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 29, Train Loss: 0.5920\n",
            "4-Class Confusion Matrix:\n",
            " [[1638  406    0    4]\n",
            " [ 750  444    1    3]\n",
            " [ 372  114    6    2]\n",
            " [ 205  147    3    1]]\n",
            "Sensitivity: 0.2202, Specificity: 0.7998, ICBHI Score: 0.5100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/boaz/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Validation] Confusion Matrix:\n",
            " [[1105  474    0    0]\n",
            " [ 318  331    0    0]\n",
            " [ 250  135    0    0]\n",
            " [  94   49    0    0]]\n",
            "Test Loss: 0.5683\n",
            "[VALIDATION] Sensitivity: 0.2812, Specificity: 0.6998, Avg ICBHI Score: 0.4905\n",
            "##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linear Evaluation:  97%|█████████▋| 31/32 [00:00<00:00, 74.99it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 157\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[1;32m    156\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 157\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m    159\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[50], line 71\u001b[0m, in \u001b[0;36mFineTuningModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 71\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(features)\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[30], line 50\u001b[0m, in \u001b[0;36mHAN_GRU.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 시간 축을 따라 Attention-GRU\u001b[39;00m\n\u001b[1;32m     49\u001b[0m time_input \u001b[38;5;241m=\u001b[39m freq_output  \u001b[38;5;66;03m# (B, T, 2*hidden_freq)\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m time_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_gru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_input\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, T, 2*hidden_time)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m time_attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(time_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_attn_fc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_context_vector, mask)  \u001b[38;5;66;03m# (B, 2*hidden_time)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 최종 임베딩 차원으로 투사\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# out = self.fc_out(time_attn_output)  # (B, output_dim)\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/opt/conda/envs/boaz/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1405\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1406\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1414\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Model Load\n",
        "# 위에서부터 했다면\n",
        "# load_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "# aug_pth_path = \"/content/drive/MyDrive/2025_BOAZ_ICBHI/aug_pth\"\n",
        "\n",
        "# for gam in [2.0,2.3,2.7,3.0]:\n",
        "# # import wandb\n",
        "# finetune_project_name = f'ReICBHI_MLS_LE_Abl(3.2)_alphaX_gamma{gam}_last_N+TS_{args.batch_size}bs_{get_timestamp()}'\n",
        "\n",
        "# # wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "# wandb.init(\n",
        "#     project=\"ICBHI_MSL_Ablation_all\",           # 프로젝트 이름\n",
        "#     name=f\"{finetune_project_name}\", # 실험 이름\n",
        "#     config={\n",
        "#         \"epochs\": args.ft_epochs,\n",
        "#         \"batch_size\": args.batch_size,\n",
        "#         \"lr\": args.lr,\n",
        "#         \"momentum\": args.momentum,\n",
        "#         \"weight_decay\": args.weight_decay,\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# 중간부터 이어서 한다면\n",
        "load_ckpt_path = \"/home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp/shuffle_GRU+ATT500_MLS_PT_128bs_N+PS_2507190020_best_checkpoint.pth.tar\"\n",
        "save_ckpt_path = CHECKPOINT_PATH+\"/LE_pth\"\n",
        "\n",
        "# 재현성을 위한 시드 재설정\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# MoCo 모델 생성 및 체크포인트 로드\n",
        "model_eval = MoCo(\n",
        "    base_encoder=backbone_han_gru,\n",
        "    dim_enc=500,  # CNN6의 출력 feature dim (default=2048)\n",
        "    dim_prj=args.dim_prj,\n",
        "    K=args.K,\n",
        "    m=args.momentum,\n",
        "    T=args.T,\n",
        "    top_k=args.top_k,\n",
        "    lambda_bce=args.lambda_bce\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(load_ckpt_path, map_location=device)\n",
        "model_eval.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "# 사전 학습된 encoder 추출\n",
        "encoder = model_eval.encoder_q.eval().to(device)\n",
        "\n",
        "# 2. Dataset 정의\n",
        "# Dataset 정의는 이미 되어있음 - test_loader\n",
        "\n",
        "# =========================================================================\n",
        "\n",
        "# 3. Fine-tuning을 위한 분류 모델 정의 ( Data 개수 작으므로, encoder 파라미터 frozen )\n",
        "class FineTuningModel(nn.Module):\n",
        "    def __init__(self, encoder, out_dim=args.out_dim, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        # 마지막 FC layer를 제외한 encoder의 모든 레이어 freeze\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 새로운 분류 헤드 추가\n",
        "        self.classifier = nn.Linear(out_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.classifier(features)\n",
        "\n",
        "# class FineTuningModel(nn.Module):\n",
        "#     def __init__(self, encoder, out_dim=2048, num_classes=2):\n",
        "#         super().__init__()\n",
        "#         self.encoder = encoder\n",
        "#         for param in self.encoder.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#         self.pooling = GeM2DSequential()\n",
        "\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.BatchNorm1d(out_dim),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(out_dim, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(512, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(512, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.encoder(x)  # [B, 2048, F, T]\n",
        "#         x = self.pooling(x)  # [B, 2048]\n",
        "#         return self.classifier(x)\n",
        "\n",
        "# 재현성을 위한 시드 재설정\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# 4. 모델, 손실 함수, 옵티마이저 설정 / #CNN6 =>  out_dim = 512\n",
        "model = FineTuningModel(encoder, out_dim = 500).to(device)\n",
        "##############################\n",
        "\n",
        "# # Ablation(3-1) LE -> BCE Loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "\n",
        "# # Ablation(3-2) LE -> Multi-label Focal Loss\n",
        "# criterion = MultiLabelFocalLoss(\n",
        "#     alpha=alpha_norm.to(device),  # 정규화된 값\n",
        "#     gamma=2.0,                    # hard label일 경우\n",
        "#     reduction='mean'\n",
        "# )\n",
        "# Ablation(3-2) LE -> Multi-label Focal Loss\n",
        "# criterion = MultiLabelFocalLoss(\n",
        "#     # alpha=class_weights.to(device),  # 정규화된 값\n",
        "#     gamma=2.0,                    # hard label일 경우\n",
        "#     reduction='mean'\n",
        "# )\n",
        "\n",
        "############################\n",
        "optimizer = optim.AdamW(model.classifier.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.ft_epochs, eta_min=1e-6)  # Linear Evaluation에서 epochs는 다르게 적용\n",
        "\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "# 5. Linear Evaluation\n",
        "for epoch in range(args.ft_epochs):\n",
        "\n",
        "    # ===============================\n",
        "    # 1. Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    pbar = tqdm(finetune_loader, desc='Linear Evaluation')\n",
        "    for i, (cycle, labels, mask, _) in enumerate(pbar):\n",
        "        # Forward pass\n",
        "        cycle = cycle.cuda(args.gpu)\n",
        "        labels = labels.cuda(args.gpu)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        output = model(cycle)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss 계산\n",
        "        total_loss += loss.item() # loss : -> float\n",
        "\n",
        "        # 예측값과 실제값 저장 ( Ablation(4-1) threshold ?? )\n",
        "        predicted = (torch.sigmoid(output) > 0.5).float()\n",
        "        all_preds.append(predicted.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "        all_outputs.append(output.detach().cpu())\n",
        "\n",
        "    # train loss\n",
        "    train_loss = total_loss / len(finetune_loader)\n",
        "\n",
        "    # Concatenate\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()    # shape: [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy()  # shape: [N, 2]\n",
        "    all_output = torch.cat(all_outputs, dim=0).numpy()\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 2. 민감도/특이도 계산 (-> crakle+wheee 만 고려 = X)\n",
        "    # ===============================\n",
        "\n",
        "    #- origin-\n",
        "    # crackle_sens = crackle_spec = wheeze_sens = wheeze_spec = 0\n",
        "\n",
        "    # for i, label_name in enumerate(['Crackle', 'Wheeze']):\n",
        "    #     y_true = all_labels[:, i]\n",
        "    #     y_pred = all_preds[:, i]\n",
        "\n",
        "    #     cm = confusion_matrix(y_true, y_pred)  # [[TN, FP], [FN, TP]]\n",
        "    #     TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "    #     sensitivity = TP / (TP + FN + 1e-6)\n",
        "    #     specificity = TN / (TN + FP + 1e-6)\n",
        "\n",
        "    #     if i == 0:\n",
        "    #         crackle_sens = sensitivity\n",
        "    #         crackle_spec = specificity\n",
        "    #     elif i == 1:\n",
        "    #         wheeze_sens = sensitivity\n",
        "    #         wheeze_spec = specificity\n",
        "\n",
        "\n",
        "    # finetune_train_sens = (crackle_sens + wheeze_sens) / 2\n",
        "    # finetune_train_spec = (crackle_spec + wheeze_spec) / 2\n",
        "    # finetune_icbhi_score = (finetune_train_sens + finetune_train_spec) / 2\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
        "    # print(f\"  [Average] Sens: {(crackle_sens+wheeze_sens)/2:.4f}, Spec: {(crackle_spec+wheeze_spec)/2:.4f}, Score: {(crackle_sens+crackle_spec+wheeze_sens+wheeze_spec)/4:.4f}\")\n",
        "    # print(f\"  [Crackle] Sens: {crackle_sens:.4f}, Spec: {crackle_spec:.4f}, Score: {(crackle_sens+crackle_spec)/2:.4f}\")\n",
        "    # print(f\"  [Wheeze]  Sens: {wheeze_sens:.4f}, Spec: {wheeze_spec:.4f}, Score: {(wheeze_sens+wheeze_spec)/2:.4f}\")\n",
        "\n",
        "    # =====================================\n",
        "    # 2-Edited. Multi-class 민감도/특이도 계산\n",
        "    # =====================================\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import wandb\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    def multilabel_to_multiclass(y):\n",
        "        # Crackle → 1, Wheeze → 2, Both → 3, None → 0\n",
        "        y = np.array(y)\n",
        "        return y[:, 0] + y[:, 1]*2\n",
        "\n",
        "    def evaluate_multiclass_confusion(y_true, y_pred, class_names=[\"Normal\", \"Wheeze\", \"Crackle\", \"Both\"]):\n",
        "        y_true_cls = multilabel_to_multiclass(y_true)\n",
        "        y_pred_cls = multilabel_to_multiclass(y_pred)\n",
        "\n",
        "        cm = confusion_matrix(y_true_cls, y_pred_cls, labels=[0, 1, 2, 3])\n",
        "\n",
        "        # N_n: 정상 → 정상\n",
        "        N_n = cm[0, 0]\n",
        "        N_total = cm[0].sum()\n",
        "\n",
        "        # 이상 클래스 정답 수: W, C, B\n",
        "        W_total = cm[1].sum()\n",
        "        C_total = cm[2].sum()\n",
        "        B_total = cm[3].sum()\n",
        "\n",
        "        # 각각의 정답 → 정확한 예측만 고려\n",
        "        W_w = cm[1, 1]\n",
        "        C_c = cm[2, 2]\n",
        "        B_b = cm[3, 3]\n",
        "\n",
        "        SP = N_n / (N_total + 1e-6) #spec\n",
        "        SE = (W_w + C_c + B_b) / (W_total + C_total + B_total + 1e-6) #sense\n",
        "\n",
        "        AS = (SP + SE) / 2\n",
        "        HS = 2 * SP * SE / (SP + SE + 1e-6)\n",
        "\n",
        "        return cm, SE, SP, y_true_cls, y_pred_cls\n",
        "\n",
        "    def log_multiclass_conf_matrix_wandb(cm, class_names, sens, spec, normalize, tag):\n",
        "        # Normalize (비율) 옵션\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "            fmt = '.2f'\n",
        "            title = \"Confusion Matrix (Normalized %)\"\n",
        "        else:\n",
        "            fmt = 'd'\n",
        "            title = \"Confusion Matrix (Raw Count)\"\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(title)\n",
        "\n",
        "        icbhi_score = (sens + spec) / 2\n",
        "        # 우하단에 성능 출력\n",
        "        ax.text(\n",
        "            0.99, 0.15,\n",
        "            f\"Sensitivity: {sens*100:.2f}%\\nSpecificity: {spec*100:.2f}%\\nICBHI Score: {icbhi_score*100:.2f}%\",\n",
        "            ha='right', va='bottom',\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        # wandb.log({tag: wandb.Image(fig)})\n",
        "        # plt.close(fig)\n",
        "        return fig\n",
        "\n",
        "    # 1. 4-class Confusion Matrix 평가\n",
        "    class_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "    cm_4x4, finetune_train_sens, finetune_train_spec, y_true_cls, y_pred_cls = evaluate_multiclass_confusion(all_labels, all_preds, class_names)\n",
        "    finetune_icbhi_score = (finetune_train_sens + finetune_train_spec)/2\n",
        "\n",
        "    print(\"4-Class Confusion Matrix:\\n\", cm_4x4)\n",
        "    print(f\"Sensitivity: {finetune_train_sens:.4f}, Specificity: {finetune_train_spec:.4f}, ICBHI Score: {finetune_icbhi_score:.4f}\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Validation\n",
        "    # ===============================\n",
        "    test_loss, test_labels, test_preds = validate(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    precision = precision_score(test_labels, test_preds, average='macro')\n",
        "    recall = recall_score(test_labels, test_preds, average='macro')\n",
        "    f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "    test_cm_4x4, test_sens, test_spec, test_y_true_cls, test_y_pred_cls = evaluate_multiclass_confusion(test_labels, test_preds)\n",
        "    test_icbhi_score = (test_sens+test_spec)/2\n",
        "\n",
        "    print(\"[Validation] Confusion Matrix:\\n\", test_cm_4x4)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"[VALIDATION] Sensitivity: {test_sens:.4f}, Specificity: {test_spec:.4f}, Avg ICBHI Score: {(test_sens+test_spec)/2:.4f}\")\n",
        "    print(\"##################################################\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 4. Confusion Matrix\n",
        "    # ===============================\n",
        "\n",
        "    # 2. Finetune Count Confusion Matrix 시각화\n",
        "    fig_finetune_raw = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, finetune_train_sens, finetune_train_spec, normalize=False, tag=\"finetune_conf_matrix_raw\")\n",
        "    fig_finetune_norm = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, finetune_train_sens, finetune_train_spec, normalize=True, tag=\"finetune_conf_matrix_norm\")\n",
        "\n",
        "    # 3. Test Confusion Matrix 시각화\n",
        "    fig_test_raw = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=False, tag=\"test_conf_matrix_raw\")\n",
        "    fig_test_norm = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=True, tag=\"test_conf_matrix_norm\")\n",
        "\n",
        "    # 4. log dictionary 생성\n",
        "    wandb_log_dict = {\n",
        "        \"finetune_conf_matrix_raw\": wandb.Image(fig_finetune_raw),\n",
        "        \"finetune_conf_matrix_norm\": wandb.Image(fig_finetune_norm),\n",
        "        \"test_conf_matrix_raw\": wandb.Image(fig_test_raw),\n",
        "        \"test_conf_matrix_norm\": wandb.Image(fig_test_norm)\n",
        "    }\n",
        "\n",
        "    # =====================================\n",
        "    # 5. Checkpoint (Every 50 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        ckpt_path = save_ckpt_path + f\"{finetune_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"💾 Saved checkpoint to {save_ckpt_path}\")\n",
        "\n",
        "    # ===============================\n",
        "    # 6. Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = save_ckpt_path + f\"{finetune_project_name}_best.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")\n",
        "\n",
        "\n",
        "        # 🔹 Confusion Matrix Logging for Best\n",
        "        cm_best, sens_best, spec_best,_, _ = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_best_raw = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=False, tag=\"best_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_best_norm = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=True, tag=\"best_test_conf_matrix_norm\")\n",
        "\n",
        "        wandb_log_dict.update({\n",
        "            \"best_test_conf_matrix_raw\": wandb.Image(fig_best_raw),\n",
        "            \"best_test_conf_matrix_norm\": wandb.Image(fig_best_norm)\n",
        "        })\n",
        "\n",
        "\n",
        "    if epoch == args.ft_epochs - 1:\n",
        "        # 🔸 Confusion Matrix Logging for Last Epoch\n",
        "        cm_last, sens_last, spec_last, _, _  = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_last_raw = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=False, tag=\"last_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_last_norm = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=True, tag=\"last_test_conf_matrix_norm\")\n",
        "\n",
        "        wandb_log_dict.update({\n",
        "            \"last_test_conf_matrix_raw\": wandb.Image(fig_last_raw),\n",
        "            \"last_test_conf_matrix_norm\": wandb.Image(fig_last_norm)\n",
        "        })\n",
        "    # =====================================\n",
        "    # 7. Logging with wandb confusion matrix\n",
        "    # =====================================\n",
        "\n",
        "    # step 1. metrics\n",
        "    wandb.log({\n",
        "        # Train metrics\n",
        "        \"Finetune/epoch\": epoch,\n",
        "        \"Finetune/train_loss\": train_loss,\n",
        "        \"Finetune/test_loss\": test_loss,\n",
        "        \"Finetune/train_sens\": finetune_train_sens,\n",
        "        \"Finetune/train_spec\": finetune_train_spec,\n",
        "        \"Finetune/icbhi_score\": finetune_icbhi_score,\n",
        "\n",
        "        # Test metrics\n",
        "        \"Test/loss\": test_loss,\n",
        "        \"Test/sensitivity\": test_sens,\n",
        "        \"Test/specificity\": test_spec,\n",
        "        \"Test/icbhi_score\": test_icbhi_score\n",
        "    })\n",
        "\n",
        "    # step 2. Confusion matrix\n",
        "    wandb.log(wandb_log_dict)\n",
        "\n",
        "    plt.close(fig_finetune_raw)\n",
        "    plt.close(fig_finetune_norm)\n",
        "    plt.close(fig_test_raw)\n",
        "    plt.close(fig_test_norm)\n",
        "    if 'fig_best_raw' in locals(): plt.close(fig_best_raw)\n",
        "    if 'fig_best_norm' in locals(): plt.close(fig_best_norm)\n",
        "    if 'fig_last_raw' in locals(): plt.close(fig_last_raw)\n",
        "    if 'fig_last_norm' in locals(): plt.close(fig_last_norm)\n",
        "\n",
        "    # ===============================\n",
        "    # 8. Scheduler Step\n",
        "    # ===============================\n",
        "    scheduler.step()\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "tvx1gKm9aOb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvx1gKm9aOb6",
        "outputId": "14b12a08-d3ee-45fa-b328-bb67c4dc7a7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[882, 421, 146, 130],\n",
              "        [232, 320,  29,  68],\n",
              "        [214, 108,  32,  31],\n",
              "        [ 71,  43,  13,  16]]),\n",
              " ['Normal', 'Crackle', 'Wheeze', 'Both'],\n",
              " np.float64(0.5607476630749807),\n",
              " np.float64(0.5585813802668895))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cm_last, class_names, sens_last, spec_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "LQVziM_eb4SL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQVziM_eb4SL",
        "outputId": "3956b198-f687-46fb-e6f1-ac08f5a21c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "660/517/697/882\n",
            "660/1177\n",
            "882/1579\n",
            "0.43925233607540154/0.5585813802668895\n",
            "0.4342906901334448\n"
          ]
        }
      ],
      "source": [
        "TP = cm_last[1:, 1:].sum()\n",
        "FN = cm_last[1:, 0].sum()\n",
        "FP = cm_last[0, 1:].sum()\n",
        "TN = cm_last[0, 0]\n",
        "print( f\"{TP}/{FN}/{FP}/{TN}\" )\n",
        "\n",
        "sens =FN / (TP + FN + 1e-6)\n",
        "spec = TN / (TN + FP + 1e-6)\n",
        "\n",
        "print(f\"{TP}/{TP + FN}\")\n",
        "print(f\"{TN}/{TN + FP}\")\n",
        "print(f\"{sens}/{spec}\")\n",
        "print(f\"{(0.31+spec)/2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ZO5KTgoxl1CN",
      "metadata": {
        "id": "ZO5KTgoxl1CN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "r4Gl8GceqNA2",
      "metadata": {
        "id": "r4Gl8GceqNA2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# sigmoid 적용\n",
        "sigmoid_output = sigmoid(all_output)  # shape: (N, 2)\n",
        "all_preds = (sigmoid_output > 0.5).astype(int)  # binary prediction\n",
        "all_labels = all_labels.astype(int)  # 정수형으로 일치\n",
        "\n",
        "# 맞춘 것들\n",
        "correct_mask = np.all(all_preds == all_labels, axis=1)\n",
        "correct = np.concatenate([sigmoid_output, all_preds, all_labels], axis=1)[correct_mask]\n",
        "\n",
        "# 틀린 것들\n",
        "incorrect_mask = ~correct_mask\n",
        "incorrect_preds = all_preds[incorrect_mask]\n",
        "incorrect_labels = all_labels[incorrect_mask]\n",
        "incorrect_sigmoid = sigmoid_output[incorrect_mask]\n",
        "incorrect_concat = np.concatenate([incorrect_sigmoid, incorrect_preds, incorrect_labels], axis=1)\n",
        "\n",
        "# 그룹별 필터링\n",
        "def get_mismatched_by_label(target_label):\n",
        "    mask = np.all(incorrect_labels == target_label, axis=1)\n",
        "    return incorrect_concat[mask]\n",
        "\n",
        "# 각 그룹 추출\n",
        "wrong_10 = get_mismatched_by_label([1, 0])  # crackle\n",
        "wrong_01 = get_mismatched_by_label([0, 1])  # wheeze\n",
        "wrong_11 = get_mismatched_by_label([1, 1])  # both\n",
        "wrong_00 = get_mismatched_by_label([0, 0])  # normal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "mXw6GqeTqzhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXw6GqeTqzhR",
        "outputId": "97c9c318-e996-488a-d1b0-c801ce9e19e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ 맞춘 것들 (예: [sigmoid1, sigmoid2, pred1, pred2, label1, label2])\n",
            "[[0.3777 0.7532 0.     1.     0.     1.    ]\n",
            " [0.6201 0.2532 1.     0.     1.     0.    ]\n",
            " [0.4055 0.2152 0.     0.     0.     0.    ]\n",
            " [0.6252 0.5529 1.     1.     1.     1.    ]\n",
            " [0.6782 0.3518 1.     0.     1.     0.    ]\n",
            " [0.2119 0.0415 0.     0.     0.     0.    ]\n",
            " [0.1671 0.0128 0.     0.     0.     0.    ]\n",
            " [0.1175 0.1351 0.     0.     0.     0.    ]\n",
            " [0.0776 0.1387 0.     0.     0.     0.    ]\n",
            " [0.1999 0.0141 0.     0.     0.     0.    ]\n",
            " [0.258  0.092  0.     0.     0.     0.    ]\n",
            " [0.368  0.3167 0.     0.     0.     0.    ]\n",
            " [0.5379 0.3661 1.     0.     1.     0.    ]\n",
            " [0.1995 0.145  0.     0.     0.     0.    ]\n",
            " [0.0943 0.1535 0.     0.     0.     0.    ]\n",
            " [0.2883 0.0929 0.     0.     0.     0.    ]\n",
            " [0.1232 0.1262 0.     0.     0.     0.    ]\n",
            " [0.1832 0.1434 0.     0.     0.     0.    ]\n",
            " [0.8271 0.5132 1.     1.     1.     1.    ]\n",
            " [0.322  0.3447 0.     0.     0.     0.    ]\n",
            " [0.2476 0.2435 0.     0.     0.     0.    ]\n",
            " [0.1662 0.3354 0.     0.     0.     0.    ]\n",
            " [0.2527 0.6452 0.     1.     0.     1.    ]\n",
            " [0.1969 0.0342 0.     0.     0.     0.    ]\n",
            " [0.2979 0.1661 0.     0.     0.     0.    ]\n",
            " [0.4084 0.2333 0.     0.     0.     0.    ]\n",
            " [0.6328 0.5813 1.     1.     1.     1.    ]\n",
            " [0.7004 0.609  1.     1.     1.     1.    ]\n",
            " [0.2912 0.3552 0.     0.     0.     0.    ]\n",
            " [0.2679 0.145  0.     0.     0.     0.    ]\n",
            " [0.0689 0.0247 0.     0.     0.     0.    ]\n",
            " [0.7109 0.4357 1.     0.     1.     0.    ]\n",
            " [0.0654 0.0818 0.     0.     0.     0.    ]\n",
            " [0.3178 0.1117 0.     0.     0.     0.    ]\n",
            " [0.0442 0.2229 0.     0.     0.     0.    ]\n",
            " [0.556  0.1292 1.     0.     1.     0.    ]\n",
            " [0.3164 0.1212 0.     0.     0.     0.    ]\n",
            " [0.8521 0.0315 1.     0.     1.     0.    ]\n",
            " [0.3674 0.0548 0.     0.     0.     0.    ]\n",
            " [0.2412 0.0935 0.     0.     0.     0.    ]\n",
            " [0.6499 0.1896 1.     0.     1.     0.    ]\n",
            " [0.2447 0.1286 0.     0.     0.     0.    ]\n",
            " [0.754  0.0443 1.     0.     1.     0.    ]\n",
            " [0.4914 0.6046 0.     1.     0.     1.    ]\n",
            " [0.653  0.242  1.     0.     1.     0.    ]\n",
            " [0.2386 0.0317 0.     0.     0.     0.    ]\n",
            " [0.2952 0.244  0.     0.     0.     0.    ]\n",
            " [0.1012 0.2803 0.     0.     0.     0.    ]\n",
            " [0.     0.0031 0.     0.     0.     0.    ]\n",
            " [0.0557 0.1615 0.     0.     0.     0.    ]\n",
            " [0.5854 0.396  1.     0.     1.     0.    ]\n",
            " [0.6412 0.0844 1.     0.     1.     0.    ]\n",
            " [0.0368 0.1651 0.     0.     0.     0.    ]\n",
            " [0.3043 0.0161 0.     0.     0.     0.    ]\n",
            " [0.7368 0.1964 1.     0.     1.     0.    ]\n",
            " [0.4956 0.1275 0.     0.     0.     0.    ]\n",
            " [0.3471 0.3229 0.     0.     0.     0.    ]\n",
            " [0.0294 0.1311 0.     0.     0.     0.    ]\n",
            " [0.1414 0.061  0.     0.     0.     0.    ]\n",
            " [0.2738 0.277  0.     0.     0.     0.    ]\n",
            " [0.4502 0.0892 0.     0.     0.     0.    ]\n",
            " [0.7288 0.2963 1.     0.     1.     0.    ]\n",
            " [0.7615 0.2919 1.     0.     1.     0.    ]\n",
            " [0.4229 0.0551 0.     0.     0.     0.    ]\n",
            " [0.7141 0.0261 1.     0.     1.     0.    ]\n",
            " [0.2082 0.2029 0.     0.     0.     0.    ]\n",
            " [0.1735 0.2519 0.     0.     0.     0.    ]\n",
            " [0.0951 0.0441 0.     0.     0.     0.    ]\n",
            " [0.1004 0.09   0.     0.     0.     0.    ]\n",
            " [0.473  0.1364 0.     0.     0.     0.    ]\n",
            " [0.6986 0.0571 1.     0.     1.     0.    ]\n",
            " [0.1917 0.4137 0.     0.     0.     0.    ]\n",
            " [1.     0.     1.     0.     1.     0.    ]\n",
            " [0.965  0.9981 1.     1.     1.     1.    ]\n",
            " [0.1202 0.0004 0.     0.     0.     0.    ]\n",
            " [0.8121 0.4271 1.     0.     1.     0.    ]\n",
            " [0.5676 0.3963 1.     0.     1.     0.    ]\n",
            " [0.6276 0.5882 1.     1.     1.     1.    ]\n",
            " [0.2907 0.1662 0.     0.     0.     0.    ]\n",
            " [0.7776 0.7876 1.     1.     1.     1.    ]\n",
            " [0.9582 0.0146 1.     0.     1.     0.    ]\n",
            " [0.3808 0.2751 0.     0.     0.     0.    ]\n",
            " [0.414  0.8202 0.     1.     0.     1.    ]\n",
            " [0.2665 0.1948 0.     0.     0.     0.    ]\n",
            " [0.2828 0.0498 0.     0.     0.     0.    ]\n",
            " [0.3318 0.1477 0.     0.     0.     0.    ]\n",
            " [0.1653 0.2547 0.     0.     0.     0.    ]\n",
            " [0.9346 0.0331 1.     0.     1.     0.    ]\n",
            " [0.2429 0.125  0.     0.     0.     0.    ]\n",
            " [0.7176 0.0674 1.     0.     1.     0.    ]\n",
            " [0.1342 0.1186 0.     0.     0.     0.    ]\n",
            " [0.1052 0.4288 0.     0.     0.     0.    ]\n",
            " [0.7058 0.5639 1.     1.     1.     1.    ]\n",
            " [0.2437 0.0859 0.     0.     0.     0.    ]\n",
            " [0.2492 0.0809 0.     0.     0.     0.    ]\n",
            " [0.241  0.4965 0.     0.     0.     0.    ]\n",
            " [0.6677 0.2241 1.     0.     1.     0.    ]\n",
            " [0.2628 0.2585 0.     0.     0.     0.    ]\n",
            " [0.2417 0.5506 0.     1.     0.     1.    ]\n",
            " [0.1352 0.0893 0.     0.     0.     0.    ]\n",
            " [0.5331 0.4144 1.     0.     1.     0.    ]\n",
            " [0.5201 0.6052 1.     1.     1.     1.    ]\n",
            " [0.6469 0.1146 1.     0.     1.     0.    ]\n",
            " [0.2725 0.2041 0.     0.     0.     0.    ]\n",
            " [0.7643 0.1812 1.     0.     1.     0.    ]\n",
            " [0.4001 0.2251 0.     0.     0.     0.    ]\n",
            " [0.6703 0.3964 1.     0.     1.     0.    ]\n",
            " [0.7006 0.7437 1.     1.     1.     1.    ]\n",
            " [0.0777 0.1049 0.     0.     0.     0.    ]\n",
            " [0.4113 0.8093 0.     1.     0.     1.    ]\n",
            " [0.4601 0.1465 0.     0.     0.     0.    ]\n",
            " [0.3756 0.2775 0.     0.     0.     0.    ]\n",
            " [0.0861 0.0683 0.     0.     0.     0.    ]\n",
            " [0.2081 0.0883 0.     0.     0.     0.    ]\n",
            " [0.5435 0.002  1.     0.     1.     0.    ]\n",
            " [0.4394 0.0157 0.     0.     0.     0.    ]\n",
            " [0.3744 0.2014 0.     0.     0.     0.    ]\n",
            " [0.7126 0.7046 1.     1.     1.     1.    ]\n",
            " [0.0389 0.684  0.     1.     0.     1.    ]\n",
            " [0.6152 0.3055 1.     0.     1.     0.    ]\n",
            " [0.4068 0.7755 0.     1.     0.     1.    ]\n",
            " [0.0647 0.1094 0.     0.     0.     0.    ]\n",
            " [0.66   0.2694 1.     0.     1.     0.    ]\n",
            " [0.7385 0.1278 1.     0.     1.     0.    ]\n",
            " [0.1478 0.6431 0.     1.     0.     1.    ]\n",
            " [0.1007 0.0939 0.     0.     0.     0.    ]\n",
            " [0.6459 0.3347 1.     0.     1.     0.    ]\n",
            " [0.5605 0.0724 1.     0.     1.     0.    ]\n",
            " [0.     0.9993 0.     1.     0.     1.    ]\n",
            " [0.579  0.422  1.     0.     1.     0.    ]\n",
            " [0.3782 0.179  0.     0.     0.     0.    ]\n",
            " [0.2191 0.4326 0.     0.     0.     0.    ]\n",
            " [0.5261 0.3111 1.     0.     1.     0.    ]\n",
            " [0.0893 0.3541 0.     0.     0.     0.    ]\n",
            " [0.0183 0.     0.     0.     0.     0.    ]\n",
            " [0.6747 0.3259 1.     0.     1.     0.    ]\n",
            " [0.1711 0.2238 0.     0.     0.     0.    ]\n",
            " [0.5087 0.5599 1.     1.     1.     1.    ]\n",
            " [0.3141 0.8243 0.     1.     0.     1.    ]\n",
            " [0.1026 0.0672 0.     0.     0.     0.    ]\n",
            " [0.5101 0.2405 1.     0.     1.     0.    ]\n",
            " [0.7301 0.2182 1.     0.     1.     0.    ]\n",
            " [0.0828 0.849  0.     1.     0.     1.    ]\n",
            " [0.244  0.1236 0.     0.     0.     0.    ]\n",
            " [0.203  0.4689 0.     0.     0.     0.    ]\n",
            " [0.4103 0.1787 0.     0.     0.     0.    ]\n",
            " [0.1402 0.3358 0.     0.     0.     0.    ]\n",
            " [0.6693 0.1954 1.     0.     1.     0.    ]\n",
            " [0.1036 0.5159 0.     1.     0.     1.    ]\n",
            " [0.2104 0.2003 0.     0.     0.     0.    ]\n",
            " [0.7744 0.5038 1.     1.     1.     1.    ]\n",
            " [0.4414 0.2463 0.     0.     0.     0.    ]\n",
            " [0.6265 0.1619 1.     0.     1.     0.    ]\n",
            " [0.1059 0.0524 0.     0.     0.     0.    ]\n",
            " [0.1183 0.3766 0.     0.     0.     0.    ]\n",
            " [0.1388 0.5791 0.     1.     0.     1.    ]\n",
            " [0.6741 0.6387 1.     1.     1.     1.    ]\n",
            " [0.2162 0.0327 0.     0.     0.     0.    ]\n",
            " [0.0509 0.5859 0.     1.     0.     1.    ]\n",
            " [0.6365 0.2079 1.     0.     1.     0.    ]\n",
            " [0.5781 0.081  1.     0.     1.     0.    ]\n",
            " [0.1015 0.0977 0.     0.     0.     0.    ]\n",
            " [0.2441 0.0167 0.     0.     0.     0.    ]\n",
            " [0.188  0.0081 0.     0.     0.     0.    ]\n",
            " [0.6842 0.6318 1.     1.     1.     1.    ]\n",
            " [0.0479 0.2557 0.     0.     0.     0.    ]\n",
            " [0.4194 0.0696 0.     0.     0.     0.    ]\n",
            " [0.5499 0.4862 1.     0.     1.     0.    ]\n",
            " [0.0291 0.1699 0.     0.     0.     0.    ]\n",
            " [0.7885 0.1328 1.     0.     1.     0.    ]\n",
            " [0.4733 0.3462 0.     0.     0.     0.    ]\n",
            " [0.8454 0.0885 1.     0.     1.     0.    ]\n",
            " [0.1298 0.4839 0.     0.     0.     0.    ]\n",
            " [0.2979 0.1417 0.     0.     0.     0.    ]\n",
            " [0.2782 0.1438 0.     0.     0.     0.    ]\n",
            " [0.7349 0.2929 1.     0.     1.     0.    ]\n",
            " [0.4704 0.1929 0.     0.     0.     0.    ]\n",
            " [0.6367 0.4475 1.     0.     1.     0.    ]\n",
            " [0.6296 0.2931 1.     0.     1.     0.    ]\n",
            " [0.085  0.2229 0.     0.     0.     0.    ]\n",
            " [0.1574 0.0767 0.     0.     0.     0.    ]\n",
            " [0.1979 0.1131 0.     0.     0.     0.    ]\n",
            " [0.0512 0.2146 0.     0.     0.     0.    ]\n",
            " [0.5215 0.1938 1.     0.     1.     0.    ]\n",
            " [0.6893 0.7015 1.     1.     1.     1.    ]\n",
            " [0.0387 0.1098 0.     0.     0.     0.    ]\n",
            " [0.7451 0.496  1.     0.     1.     0.    ]\n",
            " [0.1268 0.0433 0.     0.     0.     0.    ]\n",
            " [0.5144 0.3274 1.     0.     1.     0.    ]\n",
            " [0.5262 0.59   1.     1.     1.     1.    ]\n",
            " [0.4806 0.0797 0.     0.     0.     0.    ]\n",
            " [0.6543 0.1866 1.     0.     1.     0.    ]\n",
            " [0.6517 0.5403 1.     1.     1.     1.    ]\n",
            " [0.1506 0.0902 0.     0.     0.     0.    ]\n",
            " [0.7596 0.2595 1.     0.     1.     0.    ]\n",
            " [0.2518 0.2525 0.     0.     0.     0.    ]\n",
            " [0.5687 0.8557 1.     1.     1.     1.    ]\n",
            " [0.6153 0.3402 1.     0.     1.     0.    ]\n",
            " [0.1204 0.1245 0.     0.     0.     0.    ]\n",
            " [0.8265 0.0575 1.     0.     1.     0.    ]\n",
            " [0.249  0.2834 0.     0.     0.     0.    ]\n",
            " [0.1683 0.1791 0.     0.     0.     0.    ]\n",
            " [0.4164 0.8591 0.     1.     0.     1.    ]\n",
            " [0.1484 0.2438 0.     0.     0.     0.    ]\n",
            " [0.1563 0.0636 0.     0.     0.     0.    ]\n",
            " [0.33   0.0825 0.     0.     0.     0.    ]\n",
            " [0.1334 0.0718 0.     0.     0.     0.    ]\n",
            " [0.0714 0.0405 0.     0.     0.     0.    ]\n",
            " [0.1911 0.32   0.     0.     0.     0.    ]\n",
            " [0.6335 0.9559 1.     1.     1.     1.    ]\n",
            " [0.0847 0.0308 0.     0.     0.     0.    ]\n",
            " [0.3259 0.2708 0.     0.     0.     0.    ]\n",
            " [0.3317 0.31   0.     0.     0.     0.    ]\n",
            " [0.2932 0.0298 0.     0.     0.     0.    ]\n",
            " [0.6399 0.1062 1.     0.     1.     0.    ]\n",
            " [0.3581 0.84   0.     1.     0.     1.    ]\n",
            " [0.6375 0.2698 1.     0.     1.     0.    ]\n",
            " [0.2902 0.0628 0.     0.     0.     0.    ]\n",
            " [0.6977 0.2893 1.     0.     1.     0.    ]\n",
            " [0.0261 0.0983 0.     0.     0.     0.    ]\n",
            " [0.0993 0.6981 0.     1.     0.     1.    ]\n",
            " [0.1854 0.2223 0.     0.     0.     0.    ]\n",
            " [0.5808 0.3482 1.     0.     1.     0.    ]\n",
            " [0.2533 0.0245 0.     0.     0.     0.    ]\n",
            " [0.546  0.25   1.     0.     1.     0.    ]\n",
            " [0.3308 0.1357 0.     0.     0.     0.    ]\n",
            " [0.5074 0.2011 1.     0.     1.     0.    ]\n",
            " [0.4361 0.7035 0.     1.     0.     1.    ]\n",
            " [0.1503 0.7173 0.     1.     0.     1.    ]\n",
            " [0.5652 0.5253 1.     1.     1.     1.    ]\n",
            " [0.1998 0.2208 0.     0.     0.     0.    ]\n",
            " [0.2697 0.0813 0.     0.     0.     0.    ]\n",
            " [0.7207 0.3472 1.     0.     1.     0.    ]\n",
            " [0.0166 0.0292 0.     0.     0.     0.    ]\n",
            " [0.1409 0.2243 0.     0.     0.     0.    ]\n",
            " [0.8221 0.1075 1.     0.     1.     0.    ]\n",
            " [0.1224 0.5826 0.     1.     0.     1.    ]\n",
            " [0.6491 0.2152 1.     0.     1.     0.    ]\n",
            " [0.7786 0.0077 1.     0.     1.     0.    ]\n",
            " [0.2297 0.1066 0.     0.     0.     0.    ]\n",
            " [0.5634 0.0469 1.     0.     1.     0.    ]\n",
            " [0.3533 0.1818 0.     0.     0.     0.    ]\n",
            " [0.0339 0.0008 0.     0.     0.     0.    ]\n",
            " [0.4608 0.1683 0.     0.     0.     0.    ]\n",
            " [0.6738 0.2371 1.     0.     1.     0.    ]\n",
            " [0.4466 0.1205 0.     0.     0.     0.    ]\n",
            " [0.5725 0.3844 1.     0.     1.     0.    ]\n",
            " [0.2301 0.1142 0.     0.     0.     0.    ]\n",
            " [0.1343 0.062  0.     0.     0.     0.    ]\n",
            " [0.4033 0.8107 0.     1.     0.     1.    ]\n",
            " [0.5924 0.0219 1.     0.     1.     0.    ]\n",
            " [0.329  0.0957 0.     0.     0.     0.    ]\n",
            " [0.3943 0.6661 0.     1.     0.     1.    ]\n",
            " [0.5101 0.2191 1.     0.     1.     0.    ]\n",
            " [0.1025 0.0522 0.     0.     0.     0.    ]\n",
            " [0.3159 0.3433 0.     0.     0.     0.    ]\n",
            " [0.1625 0.2857 0.     0.     0.     0.    ]\n",
            " [0.1229 0.0878 0.     0.     0.     0.    ]\n",
            " [0.542  0.1763 1.     0.     1.     0.    ]\n",
            " [0.3323 0.7211 0.     1.     0.     1.    ]\n",
            " [0.5387 0.0245 1.     0.     1.     0.    ]\n",
            " [0.0855 0.0471 0.     0.     0.     0.    ]\n",
            " [0.5621 0.3727 1.     0.     1.     0.    ]\n",
            " [0.462  0.2621 0.     0.     0.     0.    ]\n",
            " [0.7243 0.7925 1.     1.     1.     1.    ]\n",
            " [0.3839 0.0981 0.     0.     0.     0.    ]\n",
            " [0.7791 0.6999 1.     1.     1.     1.    ]\n",
            " [0.6881 0.5827 1.     1.     1.     1.    ]\n",
            " [0.1116 0.0354 0.     0.     0.     0.    ]\n",
            " [0.5474 0.1194 1.     0.     1.     0.    ]\n",
            " [0.1609 0.5705 0.     1.     0.     1.    ]\n",
            " [0.6841 0.2461 1.     0.     1.     0.    ]\n",
            " [0.5833 0.4142 1.     0.     1.     0.    ]\n",
            " [0.3341 0.0635 0.     0.     0.     0.    ]\n",
            " [0.17   0.2078 0.     0.     0.     0.    ]\n",
            " [0.1155 0.8039 0.     1.     0.     1.    ]\n",
            " [0.1694 0.0237 0.     0.     0.     0.    ]\n",
            " [0.154  0.194  0.     0.     0.     0.    ]\n",
            " [0.7007 0.6459 1.     1.     1.     1.    ]\n",
            " [0.4846 0.0248 0.     0.     0.     0.    ]\n",
            " [0.5984 0.1448 1.     0.     1.     0.    ]\n",
            " [0.0255 0.0308 0.     0.     0.     0.    ]\n",
            " [0.3805 0.3439 0.     0.     0.     0.    ]\n",
            " [0.4027 0.1774 0.     0.     0.     0.    ]\n",
            " [0.046  0.1796 0.     0.     0.     0.    ]\n",
            " [0.1381 0.1326 0.     0.     0.     0.    ]\n",
            " [0.2332 0.0162 0.     0.     0.     0.    ]\n",
            " [0.0173 0.9922 0.     1.     0.     1.    ]\n",
            " [0.6832 0.1514 1.     0.     1.     0.    ]\n",
            " [0.1129 0.1412 0.     0.     0.     0.    ]\n",
            " [0.0174 0.0194 0.     0.     0.     0.    ]\n",
            " [0.481  0.1367 0.     0.     0.     0.    ]\n",
            " [0.743  0.1237 1.     0.     1.     0.    ]\n",
            " [0.3188 0.1165 0.     0.     0.     0.    ]\n",
            " [0.324  0.6122 0.     1.     0.     1.    ]\n",
            " [0.236  0.3626 0.     0.     0.     0.    ]\n",
            " [0.6664 0.1718 1.     0.     1.     0.    ]\n",
            " [0.6275 0.1503 1.     0.     1.     0.    ]\n",
            " [0.5394 0.2954 1.     0.     1.     0.    ]\n",
            " [0.0948 0.1296 0.     0.     0.     0.    ]\n",
            " [0.9669 0.0298 1.     0.     1.     0.    ]\n",
            " [0.5765 0.3828 1.     0.     1.     0.    ]\n",
            " [0.3488 0.5714 0.     1.     0.     1.    ]\n",
            " [0.3425 0.2944 0.     0.     0.     0.    ]\n",
            " [0.3086 0.3466 0.     0.     0.     0.    ]\n",
            " [0.2946 0.1576 0.     0.     0.     0.    ]\n",
            " [0.1022 0.9162 0.     1.     0.     1.    ]\n",
            " [0.3804 0.2681 0.     0.     0.     0.    ]\n",
            " [0.0394 0.0025 0.     0.     0.     0.    ]\n",
            " [0.5374 0.3277 1.     0.     1.     0.    ]\n",
            " [0.2221 0.3866 0.     0.     0.     0.    ]\n",
            " [0.6664 0.1713 1.     0.     1.     0.    ]\n",
            " [0.2768 0.1223 0.     0.     0.     0.    ]\n",
            " [0.1308 0.2583 0.     0.     0.     0.    ]\n",
            " [0.3029 0.6388 0.     1.     0.     1.    ]\n",
            " [0.2155 0.1535 0.     0.     0.     0.    ]\n",
            " [0.6322 0.3454 1.     0.     1.     0.    ]\n",
            " [0.6113 0.2679 1.     0.     1.     0.    ]\n",
            " [0.0982 0.0665 0.     0.     0.     0.    ]\n",
            " [0.6978 0.2083 1.     0.     1.     0.    ]\n",
            " [0.579  0.2225 1.     0.     1.     0.    ]\n",
            " [0.3389 0.0219 0.     0.     0.     0.    ]\n",
            " [0.1791 0.0796 0.     0.     0.     0.    ]\n",
            " [0.3787 0.0875 0.     0.     0.     0.    ]\n",
            " [0.5406 0.1245 1.     0.     1.     0.    ]\n",
            " [0.5328 0.2936 1.     0.     1.     0.    ]\n",
            " [0.07   0.0809 0.     0.     0.     0.    ]\n",
            " [0.4133 0.1117 0.     0.     0.     0.    ]\n",
            " [0.465  0.2947 0.     0.     0.     0.    ]\n",
            " [0.2859 0.12   0.     0.     0.     0.    ]\n",
            " [0.0282 0.0114 0.     0.     0.     0.    ]\n",
            " [0.6563 0.0405 1.     0.     1.     0.    ]\n",
            " [0.6436 0.3499 1.     0.     1.     0.    ]\n",
            " [0.5044 0.2474 1.     0.     1.     0.    ]\n",
            " [0.7975 0.0388 1.     0.     1.     0.    ]\n",
            " [0.1411 0.0871 0.     0.     0.     0.    ]\n",
            " [0.4035 0.2721 0.     0.     0.     0.    ]\n",
            " [0.0463 0.1277 0.     0.     0.     0.    ]\n",
            " [0.931  0.1145 1.     0.     1.     0.    ]\n",
            " [0.3291 0.1371 0.     0.     0.     0.    ]\n",
            " [0.5999 0.2594 1.     0.     1.     0.    ]\n",
            " [0.0722 0.1051 0.     0.     0.     0.    ]\n",
            " [0.7725 0.3003 1.     0.     1.     0.    ]\n",
            " [0.5743 0.2333 1.     0.     1.     0.    ]\n",
            " [0.2035 0.0875 0.     0.     0.     0.    ]\n",
            " [0.9336 0.0747 1.     0.     1.     0.    ]\n",
            " [0.4574 0.224  0.     0.     0.     0.    ]\n",
            " [0.122  0.4225 0.     0.     0.     0.    ]\n",
            " [0.9986 1.     1.     1.     1.     1.    ]\n",
            " [0.6598 0.0845 1.     0.     1.     0.    ]\n",
            " [0.5085 0.2563 1.     0.     1.     0.    ]\n",
            " [0.2978 0.4213 0.     0.     0.     0.    ]\n",
            " [0.3334 0.3387 0.     0.     0.     0.    ]\n",
            " [0.0259 0.1634 0.     0.     0.     0.    ]\n",
            " [0.2487 0.255  0.     0.     0.     0.    ]\n",
            " [0.284  0.2946 0.     0.     0.     0.    ]\n",
            " [0.3882 0.426  0.     0.     0.     0.    ]\n",
            " [0.3932 0.1575 0.     0.     0.     0.    ]\n",
            " [0.3718 0.1607 0.     0.     0.     0.    ]\n",
            " [0.0408 0.0781 0.     0.     0.     0.    ]\n",
            " [0.1232 0.2389 0.     0.     0.     0.    ]\n",
            " [0.5558 0.2079 1.     0.     1.     0.    ]\n",
            " [0.1942 0.1724 0.     0.     0.     0.    ]\n",
            " [0.0613 0.0548 0.     0.     0.     0.    ]\n",
            " [0.0602 0.1073 0.     0.     0.     0.    ]\n",
            " [0.5208 0.2909 1.     0.     1.     0.    ]\n",
            " [0.0872 0.0647 0.     0.     0.     0.    ]\n",
            " [0.5496 0.4665 1.     0.     1.     0.    ]\n",
            " [0.3507 0.3742 0.     0.     0.     0.    ]\n",
            " [0.1932 0.0589 0.     0.     0.     0.    ]\n",
            " [0.653  0.0195 1.     0.     1.     0.    ]\n",
            " [0.3578 0.0432 0.     0.     0.     0.    ]\n",
            " [0.5987 0.2186 1.     0.     1.     0.    ]\n",
            " [0.5324 0.2447 1.     0.     1.     0.    ]\n",
            " [0.4847 0.1358 0.     0.     0.     0.    ]\n",
            " [0.0668 0.0589 0.     0.     0.     0.    ]\n",
            " [0.5873 0.3176 1.     0.     1.     0.    ]\n",
            " [0.3859 0.1435 0.     0.     0.     0.    ]\n",
            " [0.5177 0.6557 1.     1.     1.     1.    ]\n",
            " [0.1332 0.0207 0.     0.     0.     0.    ]\n",
            " [0.567  0.3062 1.     0.     1.     0.    ]\n",
            " [0.8416 0.0718 1.     0.     1.     0.    ]\n",
            " [0.3943 0.1737 0.     0.     0.     0.    ]\n",
            " [0.1367 0.2451 0.     0.     0.     0.    ]\n",
            " [0.6528 0.5435 1.     1.     1.     1.    ]\n",
            " [0.147  0.6617 0.     1.     0.     1.    ]\n",
            " [0.0521 0.0425 0.     0.     0.     0.    ]\n",
            " [0.91   0.0059 1.     0.     1.     0.    ]\n",
            " [0.6761 0.594  1.     1.     1.     1.    ]\n",
            " [0.1983 0.5416 0.     1.     0.     1.    ]\n",
            " [0.5563 0.1168 1.     0.     1.     0.    ]\n",
            " [0.3159 0.2685 0.     0.     0.     0.    ]\n",
            " [0.7691 0.1886 1.     0.     1.     0.    ]\n",
            " [0.3529 0.6696 0.     1.     0.     1.    ]\n",
            " [0.4514 0.2313 0.     0.     0.     0.    ]\n",
            " [0.2418 0.1537 0.     0.     0.     0.    ]\n",
            " [0.7617 0.259  1.     0.     1.     0.    ]\n",
            " [0.2323 0.0926 0.     0.     0.     0.    ]\n",
            " [0.5831 0.1571 1.     0.     1.     0.    ]\n",
            " [0.1322 0.22   0.     0.     0.     0.    ]\n",
            " [0.2379 0.1224 0.     0.     0.     0.    ]\n",
            " [0.3882 0.5188 0.     1.     0.     1.    ]\n",
            " [0.1524 0.1348 0.     0.     0.     0.    ]\n",
            " [0.2863 0.1679 0.     0.     0.     0.    ]\n",
            " [0.8056 0.1379 1.     0.     1.     0.    ]\n",
            " [0.1677 0.2667 0.     0.     0.     0.    ]\n",
            " [0.6294 0.0963 1.     0.     1.     0.    ]\n",
            " [0.4006 0.4482 0.     0.     0.     0.    ]\n",
            " [0.5633 0.2761 1.     0.     1.     0.    ]\n",
            " [0.1157 0.411  0.     0.     0.     0.    ]\n",
            " [0.6785 0.2925 1.     0.     1.     0.    ]\n",
            " [0.1212 0.079  0.     0.     0.     0.    ]\n",
            " [0.7654 0.2134 1.     0.     1.     0.    ]\n",
            " [0.4726 0.3705 0.     0.     0.     0.    ]\n",
            " [0.0706 0.1863 0.     0.     0.     0.    ]\n",
            " [0.5722 0.7033 1.     1.     1.     1.    ]\n",
            " [0.7433 0.6326 1.     1.     1.     1.    ]\n",
            " [0.2356 0.1859 0.     0.     0.     0.    ]\n",
            " [0.3037 0.1199 0.     0.     0.     0.    ]\n",
            " [0.7207 0.2738 1.     0.     1.     0.    ]\n",
            " [0.0862 0.2281 0.     0.     0.     0.    ]\n",
            " [0.7531 0.003  1.     0.     1.     0.    ]\n",
            " [0.2204 0.504  0.     1.     0.     1.    ]\n",
            " [0.091  0.077  0.     0.     0.     0.    ]\n",
            " [0.7033 0.286  1.     0.     1.     0.    ]\n",
            " [0.7761 0.3343 1.     0.     1.     0.    ]\n",
            " [0.1704 0.2886 0.     0.     0.     0.    ]\n",
            " [0.8084 0.1517 1.     0.     1.     0.    ]\n",
            " [0.1004 0.0169 0.     0.     0.     0.    ]\n",
            " [0.5462 0.5652 1.     1.     1.     1.    ]\n",
            " [0.3758 0.0704 0.     0.     0.     0.    ]\n",
            " [0.7025 0.4292 1.     0.     1.     0.    ]\n",
            " [0.     0.9985 0.     1.     0.     1.    ]\n",
            " [0.608  0.0236 1.     0.     1.     0.    ]\n",
            " [0.4558 0.3948 0.     0.     0.     0.    ]\n",
            " [0.4199 0.3994 0.     0.     0.     0.    ]\n",
            " [0.8323 0.0273 1.     0.     1.     0.    ]\n",
            " [0.2914 0.1247 0.     0.     0.     0.    ]\n",
            " [0.58   0.2841 1.     0.     1.     0.    ]\n",
            " [0.3958 0.5287 0.     1.     0.     1.    ]\n",
            " [0.3832 0.2001 0.     0.     0.     0.    ]\n",
            " [0.6302 0.4019 1.     0.     1.     0.    ]\n",
            " [0.4597 0.0751 0.     0.     0.     0.    ]\n",
            " [0.028  0.1706 0.     0.     0.     0.    ]\n",
            " [0.4783 0.2562 0.     0.     0.     0.    ]\n",
            " [0.2566 0.7608 0.     1.     0.     1.    ]\n",
            " [0.6002 0.1954 1.     0.     1.     0.    ]\n",
            " [0.1759 0.1103 0.     0.     0.     0.    ]\n",
            " [0.5875 0.1153 1.     0.     1.     0.    ]\n",
            " [0.3838 0.1861 0.     0.     0.     0.    ]\n",
            " [0.1465 0.1479 0.     0.     0.     0.    ]\n",
            " [0.0293 0.4254 0.     0.     0.     0.    ]\n",
            " [0.6319 0.6759 1.     1.     1.     1.    ]\n",
            " [0.4728 0.1285 0.     0.     0.     0.    ]\n",
            " [0.4882 0.4608 0.     0.     0.     0.    ]\n",
            " [0.3383 0.3558 0.     0.     0.     0.    ]\n",
            " [0.6436 0.4128 1.     0.     1.     0.    ]\n",
            " [0.0279 0.1405 0.     0.     0.     0.    ]\n",
            " [0.265  0.1785 0.     0.     0.     0.    ]\n",
            " [0.0779 0.2668 0.     0.     0.     0.    ]\n",
            " [0.1164 0.0639 0.     0.     0.     0.    ]\n",
            " [0.417  0.24   0.     0.     0.     0.    ]\n",
            " [0.5512 0.2983 1.     0.     1.     0.    ]\n",
            " [0.1337 0.0735 0.     0.     0.     0.    ]\n",
            " [0.126  0.1621 0.     0.     0.     0.    ]\n",
            " [0.7291 0.3836 1.     0.     1.     0.    ]\n",
            " [0.494  0.3365 0.     0.     0.     0.    ]\n",
            " [0.0544 0.0013 0.     0.     0.     0.    ]\n",
            " [0.6831 0.3366 1.     0.     1.     0.    ]\n",
            " [0.1561 0.1099 0.     0.     0.     0.    ]\n",
            " [0.2671 0.1445 0.     0.     0.     0.    ]\n",
            " [0.1464 0.3159 0.     0.     0.     0.    ]\n",
            " [0.6763 0.227  1.     0.     1.     0.    ]\n",
            " [0.0789 0.1533 0.     0.     0.     0.    ]\n",
            " [0.3284 0.1643 0.     0.     0.     0.    ]\n",
            " [0.0565 0.1616 0.     0.     0.     0.    ]\n",
            " [0.12   0.1944 0.     0.     0.     0.    ]\n",
            " [0.1472 0.1394 0.     0.     0.     0.    ]\n",
            " [0.7825 0.7138 1.     1.     1.     1.    ]\n",
            " [0.3478 0.0845 0.     0.     0.     0.    ]\n",
            " [0.4484 0.1331 0.     0.     0.     0.    ]\n",
            " [0.3212 0.1954 0.     0.     0.     0.    ]\n",
            " [0.2354 0.2105 0.     0.     0.     0.    ]\n",
            " [0.074  0.0045 0.     0.     0.     0.    ]\n",
            " [0.5235 0.2496 1.     0.     1.     0.    ]\n",
            " [0.8479 0.0238 1.     0.     1.     0.    ]\n",
            " [0.5358 0.4286 1.     0.     1.     0.    ]\n",
            " [0.025  0.1993 0.     0.     0.     0.    ]\n",
            " [0.2607 0.1764 0.     0.     0.     0.    ]\n",
            " [0.0426 0.1301 0.     0.     0.     0.    ]\n",
            " [0.2531 0.6303 0.     1.     0.     1.    ]\n",
            " [0.654  0.2899 1.     0.     1.     0.    ]\n",
            " [0.3005 0.2967 0.     0.     0.     0.    ]\n",
            " [0.0195 0.5416 0.     1.     0.     1.    ]\n",
            " [0.3172 0.7712 0.     1.     0.     1.    ]\n",
            " [0.6792 0.6513 1.     1.     1.     1.    ]\n",
            " [0.4775 0.251  0.     0.     0.     0.    ]\n",
            " [0.2472 0.3115 0.     0.     0.     0.    ]\n",
            " [0.1209 0.3383 0.     0.     0.     0.    ]\n",
            " [0.0132 0.0104 0.     0.     0.     0.    ]\n",
            " [0.5193 0.0635 1.     0.     1.     0.    ]\n",
            " [0.0404 0.3092 0.     0.     0.     0.    ]\n",
            " [0.294  0.2116 0.     0.     0.     0.    ]\n",
            " [0.6339 0.427  1.     0.     1.     0.    ]\n",
            " [0.2921 0.2969 0.     0.     0.     0.    ]\n",
            " [0.2225 0.3847 0.     0.     0.     0.    ]\n",
            " [0.1289 0.353  0.     0.     0.     0.    ]\n",
            " [0.4494 0.7555 0.     1.     0.     1.    ]\n",
            " [0.3332 0.1335 0.     0.     0.     0.    ]\n",
            " [0.6777 0.0875 1.     0.     1.     0.    ]\n",
            " [0.0753 0.133  0.     0.     0.     0.    ]\n",
            " [0.7895 0.1304 1.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.    ]\n",
            " [0.4731 0.2862 0.     0.     0.     0.    ]\n",
            " [0.2223 0.0121 0.     0.     0.     0.    ]\n",
            " [0.0767 0.0082 0.     0.     0.     0.    ]\n",
            " [0.3003 0.2795 0.     0.     0.     0.    ]\n",
            " [0.0951 0.134  0.     0.     0.     0.    ]\n",
            " [0.0675 0.1176 0.     0.     0.     0.    ]\n",
            " [0.1844 0.0643 0.     0.     0.     0.    ]\n",
            " [0.2022 0.1864 0.     0.     0.     0.    ]\n",
            " [0.2315 0.3064 0.     0.     0.     0.    ]\n",
            " [0.2319 0.7055 0.     1.     0.     1.    ]\n",
            " [0.1669 0.0991 0.     0.     0.     0.    ]\n",
            " [0.3969 0.2528 0.     0.     0.     0.    ]\n",
            " [0.0836 0.4085 0.     0.     0.     0.    ]\n",
            " [0.6638 0.3156 1.     0.     1.     0.    ]\n",
            " [0.415  0.0804 0.     0.     0.     0.    ]\n",
            " [0.6431 0.2978 1.     0.     1.     0.    ]\n",
            " [0.691  0.1567 1.     0.     1.     0.    ]\n",
            " [0.7762 0.6353 1.     1.     1.     1.    ]\n",
            " [0.7276 0.558  1.     1.     1.     1.    ]\n",
            " [0.4247 0.5741 0.     1.     0.     1.    ]\n",
            " [0.2983 0.012  0.     0.     0.     0.    ]\n",
            " [0.2802 0.212  0.     0.     0.     0.    ]\n",
            " [0.5401 0.2726 1.     0.     1.     0.    ]\n",
            " [0.7863 0.2792 1.     0.     1.     0.    ]\n",
            " [0.5539 0.3359 1.     0.     1.     0.    ]\n",
            " [0.2606 0.4707 0.     0.     0.     0.    ]\n",
            " [0.2947 0.5024 0.     1.     0.     1.    ]\n",
            " [0.2484 0.5303 0.     1.     0.     1.    ]\n",
            " [0.4409 0.1976 0.     0.     0.     0.    ]\n",
            " [0.8176 0.7068 1.     1.     1.     1.    ]\n",
            " [0.6277 0.2181 1.     0.     1.     0.    ]\n",
            " [0.256  0.406  0.     0.     0.     0.    ]\n",
            " [0.7062 0.2265 1.     0.     1.     0.    ]\n",
            " [0.0925 0.2937 0.     0.     0.     0.    ]\n",
            " [0.0318 0.025  0.     0.     0.     0.    ]\n",
            " [0.4001 0.2303 0.     0.     0.     0.    ]\n",
            " [0.5627 0.5266 1.     1.     1.     1.    ]\n",
            " [0.6419 0.2605 1.     0.     1.     0.    ]\n",
            " [0.1757 0.1339 0.     0.     0.     0.    ]\n",
            " [0.6987 0.4559 1.     0.     1.     0.    ]\n",
            " [0.7176 0.373  1.     0.     1.     0.    ]\n",
            " [0.1362 0.0356 0.     0.     0.     0.    ]\n",
            " [0.1273 0.0944 0.     0.     0.     0.    ]\n",
            " [0.055  0.2736 0.     0.     0.     0.    ]\n",
            " [0.4908 0.1267 0.     0.     0.     0.    ]\n",
            " [0.7583 0.3918 1.     0.     1.     0.    ]\n",
            " [0.3333 0.4945 0.     0.     0.     0.    ]\n",
            " [0.7326 0.3078 1.     0.     1.     0.    ]\n",
            " [0.3466 0.5771 0.     1.     0.     1.    ]\n",
            " [0.4287 0.856  0.     1.     0.     1.    ]\n",
            " [0.2938 0.4579 0.     0.     0.     0.    ]\n",
            " [0.1805 0.1538 0.     0.     0.     0.    ]\n",
            " [0.1826 0.1068 0.     0.     0.     0.    ]\n",
            " [0.4175 0.3687 0.     0.     0.     0.    ]\n",
            " [0.4113 0.2127 0.     0.     0.     0.    ]\n",
            " [0.5259 0.2708 1.     0.     1.     0.    ]\n",
            " [0.5803 0.1859 1.     0.     1.     0.    ]\n",
            " [0.3273 0.2371 0.     0.     0.     0.    ]\n",
            " [0.4915 0.1749 0.     0.     0.     0.    ]\n",
            " [0.2794 0.2639 0.     0.     0.     0.    ]\n",
            " [0.4799 0.3318 0.     0.     0.     0.    ]\n",
            " [0.3696 0.1852 0.     0.     0.     0.    ]\n",
            " [0.509  0.1298 1.     0.     1.     0.    ]\n",
            " [0.0529 0.3405 0.     0.     0.     0.    ]\n",
            " [0.4835 0.1324 0.     0.     0.     0.    ]\n",
            " [0.2055 0.1188 0.     0.     0.     0.    ]\n",
            " [0.1024 0.059  0.     0.     0.     0.    ]\n",
            " [0.2632 0.4571 0.     0.     0.     0.    ]\n",
            " [0.1649 0.0165 0.     0.     0.     0.    ]\n",
            " [0.5418 0.5128 1.     1.     1.     1.    ]\n",
            " [0.2424 0.2227 0.     0.     0.     0.    ]\n",
            " [0.6179 0.3363 1.     0.     1.     0.    ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n✅ 맞춘 것들 (예: [sigmoid1, sigmoid2, pred1, pred2, label1, label2])\")\n",
        "print(correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "15BfpFS8j3BR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15BfpFS8j3BR",
        "outputId": "3cf833f6-9884-4f4e-988f-a38720b6fd97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.3777 0.7532 0.     1.     0.     1.    ]\n",
            " [0.6394 0.3415 1.     0.     0.     0.    ]\n",
            " [0.6201 0.2532 1.     0.     1.     0.    ]\n",
            " [0.5947 0.8443 1.     1.     0.     1.    ]\n",
            " [0.6154 0.2961 1.     0.     0.     0.    ]\n",
            " [0.4523 0.1755 0.     0.     1.     0.    ]\n",
            " [0.4055 0.2152 0.     0.     0.     0.    ]\n",
            " [0.6252 0.5529 1.     1.     1.     1.    ]\n",
            " [0.6782 0.3518 1.     0.     1.     0.    ]\n",
            " [0.6107 0.5067 1.     1.     0.     1.    ]\n",
            " [0.2119 0.0415 0.     0.     0.     0.    ]\n",
            " [0.1671 0.0128 0.     0.     0.     0.    ]\n",
            " [0.1175 0.1351 0.     0.     0.     0.    ]\n",
            " [0.0776 0.1387 0.     0.     0.     0.    ]\n",
            " [0.1999 0.0141 0.     0.     0.     0.    ]\n",
            " [0.4829 0.1669 0.     0.     1.     0.    ]\n",
            " [0.258  0.092  0.     0.     0.     0.    ]\n",
            " [0.368  0.3167 0.     0.     0.     0.    ]\n",
            " [0.5379 0.3661 1.     0.     1.     0.    ]\n",
            " [0.1995 0.145  0.     0.     0.     0.    ]\n",
            " [0.5116 0.48   1.     0.     1.     1.    ]\n",
            " [0.0943 0.1535 0.     0.     0.     0.    ]\n",
            " [0.7015 0.0734 1.     0.     0.     0.    ]\n",
            " [0.2883 0.0929 0.     0.     0.     0.    ]\n",
            " [0.1232 0.1262 0.     0.     0.     0.    ]\n",
            " [0.1832 0.1434 0.     0.     0.     0.    ]\n",
            " [0.5684 0.3739 1.     0.     1.     1.    ]\n",
            " [0.8271 0.5132 1.     1.     1.     1.    ]\n",
            " [0.322  0.3447 0.     0.     0.     0.    ]\n",
            " [0.2476 0.2435 0.     0.     0.     0.    ]\n",
            " [0.1662 0.3354 0.     0.     0.     0.    ]\n",
            " [0.2527 0.6452 0.     1.     0.     1.    ]\n",
            " [0.1969 0.0342 0.     0.     0.     0.    ]\n",
            " [0.5731 0.1378 1.     0.     0.     0.    ]\n",
            " [0.2979 0.1661 0.     0.     0.     0.    ]\n",
            " [0.4084 0.2333 0.     0.     0.     0.    ]\n",
            " [0.6328 0.5813 1.     1.     1.     1.    ]\n",
            " [0.7004 0.609  1.     1.     1.     1.    ]\n",
            " [0.2912 0.3552 0.     0.     0.     0.    ]\n",
            " [0.2679 0.145  0.     0.     0.     0.    ]\n",
            " [0.0689 0.0247 0.     0.     0.     0.    ]\n",
            " [0.5785 0.2315 1.     0.     0.     0.    ]\n",
            " [0.7109 0.4357 1.     0.     1.     0.    ]\n",
            " [0.0654 0.0818 0.     0.     0.     0.    ]\n",
            " [0.3178 0.1117 0.     0.     0.     0.    ]\n",
            " [0.0442 0.2229 0.     0.     0.     0.    ]\n",
            " [0.556  0.1292 1.     0.     1.     0.    ]\n",
            " [0.3164 0.1212 0.     0.     0.     0.    ]\n",
            " [0.8521 0.0315 1.     0.     1.     0.    ]\n",
            " [0.3674 0.0548 0.     0.     0.     0.    ]\n",
            " [0.2412 0.0935 0.     0.     0.     0.    ]\n",
            " [0.6499 0.1896 1.     0.     1.     0.    ]\n",
            " [0.2447 0.1286 0.     0.     0.     0.    ]\n",
            " [0.754  0.0443 1.     0.     1.     0.    ]\n",
            " [0.5477 0.5746 1.     1.     0.     1.    ]\n",
            " [0.4914 0.6046 0.     1.     0.     1.    ]\n",
            " [0.653  0.242  1.     0.     1.     0.    ]\n",
            " [0.2386 0.0317 0.     0.     0.     0.    ]\n",
            " [0.6671 0.3581 1.     0.     0.     0.    ]\n",
            " [0.2952 0.244  0.     0.     0.     0.    ]\n",
            " [0.1012 0.2803 0.     0.     0.     0.    ]\n",
            " [0.     0.0031 0.     0.     0.     0.    ]\n",
            " [0.0557 0.1615 0.     0.     0.     0.    ]\n",
            " [0.5854 0.396  1.     0.     1.     0.    ]\n",
            " [0.6412 0.0844 1.     0.     1.     0.    ]\n",
            " [0.5184 0.1602 1.     0.     0.     0.    ]\n",
            " [0.0368 0.1651 0.     0.     0.     0.    ]\n",
            " [0.3043 0.0161 0.     0.     0.     0.    ]\n",
            " [0.5196 0.1928 1.     0.     0.     0.    ]\n",
            " [0.7368 0.1964 1.     0.     1.     0.    ]\n",
            " [0.4956 0.1275 0.     0.     0.     0.    ]\n",
            " [0.481  0.0392 0.     0.     1.     0.    ]\n",
            " [0.5382 0.2301 1.     0.     0.     0.    ]\n",
            " [0.5245 0.151  1.     0.     0.     0.    ]\n",
            " [0.3471 0.3229 0.     0.     0.     0.    ]\n",
            " [0.0294 0.1311 0.     0.     0.     0.    ]\n",
            " [0.1414 0.061  0.     0.     0.     0.    ]\n",
            " [0.2738 0.277  0.     0.     0.     0.    ]\n",
            " [0.4502 0.0892 0.     0.     0.     0.    ]\n",
            " [0.7288 0.2963 1.     0.     1.     0.    ]\n",
            " [0.7615 0.2919 1.     0.     1.     0.    ]\n",
            " [0.4229 0.0551 0.     0.     0.     0.    ]\n",
            " [0.7141 0.0261 1.     0.     1.     0.    ]\n",
            " [0.5174 0.4089 1.     0.     0.     0.    ]\n",
            " [0.4879 0.0734 0.     0.     1.     0.    ]\n",
            " [0.2082 0.2029 0.     0.     0.     0.    ]\n",
            " [0.1735 0.2519 0.     0.     0.     0.    ]\n",
            " [0.0951 0.0441 0.     0.     0.     0.    ]\n",
            " [0.6159 0.7081 1.     1.     0.     1.    ]\n",
            " [0.1004 0.09   0.     0.     0.     0.    ]\n",
            " [0.4437 0.5089 0.     1.     1.     1.    ]\n",
            " [0.473  0.1364 0.     0.     0.     0.    ]\n",
            " [0.6986 0.0571 1.     0.     1.     0.    ]\n",
            " [0.1917 0.4137 0.     0.     0.     0.    ]\n",
            " [0.6401 0.1575 1.     0.     0.     0.    ]\n",
            " [1.     0.     1.     0.     1.     0.    ]\n",
            " [0.965  0.9981 1.     1.     1.     1.    ]\n",
            " [0.1202 0.0004 0.     0.     0.     0.    ]\n",
            " [0.8121 0.4271 1.     0.     1.     0.    ]\n",
            " [0.5676 0.3963 1.     0.     1.     0.    ]\n",
            " [0.6276 0.5882 1.     1.     1.     1.    ]\n",
            " [0.2907 0.1662 0.     0.     0.     0.    ]\n",
            " [0.7776 0.7876 1.     1.     1.     1.    ]\n",
            " [0.9582 0.0146 1.     0.     1.     0.    ]\n",
            " [0.3808 0.2751 0.     0.     0.     0.    ]\n",
            " [0.534  0.4677 1.     0.     0.     0.    ]\n",
            " [0.414  0.8202 0.     1.     0.     1.    ]\n",
            " [0.2665 0.1948 0.     0.     0.     0.    ]\n",
            " [0.2828 0.0498 0.     0.     0.     0.    ]\n",
            " [0.3318 0.1477 0.     0.     0.     0.    ]\n",
            " [0.5282 0.1773 1.     0.     0.     0.    ]\n",
            " [0.1653 0.2547 0.     0.     0.     0.    ]\n",
            " [0.9346 0.0331 1.     0.     1.     0.    ]\n",
            " [0.2429 0.125  0.     0.     0.     0.    ]\n",
            " [0.7176 0.0674 1.     0.     1.     0.    ]\n",
            " [0.5339 0.0711 1.     0.     0.     0.    ]\n",
            " [0.5964 0.1952 1.     0.     0.     0.    ]\n",
            " [0.1342 0.1186 0.     0.     0.     0.    ]\n",
            " [0.1052 0.4288 0.     0.     0.     0.    ]\n",
            " [0.7058 0.5639 1.     1.     1.     1.    ]\n",
            " [0.2437 0.0859 0.     0.     0.     0.    ]\n",
            " [0.2492 0.0809 0.     0.     0.     0.    ]\n",
            " [0.241  0.4965 0.     0.     0.     0.    ]\n",
            " [0.6677 0.2241 1.     0.     1.     0.    ]\n",
            " [0.5221 0.0403 1.     0.     0.     0.    ]\n",
            " [0.2628 0.2585 0.     0.     0.     0.    ]\n",
            " [0.2417 0.5506 0.     1.     0.     1.    ]\n",
            " [0.1352 0.0893 0.     0.     0.     0.    ]\n",
            " [0.5331 0.4144 1.     0.     1.     0.    ]\n",
            " [0.5801 0.0898 1.     0.     0.     0.    ]\n",
            " [0.5201 0.6052 1.     1.     1.     1.    ]\n",
            " [0.177  0.5139 0.     1.     0.     0.    ]\n",
            " [0.6469 0.1146 1.     0.     1.     0.    ]\n",
            " [0.2725 0.2041 0.     0.     0.     0.    ]\n",
            " [0.7643 0.1812 1.     0.     1.     0.    ]\n",
            " [0.4001 0.2251 0.     0.     0.     0.    ]\n",
            " [0.6703 0.3964 1.     0.     1.     0.    ]\n",
            " [0.7006 0.7437 1.     1.     1.     1.    ]\n",
            " [0.0777 0.1049 0.     0.     0.     0.    ]\n",
            " [0.4113 0.8093 0.     1.     0.     1.    ]\n",
            " [0.4986 0.2239 0.     0.     1.     0.    ]\n",
            " [0.4601 0.1465 0.     0.     0.     0.    ]\n",
            " [0.6377 0.5944 1.     1.     1.     0.    ]\n",
            " [0.3756 0.2775 0.     0.     0.     0.    ]\n",
            " [0.0861 0.0683 0.     0.     0.     0.    ]\n",
            " [0.2081 0.0883 0.     0.     0.     0.    ]\n",
            " [0.5435 0.002  1.     0.     1.     0.    ]\n",
            " [0.4394 0.0157 0.     0.     0.     0.    ]\n",
            " [0.3744 0.2014 0.     0.     0.     0.    ]\n",
            " [0.7126 0.7046 1.     1.     1.     1.    ]\n",
            " [0.0389 0.684  0.     1.     0.     1.    ]\n",
            " [0.6025 0.802  1.     1.     0.     1.    ]\n",
            " [0.6152 0.3055 1.     0.     1.     0.    ]\n",
            " [0.4068 0.7755 0.     1.     0.     1.    ]\n",
            " [0.0647 0.1094 0.     0.     0.     0.    ]\n",
            " [0.66   0.2694 1.     0.     1.     0.    ]\n",
            " [0.7385 0.1278 1.     0.     1.     0.    ]\n",
            " [0.1478 0.6431 0.     1.     0.     1.    ]\n",
            " [0.1007 0.0939 0.     0.     0.     0.    ]\n",
            " [0.523  0.3008 1.     0.     1.     1.    ]\n",
            " [0.6459 0.3347 1.     0.     1.     0.    ]\n",
            " [0.5605 0.0724 1.     0.     1.     0.    ]\n",
            " [0.     0.9993 0.     1.     0.     1.    ]\n",
            " [0.579  0.422  1.     0.     1.     0.    ]\n",
            " [0.3782 0.179  0.     0.     0.     0.    ]\n",
            " [0.2191 0.4326 0.     0.     0.     0.    ]\n",
            " [0.5261 0.3111 1.     0.     1.     0.    ]\n",
            " [0.5012 0.2117 1.     0.     0.     0.    ]\n",
            " [0.5872 0.3596 1.     0.     0.     0.    ]\n",
            " [0.5218 0.5521 1.     1.     1.     0.    ]\n",
            " [0.0893 0.3541 0.     0.     0.     0.    ]\n",
            " [0.0183 0.     0.     0.     0.     0.    ]\n",
            " [0.6747 0.3259 1.     0.     1.     0.    ]\n",
            " [0.1711 0.2238 0.     0.     0.     0.    ]\n",
            " [0.5087 0.5599 1.     1.     1.     1.    ]\n",
            " [0.3141 0.8243 0.     1.     0.     1.    ]\n",
            " [0.1026 0.0672 0.     0.     0.     0.    ]\n",
            " [0.5101 0.2405 1.     0.     1.     0.    ]\n",
            " [0.8654 0.5426 1.     1.     1.     0.    ]\n",
            " [0.7301 0.2182 1.     0.     1.     0.    ]\n",
            " [0.0828 0.849  0.     1.     0.     1.    ]\n",
            " [0.244  0.1236 0.     0.     0.     0.    ]\n",
            " [0.393  0.1179 0.     0.     1.     0.    ]\n",
            " [0.203  0.4689 0.     0.     0.     0.    ]\n",
            " [0.4103 0.1787 0.     0.     0.     0.    ]\n",
            " [0.1402 0.3358 0.     0.     0.     0.    ]\n",
            " [0.4939 0.4866 0.     0.     1.     1.    ]\n",
            " [0.6693 0.1954 1.     0.     1.     0.    ]\n",
            " [0.4974 0.452  0.     0.     1.     0.    ]\n",
            " [0.1036 0.5159 0.     1.     0.     1.    ]\n",
            " [0.2104 0.2003 0.     0.     0.     0.    ]\n",
            " [0.7744 0.5038 1.     1.     1.     1.    ]\n",
            " [0.4414 0.2463 0.     0.     0.     0.    ]\n",
            " [0.6265 0.1619 1.     0.     1.     0.    ]\n",
            " [0.1059 0.0524 0.     0.     0.     0.    ]\n",
            " [0.1183 0.3766 0.     0.     0.     0.    ]\n",
            " [0.1388 0.5791 0.     1.     0.     1.    ]\n",
            " [0.6741 0.6387 1.     1.     1.     1.    ]\n",
            " [0.2162 0.0327 0.     0.     0.     0.    ]\n",
            " [0.4979 0.1843 0.     0.     1.     0.    ]\n",
            " [0.0509 0.5859 0.     1.     0.     1.    ]\n",
            " [0.6365 0.2079 1.     0.     1.     0.    ]\n",
            " [0.4917 0.0833 0.     0.     1.     0.    ]\n",
            " [0.244  0.1309 0.     0.     1.     0.    ]\n",
            " [0.5781 0.081  1.     0.     1.     0.    ]\n",
            " [0.1015 0.0977 0.     0.     0.     0.    ]\n",
            " [0.4706 0.5248 0.     1.     1.     1.    ]\n",
            " [0.2441 0.0167 0.     0.     0.     0.    ]\n",
            " [0.188  0.0081 0.     0.     0.     0.    ]\n",
            " [0.71   0.386  1.     0.     1.     1.    ]\n",
            " [0.6842 0.6318 1.     1.     1.     1.    ]\n",
            " [0.0479 0.2557 0.     0.     0.     0.    ]\n",
            " [0.6522 0.4988 1.     0.     0.     0.    ]\n",
            " [0.4194 0.0696 0.     0.     0.     0.    ]\n",
            " [0.5499 0.4862 1.     0.     1.     0.    ]\n",
            " [0.0291 0.1699 0.     0.     0.     0.    ]\n",
            " [0.7885 0.1328 1.     0.     1.     0.    ]\n",
            " [0.6176 0.4073 1.     0.     1.     1.    ]\n",
            " [0.4733 0.3462 0.     0.     0.     0.    ]\n",
            " [0.4727 0.2752 0.     0.     1.     0.    ]\n",
            " [0.8454 0.0885 1.     0.     1.     0.    ]\n",
            " [0.1298 0.4839 0.     0.     0.     0.    ]\n",
            " [0.4018 0.2314 0.     0.     1.     0.    ]\n",
            " [0.2979 0.1417 0.     0.     0.     0.    ]\n",
            " [0.2782 0.1438 0.     0.     0.     0.    ]\n",
            " [0.7349 0.2929 1.     0.     1.     0.    ]\n",
            " [0.5616 0.1958 1.     0.     0.     0.    ]\n",
            " [0.4704 0.1929 0.     0.     0.     0.    ]\n",
            " [0.6367 0.4475 1.     0.     1.     0.    ]\n",
            " [0.6296 0.2931 1.     0.     1.     0.    ]\n",
            " [0.085  0.2229 0.     0.     0.     0.    ]\n",
            " [0.5456 0.243  1.     0.     0.     0.    ]\n",
            " [0.1574 0.0767 0.     0.     0.     0.    ]\n",
            " [0.1979 0.1131 0.     0.     0.     0.    ]\n",
            " [0.0512 0.2146 0.     0.     0.     0.    ]\n",
            " [0.4745 0.1387 0.     0.     1.     0.    ]\n",
            " [0.5215 0.1938 1.     0.     1.     0.    ]\n",
            " [0.6893 0.7015 1.     1.     1.     1.    ]\n",
            " [0.0387 0.1098 0.     0.     0.     0.    ]\n",
            " [0.3162 0.4092 0.     0.     0.     1.    ]\n",
            " [0.7451 0.496  1.     0.     1.     0.    ]\n",
            " [0.1268 0.0433 0.     0.     0.     0.    ]\n",
            " [0.72   0.5363 1.     1.     1.     0.    ]\n",
            " [0.6994 0.5004 1.     1.     1.     0.    ]\n",
            " [0.5144 0.3274 1.     0.     1.     0.    ]\n",
            " [0.5262 0.59   1.     1.     1.     1.    ]\n",
            " [0.4806 0.0797 0.     0.     0.     0.    ]\n",
            " [0.6543 0.1866 1.     0.     1.     0.    ]\n",
            " [0.2764 0.1387 0.     0.     1.     0.    ]\n",
            " [0.6517 0.5403 1.     1.     1.     1.    ]\n",
            " [0.1506 0.0902 0.     0.     0.     0.    ]\n",
            " [0.553  0.3875 1.     0.     0.     0.    ]\n",
            " [0.7596 0.2595 1.     0.     1.     0.    ]\n",
            " [0.2518 0.2525 0.     0.     0.     0.    ]\n",
            " [0.5687 0.8557 1.     1.     1.     1.    ]\n",
            " [0.6153 0.3402 1.     0.     1.     0.    ]\n",
            " [0.1204 0.1245 0.     0.     0.     0.    ]\n",
            " [0.8265 0.0575 1.     0.     1.     0.    ]\n",
            " [0.249  0.2834 0.     0.     0.     0.    ]\n",
            " [0.1683 0.1791 0.     0.     0.     0.    ]\n",
            " [0.4164 0.8591 0.     1.     0.     1.    ]\n",
            " [0.1484 0.2438 0.     0.     0.     0.    ]\n",
            " [0.1563 0.0636 0.     0.     0.     0.    ]\n",
            " [0.5661 0.4724 1.     0.     0.     0.    ]\n",
            " [0.33   0.0825 0.     0.     0.     0.    ]\n",
            " [0.1334 0.0718 0.     0.     0.     0.    ]\n",
            " [0.6457 0.4133 1.     0.     1.     1.    ]\n",
            " [0.0714 0.0405 0.     0.     0.     0.    ]\n",
            " [0.1911 0.32   0.     0.     0.     0.    ]\n",
            " [0.6335 0.9559 1.     1.     1.     1.    ]\n",
            " [0.0847 0.0308 0.     0.     0.     0.    ]\n",
            " [0.3259 0.2708 0.     0.     0.     0.    ]\n",
            " [0.3317 0.31   0.     0.     0.     0.    ]\n",
            " [0.2932 0.0298 0.     0.     0.     0.    ]\n",
            " [0.6399 0.1062 1.     0.     1.     0.    ]\n",
            " [0.3581 0.84   0.     1.     0.     1.    ]\n",
            " [0.6375 0.2698 1.     0.     1.     0.    ]\n",
            " [0.4879 0.2316 0.     0.     1.     0.    ]\n",
            " [0.2902 0.0628 0.     0.     0.     0.    ]\n",
            " [0.6977 0.2893 1.     0.     1.     0.    ]\n",
            " [0.0261 0.0983 0.     0.     0.     0.    ]\n",
            " [0.0993 0.6981 0.     1.     0.     1.    ]\n",
            " [0.1854 0.2223 0.     0.     0.     0.    ]\n",
            " [0.5808 0.3482 1.     0.     1.     0.    ]\n",
            " [0.2533 0.0245 0.     0.     0.     0.    ]\n",
            " [0.546  0.25   1.     0.     1.     0.    ]\n",
            " [0.3308 0.1357 0.     0.     0.     0.    ]\n",
            " [0.5074 0.2011 1.     0.     1.     0.    ]\n",
            " [0.4361 0.7035 0.     1.     0.     1.    ]\n",
            " [0.8474 0.5607 1.     1.     1.     0.    ]\n",
            " [0.1503 0.7173 0.     1.     0.     1.    ]\n",
            " [0.6616 0.5    1.     0.     1.     1.    ]\n",
            " [0.5652 0.5253 1.     1.     1.     1.    ]\n",
            " [0.1998 0.2208 0.     0.     0.     0.    ]\n",
            " [0.2697 0.0813 0.     0.     0.     0.    ]\n",
            " [0.7207 0.3472 1.     0.     1.     0.    ]\n",
            " [0.0166 0.0292 0.     0.     0.     0.    ]\n",
            " [0.1409 0.2243 0.     0.     0.     0.    ]\n",
            " [0.8221 0.1075 1.     0.     1.     0.    ]\n",
            " [0.1224 0.5826 0.     1.     0.     1.    ]\n",
            " [0.4961 0.3237 0.     0.     1.     0.    ]\n",
            " [0.6491 0.2152 1.     0.     1.     0.    ]\n",
            " [0.7786 0.0077 1.     0.     1.     0.    ]\n",
            " [0.2297 0.1066 0.     0.     0.     0.    ]\n",
            " [0.5634 0.0469 1.     0.     1.     0.    ]\n",
            " [0.5164 0.435  1.     0.     0.     1.    ]\n",
            " [0.3533 0.1818 0.     0.     0.     0.    ]\n",
            " [0.0339 0.0008 0.     0.     0.     0.    ]\n",
            " [0.4608 0.1683 0.     0.     0.     0.    ]\n",
            " [0.6738 0.2371 1.     0.     1.     0.    ]\n",
            " [0.4466 0.1205 0.     0.     0.     0.    ]\n",
            " [0.5725 0.3844 1.     0.     1.     0.    ]\n",
            " [0.2301 0.1142 0.     0.     0.     0.    ]\n",
            " [0.1343 0.062  0.     0.     0.     0.    ]\n",
            " [0.4033 0.8107 0.     1.     0.     1.    ]\n",
            " [0.5924 0.0219 1.     0.     1.     0.    ]\n",
            " [0.329  0.0957 0.     0.     0.     0.    ]\n",
            " [0.3943 0.6661 0.     1.     0.     1.    ]\n",
            " [0.5101 0.2191 1.     0.     1.     0.    ]\n",
            " [0.5194 0.1648 1.     0.     0.     0.    ]\n",
            " [0.1025 0.0522 0.     0.     0.     0.    ]\n",
            " [0.3159 0.3433 0.     0.     0.     0.    ]\n",
            " [0.1625 0.2857 0.     0.     0.     0.    ]\n",
            " [0.1229 0.0878 0.     0.     0.     0.    ]\n",
            " [0.542  0.1763 1.     0.     1.     0.    ]\n",
            " [0.3965 0.1596 0.     0.     1.     0.    ]\n",
            " [0.3323 0.7211 0.     1.     0.     1.    ]\n",
            " [0.5387 0.0245 1.     0.     1.     0.    ]\n",
            " [0.0855 0.0471 0.     0.     0.     0.    ]\n",
            " [0.5621 0.3727 1.     0.     1.     0.    ]\n",
            " [0.632  0.4677 1.     0.     1.     1.    ]\n",
            " [0.462  0.2621 0.     0.     0.     0.    ]\n",
            " [0.7243 0.7925 1.     1.     1.     1.    ]\n",
            " [0.3644 0.5032 0.     1.     1.     1.    ]\n",
            " [0.3839 0.0981 0.     0.     0.     0.    ]\n",
            " [0.7791 0.6999 1.     1.     1.     1.    ]\n",
            " [0.3565 0.4577 0.     0.     1.     0.    ]\n",
            " [0.4908 0.3861 0.     0.     1.     0.    ]\n",
            " [0.6881 0.5827 1.     1.     1.     1.    ]\n",
            " [0.1116 0.0354 0.     0.     0.     0.    ]\n",
            " [0.5474 0.1194 1.     0.     1.     0.    ]\n",
            " [0.1609 0.5705 0.     1.     0.     1.    ]\n",
            " [0.6841 0.2461 1.     0.     1.     0.    ]\n",
            " [0.5833 0.4142 1.     0.     1.     0.    ]\n",
            " [0.0371 0.4498 0.     0.     0.     1.    ]\n",
            " [0.5755 0.0967 1.     0.     0.     0.    ]\n",
            " [0.3341 0.0635 0.     0.     0.     0.    ]\n",
            " [0.4479 0.468  0.     0.     1.     0.    ]\n",
            " [0.17   0.2078 0.     0.     0.     0.    ]\n",
            " [0.1155 0.8039 0.     1.     0.     1.    ]\n",
            " [0.4832 0.4088 0.     0.     1.     0.    ]\n",
            " [0.1694 0.0237 0.     0.     0.     0.    ]\n",
            " [0.154  0.194  0.     0.     0.     0.    ]\n",
            " [0.4866 0.5591 0.     1.     1.     1.    ]\n",
            " [0.5558 0.0833 1.     0.     0.     0.    ]\n",
            " [0.7007 0.6459 1.     1.     1.     1.    ]\n",
            " [0.4846 0.0248 0.     0.     0.     0.    ]\n",
            " [0.5984 0.1448 1.     0.     1.     0.    ]\n",
            " [0.0255 0.0308 0.     0.     0.     0.    ]\n",
            " [0.3805 0.3439 0.     0.     0.     0.    ]\n",
            " [0.4027 0.1774 0.     0.     0.     0.    ]\n",
            " [0.4922 0.2275 0.     0.     1.     0.    ]\n",
            " [0.046  0.1796 0.     0.     0.     0.    ]\n",
            " [0.2069 0.5191 0.     1.     0.     0.    ]\n",
            " [0.1381 0.1326 0.     0.     0.     0.    ]\n",
            " [0.2332 0.0162 0.     0.     0.     0.    ]\n",
            " [0.0173 0.9922 0.     1.     0.     1.    ]\n",
            " [0.6832 0.1514 1.     0.     1.     0.    ]\n",
            " [0.392  0.4915 0.     0.     0.     1.    ]\n",
            " [0.2282 0.1205 0.     0.     1.     0.    ]\n",
            " [0.1129 0.1412 0.     0.     0.     0.    ]\n",
            " [0.4828 0.0814 0.     0.     1.     0.    ]\n",
            " [0.5704 0.2073 1.     0.     0.     0.    ]\n",
            " [0.0174 0.0194 0.     0.     0.     0.    ]\n",
            " [0.481  0.1367 0.     0.     0.     0.    ]\n",
            " [0.743  0.1237 1.     0.     1.     0.    ]\n",
            " [0.4719 0.6744 0.     1.     1.     1.    ]\n",
            " [0.5244 0.2692 1.     0.     0.     0.    ]\n",
            " [0.3188 0.1165 0.     0.     0.     0.    ]\n",
            " [0.4691 0.521  0.     1.     0.     0.    ]\n",
            " [0.324  0.6122 0.     1.     0.     1.    ]\n",
            " [0.236  0.3626 0.     0.     0.     0.    ]\n",
            " [0.6664 0.1718 1.     0.     1.     0.    ]\n",
            " [0.6275 0.1503 1.     0.     1.     0.    ]\n",
            " [0.5394 0.2954 1.     0.     1.     0.    ]\n",
            " [0.0948 0.1296 0.     0.     0.     0.    ]\n",
            " [0.9669 0.0298 1.     0.     1.     0.    ]\n",
            " [0.4616 0.3904 0.     0.     1.     1.    ]\n",
            " [0.5765 0.3828 1.     0.     1.     0.    ]\n",
            " [0.3488 0.5714 0.     1.     0.     1.    ]\n",
            " [0.3425 0.2944 0.     0.     0.     0.    ]\n",
            " [0.5139 0.2798 1.     0.     0.     0.    ]\n",
            " [0.3681 0.4149 0.     0.     1.     0.    ]\n",
            " [0.4711 0.0256 0.     0.     1.     0.    ]\n",
            " [0.5186 0.2896 1.     0.     0.     0.    ]\n",
            " [0.3086 0.3466 0.     0.     0.     0.    ]\n",
            " [0.2946 0.1576 0.     0.     0.     0.    ]\n",
            " [0.1022 0.9162 0.     1.     0.     1.    ]\n",
            " [0.293  0.1507 0.     0.     1.     0.    ]\n",
            " [0.3804 0.2681 0.     0.     0.     0.    ]\n",
            " [0.4901 0.4642 0.     0.     0.     1.    ]\n",
            " [0.0394 0.0025 0.     0.     0.     0.    ]\n",
            " [0.5374 0.3277 1.     0.     1.     0.    ]\n",
            " [0.2221 0.3866 0.     0.     0.     0.    ]\n",
            " [0.6664 0.1713 1.     0.     1.     0.    ]\n",
            " [0.2768 0.1223 0.     0.     0.     0.    ]\n",
            " [0.1308 0.2583 0.     0.     0.     0.    ]\n",
            " [0.3029 0.6388 0.     1.     0.     1.    ]\n",
            " [0.4917 0.4336 0.     0.     1.     1.    ]\n",
            " [0.2155 0.1535 0.     0.     0.     0.    ]\n",
            " [0.6322 0.3454 1.     0.     1.     0.    ]\n",
            " [0.6113 0.2679 1.     0.     1.     0.    ]\n",
            " [0.392  0.7053 0.     1.     1.     1.    ]\n",
            " [0.0982 0.0665 0.     0.     0.     0.    ]\n",
            " [0.4731 0.2469 0.     0.     1.     0.    ]\n",
            " [0.4974 0.0131 0.     0.     1.     0.    ]\n",
            " [0.6978 0.2083 1.     0.     1.     0.    ]\n",
            " [0.579  0.2225 1.     0.     1.     0.    ]\n",
            " [0.3389 0.0219 0.     0.     0.     0.    ]\n",
            " [0.1791 0.0796 0.     0.     0.     0.    ]\n",
            " [0.3787 0.0875 0.     0.     0.     0.    ]\n",
            " [0.5406 0.1245 1.     0.     1.     0.    ]\n",
            " [0.5328 0.2936 1.     0.     1.     0.    ]\n",
            " [0.07   0.0809 0.     0.     0.     0.    ]\n",
            " [0.4133 0.1117 0.     0.     0.     0.    ]\n",
            " [0.465  0.2947 0.     0.     0.     0.    ]\n",
            " [0.2859 0.12   0.     0.     0.     0.    ]\n",
            " [0.0282 0.0114 0.     0.     0.     0.    ]\n",
            " [0.6563 0.0405 1.     0.     1.     0.    ]\n",
            " [0.6436 0.3499 1.     0.     1.     0.    ]\n",
            " [0.5044 0.2474 1.     0.     1.     0.    ]\n",
            " [0.4772 0.0623 0.     0.     1.     0.    ]\n",
            " [0.7975 0.0388 1.     0.     1.     0.    ]\n",
            " [0.1411 0.0871 0.     0.     0.     0.    ]\n",
            " [0.4035 0.2721 0.     0.     0.     0.    ]\n",
            " [0.0463 0.1277 0.     0.     0.     0.    ]\n",
            " [0.931  0.1145 1.     0.     1.     0.    ]\n",
            " [0.3291 0.1371 0.     0.     0.     0.    ]\n",
            " [0.5999 0.2594 1.     0.     1.     0.    ]\n",
            " [0.3345 0.5    0.     1.     0.     0.    ]\n",
            " [0.0722 0.1051 0.     0.     0.     0.    ]\n",
            " [0.4743 0.1055 0.     0.     1.     0.    ]\n",
            " [0.7725 0.3003 1.     0.     1.     0.    ]\n",
            " [0.5743 0.2333 1.     0.     1.     0.    ]\n",
            " [0.5727 0.5118 1.     1.     0.     0.    ]\n",
            " [0.2035 0.0875 0.     0.     0.     0.    ]\n",
            " [0.9336 0.0747 1.     0.     1.     0.    ]\n",
            " [0.4845 0.5859 0.     1.     1.     1.    ]\n",
            " [0.2752 0.1578 0.     0.     1.     0.    ]\n",
            " [0.4574 0.224  0.     0.     0.     0.    ]\n",
            " [0.122  0.4225 0.     0.     0.     0.    ]\n",
            " [0.3559 0.3623 0.     0.     0.     1.    ]\n",
            " [0.9986 1.     1.     1.     1.     1.    ]\n",
            " [0.6598 0.0845 1.     0.     1.     0.    ]\n",
            " [0.5085 0.2563 1.     0.     1.     0.    ]\n",
            " [0.2978 0.4213 0.     0.     0.     0.    ]\n",
            " [0.3334 0.3387 0.     0.     0.     0.    ]\n",
            " [0.0259 0.1634 0.     0.     0.     0.    ]\n",
            " [0.7202 0.3542 1.     0.     0.     0.    ]\n",
            " [0.2487 0.255  0.     0.     0.     0.    ]\n",
            " [0.284  0.2946 0.     0.     0.     0.    ]\n",
            " [0.3882 0.426  0.     0.     0.     0.    ]\n",
            " [0.5069 0.6199 1.     1.     0.     1.    ]\n",
            " [0.3932 0.1575 0.     0.     0.     0.    ]\n",
            " [0.3718 0.1607 0.     0.     0.     0.    ]\n",
            " [0.0408 0.0781 0.     0.     0.     0.    ]\n",
            " [0.1211 0.4829 0.     0.     0.     1.    ]\n",
            " [0.1232 0.2389 0.     0.     0.     0.    ]\n",
            " [0.5641 0.5774 1.     1.     0.     1.    ]\n",
            " [0.6417 0.5027 1.     1.     1.     0.    ]\n",
            " [0.5558 0.2079 1.     0.     1.     0.    ]\n",
            " [0.1942 0.1724 0.     0.     0.     0.    ]\n",
            " [0.4775 0.0748 0.     0.     1.     0.    ]\n",
            " [0.0613 0.0548 0.     0.     0.     0.    ]\n",
            " [0.0602 0.1073 0.     0.     0.     0.    ]\n",
            " [0.5208 0.2909 1.     0.     1.     0.    ]\n",
            " [0.4196 0.2059 0.     0.     0.     1.    ]\n",
            " [0.391  0.5318 0.     1.     1.     1.    ]\n",
            " [0.0872 0.0647 0.     0.     0.     0.    ]\n",
            " [0.2496 0.1673 0.     0.     1.     0.    ]\n",
            " [0.5496 0.4665 1.     0.     1.     0.    ]\n",
            " [0.3507 0.3742 0.     0.     0.     0.    ]\n",
            " [0.3418 0.2101 0.     0.     1.     0.    ]\n",
            " [0.1932 0.0589 0.     0.     0.     0.    ]\n",
            " [0.653  0.0195 1.     0.     1.     0.    ]\n",
            " [0.3578 0.0432 0.     0.     0.     0.    ]\n",
            " [0.5987 0.2186 1.     0.     1.     0.    ]\n",
            " [0.5324 0.2447 1.     0.     1.     0.    ]\n",
            " [0.4847 0.1358 0.     0.     0.     0.    ]\n",
            " [0.0668 0.0589 0.     0.     0.     0.    ]\n",
            " [0.5873 0.3176 1.     0.     1.     0.    ]\n",
            " [0.3859 0.1435 0.     0.     0.     0.    ]\n",
            " [0.5964 0.1646 1.     0.     0.     0.    ]\n",
            " [0.5177 0.6557 1.     1.     1.     1.    ]\n",
            " [0.491  0.1791 0.     0.     1.     0.    ]\n",
            " [0.1332 0.0207 0.     0.     0.     0.    ]\n",
            " [0.567  0.3062 1.     0.     1.     0.    ]\n",
            " [0.8416 0.0718 1.     0.     1.     0.    ]\n",
            " [0.4633 0.2336 0.     0.     1.     0.    ]\n",
            " [0.3943 0.1737 0.     0.     0.     0.    ]\n",
            " [0.1367 0.2451 0.     0.     0.     0.    ]\n",
            " [0.6528 0.5435 1.     1.     1.     1.    ]\n",
            " [0.147  0.6617 0.     1.     0.     1.    ]\n",
            " [0.0521 0.0425 0.     0.     0.     0.    ]\n",
            " [0.91   0.0059 1.     0.     1.     0.    ]\n",
            " [0.386  0.4063 0.     0.     1.     1.    ]\n",
            " [0.347  0.0274 0.     0.     1.     0.    ]\n",
            " [0.5321 0.4395 1.     0.     1.     1.    ]\n",
            " [0.6761 0.594  1.     1.     1.     1.    ]\n",
            " [0.1983 0.5416 0.     1.     0.     1.    ]\n",
            " [0.5563 0.1168 1.     0.     1.     0.    ]\n",
            " [0.3159 0.2685 0.     0.     0.     0.    ]\n",
            " [0.7691 0.1886 1.     0.     1.     0.    ]\n",
            " [0.3529 0.6696 0.     1.     0.     1.    ]\n",
            " [0.4514 0.2313 0.     0.     0.     0.    ]\n",
            " [0.2418 0.1537 0.     0.     0.     0.    ]\n",
            " [0.7617 0.259  1.     0.     1.     0.    ]\n",
            " [0.2323 0.0926 0.     0.     0.     0.    ]\n",
            " [0.5831 0.1571 1.     0.     1.     0.    ]\n",
            " [0.1322 0.22   0.     0.     0.     0.    ]\n",
            " [0.2379 0.1224 0.     0.     0.     0.    ]\n",
            " [0.3882 0.5188 0.     1.     0.     1.    ]\n",
            " [0.1524 0.1348 0.     0.     0.     0.    ]\n",
            " [0.2863 0.1679 0.     0.     0.     0.    ]\n",
            " [0.8056 0.1379 1.     0.     1.     0.    ]\n",
            " [0.1677 0.2667 0.     0.     0.     0.    ]\n",
            " [0.6294 0.0963 1.     0.     1.     0.    ]\n",
            " [0.6235 0.532  1.     1.     0.     1.    ]\n",
            " [0.3728 0.1962 0.     0.     1.     0.    ]\n",
            " [0.4006 0.4482 0.     0.     0.     0.    ]\n",
            " [0.5633 0.2761 1.     0.     1.     0.    ]\n",
            " [0.1157 0.411  0.     0.     0.     0.    ]\n",
            " [0.6785 0.2925 1.     0.     1.     0.    ]\n",
            " [0.1212 0.079  0.     0.     0.     0.    ]\n",
            " [0.7654 0.2134 1.     0.     1.     0.    ]\n",
            " [0.1933 0.4785 0.     0.     0.     1.    ]\n",
            " [0.4726 0.3705 0.     0.     0.     0.    ]\n",
            " [0.0706 0.1863 0.     0.     0.     0.    ]\n",
            " [0.5722 0.7033 1.     1.     1.     1.    ]\n",
            " [0.7433 0.6326 1.     1.     1.     1.    ]\n",
            " [0.3816 0.4584 0.     0.     1.     0.    ]\n",
            " [0.2356 0.1859 0.     0.     0.     0.    ]\n",
            " [0.5958 0.157  1.     0.     0.     0.    ]\n",
            " [0.3037 0.1199 0.     0.     0.     0.    ]\n",
            " [0.7207 0.2738 1.     0.     1.     0.    ]\n",
            " [0.0862 0.2281 0.     0.     0.     0.    ]\n",
            " [0.5911 0.5431 1.     1.     0.     1.    ]\n",
            " [0.7531 0.003  1.     0.     1.     0.    ]\n",
            " [0.7513 0.3604 1.     0.     1.     1.    ]\n",
            " [0.5534 0.2653 1.     0.     0.     0.    ]\n",
            " [0.2204 0.504  0.     1.     0.     1.    ]\n",
            " [0.091  0.077  0.     0.     0.     0.    ]\n",
            " [0.7033 0.286  1.     0.     1.     0.    ]\n",
            " [0.5435 0.3285 1.     0.     0.     1.    ]\n",
            " [0.7761 0.3343 1.     0.     1.     0.    ]\n",
            " [0.1704 0.2886 0.     0.     0.     0.    ]\n",
            " [0.5712 0.5015 1.     1.     1.     0.    ]\n",
            " [0.8084 0.1517 1.     0.     1.     0.    ]\n",
            " [0.1004 0.0169 0.     0.     0.     0.    ]\n",
            " [0.5462 0.5652 1.     1.     1.     1.    ]\n",
            " [0.3758 0.0704 0.     0.     0.     0.    ]\n",
            " [0.7025 0.4292 1.     0.     1.     0.    ]\n",
            " [0.     0.9985 0.     1.     0.     1.    ]\n",
            " [0.608  0.0236 1.     0.     1.     0.    ]\n",
            " [0.4558 0.3948 0.     0.     0.     0.    ]\n",
            " [0.4199 0.3994 0.     0.     0.     0.    ]\n",
            " [0.8323 0.0273 1.     0.     1.     0.    ]\n",
            " [0.5437 0.2655 1.     0.     0.     0.    ]\n",
            " [0.2914 0.1247 0.     0.     0.     0.    ]\n",
            " [0.58   0.2841 1.     0.     1.     0.    ]\n",
            " [0.3958 0.5287 0.     1.     0.     1.    ]\n",
            " [0.3832 0.2001 0.     0.     0.     0.    ]\n",
            " [0.6302 0.4019 1.     0.     1.     0.    ]\n",
            " [0.5253 0.2511 1.     0.     0.     0.    ]\n",
            " [0.4597 0.0751 0.     0.     0.     0.    ]\n",
            " [0.028  0.1706 0.     0.     0.     0.    ]\n",
            " [0.6181 0.3541 1.     0.     1.     1.    ]\n",
            " [0.4399 0.6314 0.     1.     1.     1.    ]\n",
            " [0.4783 0.2562 0.     0.     0.     0.    ]\n",
            " [0.2566 0.7608 0.     1.     0.     1.    ]\n",
            " [0.6002 0.1954 1.     0.     1.     0.    ]\n",
            " [0.1136 0.4146 0.     0.     0.     1.    ]\n",
            " [0.1759 0.1103 0.     0.     0.     0.    ]\n",
            " [0.5875 0.1153 1.     0.     1.     0.    ]\n",
            " [0.3838 0.1861 0.     0.     0.     0.    ]\n",
            " [0.5251 0.308  1.     0.     0.     0.    ]\n",
            " [0.1465 0.1479 0.     0.     0.     0.    ]\n",
            " [0.0293 0.4254 0.     0.     0.     0.    ]\n",
            " [0.1028 0.5254 0.     1.     0.     0.    ]\n",
            " [0.2937 0.1602 0.     0.     1.     0.    ]\n",
            " [0.5642 0.4592 1.     0.     1.     1.    ]\n",
            " [0.6319 0.6759 1.     1.     1.     1.    ]\n",
            " [0.4831 0.061  0.     0.     1.     0.    ]\n",
            " [0.4728 0.1285 0.     0.     0.     0.    ]\n",
            " [0.4882 0.4608 0.     0.     0.     0.    ]\n",
            " [0.3383 0.3558 0.     0.     0.     0.    ]\n",
            " [0.6436 0.4128 1.     0.     1.     0.    ]\n",
            " [0.0279 0.1405 0.     0.     0.     0.    ]\n",
            " [0.265  0.1785 0.     0.     0.     0.    ]\n",
            " [0.0779 0.2668 0.     0.     0.     0.    ]\n",
            " [0.1164 0.0639 0.     0.     0.     0.    ]\n",
            " [0.417  0.24   0.     0.     0.     0.    ]\n",
            " [0.5512 0.2983 1.     0.     1.     0.    ]\n",
            " [0.1337 0.0735 0.     0.     0.     0.    ]\n",
            " [0.4803 0.1318 0.     0.     1.     0.    ]\n",
            " [0.126  0.1621 0.     0.     0.     0.    ]\n",
            " [0.7291 0.3836 1.     0.     1.     0.    ]\n",
            " [0.494  0.3365 0.     0.     0.     0.    ]\n",
            " [0.539  0.5379 1.     1.     0.     1.    ]\n",
            " [0.0544 0.0013 0.     0.     0.     0.    ]\n",
            " [0.5082 0.1707 1.     0.     0.     0.    ]\n",
            " [0.6831 0.3366 1.     0.     1.     0.    ]\n",
            " [0.1561 0.1099 0.     0.     0.     0.    ]\n",
            " [0.2671 0.1445 0.     0.     0.     0.    ]\n",
            " [0.1464 0.3159 0.     0.     0.     0.    ]\n",
            " [0.6763 0.227  1.     0.     1.     0.    ]\n",
            " [0.0789 0.1533 0.     0.     0.     0.    ]\n",
            " [0.3284 0.1643 0.     0.     0.     0.    ]\n",
            " [0.0565 0.1616 0.     0.     0.     0.    ]\n",
            " [0.5278 0.5042 1.     1.     0.     0.    ]\n",
            " [0.12   0.1944 0.     0.     0.     0.    ]\n",
            " [0.6189 0.7367 1.     1.     0.     1.    ]\n",
            " [0.1472 0.1394 0.     0.     0.     0.    ]\n",
            " [0.7825 0.7138 1.     1.     1.     1.    ]\n",
            " [0.3478 0.0845 0.     0.     0.     0.    ]\n",
            " [0.4484 0.1331 0.     0.     0.     0.    ]\n",
            " [0.3212 0.1954 0.     0.     0.     0.    ]\n",
            " [0.3405 0.1277 0.     0.     1.     0.    ]\n",
            " [0.2354 0.2105 0.     0.     0.     0.    ]\n",
            " [0.5337 0.572  1.     1.     0.     1.    ]\n",
            " [0.074  0.0045 0.     0.     0.     0.    ]\n",
            " [0.4316 0.249  0.     0.     0.     1.    ]\n",
            " [0.5235 0.2496 1.     0.     1.     0.    ]\n",
            " [0.8479 0.0238 1.     0.     1.     0.    ]\n",
            " [0.5248 0.341  1.     0.     0.     0.    ]\n",
            " [0.5358 0.4286 1.     0.     1.     0.    ]\n",
            " [0.025  0.1993 0.     0.     0.     0.    ]\n",
            " [0.2607 0.1764 0.     0.     0.     0.    ]\n",
            " [0.0426 0.1301 0.     0.     0.     0.    ]\n",
            " [0.2531 0.6303 0.     1.     0.     1.    ]\n",
            " [0.654  0.2899 1.     0.     1.     0.    ]\n",
            " [0.5167 0.4246 1.     0.     0.     0.    ]\n",
            " [0.4922 0.5255 0.     1.     0.     0.    ]\n",
            " [0.3005 0.2967 0.     0.     0.     0.    ]\n",
            " [0.0195 0.5416 0.     1.     0.     1.    ]\n",
            " [0.3172 0.7712 0.     1.     0.     1.    ]\n",
            " [0.6792 0.6513 1.     1.     1.     1.    ]\n",
            " [0.6092 0.4293 1.     0.     1.     1.    ]\n",
            " [0.4775 0.251  0.     0.     0.     0.    ]\n",
            " [0.5809 0.3451 1.     0.     0.     0.    ]\n",
            " [0.2472 0.3115 0.     0.     0.     0.    ]\n",
            " [0.1209 0.3383 0.     0.     0.     0.    ]\n",
            " [0.5612 0.5709 1.     1.     0.     1.    ]\n",
            " [0.3986 0.2514 0.     0.     1.     0.    ]\n",
            " [0.0132 0.0104 0.     0.     0.     0.    ]\n",
            " [0.5193 0.0635 1.     0.     1.     0.    ]\n",
            " [0.0404 0.3092 0.     0.     0.     0.    ]\n",
            " [0.294  0.2116 0.     0.     0.     0.    ]\n",
            " [0.6339 0.427  1.     0.     1.     0.    ]\n",
            " [0.2921 0.2969 0.     0.     0.     0.    ]\n",
            " [0.0426 0.2669 0.     0.     0.     1.    ]\n",
            " [0.2225 0.3847 0.     0.     0.     0.    ]\n",
            " [0.1289 0.353  0.     0.     0.     0.    ]\n",
            " [0.4494 0.7555 0.     1.     0.     1.    ]\n",
            " [0.5347 0.0681 1.     0.     0.     0.    ]\n",
            " [0.4775 0.1704 0.     0.     1.     0.    ]\n",
            " [0.3332 0.1335 0.     0.     0.     0.    ]\n",
            " [0.6777 0.0875 1.     0.     1.     0.    ]\n",
            " [0.0753 0.133  0.     0.     0.     0.    ]\n",
            " [0.5576 0.4064 1.     0.     1.     1.    ]\n",
            " [0.7895 0.1304 1.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.    ]\n",
            " [0.6024 0.2306 1.     0.     0.     0.    ]\n",
            " [0.4731 0.2862 0.     0.     0.     0.    ]\n",
            " [0.2223 0.0121 0.     0.     0.     0.    ]\n",
            " [0.0767 0.0082 0.     0.     0.     0.    ]\n",
            " [0.3003 0.2795 0.     0.     0.     0.    ]\n",
            " [0.0951 0.134  0.     0.     0.     0.    ]\n",
            " [0.0675 0.1176 0.     0.     0.     0.    ]\n",
            " [0.1844 0.0643 0.     0.     0.     0.    ]\n",
            " [0.6152 0.3656 1.     0.     1.     1.    ]\n",
            " [0.5572 0.2668 1.     0.     0.     0.    ]\n",
            " [0.386  0.452  0.     0.     1.     1.    ]\n",
            " [0.2022 0.1864 0.     0.     0.     0.    ]\n",
            " [0.2315 0.3064 0.     0.     0.     0.    ]\n",
            " [0.2864 0.5149 0.     1.     0.     0.    ]\n",
            " [0.2319 0.7055 0.     1.     0.     1.    ]\n",
            " [0.1349 0.4777 0.     0.     0.     1.    ]\n",
            " [0.1669 0.0991 0.     0.     0.     0.    ]\n",
            " [0.3969 0.2528 0.     0.     0.     0.    ]\n",
            " [0.5212 0.4354 1.     0.     0.     0.    ]\n",
            " [0.4169 0.1941 0.     0.     1.     0.    ]\n",
            " [0.0836 0.4085 0.     0.     0.     0.    ]\n",
            " [0.6638 0.3156 1.     0.     1.     0.    ]\n",
            " [0.415  0.0804 0.     0.     0.     0.    ]\n",
            " [0.6431 0.2978 1.     0.     1.     0.    ]\n",
            " [0.5644 0.0722 1.     0.     0.     0.    ]\n",
            " [0.691  0.1567 1.     0.     1.     0.    ]\n",
            " [0.7762 0.6353 1.     1.     1.     1.    ]\n",
            " [0.7276 0.558  1.     1.     1.     1.    ]\n",
            " [0.5216 0.4513 1.     0.     0.     0.    ]\n",
            " [0.4247 0.5741 0.     1.     0.     1.    ]\n",
            " [0.2983 0.012  0.     0.     0.     0.    ]\n",
            " [0.1174 0.6181 0.     1.     0.     0.    ]\n",
            " [0.2802 0.212  0.     0.     0.     0.    ]\n",
            " [0.5401 0.2726 1.     0.     1.     0.    ]\n",
            " [0.5166 0.128  1.     0.     0.     0.    ]\n",
            " [0.4839 0.1403 0.     0.     1.     0.    ]\n",
            " [0.7863 0.2792 1.     0.     1.     0.    ]\n",
            " [0.57   0.2923 1.     0.     0.     0.    ]\n",
            " [0.5539 0.3359 1.     0.     1.     0.    ]\n",
            " [0.2606 0.4707 0.     0.     0.     0.    ]\n",
            " [0.6558 0.0894 1.     0.     0.     0.    ]\n",
            " [0.2947 0.5024 0.     1.     0.     1.    ]\n",
            " [0.2484 0.5303 0.     1.     0.     1.    ]\n",
            " [0.4409 0.1976 0.     0.     0.     0.    ]\n",
            " [0.5531 0.3525 1.     0.     1.     1.    ]\n",
            " [0.8176 0.7068 1.     1.     1.     1.    ]\n",
            " [0.6277 0.2181 1.     0.     1.     0.    ]\n",
            " [0.7317 0.4731 1.     0.     1.     1.    ]\n",
            " [0.256  0.406  0.     0.     0.     0.    ]\n",
            " [0.7062 0.2265 1.     0.     1.     0.    ]\n",
            " [0.0925 0.2937 0.     0.     0.     0.    ]\n",
            " [0.0318 0.025  0.     0.     0.     0.    ]\n",
            " [0.4001 0.2303 0.     0.     0.     0.    ]\n",
            " [0.5627 0.5266 1.     1.     1.     1.    ]\n",
            " [0.6419 0.2605 1.     0.     1.     0.    ]\n",
            " [0.1757 0.1339 0.     0.     0.     0.    ]\n",
            " [0.6987 0.4559 1.     0.     1.     0.    ]\n",
            " [0.7176 0.373  1.     0.     1.     0.    ]\n",
            " [0.6747 0.2916 1.     0.     0.     0.    ]\n",
            " [0.1362 0.0356 0.     0.     0.     0.    ]\n",
            " [0.1273 0.0944 0.     0.     0.     0.    ]\n",
            " [0.055  0.2736 0.     0.     0.     0.    ]\n",
            " [0.6755 0.4927 1.     0.     1.     1.    ]\n",
            " [0.4908 0.1267 0.     0.     0.     0.    ]\n",
            " [0.7583 0.3918 1.     0.     1.     0.    ]\n",
            " [0.3333 0.4945 0.     0.     0.     0.    ]\n",
            " [0.7326 0.3078 1.     0.     1.     0.    ]\n",
            " [0.3466 0.5771 0.     1.     0.     1.    ]\n",
            " [0.4287 0.856  0.     1.     0.     1.    ]\n",
            " [0.2938 0.4579 0.     0.     0.     0.    ]\n",
            " [0.1805 0.1538 0.     0.     0.     0.    ]\n",
            " [0.631  0.4201 1.     0.     1.     1.    ]\n",
            " [0.1826 0.1068 0.     0.     0.     0.    ]\n",
            " [0.4876 0.4755 0.     0.     1.     1.    ]\n",
            " [0.4349 0.7289 0.     1.     1.     1.    ]\n",
            " [0.4175 0.3687 0.     0.     0.     0.    ]\n",
            " [0.4113 0.2127 0.     0.     0.     0.    ]\n",
            " [0.5259 0.2708 1.     0.     1.     0.    ]\n",
            " [0.5803 0.1859 1.     0.     1.     0.    ]\n",
            " [0.3273 0.2371 0.     0.     0.     0.    ]\n",
            " [0.4915 0.1749 0.     0.     0.     0.    ]\n",
            " [0.2794 0.2639 0.     0.     0.     0.    ]\n",
            " [0.4799 0.3318 0.     0.     0.     0.    ]\n",
            " [0.3696 0.1852 0.     0.     0.     0.    ]\n",
            " [0.509  0.1298 1.     0.     1.     0.    ]\n",
            " [0.5616 0.2313 1.     0.     0.     0.    ]\n",
            " [0.0529 0.3405 0.     0.     0.     0.    ]\n",
            " [0.4835 0.1324 0.     0.     0.     0.    ]\n",
            " [0.2055 0.1188 0.     0.     0.     0.    ]\n",
            " [0.1024 0.059  0.     0.     0.     0.    ]\n",
            " [0.2632 0.4571 0.     0.     0.     0.    ]\n",
            " [0.1649 0.0165 0.     0.     0.     0.    ]\n",
            " [0.5418 0.5128 1.     1.     1.     1.    ]\n",
            " [0.5035 0.309  1.     0.     0.     0.    ]\n",
            " [0.2424 0.2227 0.     0.     0.     0.    ]\n",
            " [0.6179 0.3363 1.     0.     1.     0.    ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(threshold=10000000)\n",
        "print(np.concatenate([sigmoid(all_output), all_preds, all_labels], axis=1)[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "pIwj_6k_iutp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIwj_6k_iutp",
        "outputId": "84c01e15-7f8a-4397-f6bf-13f214c93221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -0.4992,   1.1156],\n",
              "       [  0.5727,  -0.6568],\n",
              "       [  0.49  ,  -1.0817],\n",
              "       [  0.3835,   1.6903],\n",
              "       [  0.4701,  -0.8658],\n",
              "       [ -0.1912,  -1.5469],\n",
              "       [ -0.3826,  -1.2941],\n",
              "       [  0.5115,   0.2126],\n",
              "       [  0.7453,  -0.6113],\n",
              "       [  0.4501,   0.027 ],\n",
              "       [ -1.3135,  -3.1398],\n",
              "       [ -1.6063,  -4.3438],\n",
              "       [ -2.0162,  -1.8562],\n",
              "       [ -2.4755,  -1.8262],\n",
              "       [ -1.3871,  -4.245 ],\n",
              "       [ -0.0686,  -1.6078],\n",
              "       [ -1.0563,  -2.2891],\n",
              "       [ -0.5406,  -0.7691],\n",
              "       [  0.152 ,  -0.5489],\n",
              "       [ -1.3897,  -1.7743],\n",
              "       [  0.0462,  -0.0802],\n",
              "       [ -2.2627,  -1.7076],\n",
              "       [  0.8546,  -2.5359],\n",
              "       [ -0.9037,  -2.279 ],\n",
              "       [ -1.9624,  -1.9354],\n",
              "       [ -1.495 ,  -1.7877],\n",
              "       [  0.2753,  -0.5156],\n",
              "       [  1.5652,   0.053 ],\n",
              "       [ -0.7446,  -0.6423],\n",
              "       [ -1.1116,  -1.1333],\n",
              "       [ -1.6125,  -0.6838],\n",
              "       [ -1.0842,   0.598 ],\n",
              "       [ -1.406 ,  -3.3415],\n",
              "       [  0.2945,  -1.8336],\n",
              "       [ -0.8574,  -1.6133],\n",
              "       [ -0.3707,  -1.1898],\n",
              "       [  0.5444,   0.3283],\n",
              "       [  0.8494,   0.443 ],\n",
              "       [ -0.8894,  -0.5963],\n",
              "       [ -1.0055,  -1.7742],\n",
              "       [ -2.6041,  -3.676 ],\n",
              "       [  0.3166,  -1.1998],\n",
              "       [  0.8997,  -0.2587],\n",
              "       [ -2.66  ,  -2.4181],\n",
              "       [ -0.7638,  -2.0739],\n",
              "       [ -3.0746,  -1.2486],\n",
              "       [  0.225 ,  -1.9078],\n",
              "       [ -0.7702,  -1.9807],\n",
              "       [  1.7513,  -3.4242],\n",
              "       [ -0.5435,  -2.8484],\n",
              "       [ -1.1461,  -2.272 ],\n",
              "       [  0.6185,  -1.4524],\n",
              "       [ -1.127 ,  -1.913 ],\n",
              "       [  1.1198,  -3.0708],\n",
              "       [  0.1914,   0.3006],\n",
              "       [ -0.0346,   0.4245],\n",
              "       [  0.6321,  -1.1415],\n",
              "       [ -1.1603,  -3.4192],\n",
              "       [  0.6951,  -0.5834],\n",
              "       [ -0.8703,  -1.1307],\n",
              "       [ -2.1844,  -0.943 ],\n",
              "       [-13.1577,  -5.7708],\n",
              "       [ -2.8312,  -1.6471],\n",
              "       [  0.345 ,  -0.4223],\n",
              "       [  0.5806,  -2.384 ],\n",
              "       [  0.0736,  -1.6569],\n",
              "       [ -3.2652,  -1.6204],\n",
              "       [ -0.827 ,  -4.111 ],\n",
              "       [  0.0784,  -1.4319],\n",
              "       [  1.0296,  -1.4091],\n",
              "       [ -0.0176,  -1.9236],\n",
              "       [ -0.0762,  -3.1996],\n",
              "       [  0.1529,  -1.2076],\n",
              "       [  0.0979,  -1.7264],\n",
              "       [ -0.6318,  -0.7407],\n",
              "       [ -3.4958,  -1.8909],\n",
              "       [ -1.8041,  -2.7336],\n",
              "       [ -0.9755,  -0.9593],\n",
              "       [ -0.2   ,  -2.3238],\n",
              "       [  0.9887,  -0.8649],\n",
              "       [  1.1608,  -0.8859],\n",
              "       [ -0.3111,  -2.8426],\n",
              "       [  0.9154,  -3.6203],\n",
              "       [  0.0697,  -0.3687],\n",
              "       [ -0.0484,  -2.5359],\n",
              "       [ -1.3358,  -1.3685],\n",
              "       [ -1.5609,  -1.0886],\n",
              "       [ -2.2529,  -3.0755],\n",
              "       [  0.4721,   0.8859],\n",
              "       [ -2.1926,  -2.3136],\n",
              "       [ -0.2262,   0.0357],\n",
              "       [ -0.108 ,  -1.8458],\n",
              "       [  0.8408,  -2.8033],\n",
              "       [ -1.4393,  -0.3486],\n",
              "       [  0.5759,  -1.6772],\n",
              "       [ 14.2672, -14.1079],\n",
              "       [  3.3177,   6.2659],\n",
              "       [ -1.991 ,  -7.8272],\n",
              "       [  1.4637,  -0.2938],\n",
              "       [  0.272 ,  -0.4211],\n",
              "       [  0.5218,   0.3567],\n",
              "       [ -0.892 ,  -1.6128],\n",
              "       [  1.2517,   1.3107],\n",
              "       [  3.1331,  -4.2113],\n",
              "       [ -0.4861,  -0.9688],\n",
              "       [  0.1361,  -0.1293],\n",
              "       [ -0.3476,   1.518 ],\n",
              "       [ -1.0125,  -1.4188],\n",
              "       [ -0.9306,  -2.9492],\n",
              "       [ -0.7002,  -1.7527],\n",
              "       [  0.1127,  -1.5348],\n",
              "       [ -1.6194,  -1.0736],\n",
              "       [  2.6604,  -3.3759],\n",
              "       [ -1.137 ,  -1.9458],\n",
              "       [  0.9325,  -2.6273],\n",
              "       [  0.1358,  -2.5702],\n",
              "       [  0.3905,  -1.4167],\n",
              "       [ -1.8646,  -2.0058],\n",
              "       [ -2.1411,  -0.2866],\n",
              "       [  0.8752,   0.257 ],\n",
              "       [ -1.1324,  -2.3644],\n",
              "       [ -1.1031,  -2.4297],\n",
              "       [ -1.1471,  -0.0139],\n",
              "       [  0.698 ,  -1.2418],\n",
              "       [  0.0884,  -3.1702],\n",
              "       [ -1.0314,  -1.0538],\n",
              "       [ -1.1435,   0.2029],\n",
              "       [ -1.8559,  -2.3224]], dtype=float32)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_output[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "7BB5kyP1cPDR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BB5kyP1cPDR",
        "outputId": "c2e31c91-364d-474c-9c9b-5f4ec6ffea95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_outputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125a868e",
      "metadata": {},
      "source": [
        "##### TSNE/U-Map 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52749c81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train set 시각화\n",
        "\n",
        "# Load fine-tuned model checkpoint\n",
        "ckpt_path = \"/home/ressera3/BOAZ-Chungzins/notebook/0710note_ckp/AllData_normX_CNN6_MLS_PT_128bs_N+PS_2507110212_best_checkpoint.pth.tar\"\n",
        "checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "\n",
        "# MoCo 모델 생성 및 체크포인트 로드\n",
        "model_vis = MoCo(\n",
        "    base_encoder=backbone_cnn6,\n",
        "    dim_enc=512,  # CNN6의 출력 feature dim (default=2048)\n",
        "    dim_prj=args.dim_prj,\n",
        "    K=args.K,\n",
        "    m=args.momentum,\n",
        "    T=args.T,\n",
        "    top_k=args.top_k,\n",
        "    lambda_bce=args.lambda_bce\n",
        ").to(device)\n",
        "model_vis.load_state_dict(checkpoint['state_dict'])\n",
        "model_vis.eval()\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y, _ in tqdm(test_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # encoder 출력 (FC 통과 전 feature 추출용)\n",
        "        features = model_vis.encoder_q(x).to(device)    # [B, C, F, T]\n",
        "\n",
        "        all_features.append(features.cpu())\n",
        "        all_labels.append(y.cpu())\n",
        "\n",
        "all_features = torch.cat(all_features, dim=0).numpy()  # shape: [N, D]\n",
        "all_labels = torch.cat(all_labels, dim=0).numpy()      # shape: [N, 2]\n",
        "\n",
        "# 3. 레이블 변환 (숫자 → 클래스명 문자열)\n",
        "def multilabel_to_multiclass(y):\n",
        "    return y[:, 0] + y[:, 1] * 2  # [Crackle, Wheeze] → 0~3\n",
        "\n",
        "label_map = {0: \"Normal\", 1: \"Crackle\", 2: \"Wheeze\", 3: \"Both\"}\n",
        "labels_cls = multilabel_to_multiclass(all_labels)\n",
        "labels_str = [label_map[i] for i in labels_cls]  # 문자열로 매핑\n",
        "\n",
        "# 4. TSNE 시각화\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "tsne_result = tsne.fit_transform(all_features)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], hue=labels_str, palette=\"tab10\", s=30)\n",
        "plt.title(\"t-SNE Visualization\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 5. UMAP 시각화\n",
        "import umap.umap_ as umap\n",
        "\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "umap_result = reducer.fit_transform(all_features)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=umap_result[:, 0], y=umap_result[:, 1], hue=labels_str, palette=\"tab10\", s=30)\n",
        "plt.title(\"UMAP Visualization\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acf3cba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test set 시각화\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y, _ in tqdm(finetune_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # encoder 출력 (FC 통과 전 feature 추출용)\n",
        "        features = model_vis.encoder_q(x).to(device)    # [B, C, F, T]\n",
        "\n",
        "        all_features.append(features.cpu())\n",
        "        all_labels.append(y.cpu())\n",
        "\n",
        "all_features = torch.cat(all_features, dim=0).numpy()  # shape: [N, D]\n",
        "all_labels = torch.cat(all_labels, dim=0).numpy()      # shape: [N, 2]\n",
        "\n",
        "# 3. 레이블 변환 (숫자 → 클래스명 문자열)\n",
        "def multilabel_to_multiclass(y):\n",
        "    return y[:, 0] + y[:, 1] * 2  # [Crackle, Wheeze] → 0~3\n",
        "\n",
        "label_map = {0: \"Normal\", 1: \"Crackle\", 2: \"Wheeze\", 3: \"Both\"}\n",
        "labels_cls = multilabel_to_multiclass(all_labels)\n",
        "labels_str = [label_map[i] for i in labels_cls]  # 문자열로 매핑\n",
        "\n",
        "# 4. TSNE 시각화\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "tsne_result = tsne.fit_transform(all_features)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], hue=labels_str, palette=\"tab10\", s=30)\n",
        "plt.title(\"t-SNE Visualization\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 5. UMAP 시각화\n",
        "import umap.umap_ as umap\n",
        "\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "umap_result = reducer.fit_transform(all_features)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=umap_result[:, 0], y=umap_result[:, 1], hue=labels_str, palette=\"tab10\", s=30)\n",
        "plt.title(\"UMAP Visualization\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "boaz",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
