{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fe581e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef6b52e2",
      "metadata": {
        "id": "ef6b52e2"
      },
      "source": [
        "#### í™˜ê²½ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc03a42",
      "metadata": {
        "id": "9dc03a42"
      },
      "source": [
        "##### 1. Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04d7d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04d7d6f",
        "outputId": "3c57e712-a314-411b-d4cf-1a953a648946"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# wandb ë¡œê·¸ì¸\n",
        "wandb.login(key=\"2fb604788cd6eed5aafafcc8d13a6aaa7737ac71\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992382bf",
      "metadata": {
        "id": "992382bf"
      },
      "source": [
        "##### 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5MISAwpScmYt",
      "metadata": {
        "id": "5MISAwpScmYt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ebed6c5",
      "metadata": {
        "id": "8ebed6c5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch import Tensor\n",
        "from torchsummary import summary\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d453e5f",
      "metadata": {
        "id": "2d453e5f"
      },
      "source": [
        "##### 3. ê²½ë¡œ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mSXgKx8GoItj",
      "metadata": {
        "id": "mSXgKx8GoItj"
      },
      "outputs": [],
      "source": [
        "ROOT = \"/home/HyeonSeok/BOAZ-Chungzins/data/raw\"\n",
        "CHECKPOINT_PATH = \"/home/HyeonSeok/BOAZ-Chungzins/save_path/checkpoint\"\n",
        "PICKLE_PATH = \"/home/HyeonSeok/BOAZ-Chungzins/save_path/pickle\"\n",
        "text = \"/home/HyeonSeok/BOAZ-Chungzins/data/metadata/train_test_split.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecaaf5a1",
      "metadata": {
        "id": "ecaaf5a1"
      },
      "source": [
        "##### 4. Seed ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f4e372",
      "metadata": {
        "id": "c9f4e372"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # âœ… ëª¨ë“  GPUì— ë™ì¼í•˜ê²Œ\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # ì¶”ê°€: DataLoaderì— worker_init_fn í™œìš© (ì•„ë˜ ì˜ˆì‹œ ì°¸ê³ )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nydfgBckyPt3",
      "metadata": {
        "id": "nydfgBckyPt3"
      },
      "source": [
        "## 1. Data Load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3fdcf1",
      "metadata": {
        "id": "ce3fdcf1"
      },
      "source": [
        "#### 1.1 Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OhJa9jivcg1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJa9jivcg1k",
        "outputId": "a78dee02-13e0-4e6f-cce1-455b6e9da489"
      },
      "outputs": [],
      "source": [
        "# WAV íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
        "data_dir = ROOT\n",
        "txt_dir = ROOT\n",
        "\n",
        "df = pd.read_csv(text, sep='\\t', header=None)\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n",
        "df.columns = ['filename', 'set']\n",
        "\n",
        "# train, test split\n",
        "train_df = df[df['set'] == 'train']\n",
        "test_df = df[df['set'] == 'test']\n",
        "\n",
        "# filename list\n",
        "train_list = sorted(train_df['filename'].tolist())\n",
        "test_list = sorted(test_df['filename'].tolist())\n",
        "\n",
        "print(f'Train :{len(train_list)}, Test: {len(test_list)}, Total: {len(train_list) + len(test_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04291977",
      "metadata": {
        "id": "04291977"
      },
      "source": [
        "#### 1.2 Pretext-Finetune Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ESBIVnKej0G9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBIVnKej0G9",
        "outputId": "849f490c-dd11-4b23-f1da-0fe6482fb71b"
      },
      "outputs": [],
      "source": [
        "# shuffle train data\n",
        "df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# split ratio\n",
        "train_size = int(len(df_shuffled))\n",
        "\n",
        "# pretrain, finetune split\n",
        "pretrain_df = df_shuffled[:train_size]\n",
        "finetune_df = pretrain_df\n",
        "\n",
        "# filename list (pretext_list -> pretrain list)\n",
        "pretrain_list = sorted(pretrain_df['filename'].tolist())\n",
        "finetune_list = sorted(finetune_df['filename'].tolist())\n",
        "\n",
        "# patient id list\n",
        "pretrain_patient_list = []\n",
        "for filename in pretrain_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    pretrain_patient_list.append(number)\n",
        "\n",
        "finetune_patient_list = []\n",
        "for filename in finetune_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    finetune_patient_list.append(number)\n",
        "\n",
        "pretrain_patient_counts = pd.Series(pretrain_patient_list).value_counts()\n",
        "finetune_patient_counts = pd.Series(finetune_patient_list).value_counts()\n",
        "\n",
        "print(f\"[Pretrain] í™˜ì ìˆ˜: {len(pretrain_patient_counts.index)}, ìƒ˜í”Œ ìˆ˜: {pretrain_patient_counts.sum()}\")\n",
        "print(f\"[Finetune] í™˜ì ìˆ˜: {len(finetune_patient_counts.index)}, ìƒ˜í”Œ ìˆ˜: {finetune_patient_counts.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oVi6lzuPpSbk",
      "metadata": {
        "id": "oVi6lzuPpSbk"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8c7719",
      "metadata": {
        "id": "5e8c7719"
      },
      "source": [
        "#### 2.1 Args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634b232e",
      "metadata": {
        "id": "634b232e"
      },
      "source": [
        "        K: queue size; number of negative keys (default: 65536)\n",
        "        m: moco momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add5c69b",
      "metadata": {
        "id": "add5c69b"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    # Audio & Spectrogram\n",
        "    target_sr = 16000    # 4KHz\n",
        "    frame_size = 1024\n",
        "    hop_length = 512    # frame_size ì ˆë°˜\n",
        "    n_mels = 64\n",
        "    target_sec = 8\n",
        "\n",
        "    # Augmentation\n",
        "    time_mask_param = 0.5\n",
        "    freq_mask_param = 0.5\n",
        "\n",
        "    # Train\n",
        "    lr = 1e-3 # adamw - 0.03\n",
        "    warm = True                     # warm-up ì‚¬ìš© ì—¬ë¶€\n",
        "    warm_epochs = 10                # warm-up ì ìš©í•  ì´ˆê¸° epoch ìˆ˜\n",
        "    warmup_from = lr * 0.1          # warm-up ì‹œì‘ learning rate (ë³´í†µ lrì˜ 10%)\n",
        "    warmup_to = lr\n",
        "\n",
        "    batch_size = 64\n",
        "    workers = 4\n",
        "    epochs = 200\n",
        "    weight_decay = 0.0\n",
        "\n",
        "    resume = None\n",
        "    schedule=[120, 160] # schedule\n",
        "\n",
        "    # MLS\n",
        "    K = 256\n",
        "    momentum = 0.999\n",
        "    T = 0.07\n",
        "    dim_prj = 128\n",
        "    top_k = 15\n",
        "    lambda_bce = 0.5\n",
        "    out_dim = 512\n",
        "\n",
        "    # Linear Evaluation\n",
        "    # ft_epochs = 3\n",
        "\n",
        "    # etc\n",
        "    gpu = 0\n",
        "    data = \"./data_path\"\n",
        "    seed=42\n",
        "    num_classes = 2\n",
        "\n",
        "    # update\n",
        "    ma_update = False\n",
        "    ma_beta = 0.5\n",
        "    target_type = 'grad_flow'\n",
        "    alpha = 0.3\n",
        "\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e1f949",
      "metadata": {
        "id": "58e1f949"
      },
      "source": [
        "#### 2.2 Utils (func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2d1329",
      "metadata": {
        "id": "8d2d1329"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# cycleì˜ í´ë˜ìŠ¤ë¥¼ ì¶”ì¶œ\n",
        "def get_class(cr, wh):\n",
        "    if cr == 1 and wh == 1:\n",
        "        return 3\n",
        "    elif cr == 0 and wh == 1:\n",
        "        return 2\n",
        "    elif cr == 1 and wh == 0:\n",
        "        return 1\n",
        "    elif cr == 0 and wh == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Mel Spectrogram ìƒì„± ( sr=4KHz, frame_size=1024, hop_length=512, n_mels=128 )\n",
        "# def generate_mel_spectrogram(waveform, sample_rate, frame_size, hop_length, n_mels):\n",
        "#     if hop_length is None:\n",
        "#         hop_length = frame_size // 2\n",
        "#     mel_spec_transform = T.MelSpectrogram(\n",
        "#         sample_rate=sample_rate,\n",
        "#         n_fft=frame_size,\n",
        "#         hop_length=hop_length,\n",
        "#         n_mels=n_mels,\n",
        "#         f_min=50,       # ë…¼ë¬¸ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ë²”ìœ„ í•˜í•œ\n",
        "#         f_max=2000      # ë…¼ë¬¸ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ë²”ìœ„ ìƒí•œ\n",
        "#     )\n",
        "#     mel_spectrogram = mel_spec_transform(waveform)\n",
        "#     mel_db = T.AmplitudeToDB()(mel_spectrogram)\n",
        "    \n",
        "#     # dB ìŠ¤ì¼€ì¼ì—ì„œ ë§¤ìš° ë‚®ì€ ê°’ì€ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
        "#     mel_db[mel_db <= -100.0] = 0.0\n",
        "    \n",
        "#     return mel_db\n",
        "\n",
        "# 256 ë§Ÿì¶°ì£¼ê¸°\n",
        "def generate_mel_spectrogram(waveform, sample_rate, frame_size, hop_length, n_mels):\n",
        "    if hop_length is None:\n",
        "        hop_length = frame_size // 2\n",
        "\n",
        "    mel_spec_transform = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=frame_size,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels,\n",
        "        f_min=50,\n",
        "        f_max=2000\n",
        "    )\n",
        "    mel_spectrogram = mel_spec_transform(waveform)\n",
        "    mel_db = T.AmplitudeToDB()(mel_spectrogram)\n",
        "\n",
        "    # dB ìŠ¤ì¼€ì¼ì—ì„œ ë§¤ìš° ë‚®ì€ ê°’ì€ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
        "    mel_db[mel_db <= -100.0] = 0.0\n",
        "\n",
        "    # ğŸ”§ ê°€ìš´ë° padding ì ìš©\n",
        "    target_frames = 256\n",
        "    current_frames = mel_db.shape[-1]\n",
        "    if current_frames < target_frames:\n",
        "        pad_total = target_frames - current_frames\n",
        "        pad_left = pad_total // 2\n",
        "        pad_right = pad_total - pad_left\n",
        "        mel_db = F.pad(mel_db, (pad_left, pad_right))  # center padding\n",
        "    elif current_frames > target_frames:\n",
        "        # ê°€ìš´ë° ìë¥´ê¸°\n",
        "        start = (current_frames - target_frames) // 2\n",
        "        mel_db = mel_db[:, :, start:start + target_frames]\n",
        "\n",
        "    return mel_db\n",
        "\n",
        "\n",
        "def preprocess_waveform_with_fade_repeat(waveform, unit_length, fade_ratio=0.1):\n",
        "    \"\"\"\n",
        "    ê¸¸ì´ unit_lengthê¹Œì§€ ë°˜ë³µí•˜ë©° fade-in/outìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ë°©ì‹ì˜ padding\n",
        "    waveform: (1, L) or (L,)\n",
        "    fade_ratio: ê° ë°˜ë³µ ì—°ê²°ë¶€ì—ì„œ fade-in/out ì ìš© ë¹„ìœ¨ (0.1 â†’ 10%)\n",
        "    \"\"\"\n",
        "    if waveform.dim() == 2:\n",
        "        waveform = waveform.squeeze(0)  # (1, L) â†’ (L,)\n",
        "\n",
        "    orig_len = len(waveform)\n",
        "    fade_len = int(orig_len * fade_ratio)\n",
        "\n",
        "    if orig_len >= unit_length:\n",
        "        # ë„ˆë¬´ ê¸¸ë©´ crop\n",
        "        length_adj = orig_len - unit_length\n",
        "        start = random.randint(0, length_adj // 4)\n",
        "        waveform = waveform[start:start + unit_length]\n",
        "        return waveform.unsqueeze(0)\n",
        "\n",
        "    # ë§Œë“¤ê³ ì í•˜ëŠ” ê¸¸ì´ë§Œí¼ ë°˜ë³µ\n",
        "    full_wave = waveform.clone()\n",
        "    while len(full_wave) < unit_length:\n",
        "        next_cycle = waveform.clone()\n",
        "\n",
        "        # fade-out ë§ˆì§€ë§‰ êµ¬ê°„\n",
        "        fade_out = torch.linspace(1.0, 0.0, fade_len)\n",
        "        full_wave[-fade_len:] *= fade_out\n",
        "\n",
        "        # fade-in ì•ë¶€ë¶„\n",
        "        fade_in = torch.linspace(0.0, 1.0, fade_len)\n",
        "        next_cycle[:fade_len] *= fade_in\n",
        "\n",
        "        # ì´ì–´ë¶™ì´ê¸°\n",
        "        full_wave = torch.cat([full_wave, next_cycle], dim=0)\n",
        "\n",
        "    # ìµœì¢… ê¸¸ì´ ë§ì¶”ê¸°\n",
        "    waveform = full_wave[:unit_length]\n",
        "    return waveform.unsqueeze(0)  # (1, L)\n",
        "\n",
        "# Cycle Repeat ë˜ëŠ” Crop\n",
        "def repeat_or_truncate_segment(mel_segment, target_frames):\n",
        "    current_frames = mel_segment.shape[-1]\n",
        "    if current_frames >= target_frames:\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "    else:\n",
        "        repeat_ratio = math.ceil(target_frames / current_frames)\n",
        "        mel_segment = mel_segment.repeat(1, 1, repeat_ratio)\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "\n",
        "def preprocess_waveform_segment(waveform, unit_length):\n",
        "\n",
        "    \"\"\"unit_length ê¸°ì¤€ìœ¼ë¡œ waveformì„ repeat + padding ë˜ëŠ” cropí•˜ì—¬ ê¸¸ì´ ì •ê·œí™”\"\"\"\n",
        "    waveform = waveform.squeeze(0)  # (1, L) â†’ (L,) ë¡œ ë°”ê¿”ë„ ë¬´ë°©\n",
        "    length_adj = unit_length - len(waveform)\n",
        "\n",
        "    if length_adj > 0:\n",
        "        # waveformì´ ë„ˆë¬´ ì§§ì€ ê²½ìš° â†’ repeat + zero-padding\n",
        "        half_unit = unit_length // 2\n",
        "\n",
        "        if length_adj < half_unit:\n",
        "            # ê¸¸ì´ ì°¨ì´ê°€ ì‘ìœ¼ë©´ ë‹¨ìˆœ padding\n",
        "            half_adj = length_adj // 2\n",
        "            waveform = F.pad(waveform, (half_adj, length_adj - half_adj))\n",
        "        else:\n",
        "            # ë°˜ë³µ í›„ ë¶€ì¡±í•œ ë¶€ë¶„ padding\n",
        "            repeat_factor = unit_length // len(waveform)\n",
        "            waveform = waveform.repeat(repeat_factor)[:unit_length]\n",
        "            remaining = unit_length - len(waveform)\n",
        "            half_pad = remaining // 2\n",
        "            waveform = F.pad(waveform, (half_pad, remaining - half_pad))\n",
        "    else:\n",
        "        # waveformì´ ë„ˆë¬´ ê¸¸ë©´ ì•ìª½ 1/4 ë‚´ì—ì„œ ëœë¤ crop\n",
        "        length_adj = len(waveform) - unit_length\n",
        "        start = random.randint(0, length_adj // 4)\n",
        "        waveform = waveform[start:start + unit_length]\n",
        "\n",
        "    return waveform.unsqueeze(0)  # ë‹¤ì‹œ (1, L)ë¡œ\n",
        "\n",
        "# # ë…¼ë¬¸ ê¸°ë°˜: Circular padding ë°©ì‹ ì ìš©\n",
        "# # - waveformì´ ì§§ì€ ê²½ìš°: circular paddingìœ¼ë¡œ 8ì´ˆ ê¸¸ì´ ë§ì¶¤\n",
        "# # - waveformì´ ê¸´ ê²½ìš°: ì•ìª½ 25% ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ crop\n",
        "# def preprocess_waveform_segment(waveform, unit_length):\n",
        "#     \"\"\"\n",
        "#     ë…¼ë¬¸ ê¸°ë°˜: Circular padding ì ìš©\n",
        "#     - waveformì´ ì§§ì€ ê²½ìš°: circular paddingìœ¼ë¡œ 8ì´ˆ ê¸¸ì´ ë§ì¶¤\n",
        "#     - waveformì´ ê¸´ ê²½ìš°: ì•ìª½ 25% ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ crop\n",
        "#     \"\"\"\n",
        "#     waveform = waveform.squeeze(0)  # (1, L) â†’ (L,)\n",
        "#     current_len = waveform.size(0)\n",
        "\n",
        "#     if current_len < unit_length:\n",
        "#         pad_len = unit_length - current_len\n",
        "#         # â¤ shapeì„ (1, L)ë¡œ ë°”ê¾¸ê³  pad ì ìš© í›„ ë‹¤ì‹œ (L,)ë¡œ\n",
        "#         waveform = waveform.unsqueeze(0)  # (L,) â†’ (1, L)\n",
        "#         waveform = F.pad(waveform, (0, pad_len), mode='circular')\n",
        "#         waveform = waveform.squeeze(0)    # (1, L+pad) â†’ (L+pad,)\n",
        "#     elif current_len > unit_length:\n",
        "#         max_start = max(0, current_len - unit_length)\n",
        "#         start = random.randint(0, max_start // 4)\n",
        "#         waveform = waveform[start:start + unit_length]\n",
        "\n",
        "#     return waveform.unsqueeze(0)  # (L,) â†’ (1, L)\n",
        "\n",
        "# ë°ì´í„° Spec Augmentation ( 0~80% Random Masking )\n",
        "def apply_spec_augment(mel_segment):\n",
        "\n",
        "    M = mel_segment.shape[-1]\n",
        "    F = mel_segment.shape[-2]\n",
        "\n",
        "    # torchaudioì˜ ë§ˆìŠ¤í‚¹ì€ 0ë¶€í„° mask_paramê¹Œì§€ ê· ë“±ë¶„í¬ì—ì„œ ëœë¤í•˜ê²Œ ê¸¸ì´ë¥¼ ì„ íƒ\n",
        "    time_masking = T.TimeMasking(time_mask_param=int(M * 0.8))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=int(F * 0.8) )\n",
        "\n",
        "    aug1 = freq_masking(mel_segment.clone())\n",
        "    aug2 = time_masking(mel_segment.clone())\n",
        "    aug3 = freq_masking(time_masking(mel_segment.clone()))\n",
        "\n",
        "    return aug1, aug2, aug3\n",
        "\n",
        "# Waveform resample\n",
        "def resample_waveform(waveform, orig_sr, target_sr=args.target_sr):\n",
        "    if orig_sr != target_sr:\n",
        "        resampler = torchaudio.transforms.Resample(\n",
        "            orig_freq=orig_sr,\n",
        "            new_freq=target_sr\n",
        "        )\n",
        "        return resampler(waveform), target_sr\n",
        "    return waveform, orig_sr\n",
        "\n",
        "# Normalize - Mean/Std\n",
        "# def get_mean_and_std(dataset):\n",
        "#     \"\"\" ì „ì²´ mel-spectrogramì—ì„œ meanê³¼ std ê³„ì‚° \"\"\"\n",
        "#     dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "#     cnt = 0\n",
        "#     fst_moment = torch.zeros(1)\n",
        "#     snd_moment = torch.zeros(1)\n",
        "#     for inputs, _, _ in tqdm(dataloader, desc=\"[Calculating Mean/Std]\"):\n",
        "#         b, c, h, w = inputs.shape  # inputs: [1, 1, n_mels, time]\n",
        "#         nb_pixels = b * h * w\n",
        "\n",
        "#         fst_moment += torch.sum(inputs, dim=[0, 2, 3])\n",
        "#         snd_moment += torch.sum(inputs**2, dim=[0, 2, 3])\n",
        "#         cnt += nb_pixels\n",
        "\n",
        "#     mean = fst_moment / cnt\n",
        "#     std = torch.sqrt(snd_moment / cnt - mean**2)\n",
        "#     return mean.item(), std.item()\n",
        "\n",
        "def get_mean_and_std(dataset, mask_threshold=-99.0):\n",
        "    \"\"\" ë§ˆìŠ¤í‚¹(-100 ë“±)ì„ ì œì™¸í•˜ê³  mean/std ê³„ì‚° \"\"\"\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    cnt = 0\n",
        "    fst_moment = 0.0\n",
        "    snd_moment = 0.0\n",
        "\n",
        "    for inputs, _, _ in tqdm(dataloader, desc=\"[Calculating Mean/Std]\"):\n",
        "        # mask: ìœ íš¨í•œ mel ê°’ë§Œ ì¶”ì¶œ (e.g. > -99.0)\n",
        "        valid = inputs[inputs > mask_threshold]  # 1D tensor\n",
        "\n",
        "        fst_moment += valid.sum().item()\n",
        "        snd_moment += (valid ** 2).sum().item()\n",
        "        cnt += valid.numel()\n",
        "\n",
        "    mean = fst_moment / cnt\n",
        "    std = np.sqrt(snd_moment / cnt - mean**2)\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70af5e6b",
      "metadata": {
        "id": "70af5e6b"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import torchaudio.transforms as T\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import math\n",
        "\n",
        "# # -------------------- Augmentation functions (Torch ê¸°ë°˜) --------------------\n",
        "\n",
        "# def spec_augment(mel, time_mask_ratio, freq_mask_ratio): # default: 0.8\n",
        "#     M = mel.shape[-1]  # ì‹œê°„ ì¶•\n",
        "#     F = mel.shape[-2]  # ì£¼íŒŒìˆ˜ ì¶•\n",
        "\n",
        "#     time_masking = T.TimeMasking(time_mask_param=int(M * time_mask_ratio))\n",
        "#     freq_masking = T.FrequencyMasking(freq_mask_param=int(F * freq_mask_ratio))\n",
        "\n",
        "#     mel = freq_masking(mel.clone())\n",
        "#     mel = time_masking(mel)\n",
        "#     return mel\n",
        "\n",
        "# # def random_crop(mel, crop_size):\n",
        "# #     if mel.shape[-1] <= crop_size:\n",
        "# #         return mel\n",
        "# #     start = torch.randint(0, mel.shape[-1] - crop_size + 1, (1,)).item()\n",
        "# #     return mel[:, :, start:start + crop_size]\n",
        "\n",
        "# def add_noise(mel, noise_level=0.005):\n",
        "#     noise = torch.randn_like(mel) * noise_level\n",
        "#     return mel + noise\n",
        "\n",
        "# def pitch_shift(mel, n_steps=2):\n",
        "#     shift = random.randint(-n_steps, n_steps)\n",
        "#     if shift == 0:\n",
        "#         return mel\n",
        "#     if shift > 0:\n",
        "#         mel = torch.cat([mel[:, shift:, :], mel[:, :shift, :]], dim=1)\n",
        "#     else:\n",
        "#         shift = abs(shift)\n",
        "#         mel = torch.cat([mel[:, -shift:, :], mel[:, :-shift, :]], dim=1)\n",
        "#     return mel\n",
        "\n",
        "# def time_stretch(mel, min_rate=0.8, max_rate=1.2):\n",
        "#     rate = random.uniform(min_rate, max_rate)\n",
        "#     if rate == 1.0:\n",
        "#         return mel\n",
        "\n",
        "#     orig_size = mel.shape[-1]\n",
        "#     target_size = int(orig_size * rate)\n",
        "#     mel_stretched = F.interpolate(\n",
        "#         mel, size=(mel.shape[1], target_size),\n",
        "#         mode='bilinear', align_corners=False\n",
        "#     )\n",
        "\n",
        "#     if target_size > orig_size:\n",
        "#         return mel_stretched[:, :, :orig_size]\n",
        "#     else:\n",
        "#         padding = orig_size - target_size\n",
        "#         return F.pad(mel_stretched, (0, padding))\n",
        "\n",
        "# # -------------------- Dispatcher --------------------\n",
        "\n",
        "# AUGMENTATION_FUNCTIONS_TORCH = {\n",
        "#     \"spec_augment\": spec_augment,\n",
        "#     # \"random_crop\": random_crop,\n",
        "#     \"add_noise\": add_noise,\n",
        "#     \"pitch_shift\": pitch_shift,\n",
        "#     \"time_stretch\": time_stretch\n",
        "# }\n",
        "\n",
        "# def apply_augmentations_torch(x, methods=[], **kwargs):\n",
        "#     for method in methods:\n",
        "#         func = AUGMENTATION_FUNCTIONS_TORCH.get(method)\n",
        "#         if func is None:\n",
        "#             raise ValueError(f\"Unknown augmentation: {method}\")\n",
        "#         x = func(x, **kwargs.get(method, {}))\n",
        "#     return x\n",
        "\n",
        "\n",
        "##############################################\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# -------------------- Augmentation functions (ICBHI ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ì— ìµœì í™”) --------------------\n",
        "\n",
        "# def spec_augment(mel, time_mask_ratio=0.15, freq_mask_ratio=0.15):\n",
        "#     \"\"\"\n",
        "#     SpecAugment: ì‹œê°„/ì£¼íŒŒìˆ˜ ì˜ì—­ ë§ˆìŠ¤í‚¹\n",
        "#     - ì‹œê°„ì¶• ë§ˆìŠ¤í‚¹: 63 * 0.15 â‰ˆ 9 í”„ë ˆì„\n",
        "#     - ì£¼íŒŒìˆ˜ ë§ˆìŠ¤í‚¹: 128 * 0.1 â‰ˆ 12 ì±„ë„\n",
        "#     \"\"\"\n",
        "#     M = mel.shape[-1]  # ì‹œê°„ ì¶•\n",
        "#     F = mel.shape[-2]  # ì£¼íŒŒìˆ˜ ì¶•\n",
        "\n",
        "#     time_masking = T.TimeMasking(time_mask_param=max(1, int(M * time_mask_ratio)))\n",
        "#     freq_masking = T.FrequencyMasking(freq_mask_param=max(1, int(F * freq_mask_ratio)))\n",
        "\n",
        "#     mel = freq_masking(mel.clone())\n",
        "#     mel = time_masking(mel)\n",
        "#     return mel\n",
        "\n",
        "# multi-label ë…¼ë¬¸ìš© spec\n",
        "def spec_augment(mel, time_mask_param=20, freq_mask_param=40):\n",
        "    \"\"\"\n",
        "    ë…¼ë¬¸ ê¸°ì¤€:\n",
        "    - ì‹œê°„ ë§ˆìŠ¤í‚¹: ìµœëŒ€ 20 frame\n",
        "    - ì£¼íŒŒìˆ˜ ë§ˆìŠ¤í‚¹: ìµœëŒ€ 40 mel bin\n",
        "    \"\"\"\n",
        "    time_masking = T.TimeMasking(time_mask_param=time_mask_param)\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=freq_mask_param)\n",
        "\n",
        "    mel = freq_masking(mel.clone())\n",
        "    mel = time_masking(mel)\n",
        "    return mel\n",
        "\n",
        "def add_noise(mel, noise_level=0.001):\n",
        "    \"\"\"\n",
        "    ë…¸ì´ì¦ˆ ì¶”ê°€: ì ë‹¹í•œ ìˆ˜ì¤€ì˜ í‘œì¤€ ì •ê·œë¶„í¬ ë…¸ì´ì¦ˆ (ë„ˆë¬´ ë†’ìœ¼ë©´ ì†ì‹¤ ì»¤ì§)\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(mel) * noise_level\n",
        "    return mel + noise\n",
        "\n",
        "def pitch_shift(mel, n_steps=2):\n",
        "    \"\"\"\n",
        "    ì£¼íŒŒìˆ˜ ì¶• ìˆœí™˜ ì´ë™ (mel axis). shapeì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨.\n",
        "    n_steps=2ë©´ Â±2 ë©œ ì±„ë„ë§Œ ì´ë™.\n",
        "    \"\"\"\n",
        "    shift = random.randint(-n_steps, n_steps)\n",
        "    if shift == 0:\n",
        "        return mel\n",
        "    if shift > 0:\n",
        "        mel = torch.cat([mel[:, :, shift:, :], mel[:, :, :shift, :]], dim=2)\n",
        "    else:\n",
        "        shift = abs(shift)\n",
        "        mel = torch.cat([mel[:, :, -shift:, :], mel[:, :, :-shift, :]], dim=2)\n",
        "    return mel\n",
        "\n",
        "def time_stretch(mel, min_rate=0.95, max_rate=1.05):\n",
        "    \"\"\"\n",
        "    ì‹œê°„ ì¶• ê¸¸ì´ ì¡°ì ˆ. ë„ˆë¬´ ì‹¬í•˜ì§€ ì•Šê²Œ Â±5% ë²”ìœ„ë¡œë§Œ ì¡°ì •.\n",
        "    - shape ìœ ì§€ ìœ„í•´ interpolation í›„ crop/pad\n",
        "    \"\"\"\n",
        "    rate = random.uniform(min_rate, max_rate)\n",
        "    if rate == 1.0:\n",
        "        return mel\n",
        "\n",
        "    orig_size = mel.shape[-1]\n",
        "    target_size = int(orig_size * rate)\n",
        "\n",
        "    mel_stretched = F.interpolate(\n",
        "        mel, size=(mel.shape[-2], target_size),  # (mel_bins, time)\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    if target_size > orig_size:\n",
        "        return mel_stretched[..., :orig_size]\n",
        "    else:\n",
        "        pad = orig_size - target_size\n",
        "        return F.pad(mel_stretched, (0, pad))\n",
        "\n",
        "# -------------------- Dispatcher --------------------\n",
        "\n",
        "AUGMENTATION_FUNCTIONS_TORCH = {\n",
        "    \"spec_augment\": spec_augment,\n",
        "    \"add_noise\": add_noise,\n",
        "    \"pitch_shift\": pitch_shift,\n",
        "    \"time_stretch\": time_stretch\n",
        "}\n",
        "\n",
        "def apply_augmentations_torch(x, methods=[], **kwargs):\n",
        "    for method in methods:\n",
        "        func = AUGMENTATION_FUNCTIONS_TORCH.get(method)\n",
        "        if func is None:\n",
        "            raise ValueError(f\"Unknown augmentation: {method}\")\n",
        "        x = func(x, **kwargs.get(method, {}))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a62aa74",
      "metadata": {
        "id": "4a62aa74"
      },
      "outputs": [],
      "source": [
        "def aug(repeat_mel):\n",
        "    # ë¨¼ì € ë³µì‚¬ë³¸ ì¤€ë¹„\n",
        "    mel1 = repeat_mel.clone()\n",
        "    mel2 = repeat_mel.clone()\n",
        "\n",
        "    # ê°ê° ë‹¤ë¥¸ ì¦ê°• A, B ì ìš©\n",
        "    # aug1 = apply_augmentations_torch(mel1, methods=[\"add_noise\"], add_noise={\"noise_level\": 0.005})\n",
        "    # aug2 = apply_augmentations_torch(mel2, methods=[\"time_stretch\"], time_stretch={\"min_rate\": 0.8, \"max_rate\": 1.2})\n",
        "    # aug3 = apply_augmentations_torch(mel2, methods=[\"pitch_shift\"], pitch_shift={\"n_steps\": 2})\n",
        "\n",
        "    # # ê° ê²°ê³¼ì— spec_augment ì¶”ê°€ ì ìš©\n",
        "    # aug1_spec = spec_augment(aug1)\n",
        "    # aug2_spec = spec_augment(aug2, time_mask_ratio=0.6, freq_mask_ratio=0.4)\n",
        "    # aug3_spec = spec_augment(aug3)\n",
        "\n",
        "    ## ìˆœìˆ˜ spec_augmentë§Œ ì ìš©í•œ ê²½ìš°\n",
        "    aug_speconly = spec_augment(mel1)\n",
        "\n",
        "    return aug_speconly, None, None\n",
        "\n",
        "\n",
        "def get_timestamp():\n",
        "    \"\"\"Outputs current time in KST like 2404070830\"\"\"\n",
        "    kst_time = datetime.now(ZoneInfo(\"Asia/Seoul\"))\n",
        "    return kst_time.strftime('%y%m%d%H%M')\n",
        "\n",
        "# Origin\n",
        "# def aug(repeat_mel):\n",
        "#     aug1, aug2, aug3 = apply_spec_augment(repeat_mel)\n",
        "#     return aug1, aug2, aug3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e684cb",
      "metadata": {
        "id": "39e684cb"
      },
      "source": [
        "#### 2.3 CycleDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1642a79a",
      "metadata": {
        "id": "1642a79a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CycleDataset(Dataset):\n",
        "    def __init__(self, filename_list, wav_dir, txt_dir, target_sec=args.target_sec, target_sr=args.target_sr, frame_size=args.frame_size, hop_length=args.hop_length, n_mels=args.n_mels, mean=None, std=None):\n",
        "        self.filename_list = filename_list\n",
        "        self.wav_dir = wav_dir\n",
        "        self.txt_dir = txt_dir\n",
        "        self.target_sec = target_sec\n",
        "        self.target_sr = target_sr\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.cycle_list = []\n",
        "\n",
        "        print(\"[INFO] Preprocessing cycles...\")\n",
        "        for filename in tqdm(self.filename_list):\n",
        "            txt_path = os.path.join(self.txt_dir, filename + '.txt')\n",
        "            wav_path = os.path.join(self.wav_dir, filename + '.wav')\n",
        "\n",
        "            if not os.path.exists(txt_path):\n",
        "                print(f\"[WARNING] Missing file: {txt_path}\")\n",
        "            if not os.path.exists(wav_path):\n",
        "                print(f\"[WARNING] Missing file: {wav_path}\")\n",
        "\n",
        "            # Load annotation\n",
        "            cycle_data = np.loadtxt(txt_path, usecols=(0, 1))\n",
        "            lung_label = np.loadtxt(txt_path, usecols=(2, 3))\n",
        "\n",
        "            # Load waveform\n",
        "            waveform, orig_sr = torchaudio.load(wav_path)\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)  # Stereo to mono\n",
        "                print(' waveform.shape[0] > 1:')\n",
        "\n",
        "            # Resample to target sample rate (4kHz)\n",
        "            waveform, sample_rate = resample_waveform(waveform, orig_sr, self.target_sr)\n",
        "\n",
        "            for idx in range(len(cycle_data)):\n",
        "                # í˜¸í¡ ì£¼ê¸° start, end\n",
        "                start_sample = int(cycle_data[idx, 0] * sample_rate)\n",
        "                end_sample = int(cycle_data[idx, 1] * sample_rate)\n",
        "                lung_duration = cycle_data[idx, 1] - cycle_data[idx, 0]\n",
        "\n",
        "                if end_sample <= start_sample:\n",
        "                    print('end_sample <= start_sample:')\n",
        "                    continue  # ì˜ëª»ëœ êµ¬ê°„ ìŠ¤í‚µ\n",
        "\n",
        "                # Waveform repeat + padding í›„ Mel_db\n",
        "                cycle_wave = waveform[:, start_sample:end_sample]\n",
        "                seg_wave = preprocess_waveform_segment(cycle_wave, unit_length=int(self.target_sec * self.target_sr))\n",
        "                mel = generate_mel_spectrogram(seg_wave, sample_rate, frame_size=self.frame_size, hop_length=self.hop_length, n_mels=self.n_mels)\n",
        "\n",
        "                # ì •ê·œí™”\n",
        "                if self.mean is not None and self.std is not None:\n",
        "                    mask_value = -100.0 # mel db ì—ì„œ ë§ˆìŠ¤í‚¹ëœ ê°’\n",
        "                    mask = (mel == mask_value)\n",
        "                    mel = (mel - mean) / std\n",
        "                    mel[mask] = 0.0\n",
        "                    \n",
        "                # crackle, wheeze -> class\n",
        "                cr = int(lung_label[idx, 0])\n",
        "                wh = int(lung_label[idx, 1])\n",
        "                label = get_class(cr, wh)\n",
        "\n",
        "                multi_label = torch.tensor([\n",
        "                    float(label in [1, 3]),\n",
        "                    float(label in [2, 3])\n",
        "                ])  # ë³€í™˜ëœ multi-label ë°˜í™˜\n",
        "\n",
        "                # meta_data\n",
        "                meta_data = (filename, lung_duration)\n",
        "\n",
        "                self.cycle_list.append((mel, multi_label, meta_data))\n",
        "\n",
        "        print(f\"[INFO] Total cycles collected: {len(self.cycle_list)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cycle_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel, label, meta_data = self.cycle_list[idx]\n",
        "        return mel, label, meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d5a070",
      "metadata": {
        "id": "55d5a070"
      },
      "source": [
        "##### Pickle.dump"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752088df",
      "metadata": {
        "id": "752088df"
      },
      "source": [
        "CycleDataset ê°ì²´ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67673cde",
      "metadata": {},
      "outputs": [],
      "source": [
        "# len(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dca6c2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "pickle_name = f'MLS_0722_{args.target_sr//1000}kHz_{args.frame_size}win_{args.hop_length}hop_{args.n_mels}mel_{args.target_sec}s'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d386e82",
      "metadata": {
        "id": "9d386e82"
      },
      "outputs": [],
      "source": [
        "# # # import random\n",
        "# # # import matplotlib.pyplot as plt\n",
        "# # # import librosa.display\n",
        "\n",
        "# # # wav_dir = ROOT\n",
        "# # # txt_dir = ROOT\n",
        "\n",
        "# # # # 1. Dataset ë¡œë“œ\n",
        "# # # train_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# # # test_dataset = CycleDataset(test_list, wav_dir, txt_dir)\n",
        "\n",
        "# # ################################################################\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "wav_dir = ROOT\n",
        "txt_dir = ROOT\n",
        "\n",
        "# # mean, std ë¨¼ì € ê³„ì‚°\n",
        "# normless_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# mean, std = get_mean_and_std(normless_dataset)\n",
        "\n",
        "# ì •ê·œí™” ì ìš©ëœ ë°ì´í„°ì…‹ ìƒì„±\n",
        "train_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "test_dataset = CycleDataset(test_list, wav_dir, txt_dir)\n",
        "\n",
        "pickle_dict = {\n",
        "    'train_dataset': train_dataset,\n",
        "    'test_dataset': test_dataset\n",
        "}\n",
        "\n",
        "save_path = os.path.join(PICKLE_PATH, pickle_name  + '.pkl')\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(pickle_dict, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BQgVyGnrDbN",
      "metadata": {
        "id": "4BQgVyGnrDbN"
      },
      "source": [
        "pickleë¡œ train_dataset, test_dataset ì™¸ë¶€ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd34caa0",
      "metadata": {
        "id": "cd34caa0"
      },
      "outputs": [],
      "source": [
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset\n",
        "# }\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, '3:7_saved_datasets_multilabel.pkl')\n",
        "# with open(save_path, 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)\n",
        "\n",
        "# # #####\n",
        "\n",
        "# # ğŸ”¹ mean, std í•¨ê»˜ ì €ì¥\n",
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset,\n",
        "#     'mean': mean,\n",
        "#     'std': std\n",
        "# }\n",
        "# with open(os.path.join(PICKLE_PATH, 'pad0_norm_saved_datasets_multilabel.pkl'), 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)\n",
        "\n",
        "# print(f'mean: {mean}, std: {std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zRqSwthYTtxq",
      "metadata": {
        "id": "zRqSwthYTtxq"
      },
      "outputs": [],
      "source": [
        "# # 2. ê°„ë‹¨ í†µê³„\n",
        "# print(f\"Total cycles: {len(train_dataset)}\")\n",
        "\n",
        "# label_counter = [0] * 4  # normal, crackle, wheeze, both\n",
        "# for _, multi_label,_ in train_dataset:\n",
        "#     if torch.equal(multi_label, torch.tensor([0., 0.])):\n",
        "#         label_counter[0] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 0.])):\n",
        "#         label_counter[1] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([0., 1.])):\n",
        "#         label_counter[2] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 1.])):\n",
        "#         label_counter[3] += 1\n",
        "\n",
        "# for idx, count in enumerate(label_counter):\n",
        "#     print(f\"Class {idx}: {count} cycles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yJPtbC3BrqAE",
      "metadata": {
        "id": "yJPtbC3BrqAE"
      },
      "source": [
        "##### Pickle.load\n",
        "ì €ì¥ëœ train_dataset, test_datasetì„ ë¡œë“œ  \n",
        "(> Aug ëŠ” Moco ëª¨ë¸ì—ì„œ ì‚¬ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EWrjdCFSrmER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWrjdCFSrmER",
        "outputId": "ad9770b7-e29b-4c41-e83e-2d35bb552c19"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(PICKLE_PATH, pickle_name  + '.pkl')\n",
        "with open(save_path, 'rb') as f:\n",
        "    pickle_dict = pickle.load(f)\n",
        "\n",
        "train_dataset = pickle_dict['train_dataset']\n",
        "test_dataset = pickle_dict['test_dataset']\n",
        "\n",
        "print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "print(f\"[Test] Cycles: {len(test_dataset)}\")\n",
        "\n",
        "###################\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, 'pad0_norm_saved_datasets_multilabel.pkl')\n",
        "# # ğŸ”¹ load with normalization values\n",
        "# with open(save_path, 'rb') as f:\n",
        "#     pickle_dict = pickle.load(f)\n",
        "\n",
        "# train_dataset = pickle_dict['train_dataset']\n",
        "# test_dataset = pickle_dict['test_dataset']\n",
        "# mean = pickle_dict['mean']\n",
        "# std = pickle_dict['std']\n",
        "\n",
        "# print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "# print(f\"[Test] Cycles: {len(test_dataset)}\")\n",
        "# print(f\"[INFO] Loaded mean={mean:.4f}, std={std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3c24b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cebfa6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "mel = train_dataset[0][0]  # (1, 64, 256)\n",
        "\n",
        "# ì¦ê°• ì ìš©\n",
        "aug_speconly, _ , _ = aug(mel)  # aug1: speconly, aug2: speconly\n",
        "\n",
        "# ì‹œê°í™” í•¨ìˆ˜\n",
        "def show_mel(mel_tensor, title):\n",
        "    # í…ì„œ shapeì´ (1, 64, 256) ë˜ëŠ” (1, 1, 64, 256)ì¼ ìˆ˜ ìˆìŒ\n",
        "    if mel_tensor.ndim == 4:\n",
        "        mel_tensor = mel_tensor.squeeze(0)  # (1, 64, 256)\n",
        "    mel_np = mel_tensor.squeeze(0).cpu().numpy()  # (64, 256)\n",
        "    \n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.imshow(mel_np, origin='lower', aspect='auto', cmap='magma')\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Mel Frequency\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‹œê°í™”\n",
        "show_mel(mel, \"Original Mel\")\n",
        "show_mel(aug_speconly, \"Augmented Mel (Spec Only)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcca3481",
      "metadata": {
        "id": "bcca3481"
      },
      "source": [
        "#### 2.4 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c9b5b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e91c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset[9][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f19b4a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f19b4a7",
        "outputId": "c2ac9fb5-3049-4aaa-f5bb-c28a747088d8"
      },
      "outputs": [],
      "source": [
        "# ---------------- í•™ìŠµ ë°ì´í„° êµ¬ì„±(seed) ----------------\n",
        "seed_everything(args.seed)\n",
        "\n",
        "# train_dataset ë‚´ì—ì„œ ê° íŒŒì¼ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œ\n",
        "pretrain_idx = []\n",
        "finetune_idx = []\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "    filename = train_dataset[i][2][0]\n",
        "\n",
        "    if filename in pretrain_list:\n",
        "        pretrain_idx.append(i)\n",
        "    # elif filename in finetune_list:\n",
        "    #     finetune_idx.append(i)\n",
        "\n",
        "    # pretrain = finetune\n",
        "    if filename in finetune_list:\n",
        "        finetune_idx.append(i)\n",
        "\n",
        "# ì¸ë±ìŠ¤ ìˆœì„œ ì…”í”Œ\n",
        "random.shuffle(pretrain_idx)\n",
        "random.shuffle(finetune_idx)\n",
        "\n",
        "print(f\"Pretrain set size: {len(pretrain_idx)}, Finetune set size: {len(finetune_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce2c3c8",
      "metadata": {
        "id": "cce2c3c8"
      },
      "source": [
        "ì½”ë“œ ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ num_workersë¥¼ ì ì ˆí•œ ê°’ìœ¼ë¡œ ì§€ì •í•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432ae0cd",
      "metadata": {
        "id": "432ae0cd"
      },
      "outputs": [],
      "source": [
        "# Dataset ìƒì„± (Subset)\n",
        "pretrain_dataset = Subset(train_dataset, pretrain_idx)\n",
        "finetune_dataset = Subset(train_dataset, finetune_idx)\n",
        "\n",
        "# DataLoader ìƒì„±\n",
        "# DataLoaderì—ì„œ shuffle=Trueë¡œ ì§€ì •í•˜ë©´ ë§¤ epochë§ˆë‹¤ ì…”í”Œ ìˆœì„œê°€ ë‹¬ë¼ì§ => ì¬í˜„ì„± ë¬¸ì œ ë°œìƒ\n",
        "# pretrain_dataset, finetune_datasetì€ ì´ë¯¸ ì…”í”Œì´ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ, ì´ê²ƒì„ DataLoaderì— ì…ë ¥í•¨\n",
        "pretrain_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "finetune_loader = DataLoader(\n",
        "    finetune_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b492ad67",
      "metadata": {
        "id": "b492ad67"
      },
      "source": [
        "label ë¶„í¬ í™•ì¸ (ë‹¨ìˆœ ì°¸ê³ ìš©, ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” pretrain setì˜ label ë¶„í¬ê°€ ì–´ë–¤ì§€ ì•Œ ìˆ˜ ì—†ìŒ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea9d290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea9d290",
        "outputId": "2066f8d9-fbc5-44a6-b3b3-0bc214f136ca"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# label\n",
        "labels = torch.stack([multi_label for _, multi_label, _ in train_dataset])\n",
        "\n",
        "# pretextì™€ finetune ë°ì´í„°ì…‹ì˜ ë¼ë²¨ ë¶„í¬ ì¶œë ¥\n",
        "pretrain_labels = labels[pretrain_idx]\n",
        "pretrain_labels_class = (\n",
        "    pretrain_labels[:, 0].long() * 1 +  # crackle bit â†’ *1\n",
        "    pretrain_labels[:, 1].long() * 2    # wheeze bit  â†’ *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "finetune_labels = labels[finetune_idx]\n",
        "finetune_labels_class = (\n",
        "    finetune_labels[:, 0].long() * 1 +  # crackle bit â†’ *1\n",
        "    finetune_labels[:, 1].long() * 2    # wheeze bit  â†’ *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "# test ë°ì´í„°ì…‹ì˜ ë¼ë²¨ ë¶„í¬ ì¶œë ¥\n",
        "test_labels = torch.stack([multi_label for _, multi_label, _ in test_dataset])\n",
        "test_labels_class = (\n",
        "    test_labels[:, 0].long() * 1 +  # crackle bit â†’ *1\n",
        "    test_labels[:, 1].long() * 2    # wheeze bit  â†’ *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "print(f\"Pretrain sample: {len(pretrain_labels_class)}\")\n",
        "print(\"Pretrain label distribution:\", Counter(pretrain_labels_class.tolist()))\n",
        "print(f\"\\nFinetune sample: {len(finetune_labels_class)}\")\n",
        "print(\"Finetune label distribution:\", Counter(finetune_labels_class.tolist()))\n",
        "print(f\"Test sample: {len(test_labels_class)}\")\n",
        "print(\"Test label distribution:\", Counter(test_labels_class.tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed559ff1",
      "metadata": {
        "id": "ed559ff1"
      },
      "source": [
        "## 3. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca710799",
      "metadata": {
        "id": "ca710799"
      },
      "source": [
        "#### 3.1 Pre-trained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2caf4a6c",
      "metadata": {
        "id": "2caf4a6c"
      },
      "outputs": [],
      "source": [
        "# def backbone_resnet():\n",
        "#     # 1. ê¸°ë³¸ ResNet50 ìƒì„± (pretrained=Falseë¡œ ì‹œì‘)\n",
        "#     resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "#     # 2. ì²« ë²ˆì§¸ conv ë ˆì´ì–´ë¥¼ 1ì±„ë„ìš©ìœ¼ë¡œ ìˆ˜ì •\n",
        "#     resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "#     # ë¨¼ì € fc ì œê±°\n",
        "#     resnet.fc = nn.Identity()\n",
        "\n",
        "#     # 3. ImageNet ê°€ì¤‘ì¹˜ ë¡œë“œ (conv1 ì œì™¸)\n",
        "#     state_dict = load_state_dict_from_url(\n",
        "#         'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "#         progress=True\n",
        "#     )\n",
        "#     if 'conv1.weight' in state_dict:\n",
        "#         del state_dict['conv1.weight']\n",
        "#     resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "#     return resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad728509",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "class ResNet50(torchvision.models.resnet.ResNet):\n",
        "    def __init__(self, track_bn=True):\n",
        "        def norm_layer(*args, **kwargs):\n",
        "            return nn.BatchNorm2d(*args, **kwargs, track_running_stats=track_bn)\n",
        "        super().__init__(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], norm_layer=norm_layer)\n",
        "        del self.fc\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.final_feat_dim = 2048\n",
        "\n",
        "    def load_sl_official_weights(self, progress=True):\n",
        "        weights = ResNet50_Weights.DEFAULT\n",
        "        state_dict = weights.get_state_dict(progress=progress)\n",
        "\n",
        "        del state_dict['conv1.weight']\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "        # if len(missing) > 0:\n",
        "            # raise AssertionError('Model code may be incorrect')\n",
        "\n",
        "    def load_ssl_official_weights(self, progress=True):\n",
        "        # only SimCLR is available\n",
        "        from pl_bolts.models.self_supervised import SimCLR\n",
        "        \n",
        "        weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
        "        simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
        "\n",
        "        state_dict = {}\n",
        "        for k, v in simclr.state_dict().items():\n",
        "            if 'encoder.' in k:\n",
        "                k = k.replace('encoder.', '')\n",
        "            if 'fc' not in k or 'project' not in k:\n",
        "                state_dict[k] = v\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "        # non_linear_evaluator.block_forward is a pretrained MLP classifier for SimCLR\n",
        "        # refer to https://github.com/Lightning-AI/lightning-bolts/blob/bcbbf6ab6c36430946dd8a416ddc7e697e8507fc/pl_bolts/models/self_supervised/evaluator.py#L7\n",
        "        if len(missing) > 0:\n",
        "            raise AssertionError('Model code may be incorrect')\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76dbd0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_resnet50_patch():\n",
        "    \"\"\"\n",
        "    MoCo êµ¬ì¡°ì— ì‚¬ìš©í•  CNN6 ë°±ë³¸ ì •ì˜ í•¨ìˆ˜.\n",
        "    \n",
        "    ì£¼ìš” ë³€ê²½ ì‚¬í•­:\n",
        "    - ResNet50 ëŒ€ì‹  CNN6 í´ë˜ìŠ¤ ì‚¬ìš©\n",
        "    - ì¶œë ¥ feature dimì€ 512ë¡œ ê³ ì •ë¨ (MoCoì—ì„œëŠ” dim_enc=2048 â†’ ì´ ë¶€ë¶„ë§Œ ë§ì¶°ì„œ ì‚¬ìš©í•˜ë©´ ë¬¸ì œ ì—†ìŒ)\n",
        "    - ImageNet pretrained ì‚¬ìš© ëŒ€ì‹  ê³µì‹ CNN6 pretrained ë¡œë”© í•¨ìˆ˜ í¬í•¨ (ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥)\n",
        "    \"\"\"\n",
        "    model = ResNet50()\n",
        "\n",
        "    # ê³µì‹ SL pretrained weightë¥¼ ì‚¬ìš©í•˜ê³ ì í•  ê²½ìš° ì•„ë˜ ì¤„ì„ ì£¼ì„ í•´ì œ\n",
        "    model.load_sl_official_weights()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d7776d9",
      "metadata": {},
      "source": [
        "#### 3.2 Pre-trained CNN6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0de338c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def init_layer(layer):\n",
        "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "    if hasattr(layer, 'bias'):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "            \n",
        "\n",
        "def init_bn(bn):\n",
        "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.)\n",
        "\n",
        "\n",
        "class ConvBlock5x5(nn.Module): #for CNN6\n",
        "    def __init__(self, in_channels, out_channels, stride=(1,1)):\n",
        "        \n",
        "        super(ConvBlock5x5, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=(5, 5), stride=stride,\n",
        "                              padding=(2, 2), bias=False)\n",
        "                              \n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.init_weight()\n",
        "        \n",
        "    def init_weight(self):\n",
        "        init_layer(self.conv1)\n",
        "        init_bn(self.bn1)\n",
        "        \n",
        "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):        \n",
        "        x = input\n",
        "        x = F.relu_(self.bn1(self.conv1(x)))\n",
        "        if pool_type == 'max':\n",
        "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg':\n",
        "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg+max':\n",
        "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            x = x1 + x2\n",
        "        else:\n",
        "            raise Exception('Incorrect argument!')\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN6, self).__init__()\n",
        "        self.final_feat_dim = 512\n",
        "\n",
        "        self.do_dropout = False\n",
        "        self.conv_block1 = ConvBlock5x5(in_channels=1, out_channels=64, stride=(1,1))\n",
        "        self.conv_block2 = ConvBlock5x5(in_channels=64, out_channels=128, stride=(1,1))\n",
        "        self.conv_block3 = ConvBlock5x5(in_channels=128, out_channels=256, stride=(1,1))\n",
        "        self.conv_block4 = ConvBlock5x5(in_channels=256, out_channels=512, stride=(1,1))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # self.linear = nn.Linear(512, num_classes, bias=True)\n",
        "\n",
        "    def load_sl_official_weights(self):\n",
        "        \"\"\" download AudioSet pretrained CNN6 in https://zenodo.org/record/3960586#.Y8dz8y_kEiY\n",
        "        \"\"\"\n",
        "        weights = torch.load('/home/HyeonSeok/Cnn6_mAP=0.343.pth')['model']\n",
        "        state_dict = {k: v for k, v in weights.items() if k in self.state_dict().keys()}\n",
        "        missing, unexpected = self.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def forward(self, x, return_feature_map=False):\n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
        "        if self.do_dropout:\n",
        "            x = self.dropout(x)\n",
        "        \n",
        "        if return_feature_map:\n",
        "            return x  # shape: (B, 512, 4, 16)\n",
        "\n",
        "        x = torch.mean(x, dim=3) #mean over time dim\n",
        "        (x1, _) = torch.max(x, dim=2) #max over freq dim\n",
        "        x2 = torch.mean(x, dim=2) #mean over freq dim (after mean over time)\n",
        "        x = x1 + x2\n",
        "\n",
        "        # if self.embed_only:\n",
        "        #     return x\n",
        "        # return self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f839c412",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_cnn6():\n",
        "    \"\"\"\n",
        "    MoCo êµ¬ì¡°ì— ì‚¬ìš©í•  CNN6 ë°±ë³¸ ì •ì˜ í•¨ìˆ˜.\n",
        "    \n",
        "    ì£¼ìš” ë³€ê²½ ì‚¬í•­:\n",
        "    - ResNet50 ëŒ€ì‹  CNN6 í´ë˜ìŠ¤ ì‚¬ìš©\n",
        "    - ì¶œë ¥ feature dimì€ 512ë¡œ ê³ ì •ë¨ (MoCoì—ì„œëŠ” dim_enc=2048 â†’ ì´ ë¶€ë¶„ë§Œ ë§ì¶°ì„œ ì‚¬ìš©í•˜ë©´ ë¬¸ì œ ì—†ìŒ)\n",
        "    - ImageNet pretrained ì‚¬ìš© ëŒ€ì‹  ê³µì‹ CNN6 pretrained ë¡œë”© í•¨ìˆ˜ í¬í•¨ (ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥)\n",
        "    \"\"\"\n",
        "    model = CNN6()\n",
        "\n",
        "    # ê³µì‹ SL pretrained weightë¥¼ ì‚¬ìš©í•˜ê³ ì í•  ê²½ìš° ì•„ë˜ ì¤„ì„ ì£¼ì„ í•´ì œ\n",
        "    model.load_sl_official_weights()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89cdc7f9",
      "metadata": {},
      "source": [
        "##### 3.3 Multilabel Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b8f81d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MultilabelAttention(nn.Module):\n",
        "    def __init__(self, backbone, num_classes=2, lambda_attn=0.5, attention_heads=[1, float('inf')]):\n",
        "        super(MultilabelAttention, self).__init__()\n",
        "        self.backbone = backbone()\n",
        "        self.num_classes = num_classes\n",
        "        self.lambda_attn = lambda_attn\n",
        "        self.attention_heads = attention_heads  # e.g., [1, inf] for H=2\n",
        "\n",
        "        self.class_weights = nn.Parameter(torch.randn(len(attention_heads), num_classes, 512))\n",
        "\n",
        "        self.output_layer = nn.ModuleList([\n",
        "            nn.Linear(512, 1) for _ in range(num_classes)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN6 ë°±ë³¸ í†µê³¼ â†’ shape: (B, 512, 4, 16)\n",
        "        feat_map = self.backbone(x, return_feature_map=True)  # (B, 512, 4, 16)\n",
        "\n",
        "        B, C, Freq, Time = feat_map.shape\n",
        "        flat_feat = feat_map.view(B, C, Freq * Time).permute(0, 2, 1)  # (B, 64, 512)\n",
        "\n",
        "        # Class-specific attention a_i ê³„ì‚°\n",
        "        attn_outputs = []\n",
        "        for h, T in enumerate(self.attention_heads):\n",
        "            Ci = self.class_weights[h]  # (num_classes, 512)\n",
        "            logits = torch.einsum(\"bnc, kc -> bnk\", flat_feat, Ci)  # (B, 64, num_classes)\n",
        "            logits = logits.permute(0, 2, 1)  # (B, num_classes, 64)\n",
        "            if T == float('inf'):\n",
        "                attn_scores = F.one_hot(torch.argmax(logits, dim=2), num_classes=logits.shape[2]).float()\n",
        "            else:\n",
        "                attn_scores = F.softmax(T * logits, dim=2)  # (B, num_classes, 64)\n",
        "\n",
        "            attn_scores = attn_scores.unsqueeze(-1)  # (B, num_classes, 64, 1)\n",
        "            flat_feat_exp = flat_feat.unsqueeze(1)  # (B, 1, 64, 512)\n",
        "            attn_feat = torch.sum(attn_scores * flat_feat_exp, dim=2)  # (B, num_classes, 512)\n",
        "            attn_outputs.append(attn_feat)\n",
        "\n",
        "        # Class-specific global feature g_i ê³„ì‚°\n",
        "        feat_avg_t = torch.mean(feat_map, dim=3)  # (B, 512, Freq)\n",
        "        gmp = torch.max(feat_avg_t, dim=2)[0]     # (B, 512)\n",
        "        gap = torch.mean(feat_avg_t, dim=2)       # (B, 512)\n",
        "        g = gmp + gap                             # (B, 512)\n",
        "        g = g.unsqueeze(1).repeat(1, self.num_classes, 1)  # (B, num_classes, 512)\n",
        "\n",
        "        # Combine: f_i = g_i + lambda * a_i\n",
        "        combined = g\n",
        "        for attn in attn_outputs:\n",
        "            combined = combined + self.lambda_attn * attn  # sum over heads\n",
        "\n",
        "        # Output layer for each class\n",
        "        out = []\n",
        "        for i in range(self.num_classes):\n",
        "            cls_feat = combined[:, i, :]  # (B, 512)\n",
        "            logit = self.output_layer[i](cls_feat).squeeze(-1)  # (B,)\n",
        "            out.append(logit)\n",
        "\n",
        "        logits = torch.stack(out, dim=1)  # (B, num_classes)\n",
        "        probs = torch.sigmoid(logits)    # (B, num_classes)\n",
        "        return combined, logits, probs                 # ë§ˆì§€ë§‰ dim: (B, 2, 512) \n",
        "\n",
        "\n",
        "def backbone_mlattention():\n",
        "    \"\"\"\n",
        "    Multi-label attention ê¸°ë°˜ backbone ì •ì˜ í•¨ìˆ˜\n",
        "    CNN6 ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œê¸° + CSRA ê¸°ë°˜ attention êµ¬ì¡° ê²°í•©\n",
        "    \n",
        "    Returns:\n",
        "        nn.Module: Multi-label attention ê¸°ë°˜ ë¶„ë¥˜ê¸°\n",
        "    \"\"\"\n",
        "    return MultilabelAttention(backbone=backbone_cnn6, num_classes=2, lambda_attn=0.5, attention_heads=[1, float('inf')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895f8785",
      "metadata": {},
      "outputs": [],
      "source": [
        "# x = torch.randn(10, 1, 64, 256) # B=10\n",
        "# model = backbone_mlattention()\n",
        "# out = model(x)  # (B, 2, 512)\n",
        "\n",
        "# print(f\"\\ntorch.Size : {out.shape}\")  # â†’ torch.Size([B=10, 2, 512])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a796d30",
      "metadata": {},
      "source": [
        "##### 3.4 Mix-MultiLabel Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8515e944",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def group_mix(group_spec, labels, beta=2.0):\n",
        "    \"\"\"\n",
        "    Group-wise PatchMix (spatial domain) for group_spec of shape [B, 64, 512]\n",
        "    \"\"\"\n",
        "    B, N, D = group_spec.shape  # B: ë°°ì¹˜ í¬ê¸°, N: ê·¸ë£¹ ìˆ˜ (ex. 64), D: ì°¨ì› ìˆ˜ (ex. 512)\n",
        "                                # e.g., group_spec.shape == [B, 64, 512]\n",
        "\n",
        "    device = group_spec.device  # e.g., 'cuda:0'\n",
        "\n",
        "    # ğŸ”¹ lam: beta ë¶„í¬ì—ì„œ ìƒ˜í”Œë§ (mix ë¹„ìœ¨)\n",
        "    lam = np.random.beta(beta, beta)  # scalar float (e.g., 0.66)\n",
        "\n",
        "    # ğŸ”¹ num_mask: ì´ N ê·¸ë£¹ ì¤‘ì—ì„œ ëª‡ ê°œë¥¼ ì„ì„ì§€ ê²°ì •\n",
        "    num_mask = int(N * (1. - lam))  # scalar int (e.g., 64 * 0.34 = 21)\n",
        "\n",
        "    # ğŸ”¹ mask: ì„ì„ group index (ê³µí†µ)\n",
        "    mask = torch.randperm(N)[:num_mask].to(device)  # shape: [num_mask] (e.g., [21])\n",
        "\n",
        "    # ğŸ”¹ index: ë‹¤ë¥¸ sampleê³¼ ì„ê¸° ìœ„í•´ ìˆœì„œë¥¼ ì„ìŒ\n",
        "    index = torch.randperm(B).to(device)  # shape: [B] (e.g., [3, 0, 1, 2])\n",
        "\n",
        "    # ğŸ”¹ mix: ê°™ì€ ìœ„ì¹˜ì˜ groupë“¤ì„ index ê¸°ì¤€ìœ¼ë¡œ ì„ê¸°\n",
        "    mixed_group_spec = group_spec.clone()                  # shape: [B, 64, 512]\n",
        "    mixed_group_spec[:, mask, :] = group_spec[index][:, mask, :]  \n",
        "    # group_spec[index]: shape [B, 64, 512]\n",
        "    # group_spec[index][:, mask, :]: shape [B, num_mask, 512]\n",
        "    # ìµœì¢…ì ìœ¼ë¡œ mixed_group_spec[:, mask, :]: shape [B, num_mask, 512]\n",
        "\n",
        "    # ğŸ”¹ lam_tensor: ê° sampleì— ëŒ€í•´ lam ê°’ì„ broadcasting í•˜ê¸° ìœ„í•œ í…ì„œ\n",
        "    lam_tensor = torch.full((B,), lam, device=device)  # shape: [B] (e.g., [0.66, 0.66, 0.66, 0.66])\n",
        "\n",
        "    # ğŸ”¹ return: ì„ì€ group, ì›ë˜ ë¼ë²¨, ì„ì¸ ë¼ë²¨, lam ê°’, ì„ì¸ index\n",
        "    return mixed_group_spec, labels, labels[index], lam_tensor, index\n",
        "    # mixed_group_spec: shape [B, 64, 512]\n",
        "    # labels: shape [B] ë˜ëŠ” [B, C] (ë©€í‹°í´ë˜ìŠ¤ì¸ì§€ ë©€í‹°ë¼ë²¨ì¸ì§€ì— ë”°ë¼ ë‹¤ë¦„)\n",
        "    # labels[index]: shape [B] ë˜ëŠ” [B, C]\n",
        "    # lam_tensor: shape [B]\n",
        "    # index: shape [B]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a00d8660",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GroupMixConLoss(torch.nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, proj_orig, proj_mix, labels_a, labels_b, lam, index):\n",
        "        \"\"\"\n",
        "        proj_orig: [B, D]   # ì›ë³¸ representation (e.g., global pooled feature)\n",
        "        proj_mix : [B, D]   # group-mix ì ìš©ëœ representation\n",
        "        labels_a:  [B, C] or [B]   # ì›ë˜ ë¼ë²¨\n",
        "        labels_b:  [B, C] or [B]   # ì„ì¸ ë¼ë²¨\n",
        "        lam:       [B]             # ê° ìƒ˜í”Œë§ˆë‹¤ lam ê°’\n",
        "        index:     [B]             # ì„ì¸ ëŒ€ìƒ ì¸ë±ìŠ¤\n",
        "        \"\"\"\n",
        "        B = proj_orig.size(0)           # ë°°ì¹˜ í¬ê¸°\n",
        "        device = proj_orig.device\n",
        "\n",
        "        # ğŸ”¹ L2 ì •ê·œí™”\n",
        "        proj_orig = F.normalize(proj_orig, dim=1)   # [B, D]\n",
        "        proj_mix  = F.normalize(proj_mix, dim=1)    # [B, D]\n",
        "        # print(f\"proj_orig.shape: {proj_orig.shape}, proj_mix.shape: {proj_mix.shape}\")\n",
        "\n",
        "        # ğŸ”¹ ìœ ì‚¬ë„ í–‰ë ¬: mix vs. original ê°„ì˜ ë‚´ì \n",
        "        sim_matrix = torch.matmul(proj_mix, proj_orig.T) / self.temperature  \n",
        "        # [B, D] x [D, B] -> [B, B]\n",
        "\n",
        "        # ğŸ”¹ ë§ˆìŠ¤í¬ A: ì›ë˜ ìê¸° ìì‹ ì´ë‘ë§Œ 1ì¸ ë§ˆìŠ¤í¬\n",
        "        mask_a = torch.eye(B, device=device)  # [B, B]\n",
        "\n",
        "        # ğŸ”¹ ë§ˆìŠ¤í¬ B: ê° mixê°€ ì„ì¸ ëŒ€ìƒê³¼ 1ì¸ ë§ˆìŠ¤í¬\n",
        "        mask_b = torch.zeros_like(mask_a)     # [B, B]\n",
        "        mask_b[torch.arange(B), index] = 1    # ì˜ˆ: i-th rowì—ì„œ index[i] columnì— 1\n",
        "\n",
        "        # ğŸ”¹ soft positive mask = lam * identity + (1 - lam) * mix_target\n",
        "        # lam: [B] -> [B, 1], broadcasting ë¨\n",
        "        mask = lam.view(-1, 1) * mask_a + (1 - lam).view(-1, 1) * mask_b  # [B, B]\n",
        "\n",
        "        # ğŸ”¹ softmax log-prob ê³„ì‚°\n",
        "        log_prob = sim_matrix - torch.logsumexp(sim_matrix, dim=1, keepdim=True)  \n",
        "        # log_softmax(sim_matrix, dim=1)ê³¼ ë™ì¼\n",
        "        # sim_matrix: [B, B], log_prob: [B, B]\n",
        "\n",
        "        # ğŸ”¹ positive log-probë§Œ í‰ê· ëƒ„\n",
        "        # ê° row (i)ì—ì„œ soft positiveì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ì— ëŒ€í•´ì„œë§Œ log_prob * mask\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(dim=1) / mask.sum(dim=1)  # [B]\n",
        "\n",
        "        # ğŸ”¹ ì „ì²´ í‰ê·  loss\n",
        "        loss = -mean_log_prob_pos.mean()  # scalar\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09304124",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MixMLATT(nn.Module):\n",
        "    def __init__(self, backbone, num_classes=2, lambda_attn=0.5, attention_heads=[1, float('inf')], projector_dim=128):\n",
        "        super(MixMLATT, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.lambda_attn = lambda_attn\n",
        "        self.attention_heads = attention_heads\n",
        "\n",
        "        # CNN6 ë°±ë³¸ (e.g., CNN6 â†’ [B, 512, 4, 16])\n",
        "        self.backbone = backbone()\n",
        "\n",
        "        # Class-specific Attention weights: ê° headë§ˆë‹¤ [num_classes, 512]\n",
        "        self.class_weights = nn.Parameter(torch.randn(len(attention_heads), num_classes, 512))\n",
        "\n",
        "    def forward(self, x, mix_feature=False, patch_mix=False, y=None, lam=None, index=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input spectrogram [B, 1, F, T]\n",
        "            return_mix_feature: whether to return raw mixed [B, 64, 512] for CE/classifier\n",
        "            patch_mix: whether to perform group-wise patch mix\n",
        "            y: labels (only used when patch_mix is True)\n",
        "            lam: lambda for mixup\n",
        "            index: mix index for patch selection\n",
        "        Returns:\n",
        "            attn_feat: [B, num_classes, 512]\n",
        "            logits: [B, num_classes]\n",
        "            probs: [B, num_classes]\n",
        "            raw_feat: [B, 64, 512] (for CE/classifier)\n",
        "        \"\"\"\n",
        "        B = x.size(0)\n",
        "        origin_feat = None\n",
        "\n",
        "        # 1. CNN6 Backbone â†’ [B, 512, 4, 16]\n",
        "        feat_map = self.backbone(x, return_feature_map=True)  # (B, 512, 4, 16)\n",
        "\n",
        "        # 2. Reshape â†’ [B, 64, 512]\n",
        "        feat_flat = feat_map.view(B, 512, -1).permute(0, 2, 1)  # (B, 64, 512)\n",
        "\n",
        "        # 3. Optional: Patch-wise Mixing\n",
        "        if patch_mix and y is not None:\n",
        "            # 1. group_mix ìˆ˜í–‰\n",
        "            # mixed_group_spec, labels, labels[index], lam_tensor, index\n",
        "            feat_flat, label_origin, label_mix, lam, index = group_mix(feat_flat, y)\n",
        "\n",
        "            # 2. origin_feat ì €ì¥\n",
        "            origin_feat = feat_flat.detach() if mix_feature else None\n",
        "\n",
        "        # 4. CSRA Attention\n",
        "        attn_outputs = []\n",
        "        for h, T in enumerate(self.attention_heads):\n",
        "            class_weight = self.class_weights[h]  # (num_classes, 512)\n",
        "            logits = torch.einsum(\"bnc,kc->bnk\", feat_flat, class_weight)  # (B, 64, num_classes)\n",
        "            logits = logits.permute(0, 2, 1)  # (B, num_classes, 64)\n",
        "\n",
        "            if T == float('inf'):\n",
        "                attn_scores = F.one_hot(torch.argmax(logits, dim=2), num_classes=logits.shape[2]).float()\n",
        "            else:\n",
        "                attn_scores = F.softmax(T * logits, dim=2)\n",
        "\n",
        "            attn_scores = attn_scores.unsqueeze(-1)           # (B, num_classes, 64, 1)\n",
        "            feat_exp = feat_flat.unsqueeze(1)                 # (B, 1, 64, 512)\n",
        "            attn_feat = torch.sum(attn_scores * feat_exp, dim=2)  # (B, num_classes, 512)\n",
        "            attn_outputs.append(attn_feat)\n",
        "\n",
        "        # 5. Global Feature Aggregation\n",
        "        feat_avg_t = torch.mean(feat_map, dim=3)  # (B, 512, Freq)\n",
        "        gmp = torch.max(feat_avg_t, dim=2)[0]     # (B, 512)\n",
        "        gap = torch.mean(feat_avg_t, dim=2)       # (B, 512)\n",
        "        g = gmp + gap                             # (B, 512)\n",
        "        g = g.unsqueeze(1).repeat(1, self.num_classes, 1)  # (B, num_classes, 512)\n",
        "\n",
        "        # 6. Combine Global + Attention Feature\n",
        "        attn_feat = g\n",
        "        for attn in attn_outputs:\n",
        "            attn_feat = attn_feat + self.lambda_attn * attn  # (B, num_classes, 512)\n",
        "\n",
        "        # 8. Return\n",
        "        if not patch_mix:\n",
        "            return attn_feat, origin_feat # [B, 2, 512], [B, 64, 512]\n",
        "        else:\n",
        "            return attn_feat, origin_feat, label_origin, label_mix, lam, index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1648eb8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def backbone_mixmlatt():\n",
        "    \"\"\"\n",
        "    Multi-label attention ê¸°ë°˜ backbone ì •ì˜ í•¨ìˆ˜\n",
        "    CNN6 ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œê¸° + CSRA ê¸°ë°˜ attention êµ¬ì¡° ê²°í•©\n",
        "    \n",
        "    Returns:\n",
        "        nn.Module: Multi-label attention ê¸°ë°˜ ë¶„ë¥˜ê¸°\n",
        "    \"\"\"\n",
        "    return MixMLATT(backbone=backbone_cnn6, num_classes=2, lambda_attn=0.5, attention_heads=[1, float('inf')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f21daa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f21daa",
        "outputId": "0c812f61-67a5-474c-a91e-2ed67a2c0c78"
      },
      "outputs": [],
      "source": [
        "# summary í•¨ìˆ˜ ì‚¬ìš©: (ì±„ë„, ë†’ì´, ë„ˆë¹„) í¬ê¸°ë¥¼ ì§€ì •\n",
        "summary(backbone_mixmlatt().to(device), input_size=(1, 64, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc1bf21",
      "metadata": {
        "id": "1cc1bf21"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-BkAfkqhyHrY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkAfkqhyHrY",
        "outputId": "70fa83d7-4e71-4275-eb00-1531ed151726"
      },
      "outputs": [],
      "source": [
        "next(iter(pretrain_loader))[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5056744",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, classifier, projector_0, projector_1, val_loader, criterion, device, args):\n",
        "    \"\"\"\n",
        "    Multi-label + GroupMix Contrastive í‰ê°€ìš© ê²€ì¦ í•¨ìˆ˜\n",
        "    - args.target_type ì— ë”°ë¼ grad_block, grad_flow, etc. ì²˜ë¦¬\n",
        "    - ì…ë ¥: inputs [B, 1, F, T], labels [B, 2]\n",
        "    - ì¶œë ¥: í‰ê·  loss, ì „ì²´ label, ì „ì²´ ì˜ˆì¸¡ê°’\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    model.eval()\n",
        "    classifier.eval()\n",
        "    projector_0.eval()\n",
        "    projector_1.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 1. Original forward (patch_mix=False)\n",
        "            attn_feat, _ = model(inputs, mix_feature=True, patch_mix=False)  # [B, 2, 512]\n",
        "\n",
        "            # 2. Classification logits\n",
        "            out = []\n",
        "            for i in range(attn_feat.shape[1]):\n",
        "                cls_feat = attn_feat[:, i, :]               # [B, 512]\n",
        "                logit = classifier[i](cls_feat).squeeze(-1) # [B]\n",
        "                out.append(logit)\n",
        "            logits = torch.stack(out, dim=1)  # [B, 2]\n",
        "\n",
        "            # 3. classification loss\n",
        "            loss_ce = criterion[0](logits, labels)\n",
        "\n",
        "            # 4. Projector1 (target type ì„¤ì •)\n",
        "            if args.target_type == 'grad_block':\n",
        "                proj1_0 = projector_0(attn_feat[:, 0, :].detach())\n",
        "                proj1_1 = projector_1(attn_feat[:, 1, :].detach())\n",
        "            elif args.target_type == 'grad_flow':\n",
        "                proj1_0 = projector_0(attn_feat[:, 0, :])\n",
        "                proj1_1 = projector_1(attn_feat[:, 1, :])\n",
        "            elif args.target_type == 'project_block':\n",
        "                proj1_0 = projector_0(attn_feat[:, 0, :]).detach()\n",
        "                proj1_1 = projector_1(attn_feat[:, 1, :]).detach()\n",
        "            elif args.target_type == 'project_flow':\n",
        "                proj1_0 = projector_0(attn_feat[:, 0, :])\n",
        "                proj1_1 = projector_1(attn_feat[:, 1, :])\n",
        "\n",
        "            # 5. PatchMix ì ìš© (mix_feature=True)\n",
        "            mix_attn_feat, origin_feat, label_origin, label_mix, lam, index = model(inputs, y=labels, patch_mix=True, mix_feature=True)\n",
        "\n",
        "            # 6. mixëŠ” ë¬´ì¡°ê±´ projector í†µê³¼\n",
        "            proj2_0 = projector_0(mix_attn_feat[:, 0, :])\n",
        "            proj2_1 = projector_1(mix_attn_feat[:, 1, :])\n",
        "\n",
        "            # 7. Contrastive loss\n",
        "            loss_con0 = criterion[1](proj1_0, proj2_0, label_origin, label_mix, lam, index)\n",
        "            loss_con1 = criterion[1](proj1_1, proj2_1, label_origin, label_mix, lam, index)\n",
        "\n",
        "            # 8. Total loss\n",
        "            loss = loss_ce + args.alpha * (loss_con0 + loss_con1)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # 9. Prediction\n",
        "            preds = (torch.sigmoid(logits) > 0.5).int()\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()   # [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy() # [N, 2]\n",
        "\n",
        "    avg_loss = running_loss / len(val_loader)\n",
        "    return avg_loss, all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69de32ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from copy import deepcopy\n",
        "from torch.cuda.amp import GradScaler\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "# from utils.meters import AverageMeter\n",
        "################################\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_icbhi_scores = []\n",
        "test_icbhi_scores = []\n",
        "test_labels_all = []\n",
        "test_preds_all = []\n",
        "epochs = []\n",
        "\n",
        "# ëª¨ë¸ ì§€ì •í•˜ê¸° ì „ seed ê³ ì • í•„ìš”\n",
        "seed_everything(args.seed) # Seed ê³ ì •\n",
        "\n",
        "pretrain_project_name = f'ATT_{args.dim_prj}prj_{args.batch_size}bs_{args.top_k}topk_{args.weight_decay}wd_{args.lambda_bce}ld_2beta_{get_timestamp()}'\n",
        "\n",
        "# -------------------------------------------wan\n",
        "# wandb ì´ˆê¸°í™” (í”„ë¡œì íŠ¸ëª…, ì‹¤í—˜ ì´ë¦„ ë“± ì„¤ì •)\n",
        "wandb.init(\n",
        "    project=\"SHS_ATT\", # í”„ë¡œì íŠ¸ ì´ë¦„\n",
        "    name=f\"{pretrain_project_name}\",  # ì‹¤í—˜ ì´ë¦„\n",
        "    config={\n",
        "        \"epochs\": args.epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay\n",
        "    }\n",
        ")\n",
        "# -------------------------------------------wan\n",
        "\n",
        "################################\n",
        "# 1. Model / Classifier \n",
        "model = MixMLATT(backbone=backbone_cnn6, \n",
        "                 num_classes=2, \n",
        "                 lambda_attn=0.5, \n",
        "                 attention_heads=[1, float('inf')]\n",
        "                 ).cuda()\n",
        "\n",
        "classifier = nn.ModuleList([nn.Linear(args.out_dim, 1) for _ in range(2)]).cuda()\n",
        "\n",
        "# 2. Projector 0/1\n",
        "projector_0 = nn.Sequential(nn.Linear(args.out_dim, args.out_dim),nn.ReLU(),nn.Linear(args.out_dim, args.dim_prj)).cuda()\n",
        "projector_1 = nn.Sequential(nn.Linear(args.out_dim, args.out_dim),nn.ReLU(),nn.Linear(args.out_dim, args.dim_prj)).cuda()\n",
        "\n",
        "# 3. EMA ì„ ì–¸\n",
        "ema_model = deepcopy(model)\n",
        "ema_projector_0 = deepcopy(projector_0)\n",
        "ema_projector_1 = deepcopy(projector_1)\n",
        "ema_classifier = deepcopy(classifier)\n",
        "for m in [ema_model, ema_projector_0, ema_projector_1, ema_classifier]:\n",
        "    m.eval()\n",
        "    for p in m.parameters():\n",
        "        p.requires_grad_(False)\n",
        "\n",
        "# 4. criterion\n",
        "criterion = [\n",
        "    nn.BCEWithLogitsLoss().cuda(),       # criterion[0]: classification\n",
        "    GroupMixConLoss(temperature=0.07).cuda()  # criterion[1]: contrastive\n",
        "]\n",
        "\n",
        "# 5. optimizer  \n",
        "optimizer = optim.Adam(\n",
        "    list(model.parameters()) + list(classifier.parameters()) + \n",
        "    list(projector_0.parameters()) + list(projector_1.parameters()),\n",
        "    lr=args.lr, weight_decay=args.weight_decay\n",
        ")\n",
        "\n",
        "\n",
        "# 6. EMA (Exponential Moving Average) ì„¤ì •\n",
        "@torch.no_grad()\n",
        "def update_ema(student, ema, beta=0.999):\n",
        "    for param, ema_param in zip(student.parameters(), ema.parameters()):\n",
        "        ema_param.data = beta * ema_param.data + (1 - beta) * param.data\n",
        "\n",
        "\n",
        "# 7. Train\n",
        "# Best loss ì´ˆê¸°í™”\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    # ===============================\n",
        "    # Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    projector_0.train()\n",
        "    projector_1.train()\n",
        "    classifier.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    pbar = tqdm(pretrain_loader, desc='Mix_MLATT Trainig only')\n",
        "    for idx, (repeat_mel, labels, _) in enumerate(pretrain_loader):\n",
        "        # # (0) EMA ì €ì¥\n",
        "        # if args.ma_update:\n",
        "        #     with torch.no_grad():\n",
        "        #         ma_ckpt = [\n",
        "        #             deepcopy(model.state_dict()),\n",
        "        #             deepcopy(projector_0.state_dict()),\n",
        "        #             deepcopy(projector_1.state_dict()),\n",
        "        #             deepcopy(classifier.state_dict())\n",
        "        #         ]\n",
        "\n",
        "        repeat_mel = repeat_mel.cuda(non_blocking=True)\n",
        "        labels = labels.cuda(non_blocking=True)\n",
        "        bsz = labels.size(0)\n",
        "\n",
        "\n",
        "        # (1) Original ì´ë¯¸ì§€ forward\n",
        "        # attn_feat: [B, 2, 512], origin_feat: [B, 64, 512]\n",
        "        attn_feat, _ = model(repeat_mel, mix_feature=True, patch_mix=False)\n",
        "        out = []\n",
        "        for i in range(args.num_classes):\n",
        "            cls_feat = attn_feat[:, i, :]  # (B, 512)\n",
        "            logit = classifier[i](cls_feat).squeeze(-1)  # (B,)\n",
        "            out.append(logit)\n",
        "        logits = torch.stack(out, dim=1) # [B, 2]\n",
        "\n",
        "        # (2) classification loss\n",
        "        loss_ce = criterion[0](logits, labels)\n",
        "\n",
        "        # (3) projector1 ìƒì„± (classë³„)\n",
        "        if args.target_type == 'grad_block':\n",
        "            proj1_0 = projector_0(attn_feat[:, 0, :].detach())   # [B, 128]\n",
        "            proj1_1 = projector_1(attn_feat[:, 1, :].detach())\n",
        "        elif args.target_type == 'grad_flow':\n",
        "            proj1_0 = attn_feat[:, 0, :]\n",
        "            proj1_1 = attn_feat[:, 1, :]\n",
        "        elif args.target_type == 'project_block':\n",
        "            proj1_0 = deepcopy(projector_0(attn_feat[:, 0, :]).detach())\n",
        "            proj1_1 = deepcopy(projector_1(attn_feat[:, 1, :]).detach())\n",
        "        elif args.target_type == 'project_flow':\n",
        "            proj1_0 = projector_0(attn_feat[:, 0, :])\n",
        "            proj1_1 = projector_1(attn_feat[:, 1, :])\n",
        "\n",
        "        # (4) PatchMix ìˆ˜í–‰ (mixëœ ì´ë¯¸ì§€ ë°˜í™˜)\n",
        "        mix_attn_feat, origin_feat, label_origin, label_mix, lam, index = model(repeat_mel, y=labels, patch_mix=True, mix_feature=True)\n",
        "\n",
        "        # (5) mixëŠ” ë¬´ì¡°ê±´ projector í†µê³¼\n",
        "        proj2_0 = mix_attn_feat[:, 0, :]  # [B, 128]\n",
        "        proj2_1 = mix_attn_feat[:, 1, :]\n",
        "\n",
        "        # (6) GroupMixConLoss & Final loss ê³„ì‚°\n",
        "        loss_con0 = criterion[1](proj1_0, proj2_0, label_origin, label_mix, lam, index)\n",
        "        loss_con1 = criterion[1](proj1_1, proj2_1, label_origin, label_mix, lam, index)\n",
        "        loss = loss_ce + args.alpha * (loss_con0 + loss_con1)\n",
        "        \n",
        "\n",
        "        # (8) Backpopagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # (9) EMA ì—…ë°ì´íŠ¸\n",
        "        if args.ma_update:\n",
        "            update_ema(model, ema_model, beta=args.ma_beta)\n",
        "            update_ema(projector_0, ema_projector_0, beta=args.ma_beta)\n",
        "            update_ema(projector_1, ema_projector_1, beta=args.ma_beta)\n",
        "            update_ema(classifier, ema_classifier, beta=args.ma_beta)\n",
        "\n",
        "        # (10) Loss ê¸°ë¡\n",
        "        total_train_loss += loss.item()\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥ ( Ablation(4-1) threshold ?? )\n",
        "        predicted = (torch.sigmoid(logits) > 0.5).float()\n",
        "        all_preds.append(predicted.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "        all_outputs.append(logits.detach().cpu())\n",
        "\n",
        "\n",
        "    # train loss\n",
        "    train_loss = total_train_loss / len(pretrain_loader)\n",
        "\n",
        "    # Concatenate\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()    # shape: [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy()  # shape: [N, 2]\n",
        "    all_output = torch.cat(all_outputs, dim=0).numpy()\n",
        "\n",
        "    print(f\"[Epoch {epoch} | Train Loss: {train_loss:.4f}, attn_feat: {attn_feat.shape}\")\n",
        "\n",
        "\n",
        "    # =====================================\n",
        "    # 2-Edited. Multi-class ë¯¼ê°ë„/íŠ¹ì´ë„ ê³„ì‚°\n",
        "    # =====================================\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import wandb\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    def multilabel_to_multiclass(y):\n",
        "        # Crackle â†’ 1, Wheeze â†’ 2, Both â†’ 3, None â†’ 0\n",
        "        y = np.array(y)\n",
        "        return y[:, 0] + y[:, 1]*2\n",
        "\n",
        "    def evaluate_multiclass_confusion(y_true, y_pred, class_names=[\"Normal\", \"Wheeze\", \"Crackle\", \"Both\"]):\n",
        "        y_true_cls = multilabel_to_multiclass(y_true)\n",
        "        y_pred_cls = multilabel_to_multiclass(y_pred)\n",
        "\n",
        "        cm = confusion_matrix(y_true_cls, y_pred_cls, labels=[0, 1, 2, 3])\n",
        "\n",
        "        # N_n: ì •ìƒ â†’ ì •ìƒ\n",
        "        N_n = cm[0, 0]\n",
        "        N_total = cm[0].sum()\n",
        "\n",
        "        # ì´ìƒ í´ë˜ìŠ¤ ì •ë‹µ ìˆ˜: W, C, B\n",
        "        W_total = cm[1].sum()\n",
        "        C_total = cm[2].sum()\n",
        "        B_total = cm[3].sum()\n",
        "\n",
        "        # ê°ê°ì˜ ì •ë‹µ â†’ ì •í™•í•œ ì˜ˆì¸¡ë§Œ ê³ ë ¤\n",
        "        W_w = cm[1, 1]\n",
        "        C_c = cm[2, 2]\n",
        "        B_b = cm[3, 3]\n",
        "\n",
        "        SP = N_n / (N_total + 1e-6) #spec\n",
        "        SE = (W_w + C_c + B_b) / (W_total + C_total + B_total + 1e-6) #sense\n",
        "\n",
        "        AS = (SP + SE) / 2\n",
        "        HS = 2 * SP * SE / (SP + SE + 1e-6)\n",
        "\n",
        "        return cm, SE, SP, y_true_cls, y_pred_cls\n",
        "\n",
        "    def log_multiclass_conf_matrix_wandb(cm, class_names, sens, spec, normalize, tag):\n",
        "        # Normalize (ë¹„ìœ¨) ì˜µì…˜\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "            fmt = '.2f'\n",
        "            title = \"Confusion Matrix (Normalized %)\"\n",
        "        else:\n",
        "            fmt = 'd'\n",
        "            title = \"Confusion Matrix (Raw Count)\"\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(7, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(title)\n",
        "\n",
        "        icbhi_score = (sens + spec) / 2\n",
        "        # ìš°í•˜ë‹¨ì— ì„±ëŠ¥ ì¶œë ¥\n",
        "        ax.text(\n",
        "            0.99, 0.15,\n",
        "            f\"Sensitivity: {sens*100:.2f}%\\nSpecificity: {spec*100:.2f}%\\nICBHI Score: {icbhi_score*100:.2f}%\",\n",
        "            ha='right', va='bottom',\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        # wandb.log({tag: wandb.Image(fig)})\n",
        "        # plt.close(fig)\n",
        "        return fig\n",
        "\n",
        "    # 1. 4-class Confusion Matrix í‰ê°€\n",
        "    class_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "    cm_4x4, train_sens, train_spec, y_true_cls, y_pred_cls = evaluate_multiclass_confusion(all_labels, all_preds, class_names)\n",
        "    icbhi_score = (train_sens + train_spec)/2\n",
        "\n",
        "    print(\"4-Class Confusion Matrix:\\n\", cm_4x4)\n",
        "    print(f\"Sensitivity: {train_sens:.4f}, Specificity: {train_spec:.4f}, ICBHI Score: {icbhi_score:.4f}\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Validation\n",
        "    # ===============================\n",
        "    # test_loss, test_labels, test_preds = validate(\n",
        "    #     model, test_loader, criterion, device\n",
        "    # )\n",
        "\n",
        "    test_loss, test_labels, test_preds = validate(\n",
        "        model=ema_model if args.ma_update else model,\n",
        "        classifier=ema_classifier if args.ma_update else classifier,\n",
        "        projector_0=ema_projector_0 if args.ma_update else projector_0,\n",
        "        projector_1=ema_projector_1 if args.ma_update else projector_1,\n",
        "        val_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        args=args\n",
        "    )\n",
        "\n",
        "    precision = precision_score(test_labels, test_preds, average='macro')\n",
        "    recall = recall_score(test_labels, test_preds, average='macro')\n",
        "    f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "    test_cm_4x4, test_sens, test_spec, test_y_true_cls, test_y_pred_cls = evaluate_multiclass_confusion(test_labels, test_preds)\n",
        "    test_icbhi_score = (test_sens+test_spec)/2\n",
        "\n",
        "    print(\"[Validation] Confusion Matrix:\\n\", test_cm_4x4)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"[VALIDATION] Sensitivity: {test_sens:.4f}, Specificity: {test_spec:.4f}, Avg ICBHI Score: {(test_sens+test_spec)/2:.4f}\")\n",
        "    print(\"##################################################\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 4. Confusion Matrix\n",
        "    # ===============================\n",
        "\n",
        "    # 2. Finetune Count Confusion Matrix ì‹œê°í™”\n",
        "    fig_finetune_raw = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, train_sens, train_spec, normalize=False, tag=\"Training_conf_matrix_raw\")\n",
        "    fig_finetune_norm = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, train_sens, train_spec, normalize=True, tag=\"Training_conf_matrix_norm\")\n",
        "\n",
        "    # 3. Test Confusion Matrix ì‹œê°í™”\n",
        "    fig_test_raw = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=False, tag=\"test_conf_matrix_raw\")\n",
        "    fig_test_norm = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=True, tag=\"test_conf_matrix_norm\")\n",
        "\n",
        "    # 4. log dictionary ìƒì„± -------------------------------------------wan\n",
        "    wandb_log_dict = {\n",
        "        \"finetune_conf_matrix_raw\": wandb.Image(fig_finetune_raw),\n",
        "        \"finetune_conf_matrix_norm\": wandb.Image(fig_finetune_norm),\n",
        "        \"test_conf_matrix_raw\": wandb.Image(fig_test_raw),\n",
        "        \"test_conf_matrix_norm\": wandb.Image(fig_test_norm)\n",
        "    }\n",
        "    # -------------------------------------------wan\n",
        "\n",
        "    # =====================================\n",
        "    # 5. Checkpoint (Every 100 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"ğŸ’¾ Saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "        # =====================================\n",
        "        # EMA ëª¨ë¸ ì €ì¥ (ì¡°ê±´: EMA í™œì„±í™”ì¼ ë•Œ)\n",
        "        if args.ma_update:\n",
        "            ema_ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_ema_{epoch:03d}.pth.tar\"\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': ema_model.state_dict(),\n",
        "                'classifier': ema_classifier.state_dict(),\n",
        "                'projector_0': ema_projector_0.state_dict(),\n",
        "                'projector_1': ema_projector_1.state_dict()\n",
        "            }, ema_ckpt_path)\n",
        "            print(f\"ğŸ’¾ Saved EMA checkpoint to {ema_ckpt_path}\")\n",
        "        # ================================\n",
        "\n",
        "    # ===============================\n",
        "    # 6. Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_best.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")\n",
        "\n",
        "        # ================================\n",
        "        # EMA ëª¨ë¸ ì €ì¥\n",
        "        if args.ma_update:\n",
        "            best_ema_ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_best_ema.pth.tar\"\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': ema_model.state_dict(),\n",
        "                'classifier': ema_classifier.state_dict(),\n",
        "                'projector_0': ema_projector_0.state_dict(),\n",
        "                'projector_1': ema_projector_1.state_dict(),\n",
        "                'loss': best_loss\n",
        "            }, best_ema_ckpt_path)\n",
        "            print(f\"=> Saved best EMA checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")\n",
        "        # ================================\n",
        "\n",
        "\n",
        "        # ğŸ”¹ Confusion Matrix Logging for Best\n",
        "        cm_best, sens_best, spec_best,_, _ = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_best_raw = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=False, tag=\"best_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_best_norm = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=True, tag=\"best_test_conf_matrix_norm\")\n",
        "\n",
        "        # -------------------------------------------wan\n",
        "        wandb_log_dict.update({\n",
        "            \"best_test_conf_matrix_raw\": wandb.Image(fig_best_raw),\n",
        "            \"best_test_conf_matrix_norm\": wandb.Image(fig_best_norm)\n",
        "        })\n",
        "        # -------------------------------------------wan\n",
        "\n",
        "\n",
        "    if epoch == args.epochs - 1:\n",
        "        # ğŸ”¸ Confusion Matrix Logging for Last Epoch\n",
        "        cm_last, sens_last, spec_last, _, _  = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "        fig_last_raw = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=False, tag=\"last_test_conf_matrix_raw\")\n",
        "\n",
        "        fig_last_norm = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=True, tag=\"last_test_conf_matrix_norm\")\n",
        "\n",
        "        # -------------------------------------------wan\n",
        "        wandb_log_dict.update({\n",
        "            \"last_test_conf_matrix_raw\": wandb.Image(fig_last_raw),\n",
        "            \"last_test_conf_matrix_norm\": wandb.Image(fig_last_norm)\n",
        "        })\n",
        "        # -------------------------------------------wan\n",
        "\n",
        "    # =====================================\n",
        "    # 7. Logging with wandb confusion matrix\n",
        "    # =====================================\n",
        "\n",
        "    # -------------------------------------------wan\n",
        "    # step 1. metrics\n",
        "    wandb.log({\n",
        "        # Train metrics\n",
        "        \"Training/epoch\": epoch,\n",
        "        \"Training/train_loss\": train_loss,\n",
        "        \"Training/test_loss\": test_loss,\n",
        "        \"Training/train_sens\": train_sens,\n",
        "        \"Training/train_spec\": train_spec,\n",
        "        \"Training/icbhi_score\": icbhi_score,\n",
        "\n",
        "        # Test metrics\n",
        "        \"Test/loss\": test_loss,\n",
        "        \"Test/sensitivity\": test_sens,\n",
        "        \"Test/specificity\": test_spec,\n",
        "        \"Test/icbhi_score\": test_icbhi_score\n",
        "    })\n",
        "\n",
        "    # step 2. Confusion matrix\n",
        "    wandb.log(wandb_log_dict)\n",
        "\n",
        "    # -------------------------------------------wan\n",
        "\n",
        "\n",
        "    plt.close(fig_finetune_raw)\n",
        "    plt.close(fig_finetune_norm)\n",
        "    plt.close(fig_test_raw)\n",
        "    plt.close(fig_test_norm)\n",
        "    if 'fig_best_raw' in locals(): plt.close(fig_best_raw)\n",
        "    if 'fig_best_norm' in locals(): plt.close(fig_best_norm)\n",
        "    if 'fig_last_raw' in locals(): plt.close(fig_last_raw)\n",
        "    if 'fig_last_norm' in locals(): plt.close(fig_last_norm)\n",
        "\n",
        "    # # ===============================\n",
        "    # # 8. Scheduler Step\n",
        "    # # ===============================\n",
        "    # scheduler.step()\n",
        "\n",
        "    # ===============================\n",
        "    # 9. Save Metrics\n",
        "    # ===============================\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_icbhi_scores.append(icbhi_score)\n",
        "    test_icbhi_scores.append(test_icbhi_score)\n",
        "    epochs.append(epoch)\n",
        "    # ================================\n",
        "\n",
        "    # ================================\n",
        "    # test_labels_all, test_preds_allì— ì €ì¥\n",
        "    # ================================\n",
        "    test_labels_all.append(test_labels)\n",
        "    test_preds_all.append(test_preds)\n",
        "    # ================================\n",
        "\n",
        "\n",
        "# -------------------------------------------wan\n",
        "wandb.finish()\n",
        "# -------------------------------------------wan\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e469a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- í›ˆë ¨ ì¢…ë£Œ í›„ ê·¸ë˜í”„ ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, train_losses, label='Train Loss')\n",
        "plt.plot(epochs, test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train/Test Loss per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, train_icbhi_scores, label='Train ICBHI Score')\n",
        "plt.plot(epochs, test_icbhi_scores, label='Test ICBHI Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('ICBHI Score')\n",
        "plt.title('Train/Test ICBHI Score per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "best_epoch_idx = np.argmax(test_icbhi_scores)\n",
        "best_epoch = epochs[best_epoch_idx]\n",
        "best_icbhi_score = test_icbhi_scores[best_epoch_idx]\n",
        "best_test_loss = test_losses[best_epoch_idx]\n",
        "\n",
        "# ìµœê³ ì  epochì—ì„œì˜ labels, preds\n",
        "best_test_labels = test_labels_all[best_epoch_idx]\n",
        "best_test_preds = test_preds_all[best_epoch_idx]\n",
        "\n",
        "best_cm, best_sens, best_spec, best_y_true_cls, best_y_pred_cls = evaluate_multiclass_confusion(\n",
        "    best_test_labels, best_test_preds)\n",
        "\n",
        "print(\"\\n=== [ìµœê³  Test ICBHI Score ì‹œì  ì •ë³´] ===\")\n",
        "print(f\"Best Test ICBHI Score: {best_icbhi_score:.4f} (Epoch {best_epoch})\")\n",
        "print(f\"Test Loss at Best: {best_test_loss:.4f}\")\n",
        "print(\"Confusion Matrix at Best ICBHI Score:\")\n",
        "print(best_cm)\n",
        "print(f\"Sensitivity: {best_sens:.4f}, Specificity: {best_spec:.4f}, ICBHI Score: {(best_sens+best_spec)/2:.4f}\")\n",
        "print(f\"Best Epoch: {best_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7c741a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# sigmoid ì ìš©\n",
        "sigmoid_output = sigmoid(all_output)  # shape: (N, 2)\n",
        "all_preds = (sigmoid_output > 0.5).astype(int)  # binary prediction\n",
        "all_labels = all_labels.astype(int)  # ì •ìˆ˜í˜•ìœ¼ë¡œ ì¼ì¹˜\n",
        "\n",
        "# ë§ì¶˜ ê²ƒë“¤\n",
        "correct_mask = np.all(all_preds == all_labels, axis=1)\n",
        "correct = np.concatenate([sigmoid_output, all_preds, all_labels], axis=1)[correct_mask]\n",
        "\n",
        "# í‹€ë¦° ê²ƒë“¤\n",
        "incorrect_mask = ~correct_mask\n",
        "incorrect_preds = all_preds[incorrect_mask]\n",
        "incorrect_labels = all_labels[incorrect_mask]\n",
        "incorrect_sigmoid = sigmoid_output[incorrect_mask]\n",
        "incorrect_concat = np.concatenate([incorrect_sigmoid, incorrect_preds, incorrect_labels], axis=1)\n",
        "\n",
        "# ê·¸ë£¹ë³„ í•„í„°ë§\n",
        "def get_mismatched_by_label(target_label):\n",
        "    mask = np.all(incorrect_labels == target_label, axis=1)\n",
        "    return incorrect_concat[mask]\n",
        "\n",
        "# ê° ê·¸ë£¹ ì¶”ì¶œ\n",
        "wrong_10 = get_mismatched_by_label([1, 0])  # crackle\n",
        "wrong_01 = get_mismatched_by_label([0, 1])  # wheeze\n",
        "wrong_11 = get_mismatched_by_label([1, 1])  # both\n",
        "wrong_00 = get_mismatched_by_label([0, 0])  # normal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nâœ… ë§ì¶˜ ê²ƒë“¤ (ì˜ˆ: [sigmoid1, sigmoid2, pred1, pred2, label1, label2])\")\n",
        "print(correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3f3d2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def group_mix(group_spec, labels, beta=1.0):\n",
        "    \"\"\"\n",
        "    Group-wise PatchMix (spatial domain) for group_spec of shape [B, 64, 512]\n",
        "    \"\"\"\n",
        "    B, N, D = group_spec.shape  # [B, 64, 512]\n",
        "    device = group_spec.device\n",
        "\n",
        "    # ğŸ”¹ lam: beta ë¶„í¬ì—ì„œ ìƒ˜í”Œë§ (mix ë¹„ìœ¨)\n",
        "    lam = np.random.beta(beta, beta)\n",
        "    num_mask = int(N * (1. - lam))  # ëª‡ ê°œ group ì„ì„ì§€\n",
        "\n",
        "    print(f\"lam: {lam:.4f}, num_mask: {num_mask}\")\n",
        "\n",
        "    # ğŸ”¹ mask: ì„ì„ group index (ê³µí†µ)\n",
        "    mask = torch.randperm(N)[:num_mask].to(device)  # [num_mask]\n",
        "    print(f\"mask shape: {mask.shape}  â†’ {mask.tolist()}\")\n",
        "\n",
        "    # ğŸ”¹ index: ë‹¤ë¥¸ sampleê³¼ ì„ê¸° ìœ„í•´ ìˆœì„œë¥¼ ì„ìŒ\n",
        "    index = torch.randperm(B).to(device)  # [B]\n",
        "    print(f\"index shape: {index.shape} â†’ {index.tolist()}\")\n",
        "\n",
        "    # ğŸ”¹ mix: ê°™ì€ ìœ„ì¹˜ì˜ groupë“¤ì„ index ê¸°ì¤€ìœ¼ë¡œ ì„ê¸°\n",
        "    mixed_group_spec = group_spec.clone()\n",
        "    mixed_group_spec[:, mask, :] = group_spec[index][:, mask, :]\n",
        "\n",
        "    print(f\"mixed_group_spec shape: {mixed_group_spec.shape}\")\n",
        "    print(f\"labels shape: {labels.shape}, labels[index] shape: {labels[index].shape}\")\n",
        "\n",
        "    # ğŸ”¹ ê° sampleì— ëŒ€í•´ lam ê°’ì„ broadcasting í•˜ê¸° ìœ„í•´ expand\n",
        "    lam_tensor = torch.full((B,), lam, device=device)\n",
        "    print(f\"lam_tensor shape: {lam_tensor.shape}\")\n",
        "\n",
        "    # ğŸ”¹ return: ì„ì€ group, ì›ë˜ ë¼ë²¨ y_a, mixëœ ë¼ë²¨ y_b, lam, index\n",
        "    return mixed_group_spec, labels, labels[index], lam_tensor, index\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "B = 4\n",
        "group_spec = torch.randn(B, 64, 512).cuda()\n",
        "labels = torch.randint(0, 2, (B, 4)).float().cuda()  # ì˜ˆì‹œ ë©€í‹°ë¼ë²¨ [B, 4]\n",
        "\n",
        "mixed, y_a, y_b, lam_tensor, index = group_mix(group_spec, labels, beta=1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e24854",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd52a82",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Multi-label (2-hot) â†’ Multi-class (0~3)ë¡œ ë³€í™˜í•˜ì—¬ í‰ê°€\n",
        "    - ì…ë ¥ shape: inputs [B, C, H, W], labels [B, 2]\n",
        "    - ì¶œë ¥ shape: preds [N, 2], labels [N, 2]\n",
        "    - ìµœì¢… multi-class í‰ê°€: (0=Normal, 1=Crackle, 2=Wheeze, 3=Both)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # forward\n",
        "            output = model(inputs)\n",
        "            if isinstance(output, (tuple, list)):  # (ex: (_, output, _))\n",
        "                output = output[1]\n",
        "            # output shape: [B, num_classes] (ex. [32, 2])\n",
        "            # criterion expects same shape\n",
        "            loss = criterion(output, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # multi-label prediction (threshold=0.5)\n",
        "            preds = (torch.sigmoid(output) > 0.5).int()   # [B, 2]\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()   # [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy() # [N, 2]\n",
        "\n",
        "    avg_loss = running_loss / len(val_loader)\n",
        "\n",
        "    # return shape: (float, [N,2], [N,2])\n",
        "    return avg_loss, all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e745fdd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "e745fdd5",
        "outputId": "3c8db9e4-49ad-4846-b176-598cb7bd18ec"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from torch.utils.data import DataLoader\n",
        "# import torch.optim as optim\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# train_losses = []\n",
        "# test_losses = []\n",
        "# train_icbhi_scores = []\n",
        "# test_icbhi_scores = []\n",
        "# test_labels_all = []\n",
        "# test_preds_all = []\n",
        "# epochs = []\n",
        "\n",
        "# # ëª¨ë¸ ì§€ì •í•˜ê¸° ì „ seed ê³ ì • í•„ìš”\n",
        "# seed_everything(args.seed) # Seed ê³ ì •\n",
        "\n",
        "# pretrain_project_name = f'ATT_{args.dim_prj}prj_{args.weight_decay}wd_{args.lambda_bce}ld_2beta_{get_timestamp()}'\n",
        "\n",
        "# # -------------------------------------------wan\n",
        "# # wandb ì´ˆê¸°í™” (í”„ë¡œì íŠ¸ëª…, ì‹¤í—˜ ì´ë¦„ ë“± ì„¤ì •)\n",
        "# wandb.init(\n",
        "#     project=\"SHS_ATT\", # í”„ë¡œì íŠ¸ ì´ë¦„\n",
        "#     name=f\"{pretrain_project_name}\",  # ì‹¤í—˜ ì´ë¦„\n",
        "#     config={\n",
        "#         \"epochs\": args.epochs,\n",
        "#         \"batch_size\": args.batch_size,\n",
        "#         \"lr\": args.lr,\n",
        "#         \"momentum\": args.momentum,\n",
        "#         \"weight_decay\": args.weight_decay\n",
        "#     }\n",
        "# )\n",
        "# # -------------------------------------------wan\n",
        "\n",
        "\n",
        "# # 1. MoCo ëª¨ë¸ ìƒì„±\n",
        "# model = MultilabelAttention(\n",
        "#     backbone=backbone_cnn6, \n",
        "#     num_classes=2, lambda_attn=0.5, \n",
        "#     attention_heads=[1, float('inf')]\n",
        "# ).cuda()\n",
        "\n",
        "# # model = MultilabelMoCo(\n",
        "# #     base_encoder = backbone_mlattention,\n",
        "# #     dim_enc = 512, # CNN6ì˜ ì¶œë ¥ feature dim (default=2048)\n",
        "# #     dim_prj = args.dim_prj,\n",
        "# #     K = args.K,\n",
        "# #     m = args.momentum,\n",
        "# #     T = args.T,\n",
        "# #     top_k = args.top_k,\n",
        "# #     lambda_bce = args.lambda_bce\n",
        "# # ).cuda()\n",
        "\n",
        "# # 2. Optimizer\n",
        "# # optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), args.lr) # weight_decay=args.weight_decay\n",
        "\n",
        "# # 3. Cosine Scheduler\n",
        "# scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)\n",
        "\n",
        "# # 4. Loss Function\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# # 5. Train\n",
        "# # Best loss ì´ˆê¸°í™”\n",
        "# best_loss = float('inf')\n",
        "# best_epoch = -1\n",
        "\n",
        "# def multilabel_to_multiclass(y):\n",
        "#     # Crackle â†’ 1, Wheeze â†’ 2, Both â†’ 3, None â†’ 0\n",
        "#     y = np.array(y)\n",
        "#     return y[:, 0] + y[:, 1] * 2\n",
        "\n",
        "# for epoch in range(args.epochs):\n",
        "#     # ===============================\n",
        "#     # Training\n",
        "#     # ===============================\n",
        "#     model.train()\n",
        "#     total_train_loss = 0.0\n",
        "#     total_predictions = 0.0\n",
        "#     correct_predictions = 0.0\n",
        "\n",
        "#     all_preds = []\n",
        "#     all_labels = []\n",
        "#     all_outputs = []\n",
        "\n",
        "#     pbar = tqdm(pretrain_loader, desc='MLATT Trainig only')\n",
        "#     for i, (repeat_mel, label, _) in enumerate(pbar): # label ì—¬ê¸°ì„  ì‚¬ìš© X\n",
        "#         img_augonly, _, _ = aug(repeat_mel)\n",
        "#         # ë””ë²„ê¹…: ë°ì´í„° ìì²´ í™•ì¸\n",
        "#         img_augonly = img_augonly.cuda(device=args.gpu, non_blocking=True)\n",
        "#         label = label.cuda(args.gpu)\n",
        "\n",
        "#         # backpropagation\n",
        "#         optimizer.zero_grad()\n",
        "#         _ , output, _ = model(img_augonly)\n",
        "#         loss = criterion(output, label)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_train_loss += loss.item()\n",
        "\n",
        "#         # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥ ( Ablation(4-1) threshold ?? )\n",
        "#         predicted = (torch.sigmoid(output) > 0.5).float()\n",
        "#         all_preds.append(predicted.detach().cpu())\n",
        "#         all_labels.append(label.detach().cpu())\n",
        "#         all_outputs.append(output.detach().cpu())\n",
        "\n",
        "#     # train loss\n",
        "#     train_loss = total_train_loss / len(pretrain_loader)\n",
        "\n",
        "#     # Concatenate\n",
        "#     all_preds = torch.cat(all_preds, dim=0).numpy()    # shape: [N, 2]\n",
        "#     all_labels = torch.cat(all_labels, dim=0).numpy()  # shape: [N, 2]\n",
        "#     all_output = torch.cat(all_outputs, dim=0).numpy()\n",
        "\n",
        "#     print(f\"[Epoch {epoch} | Train Loss: {train_loss:.4f}, img_augonly: {img_augonly.shape}\")\n",
        "\n",
        "\n",
        "#     # =====================================\n",
        "#     # 2-Edited. Multi-class ë¯¼ê°ë„/íŠ¹ì´ë„ ê³„ì‚°\n",
        "#     # =====================================\n",
        "#     import numpy as np\n",
        "#     import matplotlib.pyplot as plt\n",
        "#     import seaborn as sns\n",
        "#     import wandb\n",
        "#     from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#     def multilabel_to_multiclass(y):\n",
        "#         # Crackle â†’ 1, Wheeze â†’ 2, Both â†’ 3, None â†’ 0\n",
        "#         y = np.array(y)\n",
        "#         return y[:, 0] + y[:, 1]*2\n",
        "\n",
        "#     def evaluate_multiclass_confusion(y_true, y_pred, class_names=[\"Normal\", \"Wheeze\", \"Crackle\", \"Both\"]):\n",
        "#         y_true_cls = multilabel_to_multiclass(y_true)\n",
        "#         y_pred_cls = multilabel_to_multiclass(y_pred)\n",
        "\n",
        "#         cm = confusion_matrix(y_true_cls, y_pred_cls, labels=[0, 1, 2, 3])\n",
        "\n",
        "#         # N_n: ì •ìƒ â†’ ì •ìƒ\n",
        "#         N_n = cm[0, 0]\n",
        "#         N_total = cm[0].sum()\n",
        "\n",
        "#         # ì´ìƒ í´ë˜ìŠ¤ ì •ë‹µ ìˆ˜: W, C, B\n",
        "#         W_total = cm[1].sum()\n",
        "#         C_total = cm[2].sum()\n",
        "#         B_total = cm[3].sum()\n",
        "\n",
        "#         # ê°ê°ì˜ ì •ë‹µ â†’ ì •í™•í•œ ì˜ˆì¸¡ë§Œ ê³ ë ¤\n",
        "#         W_w = cm[1, 1]\n",
        "#         C_c = cm[2, 2]\n",
        "#         B_b = cm[3, 3]\n",
        "\n",
        "#         SP = N_n / (N_total + 1e-6) #spec\n",
        "#         SE = (W_w + C_c + B_b) / (W_total + C_total + B_total + 1e-6) #sense\n",
        "\n",
        "#         AS = (SP + SE) / 2\n",
        "#         HS = 2 * SP * SE / (SP + SE + 1e-6)\n",
        "\n",
        "#         return cm, SE, SP, y_true_cls, y_pred_cls\n",
        "\n",
        "#     def log_multiclass_conf_matrix_wandb(cm, class_names, sens, spec, normalize, tag):\n",
        "#         # Normalize (ë¹„ìœ¨) ì˜µì…˜\n",
        "#         if normalize:\n",
        "#             cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "#             fmt = '.2f'\n",
        "#             title = \"Confusion Matrix (Normalized %)\"\n",
        "#         else:\n",
        "#             fmt = 'd'\n",
        "#             title = \"Confusion Matrix (Raw Count)\"\n",
        "\n",
        "#         fig, ax = plt.subplots(figsize=(7, 6))\n",
        "#         sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
        "#                     xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "\n",
        "#         ax.set_xlabel('Predicted')\n",
        "#         ax.set_ylabel('True')\n",
        "#         ax.set_title(title)\n",
        "\n",
        "#         icbhi_score = (sens + spec) / 2\n",
        "#         # ìš°í•˜ë‹¨ì— ì„±ëŠ¥ ì¶œë ¥\n",
        "#         ax.text(\n",
        "#             0.99, 0.15,\n",
        "#             f\"Sensitivity: {sens*100:.2f}%\\nSpecificity: {spec*100:.2f}%\\nICBHI Score: {icbhi_score*100:.2f}%\",\n",
        "#             ha='right', va='bottom',\n",
        "#             transform=plt.gca().transAxes,\n",
        "#             fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "#         )\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         # wandb.log({tag: wandb.Image(fig)})\n",
        "#         # plt.close(fig)\n",
        "#         return fig\n",
        "\n",
        "#     # 1. 4-class Confusion Matrix í‰ê°€\n",
        "#     class_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "#     cm_4x4, train_sens, train_spec, y_true_cls, y_pred_cls = evaluate_multiclass_confusion(all_labels, all_preds, class_names)\n",
        "#     icbhi_score = (train_sens + train_spec)/2\n",
        "\n",
        "#     print(\"4-Class Confusion Matrix:\\n\", cm_4x4)\n",
        "#     print(f\"Sensitivity: {train_sens:.4f}, Specificity: {train_spec:.4f}, ICBHI Score: {icbhi_score:.4f}\")\n",
        "\n",
        "\n",
        "#     # ===============================\n",
        "#     # 3. Validation\n",
        "#     # ===============================\n",
        "#     test_loss, test_labels, test_preds = validate(\n",
        "#         model, test_loader, criterion, device\n",
        "#     )\n",
        "\n",
        "#     precision = precision_score(test_labels, test_preds, average='macro')\n",
        "#     recall = recall_score(test_labels, test_preds, average='macro')\n",
        "#     f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "#     test_cm_4x4, test_sens, test_spec, test_y_true_cls, test_y_pred_cls = evaluate_multiclass_confusion(test_labels, test_preds)\n",
        "#     test_icbhi_score = (test_sens+test_spec)/2\n",
        "\n",
        "#     print(\"[Validation] Confusion Matrix:\\n\", test_cm_4x4)\n",
        "#     print(f\"Test Loss: {test_loss:.4f}\")\n",
        "#     print(f\"[VALIDATION] Sensitivity: {test_sens:.4f}, Specificity: {test_spec:.4f}, Avg ICBHI Score: {(test_sens+test_spec)/2:.4f}\")\n",
        "#     print(\"##################################################\")\n",
        "\n",
        "\n",
        "#     # ===============================\n",
        "#     # 4. Confusion Matrix\n",
        "#     # ===============================\n",
        "\n",
        "#     # 2. Finetune Count Confusion Matrix ì‹œê°í™”\n",
        "#     fig_finetune_raw = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, train_sens, train_spec, normalize=False, tag=\"Training_conf_matrix_raw\")\n",
        "#     fig_finetune_norm = log_multiclass_conf_matrix_wandb(cm_4x4, class_names, train_sens, train_spec, normalize=True, tag=\"Training_conf_matrix_norm\")\n",
        "\n",
        "#     # 3. Test Confusion Matrix ì‹œê°í™”\n",
        "#     fig_test_raw = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=False, tag=\"test_conf_matrix_raw\")\n",
        "#     fig_test_norm = log_multiclass_conf_matrix_wandb(test_cm_4x4, class_names, test_sens, test_spec, normalize=True, tag=\"test_conf_matrix_norm\")\n",
        "\n",
        "#     # 4. log dictionary ìƒì„± -------------------------------------------wan\n",
        "#     wandb_log_dict = {\n",
        "#         \"finetune_conf_matrix_raw\": wandb.Image(fig_finetune_raw),\n",
        "#         \"finetune_conf_matrix_norm\": wandb.Image(fig_finetune_norm),\n",
        "#         \"test_conf_matrix_raw\": wandb.Image(fig_test_raw),\n",
        "#         \"test_conf_matrix_norm\": wandb.Image(fig_test_norm)\n",
        "#     }\n",
        "#     # -------------------------------------------wan\n",
        "\n",
        "#     # =====================================\n",
        "#     # 5. Checkpoint (Every 100 epochs)\n",
        "#     # =====================================\n",
        "#     if (epoch + 1) % 100 == 0:\n",
        "#         ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_{epoch:03d}.pth.tar\"\n",
        "#         torch.save({\n",
        "#             'epoch': epoch + 1,\n",
        "#             'state_dict': model.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict()\n",
        "#         }, ckpt_path)\n",
        "#         print(f\"ğŸ’¾ Saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "#     # ===============================\n",
        "#     # 6. Save Best Checkpoint\n",
        "#     # ===============================\n",
        "#     if test_loss < best_loss:\n",
        "#         best_loss = test_loss\n",
        "#         best_epoch = epoch\n",
        "#         best_ckpt_path = CHECKPOINT_PATH + f\"{pretrain_project_name}_best.pth.tar\"\n",
        "#         torch.save({\n",
        "#             'epoch': epoch + 1,\n",
        "#             'state_dict': model.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#             'loss': best_loss\n",
        "#         }, best_ckpt_path)\n",
        "#         print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")\n",
        "\n",
        "\n",
        "#         # ğŸ”¹ Confusion Matrix Logging for Best\n",
        "#         cm_best, sens_best, spec_best,_, _ = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "#         fig_best_raw = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=False, tag=\"best_test_conf_matrix_raw\")\n",
        "\n",
        "#         fig_best_norm = log_multiclass_conf_matrix_wandb(cm_best, class_names, sens_best, spec_best, normalize=True, tag=\"best_test_conf_matrix_norm\")\n",
        "\n",
        "#         # -------------------------------------------wan\n",
        "#         wandb_log_dict.update({\n",
        "#             \"best_test_conf_matrix_raw\": wandb.Image(fig_best_raw),\n",
        "#             \"best_test_conf_matrix_norm\": wandb.Image(fig_best_norm)\n",
        "#         })\n",
        "#         # -------------------------------------------wan\n",
        "\n",
        "\n",
        "#     if epoch == args.epochs - 1:\n",
        "#         # ğŸ”¸ Confusion Matrix Logging for Last Epoch\n",
        "#         cm_last, sens_last, spec_last, _, _  = evaluate_multiclass_confusion(test_labels, test_preds, class_names)\n",
        "#         fig_last_raw = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=False, tag=\"last_test_conf_matrix_raw\")\n",
        "\n",
        "#         fig_last_norm = log_multiclass_conf_matrix_wandb(cm_last, class_names, sens_last, spec_last, normalize=True, tag=\"last_test_conf_matrix_norm\")\n",
        "\n",
        "#         # -------------------------------------------wan\n",
        "#         wandb_log_dict.update({\n",
        "#             \"last_test_conf_matrix_raw\": wandb.Image(fig_last_raw),\n",
        "#             \"last_test_conf_matrix_norm\": wandb.Image(fig_last_norm)\n",
        "#         })\n",
        "#         # -------------------------------------------wan\n",
        "\n",
        "#     # =====================================\n",
        "#     # 7. Logging with wandb confusion matrix\n",
        "#     # =====================================\n",
        "\n",
        "#     # -------------------------------------------wan\n",
        "#     # step 1. metrics\n",
        "#     wandb.log({\n",
        "#         # Train metrics\n",
        "#         \"Training/epoch\": epoch,\n",
        "#         \"Training/train_loss\": train_loss,\n",
        "#         \"Training/test_loss\": test_loss,\n",
        "#         \"Training/train_sens\": train_sens,\n",
        "#         \"Training/train_spec\": train_spec,\n",
        "#         \"Training/icbhi_score\": icbhi_score,\n",
        "\n",
        "#         # Test metrics\n",
        "#         \"Test/loss\": test_loss,\n",
        "#         \"Test/sensitivity\": test_sens,\n",
        "#         \"Test/specificity\": test_spec,\n",
        "#         \"Test/icbhi_score\": test_icbhi_score\n",
        "#     })\n",
        "\n",
        "#     # step 2. Confusion matrix\n",
        "#     wandb.log(wandb_log_dict)\n",
        "\n",
        "#     # -------------------------------------------wan\n",
        "\n",
        "\n",
        "#     plt.close(fig_finetune_raw)\n",
        "#     plt.close(fig_finetune_norm)\n",
        "#     plt.close(fig_test_raw)\n",
        "#     plt.close(fig_test_norm)\n",
        "#     if 'fig_best_raw' in locals(): plt.close(fig_best_raw)\n",
        "#     if 'fig_best_norm' in locals(): plt.close(fig_best_norm)\n",
        "#     if 'fig_last_raw' in locals(): plt.close(fig_last_raw)\n",
        "#     if 'fig_last_norm' in locals(): plt.close(fig_last_norm)\n",
        "\n",
        "#     # ===============================\n",
        "#     # 8. Scheduler Step\n",
        "#     # ===============================\n",
        "#     scheduler.step()\n",
        "\n",
        "#     # ===============================\n",
        "#     # 9. Save Metrics\n",
        "#     # ===============================\n",
        "#     train_losses.append(train_loss)\n",
        "#     test_losses.append(test_loss)\n",
        "#     train_icbhi_scores.append(icbhi_score)\n",
        "#     test_icbhi_scores.append(test_icbhi_score)\n",
        "#     epochs.append(epoch)\n",
        "#     # ================================\n",
        "\n",
        "#     # ================================\n",
        "#     # test_labels_all, test_preds_allì— ì €ì¥\n",
        "#     # ================================\n",
        "#     test_labels_all.append(test_labels)\n",
        "#     test_preds_all.append(test_preds)\n",
        "#     # ================================\n",
        "\n",
        "\n",
        "# # -------------------------------------------wan\n",
        "# wandb.finish()\n",
        "# # -------------------------------------------wan"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.10.15)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
