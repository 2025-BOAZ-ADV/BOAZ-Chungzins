{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef6b52e2",
      "metadata": {
        "id": "ef6b52e2"
      },
      "source": [
        "#### 환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc03a42",
      "metadata": {
        "id": "9dc03a42"
      },
      "source": [
        "##### 1. Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f04d7d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04d7d6f",
        "outputId": "5882ee3a-d5dc-40c3-d3ae-7b3233440c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanillahub12\u001b[0m (\u001b[33mboaz_woony-boaz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# wandb 로그인\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992382bf",
      "metadata": {
        "id": "992382bf"
      },
      "source": [
        "##### 2. 라이브러리 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5MISAwpScmYt",
      "metadata": {
        "id": "5MISAwpScmYt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8ebed6c5",
      "metadata": {
        "id": "8ebed6c5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch import Tensor\n",
        "from torchsummary import summary\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d453e5f",
      "metadata": {
        "id": "2d453e5f"
      },
      "source": [
        "##### 3. 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "mSXgKx8GoItj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSXgKx8GoItj",
        "outputId": "fbd58ac1-5ccb-4e98-bbaa-4f77cc14132e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/ADV 프로젝트/data/ICBHI/ICBHI_final_database\"\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/ADV 프로젝트/checkpoints\"\n",
        "PICKLE_PATH = \"/content/drive/MyDrive/ADV 프로젝트/pickle\"\n",
        "text = \"/content/drive/MyDrive/ADV 프로젝트/data/ICBHI/ICBHI_challenge_train_test.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nydfgBckyPt3",
      "metadata": {
        "id": "nydfgBckyPt3"
      },
      "source": [
        "## 1. Data Load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3fdcf1",
      "metadata": {
        "id": "ce3fdcf1"
      },
      "source": [
        "#### 1.1 Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "OhJa9jivcg1k",
      "metadata": {
        "id": "OhJa9jivcg1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cfe10ae-2e95-462e-d95b-d7bcea6b085e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train :539, Test: 381, Total: 920\n"
          ]
        }
      ],
      "source": [
        "# WAV 파일이 있는 디렉토리 경로\n",
        "data_dir = ROOT\n",
        "txt_dir = ROOT\n",
        "\n",
        "df = pd.read_csv(text, sep='\\t', header=None)\n",
        "\n",
        "# 컬럼 이름 변경\n",
        "df.columns = ['filename', 'set']\n",
        "\n",
        "# train, test split\n",
        "train_df = df[df['set'] == 'train']\n",
        "test_df = df[df['set'] == 'test']\n",
        "\n",
        "# filename list\n",
        "train_list = sorted(train_df['filename'].tolist())\n",
        "test_list = sorted(test_df['filename'].tolist())\n",
        "\n",
        "print(f'Train :{len(train_list)}, Test: {len(test_list)}, Total: {len(train_list) + len(test_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04291977",
      "metadata": {
        "id": "04291977"
      },
      "source": [
        "#### 1.2 Pretext-Finetune Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ESBIVnKej0G9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBIVnKej0G9",
        "outputId": "7c08c7ae-a48c-49a5-cf13-2aa3932376ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pretrain] 환자 수: 74, 샘플 수: 431\n",
            "[Finetune] 환자 수: 43, 샘플 수: 108\n"
          ]
        }
      ],
      "source": [
        "# shuffle train data\n",
        "df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# split ratio\n",
        "train_size = int(0.8 * len(df_shuffled))\n",
        "\n",
        "# pretrain, finetune split\n",
        "pretrain_df = df_shuffled[:train_size]\n",
        "finetune_df = df_shuffled[train_size:]\n",
        "\n",
        "# filename list (pretext_list -> pretrain list)\n",
        "pretrain_list = sorted(pretrain_df['filename'].tolist())\n",
        "finetune_list = sorted(finetune_df['filename'].tolist())\n",
        "\n",
        "# patient id list\n",
        "pretrain_patient_list = []\n",
        "for filename in pretrain_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    pretrain_patient_list.append(number)\n",
        "\n",
        "finetune_patient_list = []\n",
        "for filename in finetune_list:\n",
        "    number = int(filename.split('_')[0])\n",
        "    finetune_patient_list.append(number)\n",
        "\n",
        "pretrain_patient_counts = pd.Series(pretrain_patient_list).value_counts()\n",
        "finetune_patient_counts = pd.Series(finetune_patient_list).value_counts()\n",
        "\n",
        "print(f\"[Pretrain] 환자 수: {len(pretrain_patient_counts.index)}, 샘플 수: {pretrain_patient_counts.sum()}\")\n",
        "print(f\"[Finetune] 환자 수: {len(finetune_patient_counts.index)}, 샘플 수: {finetune_patient_counts.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oVi6lzuPpSbk",
      "metadata": {
        "id": "oVi6lzuPpSbk"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8c7719",
      "metadata": {
        "id": "5e8c7719"
      },
      "source": [
        "#### 2.1 Args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634b232e",
      "metadata": {
        "id": "634b232e"
      },
      "source": [
        "        K: queue size; number of negative keys (default: 65536)\n",
        "        m: moco momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "add5c69b",
      "metadata": {
        "id": "add5c69b"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    # Audio & Spectrogram\n",
        "    target_sr = 4000    # 4KHz\n",
        "    frame_size = 1024\n",
        "    hop_length = 512    # frame_size 절반\n",
        "    n_mels = 128\n",
        "    target_sec = 8\n",
        "\n",
        "    # Augmentation\n",
        "    time_mask_param = 0.5\n",
        "    freq_mask_param = 0.5\n",
        "\n",
        "    # Train\n",
        "    lr = 0.03\n",
        "    warm = True                     # warm-up 사용 여부\n",
        "    warm_epochs = 10                # warm-up 적용할 초기 epoch 수\n",
        "    warmup_from = lr * 0.1          # warm-up 시작 learning rate (보통 lr의 10%)\n",
        "    warmup_to = lr\n",
        "\n",
        "    batch_size = 128\n",
        "    workers = 2\n",
        "    epochs = 300\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    resume = None\n",
        "    schedule=[120, 160] # schedule\n",
        "\n",
        "    # MLS\n",
        "    K = 512\n",
        "    momentum = 0.999\n",
        "    T = 0.07\n",
        "    dim_prj = 128\n",
        "    top_k = 20\n",
        "    lambda_bce = 0.3\n",
        "    out_dim = 2048\n",
        "\n",
        "    # Linear Evaluation\n",
        "    ft_epochs = 100\n",
        "\n",
        "    # etc\n",
        "    gpu = 0\n",
        "    data = \"./data_path\"\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e1f949",
      "metadata": {
        "id": "58e1f949"
      },
      "source": [
        "#### 2.2 Utils (func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8d2d1329",
      "metadata": {
        "id": "8d2d1329"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# cycle의 클래스를 추출\n",
        "def get_class(cr, wh):\n",
        "    if cr == 1 and wh == 1:\n",
        "        return 3\n",
        "    elif cr == 0 and wh == 1:\n",
        "        return 2\n",
        "    elif cr == 1 and wh == 0:\n",
        "        return 1\n",
        "    elif cr == 0 and wh == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Mel Spectrogram 생성 ( sr=4KHz, frame_size=1024, hop_length=512, n_mels=128 )\n",
        "def generate_mel_spectrogram(waveform, sample_rate, frame_size, hop_length, n_mels):\n",
        "    if hop_length is None:\n",
        "        hop_length = frame_size // 2\n",
        "    mel_spec_transform = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=frame_size,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "    mel_spectrogram = mel_spec_transform(waveform)\n",
        "    mel_db = T.AmplitudeToDB()(mel_spectrogram)\n",
        "    return mel_db\n",
        "\n",
        "# Cycle Repeat 또는 Crop\n",
        "def repeat_or_truncate_segment(mel_segment, target_frames):\n",
        "    current_frames = mel_segment.shape[-1]\n",
        "    if current_frames >= target_frames:\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "    else:\n",
        "        repeat_ratio = math.ceil(target_frames / current_frames)\n",
        "        mel_segment = mel_segment.repeat(1, 1, repeat_ratio)\n",
        "        return mel_segment[:, :, :target_frames]\n",
        "\n",
        "def preprocess_waveform_segment(waveform, unit_length):\n",
        "    \"\"\"unit_length 기준으로 waveform을 repeat + padding 또는 crop하여 길이 정규화\"\"\"\n",
        "    waveform = waveform.squeeze(0)  # (1, L) → (L,) 로 바꿔도 무방\n",
        "    length_adj = unit_length - len(waveform)\n",
        "\n",
        "    if length_adj > 0:\n",
        "        # waveform이 너무 짧은 경우 → repeat + zero-padding\n",
        "        half_unit = unit_length // 2\n",
        "\n",
        "        if length_adj < half_unit:\n",
        "            # 길이 차이가 작으면 단순 padding\n",
        "            half_adj = length_adj // 2\n",
        "            waveform = F.pad(waveform, (half_adj, length_adj - half_adj))\n",
        "        else:\n",
        "            # 반복 후 부족한 부분 padding\n",
        "            repeat_factor = unit_length // len(waveform)\n",
        "            waveform = waveform.repeat(repeat_factor)[:unit_length]\n",
        "            remaining = unit_length - len(waveform)\n",
        "            half_pad = remaining // 2\n",
        "            waveform = F.pad(waveform, (half_pad, remaining - half_pad))\n",
        "    else:\n",
        "        # waveform이 너무 길면 앞쪽 1/4 내에서 랜덤 crop\n",
        "        length_adj = len(waveform) - unit_length\n",
        "        start = random.randint(0, length_adj // 4)\n",
        "        waveform = waveform[start:start + unit_length]\n",
        "\n",
        "    return waveform.unsqueeze(0)  # 다시 (1, L)로\n",
        "\n",
        "# 데이터 Spec Augmentation ( 0~80% Random Masking )\n",
        "def apply_spec_augment(mel_segment):\n",
        "    M = mel_segment.shape[-1]\n",
        "    F = mel_segment.shape[-2]\n",
        "\n",
        "    # torchaudio의 마스킹은 0부터 mask_param까지 균등분포에서 랜덤하게 길이를 선택\n",
        "    time_masking = T.TimeMasking(time_mask_param=int(M * 0.8))\n",
        "    freq_masking = T.FrequencyMasking(freq_mask_param=int(F * 0.8) )\n",
        "\n",
        "    aug1 = freq_masking(mel_segment.clone())\n",
        "    aug2 = time_masking(mel_segment.clone())\n",
        "    aug3 = freq_masking(time_masking(mel_segment.clone()))\n",
        "\n",
        "    return aug1, aug2, aug3\n",
        "\n",
        "# Waveform resample\n",
        "def resample_waveform(waveform, orig_sr, target_sr=args.target_sr):\n",
        "    if orig_sr != target_sr:\n",
        "        resampler = torchaudio.transforms.Resample(\n",
        "            orig_freq=orig_sr,\n",
        "            new_freq=target_sr\n",
        "        )\n",
        "        return resampler(waveform), target_sr\n",
        "    return waveform, orig_sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d7f3640",
      "metadata": {
        "id": "5d7f3640"
      },
      "outputs": [],
      "source": [
        "def aug(repeat_mel):\n",
        "    aug1, aug2, aug3 = apply_spec_augment(repeat_mel)\n",
        "    return aug1, aug2, aug3\n",
        "\n",
        "def get_timestamp():\n",
        "    \"\"\"Outputs current time in KST like 2404070830\"\"\"\n",
        "    kst_time = datetime.now(ZoneInfo(\"Asia/Seoul\"))\n",
        "    return kst_time.strftime('%y%m%d%H%M')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e684cb",
      "metadata": {
        "id": "39e684cb"
      },
      "source": [
        "#### 2.3 CycleDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1642a79a",
      "metadata": {
        "id": "1642a79a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CycleDataset(Dataset):\n",
        "    def __init__(self, filename_list, wav_dir, txt_dir, target_sec=args.target_sec, target_sr=args.target_sr, frame_size=args.frame_size, hop_length=args.hop_length, n_mels=args.n_mels):\n",
        "        self.filename_list = filename_list\n",
        "        self.wav_dir = wav_dir\n",
        "        self.txt_dir = txt_dir\n",
        "        self.target_sec = target_sec\n",
        "        self.target_sr = target_sr\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "\n",
        "        self.cycle_list = []\n",
        "\n",
        "        print(\"[INFO] Preprocessing cycles...\")\n",
        "        for filename in tqdm(self.filename_list):\n",
        "            txt_path = os.path.join(self.txt_dir, filename + '.txt')\n",
        "            wav_path = os.path.join(self.wav_dir, filename + '.wav')\n",
        "\n",
        "            if not os.path.exists(txt_path):\n",
        "                print(f\"[WARNING] Missing file: {txt_path}\")\n",
        "            if not os.path.exists(wav_path):\n",
        "                print(f\"[WARNING] Missing file: {wav_path}\")\n",
        "\n",
        "            # Load annotation\n",
        "            cycle_data = np.loadtxt(txt_path, usecols=(0, 1))\n",
        "            lung_label = np.loadtxt(txt_path, usecols=(2, 3))\n",
        "\n",
        "            # Load waveform\n",
        "            waveform, orig_sr = torchaudio.load(wav_path)\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)  # Stereo to mono\n",
        "\n",
        "            # Resample to target sample rate (4kHz)\n",
        "            waveform, sample_rate = resample_waveform(waveform, orig_sr, self.target_sr)\n",
        "\n",
        "            for idx in range(len(cycle_data)):\n",
        "                # 호흡 주기 start, end\n",
        "                start_sample = int(cycle_data[idx, 0] * sample_rate)\n",
        "                end_sample = int(cycle_data[idx, 1] * sample_rate)\n",
        "                lung_duration = cycle_data[idx, 1] - cycle_data[idx, 0]\n",
        "\n",
        "                if end_sample <= start_sample:\n",
        "                    continue  # 잘못된 구간 스킵\n",
        "\n",
        "                # Waveform repeat + padding 후 Mel_db\n",
        "                cycle_wave = waveform[:, start_sample:end_sample]\n",
        "                normed_wave = preprocess_waveform_segment(cycle_wave, unit_length=int(self.target_sec * self.target_sr))\n",
        "                mel = generate_mel_spectrogram(normed_wave, sample_rate, frame_size=self.frame_size, hop_length=self.hop_length, n_mels=self.n_mels)\n",
        "\n",
        "                # crackle, wheeze -> class\n",
        "                cr = int(lung_label[idx, 0])\n",
        "                wh = int(lung_label[idx, 1])\n",
        "                label = get_class(cr, wh)\n",
        "\n",
        "                multi_label = torch.tensor([\n",
        "                    float(label in [1, 3]),\n",
        "                    float(label in [2, 3])\n",
        "                ])  # 변환된 multi-label 반환\n",
        "\n",
        "                # meta_data\n",
        "                meta_data = (filename, lung_duration)\n",
        "\n",
        "                self.cycle_list.append((mel, multi_label, meta_data))\n",
        "\n",
        "        print(f\"[INFO] Total cycles collected: {len(self.cycle_list)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cycle_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel, label, meta_data = self.cycle_list[idx]\n",
        "        return mel, label, meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d5a070",
      "metadata": {
        "id": "55d5a070"
      },
      "source": [
        "##### Pickle.dump"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752088df",
      "metadata": {
        "id": "752088df"
      },
      "source": [
        "CycleDataset 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d386e82",
      "metadata": {
        "id": "9d386e82"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import matplotlib.pyplot as plt\n",
        "# import librosa.display\n",
        "\n",
        "# wav_dir = ROOT\n",
        "# txt_dir = ROOT\n",
        "\n",
        "# # 1. Dataset 로드\n",
        "# train_dataset = CycleDataset(train_list, wav_dir, txt_dir)\n",
        "# test_dataset = CycleDataset(test_list, wav_dir, txt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "zRqSwthYTtxq",
      "metadata": {
        "id": "zRqSwthYTtxq"
      },
      "outputs": [],
      "source": [
        "# # 2. 간단 통계\n",
        "# print(f\"Total cycles: {len(train_dataset)}\")\n",
        "\n",
        "# label_counter = [0] * 4  # normal, crackle, wheeze, both\n",
        "# for _, multi_label,_ in train_dataset:\n",
        "#     if torch.equal(multi_label, torch.tensor([0., 0.])):\n",
        "#         label_counter[0] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 0.])):\n",
        "#         label_counter[1] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([0., 1.])):\n",
        "#         label_counter[2] += 1\n",
        "#     elif torch.equal(multi_label, torch.tensor([1., 1.])):\n",
        "#         label_counter[3] += 1\n",
        "\n",
        "# for idx, count in enumerate(label_counter):\n",
        "#     print(f\"Class {idx}: {count} cycles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4BQgVyGnrDbN",
      "metadata": {
        "id": "4BQgVyGnrDbN"
      },
      "source": [
        "pickle로 train_dataset, test_dataset 외부 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "apdA4f-hrBXt",
      "metadata": {
        "id": "apdA4f-hrBXt"
      },
      "outputs": [],
      "source": [
        "# pickle_dict = {\n",
        "#     'train_dataset': train_dataset,\n",
        "#     'test_dataset': test_dataset\n",
        "# }\n",
        "\n",
        "# save_path = os.path.join(PICKLE_PATH, 'saved_datasets_multilabel.pkl')\n",
        "# with open(save_path, 'wb') as f:\n",
        "#     pickle.dump(pickle_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yJPtbC3BrqAE",
      "metadata": {
        "id": "yJPtbC3BrqAE"
      },
      "source": [
        "##### Pickle.load\n",
        "저장된 train_dataset, test_dataset을 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "EWrjdCFSrmER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWrjdCFSrmER",
        "outputId": "541032bc-e1c0-47de-f09c-a464e122d950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train] Cycles: 4142\n",
            "[Test] Cycles: 4142\n"
          ]
        }
      ],
      "source": [
        "save_path = os.path.join(PICKLE_PATH, 'saved_datasets_multilabel.pkl')\n",
        "with open(save_path, 'rb') as f:\n",
        "    pickle_dict = pickle.load(f)\n",
        "\n",
        "train_dataset = pickle_dict['train_dataset']\n",
        "test_dataset = pickle_dict['test_dataset']\n",
        "\n",
        "print(f\"[Train] Cycles: {len(train_dataset)}\")\n",
        "print(f\"[Test] Cycles: {len(train_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcca3481",
      "metadata": {
        "id": "bcca3481"
      },
      "source": [
        "#### 2.4 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5f19b4a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f19b4a7",
        "outputId": "30d539fe-d473-4c41-a60a-046d6eb81fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrain set size: 3257, Finetune set size: 885\n"
          ]
        }
      ],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# train_dataset 내에서 각 파일의 인덱스를 추출\n",
        "pretrain_idx = []\n",
        "finetune_idx = []\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "    filename = train_dataset[i][2][0]\n",
        "\n",
        "    if filename in pretrain_list:\n",
        "        pretrain_idx.append(i)\n",
        "    elif filename in finetune_list:\n",
        "        finetune_idx.append(i)\n",
        "\n",
        "# 인덱스 순서 셔플\n",
        "random.shuffle(pretrain_idx)\n",
        "random.shuffle(finetune_idx)\n",
        "\n",
        "print(f\"Pretrain set size: {len(pretrain_idx)}, Finetune set size: {len(finetune_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce2c3c8",
      "metadata": {
        "id": "cce2c3c8"
      },
      "source": [
        "코드 실행 환경에 따라 num_workers를 적절한 값으로 지정해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "432ae0cd",
      "metadata": {
        "id": "432ae0cd"
      },
      "outputs": [],
      "source": [
        "# Dataset 생성 (Subset)\n",
        "pretrain_dataset = Subset(train_dataset, pretrain_idx)\n",
        "finetune_dataset = Subset(train_dataset, finetune_idx)\n",
        "\n",
        "# DataLoader 생성\n",
        "# DataLoader에서 shuffle=True로 지정하면 매 epoch마다 셔플 순서가 달라짐 => 재현성 문제 발생\n",
        "# pretrain_dataset, finetune_dataset은 이미 셔플이 완료된 것으로, 이것을 DataLoader에 입력함\n",
        "pretrain_loader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=2,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "finetune_loader = DataLoader(\n",
        "    finetune_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=2,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b492ad67",
      "metadata": {
        "id": "b492ad67"
      },
      "source": [
        "label 분포 확인 (단순 참고용, 실제 환경에서는 pretrain set의 label 분포가 어떤지 알 수 없음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fea9d290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea9d290",
        "outputId": "53812a54-54dc-4d98-ecb9-2e0091c2a467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrain sample: 3257\n",
            "Pretrain label distribution: Counter({0: 1607, 1: 953, 2: 417, 3: 280})\n",
            "\n",
            "Finetune sample: 885\n",
            "Finetune label distribution: Counter({0: 456, 1: 262, 2: 84, 3: 83})\n",
            "Test sample: 2756\n",
            "Test label distribution: Counter({0: 1579, 1: 649, 2: 385, 3: 143})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# label\n",
        "labels = torch.stack([multi_label for _, multi_label, _ in train_dataset])\n",
        "\n",
        "# pretext와 finetune 데이터셋의 라벨 분포 출력\n",
        "pretrain_labels = labels[pretrain_idx]\n",
        "pretrain_labels_class = (\n",
        "    pretrain_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    pretrain_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "finetune_labels = labels[finetune_idx]\n",
        "finetune_labels_class = (\n",
        "    finetune_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    finetune_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "# test 데이터셋의 라벨 분포 출력\n",
        "test_labels = torch.stack([multi_label for _, multi_label, _ in test_dataset])\n",
        "test_labels_class = (\n",
        "    test_labels[:, 0].long() * 1 +  # crackle bit → *1\n",
        "    test_labels[:, 1].long() * 2    # wheeze bit  → *2\n",
        ")  # [N] shape, values in {0, 1, 2, 3}\n",
        "\n",
        "print(f\"Pretrain sample: {len(pretrain_labels_class)}\")\n",
        "print(\"Pretrain label distribution:\", Counter(pretrain_labels_class.tolist()))\n",
        "print(f\"\\nFinetune sample: {len(finetune_labels_class)}\")\n",
        "print(\"Finetune label distribution:\", Counter(finetune_labels_class.tolist()))\n",
        "print(f\"Test sample: {len(test_labels_class)}\")\n",
        "print(\"Test label distribution:\", Counter(test_labels_class.tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed559ff1",
      "metadata": {
        "id": "ed559ff1"
      },
      "source": [
        "## 3. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca710799",
      "metadata": {
        "id": "ca710799"
      },
      "source": [
        "#### 3.1 Pre-trained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2caf4a6c",
      "metadata": {
        "id": "2caf4a6c"
      },
      "outputs": [],
      "source": [
        "def backbone_resnet():\n",
        "    # 1. 기본 ResNet50 생성 (pretrained=False로 시작)\n",
        "    resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "    # 2. 첫 번째 conv 레이어를 1채널용으로 수정\n",
        "    resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # 먼저 fc 제거\n",
        "    resnet.fc = nn.Identity()\n",
        "\n",
        "    # 3. ImageNet 가중치 로드 (conv1 제외)\n",
        "    state_dict = load_state_dict_from_url(\n",
        "        'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "        progress=True\n",
        "    )\n",
        "    if 'conv1.weight' in state_dict:\n",
        "        del state_dict['conv1.weight']\n",
        "    resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    return resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "515805a1",
      "metadata": {
        "id": "515805a1"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torchvision.models as models\n",
        "# from torch.hub import load_state_dict_from_url\n",
        "# from torchvision.models import resnet50\n",
        "\n",
        "# def backbone_resnet(dim=args.mlp_dim, mlp=False):\n",
        "#     resnet = resnet50(weights=None, num_classes=dim)  # deprecated 대응\n",
        "\n",
        "#     # 1채널 입력 변경\n",
        "#     resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "#     # Pretrained weight 불러오기 (conv1, fc 제외)\n",
        "#     state_dict = load_state_dict_from_url(\n",
        "#         'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "#         progress=True\n",
        "#     )\n",
        "#     for k in ['conv1.weight', 'fc.weight', 'fc.bias']:\n",
        "#         if k in state_dict:\n",
        "#             del state_dict[k]\n",
        "#     resnet.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "#     return resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "09f21daa",
      "metadata": {
        "id": "09f21daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141cdb1d-1678-440a-e5e9-6282175058db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 309MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 112, 32]           3,136\n",
            "       BatchNorm2d-2          [-1, 64, 112, 32]             128\n",
            "              ReLU-3          [-1, 64, 112, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 16]               0\n",
            "            Conv2d-5           [-1, 64, 56, 16]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 16]             128\n",
            "              ReLU-7           [-1, 64, 56, 16]               0\n",
            "            Conv2d-8           [-1, 64, 56, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 16]             128\n",
            "             ReLU-10           [-1, 64, 56, 16]               0\n",
            "           Conv2d-11          [-1, 256, 56, 16]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 16]             512\n",
            "           Conv2d-13          [-1, 256, 56, 16]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 16]             512\n",
            "             ReLU-15          [-1, 256, 56, 16]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 16]               0\n",
            "           Conv2d-17           [-1, 64, 56, 16]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 16]             128\n",
            "             ReLU-19           [-1, 64, 56, 16]               0\n",
            "           Conv2d-20           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 16]             128\n",
            "             ReLU-22           [-1, 64, 56, 16]               0\n",
            "           Conv2d-23          [-1, 256, 56, 16]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 16]             512\n",
            "             ReLU-25          [-1, 256, 56, 16]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 16]               0\n",
            "           Conv2d-27           [-1, 64, 56, 16]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 16]             128\n",
            "             ReLU-29           [-1, 64, 56, 16]               0\n",
            "           Conv2d-30           [-1, 64, 56, 16]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 16]             128\n",
            "             ReLU-32           [-1, 64, 56, 16]               0\n",
            "           Conv2d-33          [-1, 256, 56, 16]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 16]             512\n",
            "             ReLU-35          [-1, 256, 56, 16]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 16]               0\n",
            "           Conv2d-37          [-1, 128, 56, 16]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 16]             256\n",
            "             ReLU-39          [-1, 128, 56, 16]               0\n",
            "           Conv2d-40           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-41           [-1, 128, 28, 8]             256\n",
            "             ReLU-42           [-1, 128, 28, 8]               0\n",
            "           Conv2d-43           [-1, 512, 28, 8]          65,536\n",
            "      BatchNorm2d-44           [-1, 512, 28, 8]           1,024\n",
            "           Conv2d-45           [-1, 512, 28, 8]         131,072\n",
            "      BatchNorm2d-46           [-1, 512, 28, 8]           1,024\n",
            "             ReLU-47           [-1, 512, 28, 8]               0\n",
            "       Bottleneck-48           [-1, 512, 28, 8]               0\n",
            "           Conv2d-49           [-1, 128, 28, 8]          65,536\n",
            "      BatchNorm2d-50           [-1, 128, 28, 8]             256\n",
            "             ReLU-51           [-1, 128, 28, 8]               0\n",
            "           Conv2d-52           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-53           [-1, 128, 28, 8]             256\n",
            "             ReLU-54           [-1, 128, 28, 8]               0\n",
            "           Conv2d-55           [-1, 512, 28, 8]          65,536\n",
            "      BatchNorm2d-56           [-1, 512, 28, 8]           1,024\n",
            "             ReLU-57           [-1, 512, 28, 8]               0\n",
            "       Bottleneck-58           [-1, 512, 28, 8]               0\n",
            "           Conv2d-59           [-1, 128, 28, 8]          65,536\n",
            "      BatchNorm2d-60           [-1, 128, 28, 8]             256\n",
            "             ReLU-61           [-1, 128, 28, 8]               0\n",
            "           Conv2d-62           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-63           [-1, 128, 28, 8]             256\n",
            "             ReLU-64           [-1, 128, 28, 8]               0\n",
            "           Conv2d-65           [-1, 512, 28, 8]          65,536\n",
            "      BatchNorm2d-66           [-1, 512, 28, 8]           1,024\n",
            "             ReLU-67           [-1, 512, 28, 8]               0\n",
            "       Bottleneck-68           [-1, 512, 28, 8]               0\n",
            "           Conv2d-69           [-1, 128, 28, 8]          65,536\n",
            "      BatchNorm2d-70           [-1, 128, 28, 8]             256\n",
            "             ReLU-71           [-1, 128, 28, 8]               0\n",
            "           Conv2d-72           [-1, 128, 28, 8]         147,456\n",
            "      BatchNorm2d-73           [-1, 128, 28, 8]             256\n",
            "             ReLU-74           [-1, 128, 28, 8]               0\n",
            "           Conv2d-75           [-1, 512, 28, 8]          65,536\n",
            "      BatchNorm2d-76           [-1, 512, 28, 8]           1,024\n",
            "             ReLU-77           [-1, 512, 28, 8]               0\n",
            "       Bottleneck-78           [-1, 512, 28, 8]               0\n",
            "           Conv2d-79           [-1, 256, 28, 8]         131,072\n",
            "      BatchNorm2d-80           [-1, 256, 28, 8]             512\n",
            "             ReLU-81           [-1, 256, 28, 8]               0\n",
            "           Conv2d-82           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-83           [-1, 256, 14, 4]             512\n",
            "             ReLU-84           [-1, 256, 14, 4]               0\n",
            "           Conv2d-85          [-1, 1024, 14, 4]         262,144\n",
            "      BatchNorm2d-86          [-1, 1024, 14, 4]           2,048\n",
            "           Conv2d-87          [-1, 1024, 14, 4]         524,288\n",
            "      BatchNorm2d-88          [-1, 1024, 14, 4]           2,048\n",
            "             ReLU-89          [-1, 1024, 14, 4]               0\n",
            "       Bottleneck-90          [-1, 1024, 14, 4]               0\n",
            "           Conv2d-91           [-1, 256, 14, 4]         262,144\n",
            "      BatchNorm2d-92           [-1, 256, 14, 4]             512\n",
            "             ReLU-93           [-1, 256, 14, 4]               0\n",
            "           Conv2d-94           [-1, 256, 14, 4]         589,824\n",
            "      BatchNorm2d-95           [-1, 256, 14, 4]             512\n",
            "             ReLU-96           [-1, 256, 14, 4]               0\n",
            "           Conv2d-97          [-1, 1024, 14, 4]         262,144\n",
            "      BatchNorm2d-98          [-1, 1024, 14, 4]           2,048\n",
            "             ReLU-99          [-1, 1024, 14, 4]               0\n",
            "      Bottleneck-100          [-1, 1024, 14, 4]               0\n",
            "          Conv2d-101           [-1, 256, 14, 4]         262,144\n",
            "     BatchNorm2d-102           [-1, 256, 14, 4]             512\n",
            "            ReLU-103           [-1, 256, 14, 4]               0\n",
            "          Conv2d-104           [-1, 256, 14, 4]         589,824\n",
            "     BatchNorm2d-105           [-1, 256, 14, 4]             512\n",
            "            ReLU-106           [-1, 256, 14, 4]               0\n",
            "          Conv2d-107          [-1, 1024, 14, 4]         262,144\n",
            "     BatchNorm2d-108          [-1, 1024, 14, 4]           2,048\n",
            "            ReLU-109          [-1, 1024, 14, 4]               0\n",
            "      Bottleneck-110          [-1, 1024, 14, 4]               0\n",
            "          Conv2d-111           [-1, 256, 14, 4]         262,144\n",
            "     BatchNorm2d-112           [-1, 256, 14, 4]             512\n",
            "            ReLU-113           [-1, 256, 14, 4]               0\n",
            "          Conv2d-114           [-1, 256, 14, 4]         589,824\n",
            "     BatchNorm2d-115           [-1, 256, 14, 4]             512\n",
            "            ReLU-116           [-1, 256, 14, 4]               0\n",
            "          Conv2d-117          [-1, 1024, 14, 4]         262,144\n",
            "     BatchNorm2d-118          [-1, 1024, 14, 4]           2,048\n",
            "            ReLU-119          [-1, 1024, 14, 4]               0\n",
            "      Bottleneck-120          [-1, 1024, 14, 4]               0\n",
            "          Conv2d-121           [-1, 256, 14, 4]         262,144\n",
            "     BatchNorm2d-122           [-1, 256, 14, 4]             512\n",
            "            ReLU-123           [-1, 256, 14, 4]               0\n",
            "          Conv2d-124           [-1, 256, 14, 4]         589,824\n",
            "     BatchNorm2d-125           [-1, 256, 14, 4]             512\n",
            "            ReLU-126           [-1, 256, 14, 4]               0\n",
            "          Conv2d-127          [-1, 1024, 14, 4]         262,144\n",
            "     BatchNorm2d-128          [-1, 1024, 14, 4]           2,048\n",
            "            ReLU-129          [-1, 1024, 14, 4]               0\n",
            "      Bottleneck-130          [-1, 1024, 14, 4]               0\n",
            "          Conv2d-131           [-1, 256, 14, 4]         262,144\n",
            "     BatchNorm2d-132           [-1, 256, 14, 4]             512\n",
            "            ReLU-133           [-1, 256, 14, 4]               0\n",
            "          Conv2d-134           [-1, 256, 14, 4]         589,824\n",
            "     BatchNorm2d-135           [-1, 256, 14, 4]             512\n",
            "            ReLU-136           [-1, 256, 14, 4]               0\n",
            "          Conv2d-137          [-1, 1024, 14, 4]         262,144\n",
            "     BatchNorm2d-138          [-1, 1024, 14, 4]           2,048\n",
            "            ReLU-139          [-1, 1024, 14, 4]               0\n",
            "      Bottleneck-140          [-1, 1024, 14, 4]               0\n",
            "          Conv2d-141           [-1, 512, 14, 4]         524,288\n",
            "     BatchNorm2d-142           [-1, 512, 14, 4]           1,024\n",
            "            ReLU-143           [-1, 512, 14, 4]               0\n",
            "          Conv2d-144            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 2]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 2]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 2]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 2]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 2]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 2]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 2]               0\n",
            "          Conv2d-153            [-1, 512, 7, 2]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 2]               0\n",
            "          Conv2d-156            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 2]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 2]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 2]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 2]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 2]               0\n",
            "          Conv2d-163            [-1, 512, 7, 2]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 2]               0\n",
            "          Conv2d-166            [-1, 512, 7, 2]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 2]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 2]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 2]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 2]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 2]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 2]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "        Identity-174                 [-1, 2048]               0\n",
            "================================================================\n",
            "Total params: 23,501,760\n",
            "Trainable params: 23,501,760\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 81.90\n",
            "Params size (MB): 89.65\n",
            "Estimated Total Size (MB): 171.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# summary 함수 사용: (채널, 높이, 너비) 크기를 지정\n",
        "summary(backbone_resnet().to(device), input_size=(1, 224, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0305c74",
      "metadata": {
        "id": "e0305c74"
      },
      "source": [
        "#### 3.2 MoCo (MLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ska5GunlcKzI",
      "metadata": {
        "id": "ska5GunlcKzI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# K: queue_g의 크기\n",
        "# dim_enc: projector 통과 전, g1,g2 벡터의 차원\n",
        "# dim_prj: projector 통과 후, z1,z2 벡터의 차원\n",
        "class MoCo(nn.Module):\n",
        "    def __init__(self, base_encoder, dim_prj=128, K=512, m=0.999, T=0.07, top_k=10, lambda_bce=0.5):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "        self.top_k = top_k\n",
        "        self.lambda_bce = lambda_bce\n",
        "\n",
        "        self.encoder_q = base_encoder()\n",
        "        self.encoder_k = base_encoder()\n",
        "\n",
        "        dim_enc = 2048\n",
        "        self.proj_head_q = nn.Sequential(\n",
        "            nn.Linear(dim_enc, dim_enc),\n",
        "            nn.BatchNorm1d(dim_enc),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_enc, dim_prj)\n",
        "        )\n",
        "        self.proj_head_k = nn.Sequential(\n",
        "            nn.Linear(dim_enc, dim_enc),\n",
        "            nn.BatchNorm1d(dim_enc),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_enc, dim_prj)\n",
        "        )\n",
        "\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False\n",
        "\n",
        "        self.register_buffer(\"queue_g\", F.normalize(torch.randn(dim_enc, K), dim=0))      # g2를 정규화한 후 열 단위로 Qg에 저장\n",
        "        self.register_buffer(\"queue_z\", F.normalize(torch.randn(dim_prj, K), dim=0))      # z2를 정규화한 후 열 단위로 Qz에 저장\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))               # 현재 queue에 새로 쓸 위치(인덱스)를 추적하는 포인터 역할\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, g2, z2):\n",
        "        batch_size = g2.shape[0]\n",
        "        ptr = int(self.queue_ptr)\n",
        "        assert self.K % batch_size == 0\n",
        "        # self.queue_g[:, ptr:ptr + batch_size] = g2.T.detach()[:, :self.queue_g.shape[1] - ptr]  # Update only available space\n",
        "        # self.queue_z[:, ptr:ptr + batch_size] = z2.T.detach()[:, :self.queue_z.shape[1] - ptr]  # Update only available space\n",
        "        self.queue_g[:, ptr:ptr+batch_size] = g2.T.detach()\n",
        "        self.queue_z[:, ptr:ptr+batch_size] = z2.T.detach()\n",
        "        self.queue_ptr[0] = (ptr + batch_size) % self.K\n",
        "\n",
        "    def forward(self, im_q, im_k, epoch=None, warmup_epochs=10):\n",
        "        # encoder_q → g1 (feature)\n",
        "        g1 = F.normalize(self.encoder_q(im_q), dim=1)  # shape: [B, 2048]\n",
        "\n",
        "        # projection head → z1\n",
        "        z1 = F.normalize(self.proj_head_q(g1), dim=1)  # shape: [B, 128]\n",
        "\n",
        "        # encoder k\n",
        "        with torch.no_grad():\n",
        "            self._momentum_update_key_encoder()\n",
        "            g2 = F.normalize(self.encoder_k(im_k), dim=1)\n",
        "            z2 = F.normalize(self.proj_head_k(g2), dim=1)\n",
        "\n",
        "        # top-k mining\n",
        "        sim_g = torch.matmul(g1, self.queue_g.clone().detach())  # [N, K]\n",
        "        topk_idx = torch.topk(sim_g, self.top_k, dim=1).indices\n",
        "        y = torch.zeros_like(sim_g)\n",
        "        y.scatter_(1, topk_idx, 1.0)\n",
        "\n",
        "        # logits from z1 · Qz\n",
        "        sim_z = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(sim_z / self.T, y)\n",
        "\n",
        "        # InfoNCE loss\n",
        "        l_pos = torch.sum(z1 * z2, dim=1, keepdim=True)\n",
        "        l_neg = torch.matmul(z1, self.queue_z.clone().detach())\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1) / self.T\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(logits.device)\n",
        "        info_nce_loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        # Total loss (with optional warmup)\n",
        "        if epoch is not None and epoch < warmup_epochs:\n",
        "            loss = info_nce_loss\n",
        "        else:\n",
        "            loss = info_nce_loss + self.lambda_bce * bce_loss\n",
        "\n",
        "        self._dequeue_and_enqueue(g2, z2)\n",
        "\n",
        "        return loss, logits, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dd06543e",
      "metadata": {
        "id": "dd06543e"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class MoCo(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Build a MoCo model with: a query encoder, a key encoder, and a queue\n",
        "#     https://arxiv.org/abs/1911.05722\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, base_encoder, dim=args.mlp_dim, K=args.K, m=args.m, T=args.T, mlp=args.mlp):\n",
        "#         \"\"\"\n",
        "#         dim: feature dimension (default: 128)\n",
        "#         K: queue size; number of negative keys (default: 8192) # original=65536\n",
        "#         m: moco momentum of updating key encoder (default: 0.999)\n",
        "#         T: softmax temperature (default: 0.07)\n",
        "#         mlp: if True, use MLP head (default: True)\n",
        "#         \"\"\"\n",
        "#         super(MoCo, self).__init__()\n",
        "\n",
        "#         self.K = K\n",
        "#         self.m = m\n",
        "#         self.T = T\n",
        "\n",
        "#         # create the encoders\n",
        "#         # num_classes is the output fc dimension\n",
        "#         self.encoder_q = base_encoder(dim=args.mlp_dim, mlp=args.mlp)\n",
        "#         self.encoder_k = base_encoder(dim=args.mlp_dim, mlp=args.mlp)\n",
        "\n",
        "#         if mlp:  # hack: brute-force replacement\n",
        "#             dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
        "#             self.encoder_q.fc = nn.Sequential(\n",
        "#                 nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc\n",
        "#             )\n",
        "#             self.encoder_k.fc = nn.Sequential(\n",
        "#                 nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc\n",
        "#             )\n",
        "\n",
        "#         for param_q, param_k in zip(\n",
        "#             self.encoder_q.parameters(), self.encoder_k.parameters()\n",
        "#         ):\n",
        "#             param_k.data.copy_(param_q.data)  # initialize\n",
        "#             param_k.requires_grad = False  # not update by gradient\n",
        "\n",
        "#         # create the queue\n",
        "#         self.register_buffer(\"queue\", torch.randn(dim, K))\n",
        "#         self.queue = nn.functional.normalize(self.queue, dim=0)\n",
        "\n",
        "#         self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def _momentum_update_key_encoder(self):\n",
        "#         \"\"\"\n",
        "#         Momentum update of the key encoder\n",
        "#         \"\"\"\n",
        "#         for param_q, param_k in zip(\n",
        "#             self.encoder_q.parameters(), self.encoder_k.parameters()\n",
        "#         ):\n",
        "#             param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def _dequeue_and_enqueue(self, keys):\n",
        "#         # gather keys before updating queue\n",
        "#         keys = keys\n",
        "\n",
        "#         batch_size = keys.shape[0]\n",
        "\n",
        "#         ptr = int(self.queue_ptr)\n",
        "#         assert self.K % batch_size == 0  # for simplicity\n",
        "\n",
        "#         # replace the keys at ptr (dequeue and enqueue)\n",
        "#         self.queue[:, ptr : ptr + batch_size] = keys.T\n",
        "#         ptr = (ptr + batch_size) % self.K  # move pointer\n",
        "\n",
        "#         self.queue_ptr[0] = ptr\n",
        "\n",
        "#     def forward(self, im_q, im_k):\n",
        "#         \"\"\"\n",
        "#         Input:\n",
        "#             im_q: a batch of query images\n",
        "#             im_k: a batch of key images\n",
        "#         Output:\n",
        "#             logits, targets\n",
        "#         \"\"\"\n",
        "\n",
        "#         # compute query features\n",
        "#         q = self.encoder_q(im_q)  # queries: NxC\n",
        "#         q = nn.functional.normalize(q, dim=1)\n",
        "\n",
        "#         # compute key features\n",
        "#         with torch.no_grad():  # no gradient to keys\n",
        "#             self._momentum_update_key_encoder()  # update the key encoder\n",
        "#             k = self.encoder_k(im_k)  # keys: NxC\n",
        "#             k = nn.functional.normalize(k, dim=1)\n",
        "\n",
        "#         # compute logits\n",
        "#         # Einstein sum is more intuitive\n",
        "#         # positive logits: Nx1\n",
        "#         l_pos = torch.einsum(\"nc,nc->n\", [q, k]).unsqueeze(-1) # [N, 1]\n",
        "#         # negative logits: NxK\n",
        "#         l_neg = torch.einsum(\"nc,ck->nk\", [q, self.queue.clone().detach()])  # [N,dim] * [dim,K] = [N,K]\n",
        "\n",
        "\n",
        "#         # logits: Nx(1+K)\n",
        "#         logits = torch.cat([l_pos, l_neg], dim=1) # [N, 1+K]\n",
        "\n",
        "#         # apply temperature\n",
        "#         logits /= self.T\n",
        "\n",
        "#         # labels: positive key indicators\n",
        "#         labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
        "\n",
        "#         # dequeue and enqueue\n",
        "#         self._dequeue_and_enqueue(k)\n",
        "\n",
        "#         return logits, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc1bf21",
      "metadata": {
        "id": "1cc1bf21"
      },
      "source": [
        "## 4. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "-BkAfkqhyHrY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkAfkqhyHrY",
        "outputId": "7dcb0e7b-40a7-4dd5-e59f-dc01e1584449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "next(iter(pretrain_loader))[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "e745fdd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e745fdd5",
        "outputId": "3c8db9e4-49ad-4846-b176-598cb7bd18ec",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250606_094144-61aoaj63</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/61aoaj63' target=\"_blank\">Moco_MLS_PT_128bs_top20_0.3ld_2506061841</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/61aoaj63' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/61aoaj63</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Avg Train Loss: 7.3025\n",
            "=> Saved best checkpoint (epoch: 0, loss: 7.3025)\n",
            "Epoch 1 | Avg Train Loss: 6.7359\n",
            "=> Saved best checkpoint (epoch: 1, loss: 6.7359)\n",
            "Epoch 2 | Avg Train Loss: 6.4584\n",
            "=> Saved best checkpoint (epoch: 2, loss: 6.4584)\n",
            "Epoch 3 | Avg Train Loss: 5.9246\n",
            "=> Saved best checkpoint (epoch: 3, loss: 5.9246)\n",
            "Epoch 4 | Avg Train Loss: 5.5460\n",
            "=> Saved best checkpoint (epoch: 4, loss: 5.5460)\n",
            "Epoch 5 | Avg Train Loss: 5.4201\n",
            "=> Saved best checkpoint (epoch: 5, loss: 5.4201)\n",
            "Epoch 6 | Avg Train Loss: 5.2855\n",
            "=> Saved best checkpoint (epoch: 6, loss: 5.2855)\n",
            "Epoch 7 | Avg Train Loss: 5.3276\n",
            "Epoch 8 | Avg Train Loss: 5.1401\n",
            "=> Saved best checkpoint (epoch: 8, loss: 5.1401)\n",
            "Epoch 9 | Avg Train Loss: 5.0494\n",
            "=> Saved best checkpoint (epoch: 9, loss: 5.0494)\n",
            "Epoch 10 | Avg Train Loss: 4.9193\n",
            "=> Saved best checkpoint (epoch: 10, loss: 4.9193)\n",
            "Epoch 11 | Avg Train Loss: 4.7761\n",
            "=> Saved best checkpoint (epoch: 11, loss: 4.7761)\n",
            "Epoch 12 | Avg Train Loss: 4.6123\n",
            "=> Saved best checkpoint (epoch: 12, loss: 4.6123)\n",
            "Epoch 13 | Avg Train Loss: 4.4855\n",
            "=> Saved best checkpoint (epoch: 13, loss: 4.4855)\n",
            "Epoch 14 | Avg Train Loss: 4.3968\n",
            "=> Saved best checkpoint (epoch: 14, loss: 4.3968)\n",
            "Epoch 15 | Avg Train Loss: 4.4161\n",
            "Epoch 16 | Avg Train Loss: 4.4326\n",
            "Epoch 17 | Avg Train Loss: 4.3077\n",
            "=> Saved best checkpoint (epoch: 17, loss: 4.3077)\n",
            "Epoch 18 | Avg Train Loss: 4.1627\n",
            "=> Saved best checkpoint (epoch: 18, loss: 4.1627)\n",
            "Epoch 19 | Avg Train Loss: 4.2011\n",
            "Epoch 20 | Avg Train Loss: 4.2906\n",
            "Epoch 21 | Avg Train Loss: 4.1775\n",
            "Epoch 22 | Avg Train Loss: 4.0943\n",
            "=> Saved best checkpoint (epoch: 22, loss: 4.0943)\n",
            "Epoch 23 | Avg Train Loss: 4.0380\n",
            "=> Saved best checkpoint (epoch: 23, loss: 4.0380)\n",
            "Epoch 24 | Avg Train Loss: 3.9589\n",
            "=> Saved best checkpoint (epoch: 24, loss: 3.9589)\n",
            "Epoch 25 | Avg Train Loss: 3.9732\n",
            "Epoch 26 | Avg Train Loss: 4.0062\n",
            "Epoch 27 | Avg Train Loss: 3.8449\n",
            "=> Saved best checkpoint (epoch: 27, loss: 3.8449)\n",
            "Epoch 28 | Avg Train Loss: 3.8810\n",
            "Epoch 29 | Avg Train Loss: 3.8685\n",
            "Epoch 30 | Avg Train Loss: 3.8678\n",
            "Epoch 31 | Avg Train Loss: 3.8751\n",
            "Epoch 32 | Avg Train Loss: 3.7178\n",
            "=> Saved best checkpoint (epoch: 32, loss: 3.7178)\n",
            "Epoch 33 | Avg Train Loss: 3.6159\n",
            "=> Saved best checkpoint (epoch: 33, loss: 3.6159)\n",
            "Epoch 34 | Avg Train Loss: 3.6864\n",
            "Epoch 35 | Avg Train Loss: 3.7116\n",
            "Epoch 36 | Avg Train Loss: 3.7209\n",
            "Epoch 37 | Avg Train Loss: 3.7971\n",
            "Epoch 38 | Avg Train Loss: 3.3114\n",
            "=> Saved best checkpoint (epoch: 38, loss: 3.3114)\n",
            "Epoch 39 | Avg Train Loss: 3.6275\n",
            "Epoch 40 | Avg Train Loss: 3.4706\n",
            "Epoch 41 | Avg Train Loss: 3.4811\n",
            "Epoch 42 | Avg Train Loss: 3.3721\n",
            "Epoch 43 | Avg Train Loss: 3.3734\n",
            "Epoch 44 | Avg Train Loss: 3.3569\n",
            "Epoch 45 | Avg Train Loss: 3.2673\n",
            "=> Saved best checkpoint (epoch: 45, loss: 3.2673)\n",
            "Epoch 46 | Avg Train Loss: 3.3352\n",
            "Epoch 47 | Avg Train Loss: 3.2405\n",
            "=> Saved best checkpoint (epoch: 47, loss: 3.2405)\n",
            "Epoch 48 | Avg Train Loss: 3.2029\n",
            "=> Saved best checkpoint (epoch: 48, loss: 3.2029)\n",
            "Epoch 49 | Avg Train Loss: 3.5525\n",
            "Epoch 50 | Avg Train Loss: 3.0400\n",
            "=> Saved best checkpoint (epoch: 50, loss: 3.0400)\n",
            "Epoch 51 | Avg Train Loss: 2.9133\n",
            "=> Saved best checkpoint (epoch: 51, loss: 2.9133)\n",
            "Epoch 52 | Avg Train Loss: 2.9164\n",
            "Epoch 53 | Avg Train Loss: 3.3911\n",
            "Epoch 54 | Avg Train Loss: 3.1333\n",
            "Epoch 55 | Avg Train Loss: 3.2914\n",
            "Epoch 56 | Avg Train Loss: 3.2925\n",
            "Epoch 57 | Avg Train Loss: 2.9780\n",
            "Epoch 58 | Avg Train Loss: 3.0969\n",
            "Epoch 59 | Avg Train Loss: 3.1450\n",
            "Epoch 60 | Avg Train Loss: 3.3169\n",
            "Epoch 61 | Avg Train Loss: 3.0775\n",
            "Epoch 62 | Avg Train Loss: 3.4822\n",
            "Epoch 63 | Avg Train Loss: 2.8500\n",
            "=> Saved best checkpoint (epoch: 63, loss: 2.8500)\n",
            "Epoch 64 | Avg Train Loss: 3.2544\n",
            "Epoch 65 | Avg Train Loss: 3.0560\n",
            "Epoch 66 | Avg Train Loss: 2.8662\n",
            "Epoch 67 | Avg Train Loss: 2.6935\n",
            "=> Saved best checkpoint (epoch: 67, loss: 2.6935)\n",
            "Epoch 68 | Avg Train Loss: 2.8893\n",
            "Epoch 69 | Avg Train Loss: 3.1318\n",
            "Epoch 70 | Avg Train Loss: 2.7822\n",
            "Epoch 71 | Avg Train Loss: 2.9121\n",
            "Epoch 72 | Avg Train Loss: 3.0536\n",
            "Epoch 73 | Avg Train Loss: 2.9835\n",
            "Epoch 74 | Avg Train Loss: 3.0345\n",
            "Epoch 75 | Avg Train Loss: 2.8572\n",
            "Epoch 76 | Avg Train Loss: 2.7223\n",
            "Epoch 77 | Avg Train Loss: 2.9193\n",
            "Epoch 78 | Avg Train Loss: 2.6557\n",
            "=> Saved best checkpoint (epoch: 78, loss: 2.6557)\n",
            "Epoch 79 | Avg Train Loss: 2.5475\n",
            "=> Saved best checkpoint (epoch: 79, loss: 2.5475)\n",
            "Epoch 80 | Avg Train Loss: 2.5848\n",
            "Epoch 81 | Avg Train Loss: 2.5632\n",
            "Epoch 82 | Avg Train Loss: 2.5629\n",
            "Epoch 83 | Avg Train Loss: 2.7657\n",
            "Epoch 84 | Avg Train Loss: 2.6879\n",
            "Epoch 85 | Avg Train Loss: 2.8003\n",
            "Epoch 86 | Avg Train Loss: 2.7918\n",
            "Epoch 87 | Avg Train Loss: 2.7104\n",
            "Epoch 88 | Avg Train Loss: 2.5644\n",
            "Epoch 89 | Avg Train Loss: 2.7263\n",
            "Epoch 90 | Avg Train Loss: 2.8433\n",
            "Epoch 91 | Avg Train Loss: 2.4543\n",
            "=> Saved best checkpoint (epoch: 91, loss: 2.4543)\n",
            "Epoch 92 | Avg Train Loss: 2.3901\n",
            "=> Saved best checkpoint (epoch: 92, loss: 2.3901)\n",
            "Epoch 93 | Avg Train Loss: 2.4798\n",
            "Epoch 94 | Avg Train Loss: 2.4394\n",
            "Epoch 95 | Avg Train Loss: 2.3188\n",
            "=> Saved best checkpoint (epoch: 95, loss: 2.3188)\n",
            "Epoch 96 | Avg Train Loss: 2.3583\n",
            "Epoch 97 | Avg Train Loss: 2.7416\n",
            "Epoch 98 | Avg Train Loss: 2.3279\n",
            "Epoch 99 | Avg Train Loss: 2.2956\n",
            "💾 Saved checkpoint to /content/drive/MyDrive/ADV 프로젝트/checkpoints/Moco_MLS_PT_128bs_top20_0.3ld_2506061841_099.pth.tar\n",
            "=> Saved best checkpoint (epoch: 99, loss: 2.2956)\n",
            "Epoch 100 | Avg Train Loss: 2.6803\n",
            "Epoch 101 | Avg Train Loss: 2.6855\n",
            "Epoch 102 | Avg Train Loss: 2.1970\n",
            "=> Saved best checkpoint (epoch: 102, loss: 2.1970)\n",
            "Epoch 103 | Avg Train Loss: 2.2067\n",
            "Epoch 104 | Avg Train Loss: 2.0830\n",
            "=> Saved best checkpoint (epoch: 104, loss: 2.0830)\n",
            "Epoch 105 | Avg Train Loss: 2.3150\n",
            "Epoch 106 | Avg Train Loss: 2.5867\n",
            "Epoch 107 | Avg Train Loss: 2.5914\n",
            "Epoch 108 | Avg Train Loss: 2.5458\n",
            "Epoch 109 | Avg Train Loss: 2.6171\n",
            "Epoch 110 | Avg Train Loss: 2.5253\n",
            "Epoch 111 | Avg Train Loss: 2.3558\n",
            "Epoch 112 | Avg Train Loss: 2.4682\n",
            "Epoch 113 | Avg Train Loss: 2.0709\n",
            "=> Saved best checkpoint (epoch: 113, loss: 2.0709)\n",
            "Epoch 114 | Avg Train Loss: 2.5740\n",
            "Epoch 115 | Avg Train Loss: 2.5870\n",
            "Epoch 116 | Avg Train Loss: 2.1269\n",
            "Epoch 117 | Avg Train Loss: 2.1774\n",
            "Epoch 118 | Avg Train Loss: 2.2418\n",
            "Epoch 119 | Avg Train Loss: 2.4172\n",
            "Epoch 120 | Avg Train Loss: 2.0231\n",
            "=> Saved best checkpoint (epoch: 120, loss: 2.0231)\n",
            "Epoch 121 | Avg Train Loss: 2.5383\n",
            "Epoch 122 | Avg Train Loss: 2.2241\n",
            "Epoch 123 | Avg Train Loss: 1.9660\n",
            "=> Saved best checkpoint (epoch: 123, loss: 1.9660)\n",
            "Epoch 124 | Avg Train Loss: 2.0183\n",
            "Epoch 125 | Avg Train Loss: 2.2819\n",
            "Epoch 126 | Avg Train Loss: 2.0779\n",
            "Epoch 127 | Avg Train Loss: 1.9991\n",
            "Epoch 128 | Avg Train Loss: 2.2374\n",
            "Epoch 129 | Avg Train Loss: 2.2399\n",
            "Epoch 130 | Avg Train Loss: 1.9322\n",
            "=> Saved best checkpoint (epoch: 130, loss: 1.9322)\n",
            "Epoch 131 | Avg Train Loss: 2.1981\n",
            "Epoch 132 | Avg Train Loss: 1.9252\n",
            "=> Saved best checkpoint (epoch: 132, loss: 1.9252)\n",
            "Epoch 133 | Avg Train Loss: 2.1187\n",
            "Epoch 134 | Avg Train Loss: 2.2029\n",
            "Epoch 135 | Avg Train Loss: 1.7356\n",
            "=> Saved best checkpoint (epoch: 135, loss: 1.7356)\n",
            "Epoch 136 | Avg Train Loss: 2.0879\n",
            "Epoch 137 | Avg Train Loss: 1.9089\n",
            "Epoch 138 | Avg Train Loss: 1.9243\n",
            "Epoch 139 | Avg Train Loss: 2.0185\n",
            "Epoch 140 | Avg Train Loss: 1.9454\n",
            "Epoch 141 | Avg Train Loss: 2.4419\n",
            "Epoch 142 | Avg Train Loss: 1.9638\n",
            "Epoch 143 | Avg Train Loss: 1.8403\n",
            "Epoch 144 | Avg Train Loss: 2.3080\n",
            "Epoch 145 | Avg Train Loss: 1.9992\n",
            "Epoch 146 | Avg Train Loss: 2.1313\n",
            "Epoch 147 | Avg Train Loss: 2.0125\n",
            "Epoch 148 | Avg Train Loss: 2.0267\n",
            "Epoch 149 | Avg Train Loss: 1.8219\n",
            "Epoch 150 | Avg Train Loss: 2.4222\n",
            "Epoch 151 | Avg Train Loss: 1.8371\n",
            "Epoch 152 | Avg Train Loss: 2.0864\n",
            "Epoch 153 | Avg Train Loss: 2.0387\n",
            "Epoch 154 | Avg Train Loss: 1.6695\n",
            "=> Saved best checkpoint (epoch: 154, loss: 1.6695)\n",
            "Epoch 155 | Avg Train Loss: 1.9993\n",
            "Epoch 156 | Avg Train Loss: 1.9869\n",
            "Epoch 157 | Avg Train Loss: 2.2514\n",
            "Epoch 158 | Avg Train Loss: 1.9792\n",
            "Epoch 159 | Avg Train Loss: 1.8872\n",
            "Epoch 160 | Avg Train Loss: 1.7955\n",
            "Epoch 161 | Avg Train Loss: 1.8146\n",
            "Epoch 162 | Avg Train Loss: 1.6569\n",
            "=> Saved best checkpoint (epoch: 162, loss: 1.6569)\n",
            "Epoch 163 | Avg Train Loss: 1.7417\n",
            "Epoch 164 | Avg Train Loss: 1.6478\n",
            "=> Saved best checkpoint (epoch: 164, loss: 1.6478)\n",
            "Epoch 165 | Avg Train Loss: 1.8176\n",
            "Epoch 166 | Avg Train Loss: 1.8413\n",
            "Epoch 167 | Avg Train Loss: 1.8709\n",
            "Epoch 168 | Avg Train Loss: 1.7093\n",
            "Epoch 169 | Avg Train Loss: 1.7428\n",
            "Epoch 170 | Avg Train Loss: 1.6459\n",
            "=> Saved best checkpoint (epoch: 170, loss: 1.6459)\n",
            "Epoch 171 | Avg Train Loss: 1.6203\n",
            "=> Saved best checkpoint (epoch: 171, loss: 1.6203)\n",
            "Epoch 172 | Avg Train Loss: 1.7440\n",
            "Epoch 173 | Avg Train Loss: 1.8960\n",
            "Epoch 174 | Avg Train Loss: 1.9723\n",
            "Epoch 175 | Avg Train Loss: 1.7487\n",
            "Epoch 176 | Avg Train Loss: 1.5656\n",
            "=> Saved best checkpoint (epoch: 176, loss: 1.5656)\n",
            "Epoch 177 | Avg Train Loss: 2.0768\n",
            "Epoch 178 | Avg Train Loss: 1.8284\n",
            "Epoch 179 | Avg Train Loss: 1.9508\n",
            "Epoch 180 | Avg Train Loss: 1.8186\n",
            "Epoch 181 | Avg Train Loss: 1.7067\n",
            "Epoch 182 | Avg Train Loss: 2.1073\n",
            "Epoch 183 | Avg Train Loss: 1.7446\n",
            "Epoch 184 | Avg Train Loss: 1.8158\n",
            "Epoch 185 | Avg Train Loss: 1.6573\n",
            "Epoch 186 | Avg Train Loss: 1.5043\n",
            "=> Saved best checkpoint (epoch: 186, loss: 1.5043)\n",
            "Epoch 187 | Avg Train Loss: 1.9519\n",
            "Epoch 188 | Avg Train Loss: 1.6416\n",
            "Epoch 189 | Avg Train Loss: 2.0735\n",
            "Epoch 190 | Avg Train Loss: 1.5562\n",
            "Epoch 191 | Avg Train Loss: 1.7887\n",
            "Epoch 192 | Avg Train Loss: 1.6202\n",
            "Epoch 193 | Avg Train Loss: 1.5650\n",
            "Epoch 194 | Avg Train Loss: 1.6662\n",
            "Epoch 195 | Avg Train Loss: 1.5119\n",
            "Epoch 196 | Avg Train Loss: 1.7378\n",
            "Epoch 197 | Avg Train Loss: 1.4574\n",
            "=> Saved best checkpoint (epoch: 197, loss: 1.4574)\n",
            "Epoch 198 | Avg Train Loss: 1.7420\n",
            "Epoch 199 | Avg Train Loss: 2.0278\n",
            "💾 Saved checkpoint to /content/drive/MyDrive/ADV 프로젝트/checkpoints/Moco_MLS_PT_128bs_top20_0.3ld_2506061841_199.pth.tar\n",
            "Epoch 200 | Avg Train Loss: 1.4751\n",
            "Epoch 201 | Avg Train Loss: 1.7787\n",
            "Epoch 202 | Avg Train Loss: 1.4178\n",
            "=> Saved best checkpoint (epoch: 202, loss: 1.4178)\n",
            "Epoch 203 | Avg Train Loss: 1.6181\n",
            "Epoch 204 | Avg Train Loss: 1.5343\n",
            "Epoch 205 | Avg Train Loss: 1.4140\n",
            "=> Saved best checkpoint (epoch: 205, loss: 1.4140)\n",
            "Epoch 206 | Avg Train Loss: 1.3379\n",
            "=> Saved best checkpoint (epoch: 206, loss: 1.3379)\n",
            "Epoch 207 | Avg Train Loss: 1.3694\n",
            "Epoch 208 | Avg Train Loss: 1.7884\n",
            "Epoch 209 | Avg Train Loss: 1.4291\n",
            "Epoch 210 | Avg Train Loss: 1.4523\n",
            "Epoch 211 | Avg Train Loss: 1.5836\n",
            "Epoch 212 | Avg Train Loss: 1.4597\n",
            "Epoch 213 | Avg Train Loss: 1.5964\n",
            "Epoch 214 | Avg Train Loss: 1.8471\n",
            "Epoch 215 | Avg Train Loss: 1.5616\n",
            "Epoch 216 | Avg Train Loss: 1.3023\n",
            "=> Saved best checkpoint (epoch: 216, loss: 1.3023)\n",
            "Epoch 217 | Avg Train Loss: 1.5424\n",
            "Epoch 218 | Avg Train Loss: 1.5301\n",
            "Epoch 219 | Avg Train Loss: 1.8871\n",
            "Epoch 220 | Avg Train Loss: 1.4741\n",
            "Epoch 221 | Avg Train Loss: 1.4129\n",
            "Epoch 222 | Avg Train Loss: 1.2663\n",
            "=> Saved best checkpoint (epoch: 222, loss: 1.2663)\n",
            "Epoch 223 | Avg Train Loss: 1.5729\n",
            "Epoch 224 | Avg Train Loss: 1.5982\n",
            "Epoch 225 | Avg Train Loss: 1.5409\n",
            "Epoch 226 | Avg Train Loss: 1.2477\n",
            "=> Saved best checkpoint (epoch: 226, loss: 1.2477)\n",
            "Epoch 227 | Avg Train Loss: 1.4697\n",
            "Epoch 228 | Avg Train Loss: 1.7066\n",
            "Epoch 229 | Avg Train Loss: 1.5623\n",
            "Epoch 230 | Avg Train Loss: 1.3433\n",
            "Epoch 231 | Avg Train Loss: 1.8201\n",
            "Epoch 232 | Avg Train Loss: 1.5030\n",
            "Epoch 233 | Avg Train Loss: 1.4378\n",
            "Epoch 234 | Avg Train Loss: 1.4619\n",
            "Epoch 235 | Avg Train Loss: 1.5269\n",
            "Epoch 236 | Avg Train Loss: 1.5532\n",
            "Epoch 237 | Avg Train Loss: 1.0755\n",
            "=> Saved best checkpoint (epoch: 237, loss: 1.0755)\n",
            "Epoch 238 | Avg Train Loss: 1.7732\n",
            "Epoch 239 | Avg Train Loss: 1.7081\n",
            "Epoch 240 | Avg Train Loss: 1.3003\n",
            "Epoch 241 | Avg Train Loss: 1.4181\n",
            "Epoch 242 | Avg Train Loss: 1.6311\n",
            "Epoch 243 | Avg Train Loss: 1.4308\n",
            "Epoch 244 | Avg Train Loss: 1.6097\n",
            "Epoch 245 | Avg Train Loss: 1.3426\n",
            "Epoch 246 | Avg Train Loss: 1.5788\n",
            "Epoch 247 | Avg Train Loss: 1.3818\n",
            "Epoch 248 | Avg Train Loss: 1.9996\n",
            "Epoch 249 | Avg Train Loss: 1.3097\n",
            "Epoch 250 | Avg Train Loss: 1.2241\n",
            "Epoch 251 | Avg Train Loss: 1.3050\n",
            "Epoch 252 | Avg Train Loss: 1.5222\n",
            "Epoch 253 | Avg Train Loss: 1.3671\n",
            "Epoch 254 | Avg Train Loss: 1.3103\n",
            "Epoch 255 | Avg Train Loss: 1.3646\n",
            "Epoch 256 | Avg Train Loss: 1.3505\n",
            "Epoch 257 | Avg Train Loss: 1.3258\n",
            "Epoch 258 | Avg Train Loss: 1.5096\n",
            "Epoch 259 | Avg Train Loss: 1.2567\n",
            "Epoch 260 | Avg Train Loss: 1.3707\n",
            "Epoch 261 | Avg Train Loss: 1.2734\n",
            "Epoch 262 | Avg Train Loss: 1.5855\n",
            "Epoch 263 | Avg Train Loss: 1.2173\n",
            "Epoch 264 | Avg Train Loss: 1.4887\n",
            "Epoch 265 | Avg Train Loss: 1.7237\n",
            "Epoch 266 | Avg Train Loss: 1.2073\n",
            "Epoch 267 | Avg Train Loss: 1.2696\n",
            "Epoch 268 | Avg Train Loss: 1.3771\n",
            "Epoch 269 | Avg Train Loss: 1.2898\n",
            "Epoch 270 | Avg Train Loss: 1.3698\n",
            "Epoch 271 | Avg Train Loss: 1.4206\n",
            "Epoch 272 | Avg Train Loss: 1.5444\n",
            "Epoch 273 | Avg Train Loss: 1.7022\n",
            "Epoch 274 | Avg Train Loss: 1.1541\n",
            "Epoch 275 | Avg Train Loss: 1.4578\n",
            "Epoch 276 | Avg Train Loss: 1.7596\n",
            "Epoch 277 | Avg Train Loss: 1.1521\n",
            "Epoch 278 | Avg Train Loss: 1.2824\n",
            "Epoch 279 | Avg Train Loss: 1.6089\n",
            "Epoch 280 | Avg Train Loss: 1.3655\n",
            "Epoch 281 | Avg Train Loss: 1.3516\n",
            "Epoch 282 | Avg Train Loss: 1.1675\n",
            "Epoch 283 | Avg Train Loss: 1.6469\n",
            "Epoch 284 | Avg Train Loss: 1.3822\n",
            "Epoch 285 | Avg Train Loss: 1.2455\n",
            "Epoch 286 | Avg Train Loss: 1.3440\n",
            "Epoch 287 | Avg Train Loss: 1.1692\n",
            "Epoch 288 | Avg Train Loss: 1.1829\n",
            "Epoch 289 | Avg Train Loss: 1.3564\n",
            "Epoch 290 | Avg Train Loss: 1.2019\n",
            "Epoch 291 | Avg Train Loss: 1.1768\n",
            "Epoch 292 | Avg Train Loss: 1.5566\n",
            "Epoch 293 | Avg Train Loss: 1.0600\n",
            "=> Saved best checkpoint (epoch: 293, loss: 1.0600)\n",
            "Epoch 294 | Avg Train Loss: 1.1792\n",
            "Epoch 295 | Avg Train Loss: 1.1483\n",
            "Epoch 296 | Avg Train Loss: 1.5288\n",
            "Epoch 297 | Avg Train Loss: 1.6540\n",
            "Epoch 298 | Avg Train Loss: 1.5475\n",
            "Epoch 299 | Avg Train Loss: 1.2608\n",
            "💾 Saved checkpoint to /content/drive/MyDrive/ADV 프로젝트/checkpoints/Moco_MLS_PT_128bs_top20_0.3ld_2506061841_299.pth.tar\n"
          ]
        }
      ],
      "source": [
        "pretrain_project_name = f'Moco_MLS_PT_{args.batch_size}bs_top{args.top_k}_{args.lambda_bce}ld_{get_timestamp()}'\n",
        "\n",
        "# wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "wandb.init(\n",
        "    project=\"SHS_ICBHI_MLS\", # 프로젝트 이름\n",
        "    name=f\"{pretrain_project_name}\",  # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay\n",
        "    }\n",
        ")\n",
        "\n",
        "# 1. MoCo 모델 생성\n",
        "model = MoCo(\n",
        "    base_encoder = backbone_resnet,\n",
        "    dim_prj = args.dim_prj,\n",
        "    K = args.K,\n",
        "    m = args.momentum,\n",
        "    T = args.T,\n",
        "    top_k = args.top_k,\n",
        "    lambda_bce = args.lambda_bce\n",
        ").cuda()\n",
        "\n",
        "# 2. Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "# 3. Cosine Scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)\n",
        "\n",
        "# 4. Train\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    # ===============================\n",
        "    # Training\n",
        "    # ===============================\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    for i, (repeat_mel, label, _) in enumerate(pretrain_loader): # label 여기선 사용 X\n",
        "        im_q, im_k, _ = aug(repeat_mel)\n",
        "        im_q = im_q.cuda(device=args.gpu, non_blocking=True)\n",
        "        im_k = im_k.cuda(device=args.gpu, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, output, target = model(im_q=im_q, im_k=im_k)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(pretrain_loader)\n",
        "    print(f\"Epoch {epoch} | Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # =====================================\n",
        "    # Scheduler\n",
        "    # =====================================\n",
        "    scheduler.step()\n",
        "\n",
        "    # =====================================\n",
        "    # Logging with wandb\n",
        "    # =====================================\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"lr\": current_lr\n",
        "    })\n",
        "\n",
        "    # =====================================\n",
        "    # Checkpoint (Every 100 epochs)\n",
        "    # =====================================\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_{epoch:03d}.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }, ckpt_path)\n",
        "        print(f\"💾 Saved checkpoint to {ckpt_path}\")\n",
        "\n",
        "    # ===============================\n",
        "    # Save Best Checkpoint\n",
        "    # ===============================\n",
        "    if avg_train_loss < best_loss:\n",
        "        best_loss = avg_train_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch}, loss: {best_loss:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "OUrCwf7XnUuS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "OUrCwf7XnUuS",
        "outputId": "3264345e-0a71-422b-85e5-3c907a59c2a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>lr</td><td>█████████▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▂▂▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>299</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.26079</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Moco_MLS_PT_128bs_top20_0.3ld_2506061841</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/61aoaj63' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/61aoaj63</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250606_094144-61aoaj63/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZSwN7t7l2n5",
      "metadata": {
        "id": "sZSwN7t7l2n5"
      },
      "source": [
        "## 5. Linear Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "XX5E04eJmWBM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XX5E04eJmWBM",
        "outputId": "65b3bfd3-ba0d-496a-f196-b74c7ac61774"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250606_102656-zzlehe9d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/zzlehe9d' target=\"_blank\">Moco_MLS_LE_128bs_top20_0.3ld_2506061926</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/zzlehe9d' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/zzlehe9d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 8.3402\n",
            "  [Average] Sens: 0.2995, Spec: 0.6539, Score: 0.4767\n",
            "  [Crackle] Sens: 0.4136, Spec: 0.4715, Score: 0.4425\n",
            "  [Wheeze]  Sens: 0.1854, Spec: 0.8363, Score: 0.5109\n",
            "=> Saved best checkpoint (epoch: 1, loss: 8.3402)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Train Loss: 7.3586\n",
            "  [Average] Sens: 0.2357, Spec: 0.7486, Score: 0.4922\n",
            "  [Crackle] Sens: 0.3390, Spec: 0.6723, Score: 0.5056\n",
            "  [Wheeze]  Sens: 0.1325, Spec: 0.8250, Score: 0.4787\n",
            "=> Saved best checkpoint (epoch: 2, loss: 7.3586)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Train Loss: 5.2327\n",
            "  [Average] Sens: 0.3599, Spec: 0.6653, Score: 0.5126\n",
            "  [Crackle] Sens: 0.4814, Spec: 0.5137, Score: 0.4975\n",
            "  [Wheeze]  Sens: 0.2384, Spec: 0.8169, Score: 0.5276\n",
            "=> Saved best checkpoint (epoch: 3, loss: 5.2327)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Train Loss: 3.2149\n",
            "  [Average] Sens: 0.1522, Spec: 0.8109, Score: 0.4815\n",
            "  [Crackle] Sens: 0.1322, Spec: 0.8097, Score: 0.4710\n",
            "  [Wheeze]  Sens: 0.1722, Spec: 0.8120, Score: 0.4921\n",
            "=> Saved best checkpoint (epoch: 4, loss: 3.2149)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train Loss: 1.7745\n",
            "  [Average] Sens: 0.5052, Spec: 0.6579, Score: 0.5816\n",
            "  [Crackle] Sens: 0.5932, Spec: 0.5687, Score: 0.5810\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.7472, Score: 0.5822\n",
            "=> Saved best checkpoint (epoch: 5, loss: 1.7745)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:01<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Train Loss: 1.3691\n",
            "  [Average] Sens: 0.3531, Spec: 0.8212, Score: 0.5872\n",
            "  [Crackle] Sens: 0.6068, Spec: 0.6765, Score: 0.6417\n",
            "  [Wheeze]  Sens: 0.0993, Spec: 0.9660, Score: 0.5327\n",
            "=> Saved best checkpoint (epoch: 6, loss: 1.3691)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  7.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Train Loss: 1.1049\n",
            "  [Average] Sens: 0.5016, Spec: 0.7368, Score: 0.6192\n",
            "  [Crackle] Sens: 0.5661, Spec: 0.6681, Score: 0.6171\n",
            "  [Wheeze]  Sens: 0.4371, Spec: 0.8055, Score: 0.6213\n",
            "=> Saved best checkpoint (epoch: 7, loss: 1.1049)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Train Loss: 1.1195\n",
            "  [Average] Sens: 0.4511, Spec: 0.7551, Score: 0.6031\n",
            "  [Crackle] Sens: 0.4915, Spec: 0.6448, Score: 0.5682\n",
            "  [Wheeze]  Sens: 0.4106, Spec: 0.8655, Score: 0.6380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Train Loss: 1.1467\n",
            "  [Average] Sens: 0.3889, Spec: 0.7694, Score: 0.5792\n",
            "  [Crackle] Sens: 0.4136, Spec: 0.6490, Score: 0.5313\n",
            "  [Wheeze]  Sens: 0.3642, Spec: 0.8898, Score: 0.6270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train Loss: 1.0375\n",
            "  [Average] Sens: 0.3990, Spec: 0.7883, Score: 0.5936\n",
            "  [Crackle] Sens: 0.4271, Spec: 0.6786, Score: 0.5529\n",
            "  [Wheeze]  Sens: 0.3709, Spec: 0.8979, Score: 0.6344\n",
            "=> Saved best checkpoint (epoch: 10, loss: 1.0375)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, Train Loss: 0.9427\n",
            "  [Average] Sens: 0.4125, Spec: 0.7980, Score: 0.6052\n",
            "  [Crackle] Sens: 0.4475, Spec: 0.6786, Score: 0.5631\n",
            "  [Wheeze]  Sens: 0.3775, Spec: 0.9173, Score: 0.6474\n",
            "=> Saved best checkpoint (epoch: 11, loss: 0.9427)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Train Loss: 0.8639\n",
            "  [Average] Sens: 0.4276, Spec: 0.8060, Score: 0.6168\n",
            "  [Crackle] Sens: 0.4712, Spec: 0.6913, Score: 0.5813\n",
            "  [Wheeze]  Sens: 0.3841, Spec: 0.9206, Score: 0.6523\n",
            "=> Saved best checkpoint (epoch: 12, loss: 0.8639)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Train Loss: 0.7799\n",
            "  [Average] Sens: 0.4693, Spec: 0.8162, Score: 0.6428\n",
            "  [Crackle] Sens: 0.4949, Spec: 0.6892, Score: 0.5921\n",
            "  [Wheeze]  Sens: 0.4437, Spec: 0.9433, Score: 0.6935\n",
            "=> Saved best checkpoint (epoch: 13, loss: 0.7799)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, Train Loss: 0.7497\n",
            "  [Average] Sens: 0.4712, Spec: 0.8025, Score: 0.6368\n",
            "  [Crackle] Sens: 0.5119, Spec: 0.6892, Score: 0.6005\n",
            "  [Wheeze]  Sens: 0.4305, Spec: 0.9157, Score: 0.6731\n",
            "=> Saved best checkpoint (epoch: 14, loss: 0.7497)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, Train Loss: 0.7307\n",
            "  [Average] Sens: 0.4532, Spec: 0.8327, Score: 0.6430\n",
            "  [Crackle] Sens: 0.5356, Spec: 0.7125, Score: 0.6240\n",
            "  [Wheeze]  Sens: 0.3709, Spec: 0.9530, Score: 0.6619\n",
            "=> Saved best checkpoint (epoch: 15, loss: 0.7307)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, Train Loss: 0.7461\n",
            "  [Average] Sens: 0.4798, Spec: 0.8410, Score: 0.6604\n",
            "  [Crackle] Sens: 0.5424, Spec: 0.7209, Score: 0.6317\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.9611, Score: 0.6892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, Train Loss: 0.8053\n",
            "  [Average] Sens: 0.4662, Spec: 0.8202, Score: 0.6432\n",
            "  [Crackle] Sens: 0.5085, Spec: 0.6956, Score: 0.6020\n",
            "  [Wheeze]  Sens: 0.4238, Spec: 0.9449, Score: 0.6844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18, Train Loss: 0.8374\n",
            "  [Average] Sens: 0.4528, Spec: 0.8233, Score: 0.6381\n",
            "  [Crackle] Sens: 0.5017, Spec: 0.6871, Score: 0.5944\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9595, Score: 0.6817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19, Train Loss: 0.8375\n",
            "  [Average] Sens: 0.4528, Spec: 0.8260, Score: 0.6394\n",
            "  [Crackle] Sens: 0.4949, Spec: 0.6892, Score: 0.5921\n",
            "  [Wheeze]  Sens: 0.4106, Spec: 0.9627, Score: 0.6867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Train Loss: 0.8089\n",
            "  [Average] Sens: 0.4343, Spec: 0.8255, Score: 0.6299\n",
            "  [Crackle] Sens: 0.4712, Spec: 0.6850, Score: 0.5781\n",
            "  [Wheeze]  Sens: 0.3974, Spec: 0.9660, Score: 0.6817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21, Train Loss: 0.7734\n",
            "  [Average] Sens: 0.4443, Spec: 0.8260, Score: 0.6352\n",
            "  [Crackle] Sens: 0.4780, Spec: 0.6829, Score: 0.5804\n",
            "  [Wheeze]  Sens: 0.4106, Spec: 0.9692, Score: 0.6899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22, Train Loss: 0.7435\n",
            "  [Average] Sens: 0.4379, Spec: 0.8316, Score: 0.6347\n",
            "  [Crackle] Sens: 0.4983, Spec: 0.6956, Score: 0.5969\n",
            "  [Wheeze]  Sens: 0.3775, Spec: 0.9676, Score: 0.6725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23, Train Loss: 0.7171\n",
            "  [Average] Sens: 0.4579, Spec: 0.8326, Score: 0.6453\n",
            "  [Crackle] Sens: 0.5119, Spec: 0.6977, Score: 0.6048\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9676, Score: 0.6858\n",
            "=> Saved best checkpoint (epoch: 23, loss: 0.7171)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24, Train Loss: 0.6984\n",
            "  [Average] Sens: 0.4580, Spec: 0.8324, Score: 0.6452\n",
            "  [Crackle] Sens: 0.5186, Spec: 0.6956, Score: 0.6071\n",
            "  [Wheeze]  Sens: 0.3974, Spec: 0.9692, Score: 0.6833\n",
            "=> Saved best checkpoint (epoch: 24, loss: 0.6984)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, Train Loss: 0.6869\n",
            "  [Average] Sens: 0.4647, Spec: 0.8419, Score: 0.6533\n",
            "  [Crackle] Sens: 0.5254, Spec: 0.7146, Score: 0.6200\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9692, Score: 0.6866\n",
            "=> Saved best checkpoint (epoch: 25, loss: 0.6869)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26, Train Loss: 0.6819\n",
            "  [Average] Sens: 0.4766, Spec: 0.8435, Score: 0.6600\n",
            "  [Crackle] Sens: 0.5492, Spec: 0.7146, Score: 0.6319\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9724, Score: 0.6882\n",
            "=> Saved best checkpoint (epoch: 26, loss: 0.6819)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27, Train Loss: 0.6804\n",
            "  [Average] Sens: 0.4733, Spec: 0.8456, Score: 0.6594\n",
            "  [Crackle] Sens: 0.5492, Spec: 0.7188, Score: 0.6340\n",
            "  [Wheeze]  Sens: 0.3974, Spec: 0.9724, Score: 0.6849\n",
            "=> Saved best checkpoint (epoch: 27, loss: 0.6804)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28, Train Loss: 0.6788\n",
            "  [Average] Sens: 0.4783, Spec: 0.8427, Score: 0.6605\n",
            "  [Crackle] Sens: 0.5525, Spec: 0.7146, Score: 0.6336\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9708, Score: 0.6874\n",
            "=> Saved best checkpoint (epoch: 28, loss: 0.6788)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29, Train Loss: 0.6754\n",
            "  [Average] Sens: 0.4766, Spec: 0.8427, Score: 0.6596\n",
            "  [Crackle] Sens: 0.5492, Spec: 0.7146, Score: 0.6319\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9708, Score: 0.6874\n",
            "=> Saved best checkpoint (epoch: 29, loss: 0.6754)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30, Train Loss: 0.6691\n",
            "  [Average] Sens: 0.4732, Spec: 0.8406, Score: 0.6569\n",
            "  [Crackle] Sens: 0.5424, Spec: 0.7104, Score: 0.6264\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9708, Score: 0.6874\n",
            "=> Saved best checkpoint (epoch: 30, loss: 0.6691)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31, Train Loss: 0.6607\n",
            "  [Average] Sens: 0.4664, Spec: 0.8417, Score: 0.6540\n",
            "  [Crackle] Sens: 0.5288, Spec: 0.7125, Score: 0.6206\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9708, Score: 0.6874\n",
            "=> Saved best checkpoint (epoch: 31, loss: 0.6607)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32, Train Loss: 0.6506\n",
            "  [Average] Sens: 0.4664, Spec: 0.8414, Score: 0.6539\n",
            "  [Crackle] Sens: 0.5288, Spec: 0.7104, Score: 0.6196\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9724, Score: 0.6882\n",
            "=> Saved best checkpoint (epoch: 32, loss: 0.6506)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33, Train Loss: 0.6398\n",
            "  [Average] Sens: 0.4630, Spec: 0.8446, Score: 0.6538\n",
            "  [Crackle] Sens: 0.5220, Spec: 0.7167, Score: 0.6194\n",
            "  [Wheeze]  Sens: 0.4040, Spec: 0.9724, Score: 0.6882\n",
            "=> Saved best checkpoint (epoch: 33, loss: 0.6398)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34, Train Loss: 0.6287\n",
            "  [Average] Sens: 0.4696, Spec: 0.8435, Score: 0.6566\n",
            "  [Crackle] Sens: 0.5220, Spec: 0.7146, Score: 0.6183\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.9724, Score: 0.6948\n",
            "=> Saved best checkpoint (epoch: 34, loss: 0.6287)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35, Train Loss: 0.6176\n",
            "  [Average] Sens: 0.4645, Spec: 0.8456, Score: 0.6551\n",
            "  [Crackle] Sens: 0.5119, Spec: 0.7188, Score: 0.6153\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.9724, Score: 0.6948\n",
            "=> Saved best checkpoint (epoch: 35, loss: 0.6176)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36, Train Loss: 0.6064\n",
            "  [Average] Sens: 0.4730, Spec: 0.8446, Score: 0.6588\n",
            "  [Crackle] Sens: 0.5288, Spec: 0.7167, Score: 0.6228\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.9724, Score: 0.6948\n",
            "=> Saved best checkpoint (epoch: 36, loss: 0.6064)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37, Train Loss: 0.5954\n",
            "  [Average] Sens: 0.4764, Spec: 0.8456, Score: 0.6610\n",
            "  [Crackle] Sens: 0.5356, Spec: 0.7188, Score: 0.6272\n",
            "  [Wheeze]  Sens: 0.4172, Spec: 0.9724, Score: 0.6948\n",
            "=> Saved best checkpoint (epoch: 37, loss: 0.5954)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38, Train Loss: 0.5845\n",
            "  [Average] Sens: 0.4898, Spec: 0.8507, Score: 0.6702\n",
            "  [Crackle] Sens: 0.5492, Spec: 0.7273, Score: 0.6382\n",
            "  [Wheeze]  Sens: 0.4305, Spec: 0.9741, Score: 0.7023\n",
            "=> Saved best checkpoint (epoch: 38, loss: 0.5845)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39, Train Loss: 0.5738\n",
            "  [Average] Sens: 0.4881, Spec: 0.8538, Score: 0.6710\n",
            "  [Crackle] Sens: 0.5458, Spec: 0.7336, Score: 0.6397\n",
            "  [Wheeze]  Sens: 0.4305, Spec: 0.9741, Score: 0.7023\n",
            "=> Saved best checkpoint (epoch: 39, loss: 0.5738)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40, Train Loss: 0.5632\n",
            "  [Average] Sens: 0.4864, Spec: 0.8560, Score: 0.6712\n",
            "  [Crackle] Sens: 0.5424, Spec: 0.7378, Score: 0.6401\n",
            "  [Wheeze]  Sens: 0.4305, Spec: 0.9741, Score: 0.7023\n",
            "=> Saved best checkpoint (epoch: 40, loss: 0.5632)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41, Train Loss: 0.5528\n",
            "  [Average] Sens: 0.4830, Spec: 0.8549, Score: 0.6690\n",
            "  [Crackle] Sens: 0.5356, Spec: 0.7357, Score: 0.6357\n",
            "  [Wheeze]  Sens: 0.4305, Spec: 0.9741, Score: 0.7023\n",
            "=> Saved best checkpoint (epoch: 41, loss: 0.5528)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42, Train Loss: 0.5424\n",
            "  [Average] Sens: 0.4846, Spec: 0.8660, Score: 0.6753\n",
            "  [Crackle] Sens: 0.5322, Spec: 0.7548, Score: 0.6435\n",
            "  [Wheeze]  Sens: 0.4371, Spec: 0.9773, Score: 0.7072\n",
            "=> Saved best checkpoint (epoch: 42, loss: 0.5424)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43, Train Loss: 0.5321\n",
            "  [Average] Sens: 0.4863, Spec: 0.8663, Score: 0.6763\n",
            "  [Crackle] Sens: 0.5356, Spec: 0.7569, Score: 0.6462\n",
            "  [Wheeze]  Sens: 0.4371, Spec: 0.9757, Score: 0.7064\n",
            "=> Saved best checkpoint (epoch: 43, loss: 0.5321)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44, Train Loss: 0.5218\n",
            "  [Average] Sens: 0.4863, Spec: 0.8652, Score: 0.6757\n",
            "  [Crackle] Sens: 0.5288, Spec: 0.7548, Score: 0.6418\n",
            "  [Wheeze]  Sens: 0.4437, Spec: 0.9757, Score: 0.7097\n",
            "=> Saved best checkpoint (epoch: 44, loss: 0.5218)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45, Train Loss: 0.5115\n",
            "  [Average] Sens: 0.4997, Spec: 0.8663, Score: 0.6830\n",
            "  [Crackle] Sens: 0.5492, Spec: 0.7569, Score: 0.6530\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9757, Score: 0.7130\n",
            "=> Saved best checkpoint (epoch: 45, loss: 0.5115)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46, Train Loss: 0.5011\n",
            "  [Average] Sens: 0.5065, Spec: 0.8689, Score: 0.6877\n",
            "  [Crackle] Sens: 0.5627, Spec: 0.7653, Score: 0.6640\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9724, Score: 0.7114\n",
            "=> Saved best checkpoint (epoch: 46, loss: 0.5011)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47, Train Loss: 0.4906\n",
            "  [Average] Sens: 0.5082, Spec: 0.8665, Score: 0.6874\n",
            "  [Crackle] Sens: 0.5661, Spec: 0.7590, Score: 0.6625\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9741, Score: 0.7122\n",
            "=> Saved best checkpoint (epoch: 47, loss: 0.4906)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48, Train Loss: 0.4801\n",
            "  [Average] Sens: 0.5099, Spec: 0.8692, Score: 0.6896\n",
            "  [Crackle] Sens: 0.5695, Spec: 0.7611, Score: 0.6653\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9773, Score: 0.7138\n",
            "=> Saved best checkpoint (epoch: 48, loss: 0.4801)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49, Train Loss: 0.4695\n",
            "  [Average] Sens: 0.5133, Spec: 0.8671, Score: 0.6902\n",
            "  [Crackle] Sens: 0.5763, Spec: 0.7569, Score: 0.6666\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9773, Score: 0.7138\n",
            "=> Saved best checkpoint (epoch: 49, loss: 0.4695)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50, Train Loss: 0.4590\n",
            "  [Average] Sens: 0.5167, Spec: 0.8695, Score: 0.6931\n",
            "  [Crackle] Sens: 0.5831, Spec: 0.7632, Score: 0.6731\n",
            "  [Wheeze]  Sens: 0.4503, Spec: 0.9757, Score: 0.7130\n",
            "=> Saved best checkpoint (epoch: 50, loss: 0.4590)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51, Train Loss: 0.4487\n",
            "  [Average] Sens: 0.5217, Spec: 0.8747, Score: 0.6982\n",
            "  [Crackle] Sens: 0.5864, Spec: 0.7738, Score: 0.6801\n",
            "  [Wheeze]  Sens: 0.4570, Spec: 0.9757, Score: 0.7163\n",
            "=> Saved best checkpoint (epoch: 51, loss: 0.4487)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52, Train Loss: 0.4386\n",
            "  [Average] Sens: 0.5251, Spec: 0.8821, Score: 0.7036\n",
            "  [Crackle] Sens: 0.5932, Spec: 0.7886, Score: 0.6909\n",
            "  [Wheeze]  Sens: 0.4570, Spec: 0.9757, Score: 0.7163\n",
            "=> Saved best checkpoint (epoch: 52, loss: 0.4386)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53, Train Loss: 0.4288\n",
            "  [Average] Sens: 0.5335, Spec: 0.8843, Score: 0.7089\n",
            "  [Crackle] Sens: 0.6034, Spec: 0.7928, Score: 0.6981\n",
            "  [Wheeze]  Sens: 0.4636, Spec: 0.9757, Score: 0.7196\n",
            "=> Saved best checkpoint (epoch: 53, loss: 0.4288)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54, Train Loss: 0.4194\n",
            "  [Average] Sens: 0.5470, Spec: 0.8895, Score: 0.7183\n",
            "  [Crackle] Sens: 0.6305, Spec: 0.8034, Score: 0.7169\n",
            "  [Wheeze]  Sens: 0.4636, Spec: 0.9757, Score: 0.7196\n",
            "=> Saved best checkpoint (epoch: 54, loss: 0.4194)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55, Train Loss: 0.4107\n",
            "  [Average] Sens: 0.5554, Spec: 0.8927, Score: 0.7241\n",
            "  [Crackle] Sens: 0.6407, Spec: 0.8097, Score: 0.7252\n",
            "  [Wheeze]  Sens: 0.4702, Spec: 0.9757, Score: 0.7229\n",
            "=> Saved best checkpoint (epoch: 55, loss: 0.4107)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56, Train Loss: 0.4028\n",
            "  [Average] Sens: 0.5571, Spec: 0.8969, Score: 0.7270\n",
            "  [Crackle] Sens: 0.6373, Spec: 0.8182, Score: 0.7277\n",
            "  [Wheeze]  Sens: 0.4768, Spec: 0.9757, Score: 0.7263\n",
            "=> Saved best checkpoint (epoch: 56, loss: 0.4028)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57, Train Loss: 0.3959\n",
            "  [Average] Sens: 0.5537, Spec: 0.9001, Score: 0.7269\n",
            "  [Crackle] Sens: 0.6305, Spec: 0.8245, Score: 0.7275\n",
            "  [Wheeze]  Sens: 0.4768, Spec: 0.9757, Score: 0.7263\n",
            "=> Saved best checkpoint (epoch: 57, loss: 0.3959)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58, Train Loss: 0.3901\n",
            "  [Average] Sens: 0.5571, Spec: 0.9025, Score: 0.7298\n",
            "  [Crackle] Sens: 0.6373, Spec: 0.8309, Score: 0.7341\n",
            "  [Wheeze]  Sens: 0.4768, Spec: 0.9741, Score: 0.7254\n",
            "=> Saved best checkpoint (epoch: 58, loss: 0.3901)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59, Train Loss: 0.3852\n",
            "  [Average] Sens: 0.5655, Spec: 0.9033, Score: 0.7344\n",
            "  [Crackle] Sens: 0.6475, Spec: 0.8309, Score: 0.7392\n",
            "  [Wheeze]  Sens: 0.4834, Spec: 0.9757, Score: 0.7296\n",
            "=> Saved best checkpoint (epoch: 59, loss: 0.3852)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60, Train Loss: 0.3811\n",
            "  [Average] Sens: 0.5621, Spec: 0.9001, Score: 0.7311\n",
            "  [Crackle] Sens: 0.6475, Spec: 0.8245, Score: 0.7360\n",
            "  [Wheeze]  Sens: 0.4768, Spec: 0.9757, Score: 0.7263\n",
            "=> Saved best checkpoint (epoch: 60, loss: 0.3811)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61, Train Loss: 0.3776\n",
            "  [Average] Sens: 0.5671, Spec: 0.8999, Score: 0.7335\n",
            "  [Crackle] Sens: 0.6508, Spec: 0.8224, Score: 0.7366\n",
            "  [Wheeze]  Sens: 0.4834, Spec: 0.9773, Score: 0.7304\n",
            "=> Saved best checkpoint (epoch: 61, loss: 0.3776)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62, Train Loss: 0.3747\n",
            "  [Average] Sens: 0.5772, Spec: 0.9038, Score: 0.7405\n",
            "  [Crackle] Sens: 0.6644, Spec: 0.8288, Score: 0.7466\n",
            "  [Wheeze]  Sens: 0.4901, Spec: 0.9789, Score: 0.7345\n",
            "=> Saved best checkpoint (epoch: 62, loss: 0.3747)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63, Train Loss: 0.3721\n",
            "  [Average] Sens: 0.5807, Spec: 0.9057, Score: 0.7432\n",
            "  [Crackle] Sens: 0.6780, Spec: 0.8309, Score: 0.7544\n",
            "  [Wheeze]  Sens: 0.4834, Spec: 0.9806, Score: 0.7320\n",
            "=> Saved best checkpoint (epoch: 63, loss: 0.3721)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64, Train Loss: 0.3702\n",
            "  [Average] Sens: 0.5841, Spec: 0.9070, Score: 0.7456\n",
            "  [Crackle] Sens: 0.6847, Spec: 0.8351, Score: 0.7599\n",
            "  [Wheeze]  Sens: 0.4834, Spec: 0.9789, Score: 0.7312\n",
            "=> Saved best checkpoint (epoch: 64, loss: 0.3702)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65, Train Loss: 0.3687\n",
            "  [Average] Sens: 0.5892, Spec: 0.9070, Score: 0.7481\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8351, Score: 0.7650\n",
            "  [Wheeze]  Sens: 0.4834, Spec: 0.9789, Score: 0.7312\n",
            "=> Saved best checkpoint (epoch: 65, loss: 0.3687)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66, Train Loss: 0.3678\n",
            "  [Average] Sens: 0.5809, Spec: 0.9064, Score: 0.7437\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8372, Score: 0.7644\n",
            "  [Wheeze]  Sens: 0.4702, Spec: 0.9757, Score: 0.7229\n",
            "=> Saved best checkpoint (epoch: 66, loss: 0.3678)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67, Train Loss: 0.3674\n",
            "  [Average] Sens: 0.5676, Spec: 0.9073, Score: 0.7374\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8372, Score: 0.7644\n",
            "  [Wheeze]  Sens: 0.4437, Spec: 0.9773, Score: 0.7105\n",
            "=> Saved best checkpoint (epoch: 67, loss: 0.3674)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68, Train Loss: 0.3674\n",
            "  [Average] Sens: 0.5742, Spec: 0.9091, Score: 0.7416\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8457, Score: 0.7686\n",
            "  [Wheeze]  Sens: 0.4570, Spec: 0.9724, Score: 0.7147\n",
            "=> Saved best checkpoint (epoch: 68, loss: 0.3674)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69, Train Loss: 0.3672\n",
            "  [Average] Sens: 0.5924, Spec: 0.9075, Score: 0.7500\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8393, Score: 0.7637\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9757, Score: 0.7362\n",
            "=> Saved best checkpoint (epoch: 69, loss: 0.3672)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70, Train Loss: 0.3656\n",
            "  [Average] Sens: 0.5990, Spec: 0.9077, Score: 0.7534\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8478, Score: 0.7680\n",
            "  [Wheeze]  Sens: 0.5099, Spec: 0.9676, Score: 0.7388\n",
            "=> Saved best checkpoint (epoch: 70, loss: 0.3656)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71, Train Loss: 0.3620\n",
            "  [Average] Sens: 0.6239, Spec: 0.9039, Score: 0.7639\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8436, Score: 0.7675\n",
            "  [Wheeze]  Sens: 0.5563, Spec: 0.9643, Score: 0.7603\n",
            "=> Saved best checkpoint (epoch: 71, loss: 0.3620)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72, Train Loss: 0.3575\n",
            "  [Average] Sens: 0.6057, Spec: 0.9048, Score: 0.7552\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8436, Score: 0.7658\n",
            "  [Wheeze]  Sens: 0.5232, Spec: 0.9660, Score: 0.7446\n",
            "=> Saved best checkpoint (epoch: 72, loss: 0.3575)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73, Train Loss: 0.3540\n",
            "  [Average] Sens: 0.5990, Spec: 0.9104, Score: 0.7547\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8436, Score: 0.7658\n",
            "  [Wheeze]  Sens: 0.5099, Spec: 0.9773, Score: 0.7436\n",
            "=> Saved best checkpoint (epoch: 73, loss: 0.3540)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74, Train Loss: 0.3525\n",
            "  [Average] Sens: 0.5924, Spec: 0.9121, Score: 0.7522\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8436, Score: 0.7658\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9806, Score: 0.7386\n",
            "=> Saved best checkpoint (epoch: 74, loss: 0.3525)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75, Train Loss: 0.3525\n",
            "  [Average] Sens: 0.5924, Spec: 0.9136, Score: 0.7530\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8499, Score: 0.7690\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9773, Score: 0.7370\n",
            "=> Saved best checkpoint (epoch: 75, loss: 0.3525)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76, Train Loss: 0.3518\n",
            "  [Average] Sens: 0.5990, Spec: 0.9136, Score: 0.7563\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8499, Score: 0.7690\n",
            "  [Wheeze]  Sens: 0.5099, Spec: 0.9773, Score: 0.7436\n",
            "=> Saved best checkpoint (epoch: 76, loss: 0.3518)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77, Train Loss: 0.3505\n",
            "  [Average] Sens: 0.5924, Spec: 0.9152, Score: 0.7538\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8499, Score: 0.7690\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9806, Score: 0.7386\n",
            "=> Saved best checkpoint (epoch: 77, loss: 0.3505)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78, Train Loss: 0.3499\n",
            "  [Average] Sens: 0.5907, Spec: 0.9150, Score: 0.7528\n",
            "  [Crackle] Sens: 0.6847, Spec: 0.8478, Score: 0.7663\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 78, loss: 0.3499)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79, Train Loss: 0.3495\n",
            "  [Average] Sens: 0.5907, Spec: 0.9134, Score: 0.7520\n",
            "  [Crackle] Sens: 0.6847, Spec: 0.8478, Score: 0.7663\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9789, Score: 0.7378\n",
            "=> Saved best checkpoint (epoch: 79, loss: 0.3495)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80, Train Loss: 0.3489\n",
            "  [Average] Sens: 0.5924, Spec: 0.9160, Score: 0.7542\n",
            "  [Crackle] Sens: 0.6881, Spec: 0.8499, Score: 0.7690\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 80, loss: 0.3489)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81, Train Loss: 0.3484\n",
            "  [Average] Sens: 0.5907, Spec: 0.9152, Score: 0.7530\n",
            "  [Crackle] Sens: 0.6847, Spec: 0.8499, Score: 0.7673\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9806, Score: 0.7386\n",
            "=> Saved best checkpoint (epoch: 81, loss: 0.3484)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82, Train Loss: 0.3480\n",
            "  [Average] Sens: 0.5941, Spec: 0.9163, Score: 0.7552\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8520, Score: 0.7718\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9806, Score: 0.7386\n",
            "=> Saved best checkpoint (epoch: 82, loss: 0.3480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83, Train Loss: 0.3476\n",
            "  [Average] Sens: 0.5941, Spec: 0.9160, Score: 0.7551\n",
            "  [Crackle] Sens: 0.6915, Spec: 0.8499, Score: 0.7707\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 83, loss: 0.3476)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84, Train Loss: 0.3473\n",
            "  [Average] Sens: 0.5958, Spec: 0.9160, Score: 0.7559\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 84, loss: 0.3473)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85, Train Loss: 0.3470\n",
            "  [Average] Sens: 0.5958, Spec: 0.9160, Score: 0.7559\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 85, loss: 0.3470)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86, Train Loss: 0.3468\n",
            "  [Average] Sens: 0.5958, Spec: 0.9160, Score: 0.7559\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 86, loss: 0.3468)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87, Train Loss: 0.3465\n",
            "  [Average] Sens: 0.5992, Spec: 0.9160, Score: 0.7576\n",
            "  [Crackle] Sens: 0.7017, Spec: 0.8499, Score: 0.7758\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 87, loss: 0.3465)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88, Train Loss: 0.3463\n",
            "  [Average] Sens: 0.5992, Spec: 0.9160, Score: 0.7576\n",
            "  [Crackle] Sens: 0.7017, Spec: 0.8499, Score: 0.7758\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 88, loss: 0.3463)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89, Train Loss: 0.3461\n",
            "  [Average] Sens: 0.5975, Spec: 0.9160, Score: 0.7568\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 89, loss: 0.3461)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90, Train Loss: 0.3459\n",
            "  [Average] Sens: 0.5958, Spec: 0.9160, Score: 0.7559\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 90, loss: 0.3459)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91, Train Loss: 0.3458\n",
            "  [Average] Sens: 0.5958, Spec: 0.9160, Score: 0.7559\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.4967, Spec: 0.9822, Score: 0.7394\n",
            "=> Saved best checkpoint (epoch: 91, loss: 0.3458)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92, Train Loss: 0.3457\n",
            "  [Average] Sens: 0.5991, Spec: 0.9160, Score: 0.7576\n",
            "  [Crackle] Sens: 0.6949, Spec: 0.8499, Score: 0.7724\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 92, loss: 0.3457)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93, Train Loss: 0.3456\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 93, loss: 0.3456)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94, Train Loss: 0.3455\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 94, loss: 0.3455)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95, Train Loss: 0.3454\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 95, loss: 0.3454)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96, Train Loss: 0.3454\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 96, loss: 0.3454)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97, Train Loss: 0.3453\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 97, loss: 0.3453)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98, Train Loss: 0.3453\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 98, loss: 0.3453)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  8.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99, Train Loss: 0.3452\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 99, loss: 0.3452)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Evaluation: 100%|██████████| 6/6 [00:00<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Train Loss: 0.3452\n",
            "  [Average] Sens: 0.6008, Spec: 0.9160, Score: 0.7584\n",
            "  [Crackle] Sens: 0.6983, Spec: 0.8499, Score: 0.7741\n",
            "  [Wheeze]  Sens: 0.5033, Spec: 0.9822, Score: 0.7427\n",
            "=> Saved best checkpoint (epoch: 100, loss: 0.3452)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Moco_MLS_LE_128bs_top20_0.3ld_2506061926</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/zzlehe9d' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/zzlehe9d</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250606_102656-zzlehe9d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "finetune_project_name = f'Moco_MLS_LE_{args.batch_size}bs_top{args.top_k}_{args.lambda_bce}ld_{get_timestamp()}'\n",
        "\n",
        "# wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "wandb.init(\n",
        "    project=\"SHS_ICBHI_MLS\",          # 프로젝트 이름\n",
        "    name=f\"{finetune_project_name}\",  # 실험 이름\n",
        "    config={\n",
        "        \"epochs\": args.ft_epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"lr\": args.lr,\n",
        "        \"momentum\": args.momentum,\n",
        "        \"weight_decay\": args.weight_decay\n",
        "    }\n",
        ")\n",
        "\n",
        "# 1. Model Load\n",
        "# ckpt_path\n",
        "load_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "save_ckpt_path = CHECKPOINT_PATH\n",
        "\n",
        "# Load Encoder\n",
        "model_eval = MoCo(\n",
        "    base_encoder=backbone_resnet,\n",
        "    dim_prj = args.dim_prj,\n",
        "    K = args.K,\n",
        "    m = args.momentum,\n",
        "    T = args.T,\n",
        "    top_k = args.top_k,\n",
        "    lambda_bce = args.lambda_bce\n",
        ")\n",
        "checkpoint = torch.load(load_ckpt_path,\n",
        "                        map_location=device)  # map_location 파라미터 추가\n",
        "model_eval.load_state_dict(checkpoint[\"state_dict\"])\n",
        "encoder = model_eval.encoder_q.eval().to(device)\n",
        "\n",
        "# 2. Dataset 정의\n",
        "# Dataset 정의는 이미 되어있음 - finetune_loader, test_loader\n",
        "\n",
        "# 3. Linear Evaluation을 위한 분류 모델 정의 ( Data 개수 작으므로, encoder 파라미터 frozen )\n",
        "class FineTuningModel(nn.Module):\n",
        "    def __init__(self, encoder, out_dim, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        # 마지막 FC layer를 제외한 encoder의 모든 레이어 freeze\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 새로운 분류 헤드 추가 (Crackle, Wheeze를 독립적으로 예측하므로 num_classes=2)\n",
        "        # self.classifier = nn.Sequential(\n",
        "        #     nn.Linear(out_dim, 256),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Linear(256, num_classes)\n",
        "        # )\n",
        "        self.classifier = nn.Linear(out_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        return self.classifier(features)\n",
        "\n",
        "# 4. 모델, 손실 함수, 옵티마이저 설정\n",
        "model = FineTuningModel(encoder, out_dim = args.out_dim).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.AdamW(model.classifier.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=args.ft_epochs, eta_min=1e-6)  # Linear Evaluation에서 epochs는 다르게 적용\n",
        "\n",
        "# Best loss 초기화\n",
        "best_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "# 5. Linear Evaluation\n",
        "for epoch in range(args.ft_epochs):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(finetune_loader, desc='Linear Evaluation')\n",
        "    for i, (cycle, labels, _) in enumerate(pbar):\n",
        "        # Forward pass\n",
        "        cycle = cycle.cuda(args.gpu)\n",
        "        labels = labels.cuda(args.gpu)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        output = model(cycle)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # 예측값과 실제값 저장\n",
        "        predicted = (torch.sigmoid(output) > 0.5).float()\n",
        "        all_preds.append(predicted.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "\n",
        "\n",
        "    # train loss\n",
        "    train_loss = total_loss / len(finetune_loader)\n",
        "\n",
        "    # Concatenate\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()    # shape: [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy()  # shape: [N, 2]\n",
        "\n",
        "    crackle_sens = 0\n",
        "    crackle_spec = 0\n",
        "    wheeze_sens = 0\n",
        "    wheeze_spec = 0\n",
        "\n",
        "    for i, label_name in enumerate(['Crackle', 'Wheeze']):\n",
        "        y_true = all_labels[:, i]\n",
        "        y_pred = all_preds[:, i]\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)  # [[TN, FP], [FN, TP]]\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        sensitivity = TP / (TP + FN + 1e-6)\n",
        "        specificity = TN / (TN + FP + 1e-6)\n",
        "\n",
        "        if i == 0:\n",
        "            crackle_sens = sensitivity\n",
        "            crackle_spec = specificity\n",
        "        elif i == 1:\n",
        "            wheeze_sens = sensitivity\n",
        "            wheeze_spec = specificity\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"  [Average] Sens: {(crackle_sens+wheeze_sens)/2:.4f}, Spec: {(crackle_spec+wheeze_spec)/2:.4f}, Score: {(crackle_sens+crackle_spec+wheeze_sens+wheeze_spec)/4:.4f}\")\n",
        "    print(f\"  [Crackle] Sens: {crackle_sens:.4f}, Spec: {crackle_spec:.4f}, Score: {(crackle_sens+crackle_spec)/2:.4f}\")\n",
        "    print(f\"  [Wheeze]  Sens: {wheeze_sens:.4f}, Spec: {wheeze_spec:.4f}, Score: {(wheeze_sens+wheeze_spec)/2:.4f}\")\n",
        "\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save Best Checkpoint\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        best_epoch = epoch\n",
        "        best_ckpt_path = save_ckpt_path + f\"/{finetune_project_name}_best.pth.tar\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': best_loss\n",
        "        }, best_ckpt_path)\n",
        "        print(f\"=> Saved best checkpoint (epoch: {epoch+1}, loss: {best_loss:.4f})\")\n",
        "\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1UvrDN2qahFy",
      "metadata": {
        "id": "1UvrDN2qahFy"
      },
      "source": [
        "## 6. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "LBJcIre5aXtS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "LBJcIre5aXtS",
        "outputId": "484a0b57-b653-4bde-9fdc-9b49dfd222a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250606_102909-y8yhsq6n</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/y8yhsq6n' target=\"_blank\">Moco_MLS_TT_128bs_top20_0.3ld_2506061929</a></strong> to <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/y8yhsq6n' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/y8yhsq6n</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test] Loss: 2.6113\n",
            "  [Crackle] Sens: 0.4015, Spec: 0.7576, ICBHI Score: 0.5796\n",
            "  [Wheeze] Sens: 0.3220, Spec: 0.7689, ICBHI Score: 0.5454\n",
            "  [Average] Sens: 0.3617, Spec: 0.7632, ICBHI Score: 0.5625\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_project_name = f'Moco_MLS_TT_{args.batch_size}bs_top{args.top_k}_{args.lambda_bce}ld_{get_timestamp()}'\n",
        "\n",
        "# wandb 초기화 (프로젝트명, 실험 이름 등 설정)\n",
        "wandb.init(\n",
        "    project=\"SHS_ICBHI_MLS\",          # 프로젝트 이름\n",
        "    name=f\"{test_project_name}\"       # 실험 이름\n",
        ")\n",
        "\n",
        "# Model Load\n",
        "# ckpt_path\n",
        "load_ckpt_path = CHECKPOINT_PATH + f\"/{pretrain_project_name}_best_checkpoint.pth.tar\"\n",
        "save_ckpt_path = CHECKPOINT_PATH\n",
        "\n",
        "# Load Encoder\n",
        "model_eval = MoCo(base_encoder=backbone_resnet)\n",
        "checkpoint = torch.load(load_ckpt_path,\n",
        "                        map_location=device)  # map_location 파라미터 추가\n",
        "model_eval.load_state_dict(checkpoint[\"state_dict\"])\n",
        "encoder = model_eval.encoder_q.eval().to(device)\n",
        "\n",
        "model = FineTuningModel(encoder, out_dim = args.out_dim).to(device)\n",
        "\n",
        "# 저장된 체크포인트 로드\n",
        "best_ckpt_path = CHECKPOINT_PATH + f\"/{finetune_project_name}_best.pth.tar\"\n",
        "checkpoint = torch.load(best_ckpt_path, map_location=device)\n",
        "\n",
        "# 모델 가중치 로드 및 평가 모드 전환\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Test 평가 함수 (multi-label 대응)\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            all_preds.append(predicted.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()   # [N, 2]\n",
        "    all_labels = torch.cat(all_labels, dim=0).numpy() # [N, 2]\n",
        "\n",
        "    avg_loss = running_loss / len(val_loader)\n",
        "\n",
        "    # 개별 label별 성능 계산\n",
        "    results = {}\n",
        "    for i, lbl_name in enumerate(['Crackle', 'Wheeze']):\n",
        "        y_true = all_labels[:, i]\n",
        "        y_pred = all_preds[:, i]\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "        sens = TP / (TP + FN + 1e-6)\n",
        "        spec = TN / (TN + FP + 1e-6)\n",
        "        score = (sens + spec) / 2\n",
        "\n",
        "        results[lbl_name] = {\n",
        "            'sensitivity': sens,\n",
        "            'specificity': spec,\n",
        "            'ICBHI score': score\n",
        "        }\n",
        "\n",
        "    # 평균 점수\n",
        "    avg_results = {\n",
        "        key: sum([results[cls][key] for cls in results]) / 2\n",
        "        for key in ['sensitivity', 'specificity', 'ICBHI score']\n",
        "    }\n",
        "\n",
        "    return avg_loss, avg_results, results, all_labels, all_preds\n",
        "\n",
        "\n",
        "# wandb 로깅용 confusion matrix 함수 (label별)\n",
        "# 이걸 비율로 바꿀 필요가 있음\n",
        "def log_confusion_matrix_multilabel(y_true, y_pred, label_names):\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "        cm = confusion_matrix(y_t, y_p)\n",
        "        fig, ax = plt.subplots(figsize=(4, 4))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['0', '1'], yticklabels=['0', '1'], ax=ax)\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(f'Confusion Matrix - {label_name}')\n",
        "        plt.tight_layout()\n",
        "        wandb.log({f\"confusion_matrix_{label_name}\": wandb.Image(fig)})\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "test_loss, avg_results, label_results, y_true, y_pred = validate(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"[Test] Loss: {test_loss:.4f}\")\n",
        "for lbl in ['Crackle', 'Wheeze']:\n",
        "    r = label_results[lbl]\n",
        "    print(f\"  [{lbl}] Sens: {r['sensitivity']:.4f}, Spec: {r['specificity']:.4f}, ICBHI Score: {r['ICBHI score']:.4f}\")\n",
        "\n",
        "# 평균 성능 출력\n",
        "print(f\"  [Average] Sens: {avg_results['sensitivity']:.4f}, Spec: {avg_results['specificity']:.4f}, ICBHI Score: {avg_results['ICBHI score']:.4f}\")\n",
        "\n",
        "# wandb 로그\n",
        "wandb.log({\n",
        "    \"Test/loss\": test_loss,\n",
        "    \"Test/sens\": avg_results[\"sensitivity\"],\n",
        "    \"Test/spec\": avg_results[\"specificity\"],\n",
        "    \"Test/Score\": avg_results[\"ICBHI score\"]\n",
        "})\n",
        "\n",
        "# Confusion matrix wandb 이미지로 로그\n",
        "log_confusion_matrix_multilabel(y_true, y_pred, label_names=[\"Crackle\", \"Wheeze\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "zpCbGxISvfwh",
      "metadata": {
        "id": "zpCbGxISvfwh"
      },
      "outputs": [],
      "source": [
        "def multilabel_to_multiclass(labels):\n",
        "    \"\"\"\n",
        "    Crackle, Wheeze → 4개의 클래스로 변환\n",
        "    [0,0] → 0 (Normal)\n",
        "    [1,0] → 1 (Crackle)\n",
        "    [0,1] → 2 (Wheeze)\n",
        "    [1,1] → 3 (Both)\n",
        "    \"\"\"\n",
        "    labels = labels.cpu().numpy() if torch.is_tensor(labels) else labels\n",
        "    return (labels[:, 0] * 1 + labels[:, 1] * 2).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9004141d",
      "metadata": {
        "id": "9004141d"
      },
      "source": [
        "Confusion Matrix를 비율로 바꿀 필요가 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "m-lmNFFqd8l7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "m-lmNFFqd8l7",
        "outputId": "183316f6-d673-418e-d0a0-acf43dd46377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4x4 Confusion Matrix:\n",
            " [[843 311 348  77]\n",
            " [318 241  51  39]\n",
            " [182  66 115  22]\n",
            " [ 74  36  31   2]]\n",
            "Sensitivity: 0.5123\n",
            "Specificity: 0.5339\n",
            "ICBHI Score: 0.5231\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Metrics/ICHBI_score_4class</td><td>▁</td></tr><tr><td>Metrics/sensitivity_4class</td><td>▁</td></tr><tr><td>Metrics/specificity_4class</td><td>▁</td></tr><tr><td>Test/Score</td><td>▁</td></tr><tr><td>Test/loss</td><td>▁</td></tr><tr><td>Test/sens</td><td>▁</td></tr><tr><td>Test/spec</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Metrics/ICHBI_score_4class</td><td>0.5231</td></tr><tr><td>Metrics/sensitivity_4class</td><td>0.51232</td></tr><tr><td>Metrics/specificity_4class</td><td>0.53388</td></tr><tr><td>Test/Score</td><td>0.56249</td></tr><tr><td>Test/loss</td><td>2.61133</td></tr><tr><td>Test/sens</td><td>0.36174</td></tr><tr><td>Test/spec</td><td>0.76324</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Moco_MLS_TT_128bs_top20_0.3ld_2506061929</strong> at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/y8yhsq6n' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS/runs/y8yhsq6n</a><br> View project at: <a href='https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS' target=\"_blank\">https://wandb.ai/boaz_woony-boaz/SHS_ICBHI_MLS</a><br>Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250606_102909-y8yhsq6n/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def evaluate_multiclass_confusion(y_true, y_pred, class_names=[\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]):\n",
        "    # 4-class confusion matrix\n",
        "    y_true_cls = multilabel_to_multiclass(y_true)\n",
        "    y_pred_cls = multilabel_to_multiclass(y_pred)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true_cls, y_pred_cls, labels=[0,1,2,3])  # 4x4 matrix\n",
        "\n",
        "    # Positive: 1,2,3 / Negative: 0\n",
        "    TP = conf_matrix[1:, 1:].sum()    # 양성 중에 양성으로 예측\n",
        "    FN = conf_matrix[1:, 0].sum()     # 양성인데 음성으로 예측\n",
        "    FP = conf_matrix[0, 1:].sum()     # 음성인데 양성으로 예측\n",
        "    TN = conf_matrix[0, 0]            # 음성인데 양성으로 예측\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0    # 민감도\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0    # 특이도\n",
        "\n",
        "    return conf_matrix, sensitivity, specificity\n",
        "\n",
        "\n",
        "def log_multiclass_confusion_matrix_wandb(conf_matrix, class_names, sensitivity, specificity):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "    ax.set_title('Multi-Class Confusion Matrix')\n",
        "\n",
        "    plt.text(\n",
        "            0.99, 0.16,  # 우하단 (x=99%, y=16%) 위치\n",
        "            f\"Sensitivity: {sensitivity*100:.2f}\\nSpecificity: {specificity*100:.2f}\\nICBHI Score: {100*(sensitivity+specificity)/2:.2f}\",\n",
        "            ha='right', va='bottom',\n",
        "            transform=plt.gca().transAxes,  # 축 기준 좌표로 해석\n",
        "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "        )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    wandb.log({\"multiclass_confusion_matrix\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# 4개 class에 대한 confusion matrix 계산 및 성능 평가\n",
        "class_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "cm_4x4, sens, spec = evaluate_multiclass_confusion(y_true, y_pred, class_names)\n",
        "\n",
        "print(\"4x4 Confusion Matrix:\\n\", cm_4x4)\n",
        "print(f\"Sensitivity: {sens:.4f}\")\n",
        "print(f\"Specificity: {spec:.4f}\")\n",
        "print(f\"ICBHI Score: {(sens+spec)/2:.4f}\")\n",
        "\n",
        "# wandb 로깅\n",
        "log_multiclass_confusion_matrix_wandb(cm_4x4, class_names, sens, spec)\n",
        "\n",
        "wandb.log({\n",
        "    \"Metrics/sensitivity_4class\": sens,\n",
        "    \"Metrics/specificity_4class\": spec,\n",
        "    \"Metrics/ICHBI_score_4class\": (sens+spec)/2\n",
        "})\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8Jg_b9ZLfCmd",
      "metadata": {
        "id": "8Jg_b9ZLfCmd"
      },
      "source": [
        "## 7. t-SNE Visualization (작업중)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "d5ZSB7xzfFsC",
      "metadata": {
        "id": "d5ZSB7xzfFsC"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.manifold import TSNE\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Multi-label → Multi-class 레이블 변환 함수\n",
        "# def multilabel_to_multiclass(labels):\n",
        "#     \"\"\"\n",
        "#     Crackle, Wheeze → 4개의 클래스로 변환\n",
        "#     [0,0] → 0 (Normal)\n",
        "#     [1,0] → 1 (Crackle)\n",
        "#     [0,1] → 2 (Wheeze)\n",
        "#     [1,1] → 3 (Both)\n",
        "#     \"\"\"\n",
        "#     labels = labels.cpu().numpy() if torch.is_tensor(labels) else labels\n",
        "#     return (labels[:, 0] * 1 + labels[:, 1] * 2).astype(int)\n",
        "\n",
        "\n",
        "# # t-SNE를 위한 feature 추출 함수\n",
        "# @torch.no_grad()\n",
        "# def extract_features(encoder, dataloader, device):\n",
        "#     features = []\n",
        "#     labels = []\n",
        "\n",
        "#     for x, label in tqdm(dataloader, desc=\"Extracting features\"):\n",
        "#         x = x.to(device)\n",
        "#         out = encoder(x)\n",
        "#         out = torch.nn.functional.normalize(out, dim=1)  # L2 정규화\n",
        "#         features.append(out.cpu())\n",
        "#         labels.append(label.cpu())\n",
        "\n",
        "#     features = torch.cat(features, dim=0).numpy()\n",
        "#     labels = torch.cat(labels, dim=0)\n",
        "#     return features, labels\n",
        "\n",
        "\n",
        "# # t-SNE 시각화 함수\n",
        "# def plot_tsne(features, labels, num_classes, sensitivity, specificity, title=\"t-SNE Visualization\"):\n",
        "#     labels_cls = multilabel_to_multiclass(labels)\n",
        "\n",
        "#     tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "#     reduced = tsne.fit_transform(features)\n",
        "\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "\n",
        "#     label_names = [\"Normal\", \"Crackle\", \"Wheeze\", \"Both\"]\n",
        "#     for i in range(num_classes):\n",
        "#         idx = labels_cls == i\n",
        "#         plt.scatter(reduced[idx, 0], reduced[idx, 1], label=label_names[i], alpha=0.6)\n",
        "\n",
        "#     plt.text(\n",
        "#         0.95, 0.1,\n",
        "#         f\"Sensitivity: {sensitivity*100:.2f}\\nSpecificity: {specificity*100:.2f}\\nICBHI Score: {(sensitivity + specificity)*50:.2f}\",\n",
        "#         ha='right', va='bottom',\n",
        "#         transform=plt.gca().transAxes,\n",
        "#         fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
        "#     )\n",
        "\n",
        "#     plt.legend()\n",
        "#     plt.title(title)\n",
        "#     plt.xlabel(\"Dim 1\")\n",
        "#     plt.ylabel(\"Dim 2\")\n",
        "#     plt.grid(True)\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# # 전체 파이프라인 실행 예시\n",
        "# encoder = model.base_model.eval().to(device)\n",
        "\n",
        "# # (1) Test 데이터에 대해 Feature 및 Multi-label 정답 추출\n",
        "# features, labels = extract_features(encoder, test_dl, device)\n",
        "\n",
        "# # (2) t-SNE 시각화\n",
        "# plot_tsne(\n",
        "#     features,\n",
        "#     labels,\n",
        "#     num_classes=4,\n",
        "#     sensitivity=sensitivity,  # 앞서 계산된 값 사용\n",
        "#     specificity=specificity,\n",
        "#     title=\"t-SNE Visualization of Test Data\"\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ef6b52e2",
        "9dc03a42",
        "992382bf",
        "nydfgBckyPt3",
        "ce3fdcf1",
        "04291977",
        "5e8c7719",
        "58e1f949",
        "39e684cb",
        "bcca3481",
        "ca710799",
        "e0305c74"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}